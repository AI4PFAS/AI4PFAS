{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPyOpt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from src import models\n",
    "from src import experimental_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = 'dnn_mordred'\n",
    "encoding = 'mordred'\n",
    "\n",
    "kfold = experimental_setup.CrossValidator(\n",
    "    splits = 5,\n",
    "    sampling_type = 'random',\n",
    ")\n",
    "\n",
    "# Define search region\n",
    "\n",
    "bounds = [\n",
    "    {'name': \"learning_rate\", 'type': 'continuous', 'domain': (0.0001,0.01)},\n",
    "    {'name': \"n_layers\",      'type': 'discrete',   'domain': range(1,6)},\n",
    "    {'name': 'layer_size',    'type': 'discrete',   'domain': [32,64,128,256,512,1024,2048,4096]},\n",
    "    {'name': 'batch_size',    'type': 'discrete',   'domain': [32,64,128,256,512,1024,2048,4096]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globally referenced in search; remain calm\n",
    "best = {'score': np.inf, 'history': None}\n",
    "\n",
    "def search(x):\n",
    "    errors = []\n",
    "    \n",
    "    \n",
    "    for fold_no, (train, test) in enumerate(kfold.get_folds(encoding)):\n",
    "        x_train, y_train, smiles_train = train\n",
    "        x_test, y_test, smiles_test = test\n",
    "        \n",
    "        y_train = experimental_setup.scaler.fit_transform(y_train)\n",
    "        y_test = experimental_setup.scaler.transform(y_test)\n",
    "        \n",
    "        model = models.DNN()\n",
    "        \n",
    "        model.learning_rate = float(x[:,0])\n",
    "        model.n_layers = int(x[:,1])\n",
    "        model.layer_size = int(x[:,2])\n",
    "        model.batch_size = int(x[:,3])\n",
    "        model.epochs = 3000\n",
    "        \n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                          monitor='val_loss',\n",
    "                                                          mode='min',\n",
    "                                                          restore_best_weights=True)\n",
    "        \n",
    "        model.fit(x_train.astype(np.float32), y_train,\n",
    "                  callbacks=[early_stopping],\n",
    "                  validation_data=(x_test.astype(np.float32), y_test),\n",
    "                  verbose=1)\n",
    "        \n",
    "        y_hat = experimental_setup.scaler.inverse_transform(model.predict(x_test))\n",
    "        y_test = experimental_setup.scaler.inverse_transform(y_test)\n",
    "        \n",
    "        errors.append( mean_absolute_error(y_test.flatten(), y_hat.flatten()) )\n",
    "    \n",
    "    score = np.mean(errors)\n",
    "    \n",
    "    # save model for final fold if score is best\n",
    "    global best\n",
    "    \n",
    "    if score < best['score']:\n",
    "        best['score'] = score\n",
    "        best['history'] = model.history\n",
    "    \n",
    "    print('Avg. MAE: %f' % score)    \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune\n",
    "To see exploration, <kbd>Ctrl</kbd> + <kbd>F</kbd> for \"Avg. MAE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin processing!\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 5s 454us/sample - loss: 1.0197 - mse: 1.0197 - mae: 0.7331 - val_loss: 1.2728 - val_mse: 1.2728 - val_mae: 0.8968\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4988 - mse: 0.4988 - mae: 0.5295 - val_loss: 1.0341 - val_mse: 1.0341 - val_mae: 0.8045\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4357 - mse: 0.4357 - mae: 0.4928 - val_loss: 1.0004 - val_mse: 1.0004 - val_mae: 0.8064\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4303 - mse: 0.4303 - mae: 0.4906 - val_loss: 0.6896 - val_mse: 0.6896 - val_mae: 0.6688\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 87us/sample - loss: 0.3704 - mse: 0.3704 - mae: 0.4549 - val_loss: 0.6491 - val_mse: 0.6491 - val_mae: 0.6427\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3441 - mse: 0.3441 - mae: 0.4426 - val_loss: 0.5157 - val_mse: 0.5157 - val_mae: 0.5582\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.3132 - mse: 0.3132 - mae: 0.4175 - val_loss: 0.4611 - val_mse: 0.4611 - val_mae: 0.5094\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.2981 - mse: 0.2981 - mae: 0.4060 - val_loss: 0.4540 - val_mse: 0.4540 - val_mae: 0.5094\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2945 - mse: 0.2945 - mae: 0.4083 - val_loss: 0.4408 - val_mse: 0.4408 - val_mae: 0.4842\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.2737 - mse: 0.2737 - mae: 0.3946 - val_loss: 0.4389 - val_mse: 0.4389 - val_mae: 0.4957\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.2580 - mse: 0.2580 - mae: 0.3809 - val_loss: 0.4393 - val_mse: 0.4393 - val_mae: 0.4853\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2450 - mse: 0.2450 - mae: 0.3725 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.4877\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2374 - mse: 0.2374 - mae: 0.3660 - val_loss: 0.4451 - val_mse: 0.4451 - val_mae: 0.4893\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2159 - mse: 0.2159 - mae: 0.3518 - val_loss: 0.4411 - val_mse: 0.4411 - val_mae: 0.4840\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2208 - mse: 0.2208 - mae: 0.3553 - val_loss: 0.4409 - val_mse: 0.4409 - val_mae: 0.4836\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2115 - mse: 0.2115 - mae: 0.3479 - val_loss: 0.4375 - val_mse: 0.4375 - val_mae: 0.4799\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2054 - mse: 0.2054 - mae: 0.3422 - val_loss: 0.4370 - val_mse: 0.4370 - val_mae: 0.4830\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2038 - mse: 0.2038 - mae: 0.3416 - val_loss: 0.4119 - val_mse: 0.4119 - val_mae: 0.4678\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1961 - mse: 0.1961 - mae: 0.3351 - val_loss: 0.4058 - val_mse: 0.4058 - val_mae: 0.4654\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.1752 - mse: 0.1752 - mae: 0.3169 - val_loss: 0.4300 - val_mse: 0.4300 - val_mae: 0.4773\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1811 - mse: 0.1811 - mae: 0.3248 - val_loss: 0.4533 - val_mse: 0.4533 - val_mae: 0.4916\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.1714 - mse: 0.1714 - mae: 0.3119 - val_loss: 0.4377 - val_mse: 0.4377 - val_mae: 0.4845\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1703 - mse: 0.1703 - mae: 0.3118 - val_loss: 0.4297 - val_mse: 0.4297 - val_mae: 0.4760\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1668 - mse: 0.1668 - mae: 0.3072 - val_loss: 0.4339 - val_mse: 0.4339 - val_mae: 0.4867\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.1703 - mse: 0.1703 - mae: 0.3120 - val_loss: 0.4309 - val_mse: 0.4309 - val_mae: 0.4774\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1578 - mse: 0.1578 - mae: 0.2999 - val_loss: 0.4615 - val_mse: 0.4615 - val_mae: 0.4909\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1595 - mse: 0.1595 - mae: 0.3025 - val_loss: 0.4194 - val_mse: 0.4194 - val_mae: 0.4676\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1512 - mse: 0.1512 - mae: 0.2927 - val_loss: 0.4036 - val_mse: 0.4036 - val_mae: 0.4600\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1458 - mse: 0.1458 - mae: 0.2902 - val_loss: 0.4219 - val_mse: 0.4219 - val_mae: 0.4713\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.1500 - mse: 0.1500 - mae: 0.2939 - val_loss: 0.4375 - val_mse: 0.4375 - val_mae: 0.4774\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.1400 - mse: 0.1400 - mae: 0.2832 - val_loss: 0.4195 - val_mse: 0.4195 - val_mae: 0.4687\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 71us/sample - loss: 0.1337 - mse: 0.1337 - mae: 0.2788 - val_loss: 0.4225 - val_mse: 0.4225 - val_mae: 0.4719\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 64us/sample - loss: 0.1317 - mse: 0.1317 - mae: 0.2749 - val_loss: 0.4200 - val_mse: 0.4200 - val_mae: 0.4672\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.1317 - mse: 0.1317 - mae: 0.2751 - val_loss: 0.4144 - val_mse: 0.4144 - val_mae: 0.4664\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1315 - mse: 0.1315 - mae: 0.2732 - val_loss: 0.4095 - val_mse: 0.4095 - val_mae: 0.4614\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 53us/sample - loss: 0.1219 - mse: 0.1219 - mae: 0.2626 - val_loss: 0.4181 - val_mse: 0.4181 - val_mae: 0.4653\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 64us/sample - loss: 0.1213 - mse: 0.1213 - mae: 0.2641 - val_loss: 0.4174 - val_mse: 0.4174 - val_mae: 0.4657\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1283 - mse: 0.1283 - mae: 0.2717 - val_loss: 0.4407 - val_mse: 0.4407 - val_mae: 0.4762\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 4s 392us/sample - loss: 0.9688 - mse: 0.9688 - mae: 0.7185 - val_loss: 1.4721 - val_mse: 1.4721 - val_mae: 0.8913\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.4994 - mse: 0.4994 - mae: 0.5322 - val_loss: 1.1677 - val_mse: 1.1677 - val_mae: 0.7996\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.4210 - mse: 0.4210 - mae: 0.4858 - val_loss: 1.1448 - val_mse: 1.1448 - val_mae: 0.8088\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.3899 - mse: 0.3899 - mae: 0.4693 - val_loss: 0.8348 - val_mse: 0.8348 - val_mae: 0.7323\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.3593 - mse: 0.3593 - mae: 0.4523 - val_loss: 0.7510 - val_mse: 0.7510 - val_mae: 0.6798\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.3456 - mse: 0.3456 - mae: 0.4409 - val_loss: 0.5874 - val_mse: 0.5874 - val_mae: 0.5698\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.3152 - mse: 0.3152 - mae: 0.4229 - val_loss: 0.5390 - val_mse: 0.5390 - val_mae: 0.5425\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.2981 - mse: 0.2981 - mae: 0.4115 - val_loss: 0.5796 - val_mse: 0.5796 - val_mae: 0.5306\n",
      "Epoch 9/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2816 - mse: 0.2816 - mae: 0.4009 - val_loss: 0.5829 - val_mse: 0.5829 - val_mae: 0.5226\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2816 - mse: 0.2816 - mae: 0.3988 - val_loss: 0.4466 - val_mse: 0.4466 - val_mae: 0.4860\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2465 - mse: 0.2465 - mae: 0.3743 - val_loss: 0.4560 - val_mse: 0.4560 - val_mae: 0.4867\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2448 - mse: 0.2448 - mae: 0.3730 - val_loss: 0.4596 - val_mse: 0.4596 - val_mae: 0.4853\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.2386 - mse: 0.2386 - mae: 0.3724 - val_loss: 0.4903 - val_mse: 0.4903 - val_mae: 0.4797\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.2317 - mse: 0.2317 - mae: 0.3638 - val_loss: 0.4909 - val_mse: 0.4909 - val_mae: 0.4842\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2213 - mse: 0.2213 - mae: 0.3542 - val_loss: 0.5292 - val_mse: 0.5292 - val_mae: 0.4878\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2207 - mse: 0.2207 - mae: 0.3548 - val_loss: 0.4498 - val_mse: 0.4498 - val_mae: 0.4712\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2119 - mse: 0.2119 - mae: 0.3489 - val_loss: 0.4267 - val_mse: 0.4267 - val_mae: 0.4669\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 53us/sample - loss: 0.2070 - mse: 0.2070 - mae: 0.3421 - val_loss: 0.4425 - val_mse: 0.4425 - val_mae: 0.4731\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1907 - mse: 0.1907 - mae: 0.3289 - val_loss: 0.4538 - val_mse: 0.4538 - val_mae: 0.4708\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.1743 - mse: 0.1743 - mae: 0.3161 - val_loss: 0.4267 - val_mse: 0.4267 - val_mae: 0.4688\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1749 - mse: 0.1749 - mae: 0.3168 - val_loss: 0.4356 - val_mse: 0.4356 - val_mae: 0.4717\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.1831 - mse: 0.1831 - mae: 0.3264 - val_loss: 0.4929 - val_mse: 0.4929 - val_mae: 0.4896\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.1852 - mse: 0.1852 - mae: 0.3248 - val_loss: 0.5238 - val_mse: 0.5238 - val_mae: 0.4813\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1643 - mse: 0.1643 - mae: 0.3075 - val_loss: 0.5095 - val_mse: 0.5095 - val_mae: 0.4841\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.1550 - mse: 0.1550 - mae: 0.3000 - val_loss: 0.4263 - val_mse: 0.4263 - val_mae: 0.4609\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.1541 - mse: 0.1541 - mae: 0.2970 - val_loss: 0.4607 - val_mse: 0.4607 - val_mae: 0.4758\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.1512 - mse: 0.1512 - mae: 0.2946 - val_loss: 0.4471 - val_mse: 0.4471 - val_mae: 0.4673\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 53us/sample - loss: 0.1450 - mse: 0.1450 - mae: 0.2863 - val_loss: 0.4878 - val_mse: 0.4878 - val_mae: 0.4700\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1433 - mse: 0.1433 - mae: 0.2889 - val_loss: 0.4990 - val_mse: 0.4990 - val_mae: 0.4843\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.1461 - mse: 0.1461 - mae: 0.2903 - val_loss: 0.4681 - val_mse: 0.4681 - val_mae: 0.4715\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 53us/sample - loss: 0.1378 - mse: 0.1378 - mae: 0.2817 - val_loss: 0.4530 - val_mse: 0.4530 - val_mae: 0.4664\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 53us/sample - loss: 0.1356 - mse: 0.1356 - mae: 0.2800 - val_loss: 0.4604 - val_mse: 0.4604 - val_mae: 0.4767\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.1363 - mse: 0.1363 - mae: 0.2792 - val_loss: 0.4321 - val_mse: 0.4321 - val_mae: 0.4578\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1356 - mse: 0.1356 - mae: 0.2816 - val_loss: 0.4501 - val_mse: 0.4501 - val_mae: 0.4656\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1277 - mse: 0.1277 - mae: 0.2720 - val_loss: 0.4314 - val_mse: 0.4314 - val_mae: 0.4577\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 5s 425us/sample - loss: 0.9641 - mse: 0.9641 - mae: 0.7220 - val_loss: 1.2038 - val_mse: 1.2038 - val_mae: 0.8604\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.5079 - mse: 0.5079 - mae: 0.5341 - val_loss: 1.1284 - val_mse: 1.1284 - val_mae: 0.8785\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.4418 - mse: 0.4418 - mae: 0.4989 - val_loss: 1.0325 - val_mse: 1.0325 - val_mae: 0.8434\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 72us/sample - loss: 0.4084 - mse: 0.4084 - mae: 0.4783 - val_loss: 0.7776 - val_mse: 0.7776 - val_mae: 0.7153\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.3713 - mse: 0.3713 - mae: 0.4593 - val_loss: 0.6097 - val_mse: 0.6097 - val_mae: 0.6183\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.3360 - mse: 0.3360 - mae: 0.4359 - val_loss: 0.5161 - val_mse: 0.5161 - val_mae: 0.5609\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3212 - mse: 0.3212 - mae: 0.4261 - val_loss: 0.4815 - val_mse: 0.4815 - val_mae: 0.5251\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.3046 - mse: 0.3046 - mae: 0.4120 - val_loss: 0.4778 - val_mse: 0.4778 - val_mae: 0.5161\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2847 - mse: 0.2847 - mae: 0.4016 - val_loss: 0.4807 - val_mse: 0.4807 - val_mae: 0.5291\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2811 - mse: 0.2811 - mae: 0.3987 - val_loss: 0.4503 - val_mse: 0.4503 - val_mae: 0.4799\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.2684 - mse: 0.2684 - mae: 0.3885 - val_loss: 0.4479 - val_mse: 0.4479 - val_mae: 0.5015\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2574 - mse: 0.2574 - mae: 0.3827 - val_loss: 0.4386 - val_mse: 0.4386 - val_mae: 0.4879\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2489 - mse: 0.2489 - mae: 0.3754 - val_loss: 0.4217 - val_mse: 0.4217 - val_mae: 0.4717\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.2272 - mse: 0.2272 - mae: 0.3597 - val_loss: 0.4003 - val_mse: 0.4003 - val_mae: 0.4660\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2130 - mse: 0.2130 - mae: 0.3487 - val_loss: 0.4196 - val_mse: 0.4196 - val_mae: 0.4666\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2160 - mse: 0.2160 - mae: 0.3499 - val_loss: 0.4029 - val_mse: 0.4029 - val_mae: 0.4604\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 53us/sample - loss: 0.2099 - mse: 0.2099 - mae: 0.3439 - val_loss: 0.4091 - val_mse: 0.4091 - val_mae: 0.4684\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2082 - mse: 0.2082 - mae: 0.3452 - val_loss: 0.4285 - val_mse: 0.4285 - val_mae: 0.4832\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1958 - mse: 0.1958 - mae: 0.3330 - val_loss: 0.4136 - val_mse: 0.4136 - val_mae: 0.4643\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.1914 - mse: 0.1914 - mae: 0.3312 - val_loss: 0.4284 - val_mse: 0.4284 - val_mae: 0.4720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.1857 - mse: 0.1857 - mae: 0.3283 - val_loss: 0.4256 - val_mse: 0.4256 - val_mae: 0.4681\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1725 - mse: 0.1725 - mae: 0.3167 - val_loss: 0.4229 - val_mse: 0.4229 - val_mae: 0.4730\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1685 - mse: 0.1685 - mae: 0.3127 - val_loss: 0.4276 - val_mse: 0.4276 - val_mae: 0.4702\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.1620 - mse: 0.1620 - mae: 0.3051 - val_loss: 0.4149 - val_mse: 0.4149 - val_mae: 0.4775\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 4s 363us/sample - loss: 0.9745 - mse: 0.9745 - mae: 0.7236 - val_loss: 1.4502 - val_mse: 1.4502 - val_mae: 0.8821\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 53us/sample - loss: 0.5053 - mse: 0.5053 - mae: 0.5302 - val_loss: 1.3257 - val_mse: 1.3257 - val_mae: 0.8984\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.4420 - mse: 0.4420 - mae: 0.4978 - val_loss: 0.9140 - val_mse: 0.9140 - val_mae: 0.7824\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.3938 - mse: 0.3938 - mae: 0.4693 - val_loss: 0.8585 - val_mse: 0.8585 - val_mae: 0.7584\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.3685 - mse: 0.3685 - mae: 0.4541 - val_loss: 0.7196 - val_mse: 0.7196 - val_mae: 0.6786\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.3483 - mse: 0.3483 - mae: 0.4424 - val_loss: 0.6022 - val_mse: 0.6022 - val_mae: 0.6046\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 47us/sample - loss: 0.3256 - mse: 0.3256 - mae: 0.4280 - val_loss: 0.5031 - val_mse: 0.5031 - val_mae: 0.5409\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.2981 - mse: 0.2981 - mae: 0.4103 - val_loss: 0.4808 - val_mse: 0.4808 - val_mae: 0.5302\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.2863 - mse: 0.2863 - mae: 0.4031 - val_loss: 0.4487 - val_mse: 0.4487 - val_mae: 0.5053\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 53us/sample - loss: 0.2640 - mse: 0.2640 - mae: 0.3881 - val_loss: 0.4792 - val_mse: 0.4792 - val_mae: 0.5258\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2493 - mse: 0.2493 - mae: 0.3768 - val_loss: 0.4315 - val_mse: 0.4315 - val_mae: 0.4803\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2635 - mse: 0.2635 - mae: 0.3838 - val_loss: 0.4388 - val_mse: 0.4388 - val_mae: 0.4861\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2424 - mse: 0.2424 - mae: 0.3727 - val_loss: 0.4337 - val_mse: 0.4337 - val_mae: 0.4810\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.2303 - mse: 0.2303 - mae: 0.3600 - val_loss: 0.4344 - val_mse: 0.4344 - val_mae: 0.4855\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.2161 - mse: 0.2161 - mae: 0.3516 - val_loss: 0.4182 - val_mse: 0.4182 - val_mae: 0.4709\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.2095 - mse: 0.2095 - mae: 0.3428 - val_loss: 0.4240 - val_mse: 0.4240 - val_mae: 0.4702\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.2140 - mse: 0.2140 - mae: 0.3463 - val_loss: 0.4363 - val_mse: 0.4363 - val_mae: 0.4793\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.2025 - mse: 0.2025 - mae: 0.3409 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4817\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 53us/sample - loss: 0.1872 - mse: 0.1872 - mae: 0.3277 - val_loss: 0.4461 - val_mse: 0.4461 - val_mae: 0.4764\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.1787 - mse: 0.1787 - mae: 0.3196 - val_loss: 0.4274 - val_mse: 0.4274 - val_mae: 0.4647\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1778 - mse: 0.1778 - mae: 0.3185 - val_loss: 0.4560 - val_mse: 0.4560 - val_mae: 0.4743\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1747 - mse: 0.1747 - mae: 0.3173 - val_loss: 0.4499 - val_mse: 0.4499 - val_mae: 0.4877\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.1675 - mse: 0.1675 - mae: 0.3092 - val_loss: 0.4239 - val_mse: 0.4239 - val_mae: 0.4686\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.1658 - mse: 0.1658 - mae: 0.3075 - val_loss: 0.4497 - val_mse: 0.4497 - val_mae: 0.4863\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.1658 - mse: 0.1658 - mae: 0.3086 - val_loss: 0.4252 - val_mse: 0.4252 - val_mae: 0.4703\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 4s 418us/sample - loss: 1.0242 - mse: 1.0242 - mae: 0.7317 - val_loss: 1.4283 - val_mse: 1.4283 - val_mae: 0.9461\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.5099 - mse: 0.5099 - mae: 0.5347 - val_loss: 1.0945 - val_mse: 1.0945 - val_mae: 0.8619\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 47us/sample - loss: 0.4286 - mse: 0.4286 - mae: 0.4904 - val_loss: 1.0247 - val_mse: 1.0247 - val_mae: 0.8230\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 52us/sample - loss: 0.3904 - mse: 0.3904 - mae: 0.4671 - val_loss: 0.9266 - val_mse: 0.9266 - val_mae: 0.7852\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 1s 53us/sample - loss: 0.3664 - mse: 0.3664 - mae: 0.4561 - val_loss: 0.6611 - val_mse: 0.6611 - val_mae: 0.6283\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.3377 - mse: 0.3377 - mae: 0.4359 - val_loss: 0.5776 - val_mse: 0.5776 - val_mae: 0.5783\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.3195 - mse: 0.3195 - mae: 0.4239 - val_loss: 0.5500 - val_mse: 0.5500 - val_mae: 0.5620\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.2997 - mse: 0.2997 - mae: 0.4124 - val_loss: 0.4660 - val_mse: 0.4660 - val_mae: 0.5175\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.2868 - mse: 0.2868 - mae: 0.4048 - val_loss: 0.4517 - val_mse: 0.4517 - val_mae: 0.5082\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 52us/sample - loss: 0.2698 - mse: 0.2698 - mae: 0.3928 - val_loss: 0.4400 - val_mse: 0.4400 - val_mae: 0.4945\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2650 - mse: 0.2650 - mae: 0.3899 - val_loss: 0.4793 - val_mse: 0.4793 - val_mae: 0.4820\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.2443 - mse: 0.2443 - mae: 0.3725 - val_loss: 0.4164 - val_mse: 0.4164 - val_mae: 0.4666\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.2443 - mse: 0.2443 - mae: 0.3727 - val_loss: 0.4450 - val_mse: 0.4450 - val_mae: 0.4724\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.2385 - mse: 0.2385 - mae: 0.3695 - val_loss: 0.4211 - val_mse: 0.4211 - val_mae: 0.4634\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 1s 53us/sample - loss: 0.2254 - mse: 0.2254 - mae: 0.3575 - val_loss: 0.4236 - val_mse: 0.4236 - val_mae: 0.4657\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 1s 51us/sample - loss: 0.2131 - mse: 0.2131 - mae: 0.3481 - val_loss: 0.4324 - val_mse: 0.4324 - val_mae: 0.4582\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 43us/sample - loss: 0.2024 - mse: 0.2024 - mae: 0.3415 - val_loss: 0.4567 - val_mse: 0.4567 - val_mae: 0.4742\n",
      "Epoch 18/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.1969 - mse: 0.1969 - mae: 0.3378 - val_loss: 0.4424 - val_mse: 0.4424 - val_mae: 0.4780\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 1s 53us/sample - loss: 0.1894 - mse: 0.1894 - mae: 0.3305 - val_loss: 0.4130 - val_mse: 0.4130 - val_mae: 0.4529\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.1756 - mse: 0.1756 - mae: 0.3184 - val_loss: 0.4262 - val_mse: 0.4262 - val_mae: 0.4645\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 1s 53us/sample - loss: 0.1741 - mse: 0.1741 - mae: 0.3164 - val_loss: 0.4165 - val_mse: 0.4165 - val_mae: 0.4582\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.1762 - mse: 0.1762 - mae: 0.3191 - val_loss: 0.4153 - val_mse: 0.4153 - val_mae: 0.4684\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.1662 - mse: 0.1662 - mae: 0.3085 - val_loss: 0.4381 - val_mse: 0.4381 - val_mae: 0.4764\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 1s 53us/sample - loss: 0.1645 - mse: 0.1645 - mae: 0.3071 - val_loss: 0.4222 - val_mse: 0.4222 - val_mae: 0.4774\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.1577 - mse: 0.1577 - mae: 0.2996 - val_loss: 0.4195 - val_mse: 0.4195 - val_mae: 0.4523\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 1s 52us/sample - loss: 0.1489 - mse: 0.1489 - mae: 0.2933 - val_loss: 0.3974 - val_mse: 0.3974 - val_mae: 0.4477\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 1s 53us/sample - loss: 0.1463 - mse: 0.1463 - mae: 0.2901 - val_loss: 0.4168 - val_mse: 0.4168 - val_mae: 0.4633\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.1490 - mse: 0.1490 - mae: 0.2942 - val_loss: 0.4195 - val_mse: 0.4195 - val_mae: 0.4621\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 1s 51us/sample - loss: 0.1438 - mse: 0.1438 - mae: 0.2876 - val_loss: 0.4052 - val_mse: 0.4052 - val_mae: 0.4536\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1368 - mse: 0.1368 - mae: 0.2820 - val_loss: 0.4046 - val_mse: 0.4046 - val_mae: 0.4518\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.1353 - mse: 0.1353 - mae: 0.2774 - val_loss: 0.4013 - val_mse: 0.4013 - val_mae: 0.4522\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 1s 51us/sample - loss: 0.1379 - mse: 0.1379 - mae: 0.2836 - val_loss: 0.4160 - val_mse: 0.4160 - val_mae: 0.4596\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1346 - mse: 0.1346 - mae: 0.2805 - val_loss: 0.4276 - val_mse: 0.4276 - val_mae: 0.4743\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 47us/sample - loss: 0.1342 - mse: 0.1342 - mae: 0.2778 - val_loss: 0.4228 - val_mse: 0.4228 - val_mae: 0.4655\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 1s 52us/sample - loss: 0.1359 - mse: 0.1359 - mae: 0.2806 - val_loss: 0.4115 - val_mse: 0.4115 - val_mae: 0.4517\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 1s 52us/sample - loss: 0.1216 - mse: 0.1216 - mae: 0.2649 - val_loss: 0.4104 - val_mse: 0.4104 - val_mae: 0.4536\n",
      "Avg. MAE: 0.406453\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 91s 9ms/sample - loss: 1800.2029 - mse: 1800.2030 - mae: 22.3985 - val_loss: 7590048768.0000 - val_mse: 7590048768.0000 - val_mae: 77549.6016\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 84s 8ms/sample - loss: 133.6044 - mse: 133.6044 - mae: 6.8845 - val_loss: 468400480.0000 - val_mse: 468400480.0000 - val_mae: 19555.9512\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 82s 8ms/sample - loss: 193.1521 - mse: 193.1521 - mae: 8.1830 - val_loss: 21025392.0000 - val_mse: 21025392.0000 - val_mae: 4295.0459\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 84s 8ms/sample - loss: 35.4742 - mse: 35.4742 - mae: 3.6026 - val_loss: 27919460.0000 - val_mse: 27919460.0000 - val_mae: 3959.5127\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 87s 8ms/sample - loss: 53.5514 - mse: 53.5514 - mae: 3.5427 - val_loss: 12745608.0000 - val_mse: 12745608.0000 - val_mae: 2733.5908\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 84s 8ms/sample - loss: 26.7062 - mse: 26.7062 - mae: 2.6574 - val_loss: 904163.9375 - val_mse: 904163.9375 - val_mae: 718.6346\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 83s 8ms/sample - loss: 27.8225 - mse: 27.8225 - mae: 3.6262 - val_loss: 88307.7109 - val_mse: 88307.7109 - val_mae: 231.0800\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 84s 8ms/sample - loss: 13.2693 - mse: 13.2693 - mae: 2.2244 - val_loss: 361124.0938 - val_mse: 361124.0938 - val_mae: 456.8441\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 83s 8ms/sample - loss: 11.3574 - mse: 11.3574 - mae: 2.3531 - val_loss: 366507.1562 - val_mse: 366507.1562 - val_mae: 455.7358\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 84s 8ms/sample - loss: 13.2519 - mse: 13.2519 - mae: 2.1892 - val_loss: 76149.8828 - val_mse: 76149.8828 - val_mae: 211.6514\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 85s 8ms/sample - loss: 4.6867 - mse: 4.6867 - mae: 1.5204 - val_loss: 11742.8535 - val_mse: 11742.8535 - val_mae: 87.7052\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 83s 8ms/sample - loss: 8.1379 - mse: 8.1379 - mae: 1.8067 - val_loss: 23008.4824 - val_mse: 23008.4824 - val_mae: 116.5701\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 84s 8ms/sample - loss: 2.5436 - mse: 2.5436 - mae: 1.2273 - val_loss: 36723.7617 - val_mse: 36723.7617 - val_mae: 141.5480\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 63s 6ms/sample - loss: 6.6135 - mse: 6.6135 - mae: 1.4953 - val_loss: 15023.3086 - val_mse: 15023.3086 - val_mae: 92.2779\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.6571 - mse: 1.6571 - mae: 0.9586 - val_loss: 3220.9741 - val_mse: 3220.9741 - val_mae: 46.1705\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 4.0586 - mse: 4.0586 - mae: 1.3026 - val_loss: 3198.8767 - val_mse: 3198.8767 - val_mae: 45.4049\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.5552 - mse: 1.5552 - mae: 0.9393 - val_loss: 5888.5566 - val_mse: 5888.5566 - val_mae: 57.8171\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 3.7481 - mse: 3.7481 - mae: 1.0917 - val_loss: 3064.5681 - val_mse: 3064.5681 - val_mae: 43.2493\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.8106 - mse: 1.8106 - mae: 0.8840 - val_loss: 841.3322 - val_mse: 841.3322 - val_mae: 25.3976\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 2.5656 - mse: 2.5656 - mae: 0.9948 - val_loss: 1133.0284 - val_mse: 1133.0284 - val_mae: 27.8154\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.7874 - mse: 1.7874 - mae: 0.8573 - val_loss: 1391.7159 - val_mse: 1391.7159 - val_mae: 29.4271\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.6535 - mse: 1.6535 - mae: 0.8135 - val_loss: 672.5432 - val_mse: 672.5432 - val_mae: 21.9319\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.3821 - mse: 1.3821 - mae: 0.8287 - val_loss: 587.5247 - val_mse: 587.5247 - val_mae: 20.3787\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0881 - mse: 1.0881 - mae: 0.7641 - val_loss: 499.3934 - val_mse: 499.3934 - val_mae: 18.7145\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.3721 - mse: 1.3721 - mae: 0.7965 - val_loss: 402.6510 - val_mse: 402.6510 - val_mae: 16.8370\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.3136 - mse: 1.3136 - mae: 0.7902 - val_loss: 230.4960 - val_mse: 230.4960 - val_mae: 13.5602\n",
      "Epoch 27/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.2713 - mse: 1.2713 - mae: 0.7984 - val_loss: 303.2392 - val_mse: 303.2392 - val_mae: 14.6382\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.4184 - mse: 1.4184 - mae: 0.7771 - val_loss: 250.5364 - val_mse: 250.5364 - val_mae: 13.4968\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.1615 - mse: 1.1615 - mae: 0.7667 - val_loss: 130.3181 - val_mse: 130.3181 - val_mae: 10.5232\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.5495 - mse: 1.5495 - mae: 0.8202 - val_loss: 180.7640 - val_mse: 180.7640 - val_mae: 11.6093\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.1004 - mse: 1.1004 - mae: 0.7505 - val_loss: 129.7849 - val_mse: 129.7849 - val_mae: 10.0527\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.0378 - mse: 1.0378 - mae: 0.7305 - val_loss: 112.1874 - val_mse: 112.1874 - val_mae: 9.4446\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8913 - mse: 0.8913 - mae: 0.7039 - val_loss: 103.5396 - val_mse: 103.5396 - val_mae: 8.9636\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0382 - mse: 1.0382 - mae: 0.7294 - val_loss: 91.3425 - val_mse: 91.3425 - val_mae: 8.4793\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8963 - mse: 0.8963 - mae: 0.6960 - val_loss: 76.6257 - val_mse: 76.6257 - val_mae: 7.8413\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.1631 - mse: 1.1631 - mae: 0.7660 - val_loss: 69.1562 - val_mse: 69.1562 - val_mae: 7.4835\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.1330 - mse: 1.1330 - mae: 0.7282 - val_loss: 67.9553 - val_mse: 67.9553 - val_mae: 7.2452\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9865 - mse: 0.9865 - mae: 0.7095 - val_loss: 43.0745 - val_mse: 43.0745 - val_mae: 6.1246\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9876 - mse: 0.9876 - mae: 0.7091 - val_loss: 48.9768 - val_mse: 48.9768 - val_mae: 6.3155\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8519 - mse: 0.8519 - mae: 0.6863 - val_loss: 45.7955 - val_mse: 45.7955 - val_mae: 6.0595\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.0115 - mse: 1.0115 - mae: 0.7084 - val_loss: 40.2539 - val_mse: 40.2539 - val_mae: 5.7150\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9968 - mse: 0.9968 - mae: 0.7138 - val_loss: 31.4086 - val_mse: 31.4086 - val_mae: 5.1980\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8116 - mse: 0.8116 - mae: 0.6766 - val_loss: 36.6884 - val_mse: 36.6884 - val_mae: 5.3666\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0009 - mse: 1.0009 - mae: 0.7003 - val_loss: 29.2838 - val_mse: 29.2838 - val_mae: 4.9213\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.2957 - mse: 1.2957 - mae: 0.7798 - val_loss: 24.5473 - val_mse: 24.5473 - val_mae: 4.5237\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8419 - mse: 0.8419 - mae: 0.6764 - val_loss: 33.6322 - val_mse: 33.6322 - val_mae: 4.9456\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.1141 - mse: 1.1141 - mae: 0.7122 - val_loss: 19.8985 - val_mse: 19.8985 - val_mae: 4.0975\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.3495 - mse: 1.3495 - mae: 0.7759 - val_loss: 19.1831 - val_mse: 19.1831 - val_mae: 4.0351\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8791 - mse: 0.8791 - mae: 0.6835 - val_loss: 27.4162 - val_mse: 27.4162 - val_mae: 4.3279\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.3731 - mse: 1.3731 - mae: 0.7317 - val_loss: 15.2376 - val_mse: 15.2376 - val_mae: 3.5610\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8738 - mse: 0.8738 - mae: 0.6790 - val_loss: 15.2951 - val_mse: 15.2951 - val_mae: 3.5885\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8025 - mse: 0.8025 - mae: 0.6699 - val_loss: 15.2221 - val_mse: 15.2221 - val_mae: 3.4998\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8809 - mse: 0.8809 - mae: 0.6727 - val_loss: 14.2839 - val_mse: 14.2839 - val_mae: 3.3992\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9245 - mse: 0.9245 - mae: 0.6907 - val_loss: 11.6545 - val_mse: 11.6545 - val_mae: 3.1089\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8287 - mse: 0.8287 - mae: 0.6715 - val_loss: 13.5824 - val_mse: 13.5824 - val_mae: 3.2445\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8921 - mse: 0.8921 - mae: 0.6829 - val_loss: 10.4696 - val_mse: 10.4696 - val_mae: 2.9439\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.1523 - mse: 1.1523 - mae: 0.7444 - val_loss: 9.7730 - val_mse: 9.7730 - val_mae: 2.8070\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8096 - mse: 0.8096 - mae: 0.6578 - val_loss: 11.4001 - val_mse: 11.4001 - val_mae: 2.9332\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8968 - mse: 0.8968 - mae: 0.6833 - val_loss: 7.7446 - val_mse: 7.7446 - val_mae: 2.5350\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9901 - mse: 0.9901 - mae: 0.6969 - val_loss: 9.2853 - val_mse: 9.2853 - val_mae: 2.6933\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8574 - mse: 0.8574 - mae: 0.6717 - val_loss: 7.6850 - val_mse: 7.6850 - val_mae: 2.4955\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7369 - mse: 0.7369 - mae: 0.6472 - val_loss: 6.7826 - val_mse: 6.7826 - val_mae: 2.3473\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7621 - mse: 0.7621 - mae: 0.6464 - val_loss: 6.7678 - val_mse: 6.7678 - val_mae: 2.3398\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7319 - mse: 0.7319 - mae: 0.6420 - val_loss: 5.6411 - val_mse: 5.6411 - val_mae: 2.1103\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8184 - mse: 0.8184 - mae: 0.6613 - val_loss: 6.2718 - val_mse: 6.2718 - val_mae: 2.2291\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7823 - mse: 0.7823 - mae: 0.6496 - val_loss: 5.3039 - val_mse: 5.3039 - val_mae: 2.0466\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7203 - mse: 0.7203 - mae: 0.6353 - val_loss: 4.8041 - val_mse: 4.8041 - val_mae: 1.9735\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8634 - mse: 0.8634 - mae: 0.6662 - val_loss: 5.4872 - val_mse: 5.4872 - val_mae: 2.0232\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7955 - mse: 0.7955 - mae: 0.6488 - val_loss: 4.2120 - val_mse: 4.2120 - val_mae: 1.8352\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7774 - mse: 0.7774 - mae: 0.6509 - val_loss: 4.3917 - val_mse: 4.3917 - val_mae: 1.8674\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7440 - mse: 0.7440 - mae: 0.6402 - val_loss: 3.8380 - val_mse: 3.8380 - val_mae: 1.7224\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7194 - mse: 0.7194 - mae: 0.6319 - val_loss: 3.7367 - val_mse: 3.7367 - val_mae: 1.7224\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7893 - mse: 0.7893 - mae: 0.6418 - val_loss: 3.8767 - val_mse: 3.8767 - val_mae: 1.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7739 - mse: 0.7739 - mae: 0.6483 - val_loss: 3.0896 - val_mse: 3.0896 - val_mae: 1.5688\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7280 - mse: 0.7280 - mae: 0.6333 - val_loss: 3.4209 - val_mse: 3.4209 - val_mae: 1.5939\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7814 - mse: 0.7814 - mae: 0.6450 - val_loss: 2.7456 - val_mse: 2.7456 - val_mae: 1.4621\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6913 - mse: 0.6913 - mae: 0.6170 - val_loss: 3.0457 - val_mse: 3.0457 - val_mae: 1.5267\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7691 - mse: 0.7691 - mae: 0.6402 - val_loss: 2.5366 - val_mse: 2.5366 - val_mae: 1.4076\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7717 - mse: 0.7717 - mae: 0.6467 - val_loss: 2.2357 - val_mse: 2.2357 - val_mae: 1.3157\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6833 - mse: 0.6833 - mae: 0.6133 - val_loss: 2.9444 - val_mse: 2.9444 - val_mae: 1.4385\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7931 - mse: 0.7931 - mae: 0.6346 - val_loss: 2.1692 - val_mse: 2.1692 - val_mae: 1.2980\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7490 - mse: 0.7490 - mae: 0.6341 - val_loss: 2.2245 - val_mse: 2.2245 - val_mae: 1.2954\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7041 - mse: 0.7041 - mae: 0.6220 - val_loss: 2.1882 - val_mse: 2.1882 - val_mae: 1.2913\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6974 - mse: 0.6974 - mae: 0.6236 - val_loss: 1.8373 - val_mse: 1.8373 - val_mae: 1.1627\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6898 - mse: 0.6898 - mae: 0.6124 - val_loss: 1.9005 - val_mse: 1.9005 - val_mae: 1.1981\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6640 - mse: 0.6640 - mae: 0.6043 - val_loss: 1.7367 - val_mse: 1.7367 - val_mae: 1.1529\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6690 - mse: 0.6690 - mae: 0.6097 - val_loss: 1.5556 - val_mse: 1.5556 - val_mae: 1.0807\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7277 - mse: 0.7277 - mae: 0.6195 - val_loss: 1.4950 - val_mse: 1.4950 - val_mae: 1.0435\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7074 - mse: 0.7074 - mae: 0.6140 - val_loss: 1.7010 - val_mse: 1.7010 - val_mae: 1.1409\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6714 - mse: 0.6714 - mae: 0.6146 - val_loss: 1.5802 - val_mse: 1.5802 - val_mae: 1.0437\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7051 - mse: 0.7051 - mae: 0.6241 - val_loss: 1.3033 - val_mse: 1.3033 - val_mae: 0.9770\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6572 - mse: 0.6572 - mae: 0.5937 - val_loss: 1.7109 - val_mse: 1.7109 - val_mae: 1.1003\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7277 - mse: 0.7277 - mae: 0.6200 - val_loss: 1.2226 - val_mse: 1.2226 - val_mae: 0.9410\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6939 - mse: 0.6939 - mae: 0.6158 - val_loss: 1.2344 - val_mse: 1.2344 - val_mae: 0.9356\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6819 - mse: 0.6819 - mae: 0.5967 - val_loss: 1.4434 - val_mse: 1.4434 - val_mae: 1.0206\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6350 - mse: 0.6350 - mae: 0.6024 - val_loss: 0.9979 - val_mse: 0.9979 - val_mae: 0.8362\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6944 - mse: 0.6944 - mae: 0.6105 - val_loss: 1.2632 - val_mse: 1.2632 - val_mae: 0.9252\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6609 - mse: 0.6609 - mae: 0.5933 - val_loss: 1.1299 - val_mse: 1.1299 - val_mae: 0.9044\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6701 - mse: 0.6701 - mae: 0.6077 - val_loss: 0.9929 - val_mse: 0.9929 - val_mae: 0.8131\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6580 - mse: 0.6580 - mae: 0.5922 - val_loss: 1.0315 - val_mse: 1.0315 - val_mae: 0.8532\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6262 - mse: 0.6262 - mae: 0.5821 - val_loss: 1.0600 - val_mse: 1.0600 - val_mae: 0.8654\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6055 - mse: 0.6055 - mae: 0.5831 - val_loss: 0.9087 - val_mse: 0.9087 - val_mae: 0.7861\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6067 - mse: 0.6067 - mae: 0.5765 - val_loss: 0.9929 - val_mse: 0.9929 - val_mae: 0.8281\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6137 - mse: 0.6137 - mae: 0.5783 - val_loss: 0.9147 - val_mse: 0.9147 - val_mae: 0.7899\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6045 - mse: 0.6045 - mae: 0.5833 - val_loss: 0.8450 - val_mse: 0.8450 - val_mae: 0.7475\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6005 - mse: 0.6005 - mae: 0.5714 - val_loss: 1.0020 - val_mse: 1.0020 - val_mae: 0.8331\n",
      "Epoch 107/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6040 - mse: 0.6040 - mae: 0.5805 - val_loss: 0.8568 - val_mse: 0.8568 - val_mae: 0.7465\n",
      "Epoch 108/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5888 - mse: 0.5888 - mae: 0.5717 - val_loss: 0.8345 - val_mse: 0.8345 - val_mae: 0.7471\n",
      "Epoch 109/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6207 - mse: 0.6207 - mae: 0.5751 - val_loss: 0.8391 - val_mse: 0.8391 - val_mae: 0.7295\n",
      "Epoch 110/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6031 - mse: 0.6031 - mae: 0.5740 - val_loss: 0.8299 - val_mse: 0.8299 - val_mae: 0.7397\n",
      "Epoch 111/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6469 - mse: 0.6469 - mae: 0.5973 - val_loss: 0.8119 - val_mse: 0.8119 - val_mae: 0.6952\n",
      "Epoch 112/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6193 - mse: 0.6193 - mae: 0.5735 - val_loss: 0.8511 - val_mse: 0.8511 - val_mae: 0.7584\n",
      "Epoch 113/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5999 - mse: 0.5999 - mae: 0.5694 - val_loss: 0.7380 - val_mse: 0.7380 - val_mae: 0.6777\n",
      "Epoch 114/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5995 - mse: 0.5995 - mae: 0.5695 - val_loss: 0.7333 - val_mse: 0.7333 - val_mae: 0.6780\n",
      "Epoch 115/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6077 - mse: 0.6077 - mae: 0.5737 - val_loss: 0.7172 - val_mse: 0.7172 - val_mae: 0.6712\n",
      "Epoch 116/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5656 - mse: 0.5656 - mae: 0.5612 - val_loss: 0.7725 - val_mse: 0.7725 - val_mae: 0.6760\n",
      "Epoch 117/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5644 - mse: 0.5644 - mae: 0.5582 - val_loss: 0.7991 - val_mse: 0.7991 - val_mae: 0.7236\n",
      "Epoch 118/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6113 - mse: 0.6113 - mae: 0.5725 - val_loss: 0.7485 - val_mse: 0.7485 - val_mae: 0.6693\n",
      "Epoch 119/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5786 - mse: 0.5786 - mae: 0.5615 - val_loss: 0.6745 - val_mse: 0.6745 - val_mae: 0.6447\n",
      "Epoch 120/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5726 - mse: 0.5726 - mae: 0.5600 - val_loss: 0.7127 - val_mse: 0.7127 - val_mae: 0.6656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5499 - mse: 0.5499 - mae: 0.5509 - val_loss: 0.6995 - val_mse: 0.6995 - val_mae: 0.6651\n",
      "Epoch 122/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5689 - mse: 0.5689 - mae: 0.5580 - val_loss: 0.6714 - val_mse: 0.6714 - val_mae: 0.6388\n",
      "Epoch 123/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5522 - mse: 0.5522 - mae: 0.5539 - val_loss: 0.7041 - val_mse: 0.7041 - val_mae: 0.6700\n",
      "Epoch 124/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5467 - mse: 0.5467 - mae: 0.5470 - val_loss: 0.6786 - val_mse: 0.6786 - val_mae: 0.6451\n",
      "Epoch 125/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5371 - mse: 0.5371 - mae: 0.5390 - val_loss: 0.6606 - val_mse: 0.6606 - val_mae: 0.6330\n",
      "Epoch 126/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5209 - mse: 0.5209 - mae: 0.5368 - val_loss: 0.6611 - val_mse: 0.6611 - val_mae: 0.6292\n",
      "Epoch 127/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5143 - mse: 0.5143 - mae: 0.5339 - val_loss: 0.6255 - val_mse: 0.6255 - val_mae: 0.6085\n",
      "Epoch 128/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5079 - mse: 0.5079 - mae: 0.5272 - val_loss: 0.6764 - val_mse: 0.6764 - val_mae: 0.6503\n",
      "Epoch 129/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5069 - mse: 0.5069 - mae: 0.5271 - val_loss: 0.6356 - val_mse: 0.6356 - val_mae: 0.6187\n",
      "Epoch 130/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5108 - mse: 0.5108 - mae: 0.5327 - val_loss: 0.6634 - val_mse: 0.6634 - val_mae: 0.6362\n",
      "Epoch 131/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5004 - mse: 0.5004 - mae: 0.5271 - val_loss: 0.6158 - val_mse: 0.6158 - val_mae: 0.5978\n",
      "Epoch 132/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5145 - mse: 0.5145 - mae: 0.5261 - val_loss: 0.6813 - val_mse: 0.6813 - val_mae: 0.6537\n",
      "Epoch 133/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5219 - mse: 0.5219 - mae: 0.5283 - val_loss: 0.5923 - val_mse: 0.5923 - val_mae: 0.5817\n",
      "Epoch 134/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5502 - mse: 0.5502 - mae: 0.5353 - val_loss: 0.6670 - val_mse: 0.6670 - val_mae: 0.6386\n",
      "Epoch 135/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5630 - mse: 0.5630 - mae: 0.5308 - val_loss: 0.6000 - val_mse: 0.6000 - val_mae: 0.5926\n",
      "Epoch 136/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5991 - mse: 0.5991 - mae: 0.5371 - val_loss: 0.6389 - val_mse: 0.6389 - val_mae: 0.6168\n",
      "Epoch 137/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5718 - mse: 0.5718 - mae: 0.5405 - val_loss: 0.6232 - val_mse: 0.6232 - val_mae: 0.5917\n",
      "Epoch 138/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5558 - mse: 0.5558 - mae: 0.5317 - val_loss: 0.6439 - val_mse: 0.6439 - val_mae: 0.6100\n",
      "Epoch 139/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5561 - mse: 0.5561 - mae: 0.5273 - val_loss: 0.6433 - val_mse: 0.6433 - val_mae: 0.6069\n",
      "Epoch 140/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5566 - mse: 0.5566 - mae: 0.5299 - val_loss: 0.5730 - val_mse: 0.5730 - val_mae: 0.5674\n",
      "Epoch 141/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5225 - mse: 0.5225 - mae: 0.5287 - val_loss: 0.5983 - val_mse: 0.5983 - val_mae: 0.5723\n",
      "Epoch 142/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5411 - mse: 0.5411 - mae: 0.5218 - val_loss: 0.5872 - val_mse: 0.5872 - val_mae: 0.5821\n",
      "Epoch 143/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4798 - mse: 0.4798 - mae: 0.5034 - val_loss: 0.5795 - val_mse: 0.5795 - val_mae: 0.5815\n",
      "Epoch 144/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4906 - mse: 0.4906 - mae: 0.5116 - val_loss: 0.5584 - val_mse: 0.5584 - val_mae: 0.5642\n",
      "Epoch 145/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4580 - mse: 0.4580 - mae: 0.5023 - val_loss: 0.5714 - val_mse: 0.5714 - val_mae: 0.5786\n",
      "Epoch 146/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.4418 - mse: 0.4418 - mae: 0.4898 - val_loss: 0.6293 - val_mse: 0.6293 - val_mae: 0.6191\n",
      "Epoch 147/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.4583 - mse: 0.4583 - mae: 0.5043 - val_loss: 0.5527 - val_mse: 0.5527 - val_mae: 0.5459\n",
      "Epoch 148/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4410 - mse: 0.4410 - mae: 0.4871 - val_loss: 0.5783 - val_mse: 0.5783 - val_mae: 0.5820\n",
      "Epoch 149/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.4288 - mse: 0.4288 - mae: 0.4798 - val_loss: 0.6173 - val_mse: 0.6173 - val_mae: 0.6203\n",
      "Epoch 150/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4372 - mse: 0.4372 - mae: 0.4963 - val_loss: 0.5640 - val_mse: 0.5640 - val_mae: 0.5517\n",
      "Epoch 151/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4364 - mse: 0.4364 - mae: 0.4936 - val_loss: 0.5755 - val_mse: 0.5755 - val_mae: 0.5714\n",
      "Epoch 152/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4277 - mse: 0.4277 - mae: 0.4793 - val_loss: 0.5949 - val_mse: 0.5949 - val_mae: 0.6028\n",
      "Epoch 153/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.4244 - mse: 0.4244 - mae: 0.4845 - val_loss: 0.5352 - val_mse: 0.5352 - val_mae: 0.5390\n",
      "Epoch 154/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4206 - mse: 0.4206 - mae: 0.4742 - val_loss: 0.6065 - val_mse: 0.6065 - val_mae: 0.5918\n",
      "Epoch 155/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4057 - mse: 0.4057 - mae: 0.4637 - val_loss: 0.5645 - val_mse: 0.5645 - val_mae: 0.5637\n",
      "Epoch 156/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.3980 - mse: 0.3980 - mae: 0.4686 - val_loss: 0.5281 - val_mse: 0.5281 - val_mae: 0.5429\n",
      "Epoch 157/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.3928 - mse: 0.3928 - mae: 0.4645 - val_loss: 0.5153 - val_mse: 0.5153 - val_mae: 0.5370\n",
      "Epoch 158/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.3800 - mse: 0.3800 - mae: 0.4567 - val_loss: 0.5323 - val_mse: 0.5323 - val_mae: 0.5469\n",
      "Epoch 159/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3688 - mse: 0.3688 - mae: 0.4472 - val_loss: 0.5253 - val_mse: 0.5253 - val_mae: 0.5421\n",
      "Epoch 160/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3712 - mse: 0.3712 - mae: 0.4537 - val_loss: 0.5214 - val_mse: 0.5214 - val_mae: 0.5379\n",
      "Epoch 161/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3707 - mse: 0.3707 - mae: 0.4521 - val_loss: 0.5174 - val_mse: 0.5174 - val_mae: 0.5369\n",
      "Epoch 162/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.3879 - mse: 0.3879 - mae: 0.4621 - val_loss: 0.5517 - val_mse: 0.5517 - val_mae: 0.5660\n",
      "Epoch 163/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3831 - mse: 0.3831 - mae: 0.4621 - val_loss: 0.6085 - val_mse: 0.6085 - val_mae: 0.5791\n",
      "Epoch 164/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3768 - mse: 0.3768 - mae: 0.4577 - val_loss: 0.5749 - val_mse: 0.5749 - val_mae: 0.5654\n",
      "Epoch 165/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3690 - mse: 0.3690 - mae: 0.4452 - val_loss: 0.5404 - val_mse: 0.5404 - val_mae: 0.5507\n",
      "Epoch 166/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3775 - mse: 0.3775 - mae: 0.4572 - val_loss: 0.5850 - val_mse: 0.5850 - val_mae: 0.5711\n",
      "Epoch 167/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4112 - mse: 0.4112 - mae: 0.4781 - val_loss: 0.5285 - val_mse: 0.5285 - val_mae: 0.5413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 47s 4ms/sample - loss: 1827.5098 - mse: 1827.5099 - mae: 22.9592 - val_loss: 6201091072.0000 - val_mse: 6201091072.0000 - val_mae: 60945.9609\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 125.5171 - mse: 125.5171 - mae: 7.2493 - val_loss: 290137568.0000 - val_mse: 290137568.0000 - val_mae: 13393.3936\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 165.9626 - mse: 165.9626 - mae: 9.2659 - val_loss: 10733779.0000 - val_mse: 10733779.0000 - val_mae: 2842.8032\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 28.4249 - mse: 28.4249 - mae: 4.0175 - val_loss: 18636576.0000 - val_mse: 18636576.0000 - val_mae: 2527.4568\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 41.7715 - mse: 41.7715 - mae: 4.2811 - val_loss: 4882698.0000 - val_mse: 4882698.0000 - val_mae: 1327.6531\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 9.3130 - mse: 9.3130 - mae: 2.1853 - val_loss: 74963.0547 - val_mse: 74963.0547 - val_mae: 184.9397\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 23.4257 - mse: 23.4257 - mae: 3.7055 - val_loss: 52513.2344 - val_mse: 52513.2344 - val_mae: 153.1302\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 7.3885 - mse: 7.3885 - mae: 2.0323 - val_loss: 381037.4375 - val_mse: 381037.4375 - val_mae: 378.4620\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 9.9799 - mse: 9.9799 - mae: 2.1266 - val_loss: 181469.2812 - val_mse: 181469.2812 - val_mae: 263.4184\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 5.4762 - mse: 5.4762 - mae: 1.7105 - val_loss: 5417.2256 - val_mse: 5417.2256 - val_mae: 56.5801\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 5.7367 - mse: 5.7367 - mae: 1.6084 - val_loss: 1396.4385 - val_mse: 1396.4385 - val_mae: 32.3785\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 3.0606 - mse: 3.0606 - mae: 1.1884 - val_loss: 20442.6504 - val_mse: 20442.6504 - val_mae: 92.9771\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 3.2438 - mse: 3.2438 - mae: 1.1317 - val_loss: 18536.1777 - val_mse: 18536.1777 - val_mae: 86.8048\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 2.1195 - mse: 2.1195 - mae: 1.0156 - val_loss: 2211.3438 - val_mse: 2211.3438 - val_mae: 35.5846\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 2.3191 - mse: 2.3191 - mae: 1.1071 - val_loss: 865.3673 - val_mse: 865.3673 - val_mae: 24.4558\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.7485 - mse: 1.7485 - mae: 0.9795 - val_loss: 3332.8306 - val_mse: 3332.8306 - val_mae: 39.2255\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.8728 - mse: 1.8728 - mae: 0.9492 - val_loss: 2012.0615 - val_mse: 2012.0615 - val_mae: 31.3676\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.2053 - mse: 1.2053 - mae: 0.8233 - val_loss: 284.3933 - val_mse: 284.3933 - val_mae: 15.0157\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.4500 - mse: 1.4500 - mae: 0.8811 - val_loss: 392.5970 - val_mse: 392.5970 - val_mae: 16.3792\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9772 - mse: 0.9772 - mae: 0.7622 - val_loss: 718.9935 - val_mse: 718.9935 - val_mae: 19.4475\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.2384 - mse: 1.2384 - mae: 0.8112 - val_loss: 338.0783 - val_mse: 338.0783 - val_mae: 14.4828\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9046 - mse: 0.9046 - mae: 0.7352 - val_loss: 136.8434 - val_mse: 136.8434 - val_mae: 10.3024\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0662 - mse: 1.0662 - mae: 0.7896 - val_loss: 205.6552 - val_mse: 205.6552 - val_mae: 11.5427\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9749 - mse: 0.9749 - mae: 0.7474 - val_loss: 239.0565 - val_mse: 239.0565 - val_mae: 11.8145\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.9485 - mse: 0.9485 - mae: 0.7317 - val_loss: 83.1647 - val_mse: 83.1647 - val_mae: 8.2341\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9833 - mse: 0.9833 - mae: 0.7546 - val_loss: 62.0329 - val_mse: 62.0329 - val_mae: 7.2912\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8765 - mse: 0.8765 - mae: 0.7117 - val_loss: 111.3583 - val_mse: 111.3583 - val_mae: 8.6216\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.0129 - mse: 1.0129 - mae: 0.7477 - val_loss: 72.4130 - val_mse: 72.4130 - val_mae: 7.3007\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8541 - mse: 0.8541 - mae: 0.7032 - val_loss: 35.0757 - val_mse: 35.0757 - val_mae: 5.5738\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9655 - mse: 0.9655 - mae: 0.7525 - val_loss: 53.0475 - val_mse: 53.0475 - val_mae: 6.2938\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8796 - mse: 0.8796 - mae: 0.7104 - val_loss: 49.3931 - val_mse: 49.3931 - val_mae: 6.0486\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8565 - mse: 0.8565 - mae: 0.7057 - val_loss: 31.9979 - val_mse: 31.9979 - val_mae: 5.1504\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8421 - mse: 0.8421 - mae: 0.6978 - val_loss: 26.5784 - val_mse: 26.5784 - val_mae: 4.7849\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8896 - mse: 0.8896 - mae: 0.7223 - val_loss: 34.1073 - val_mse: 34.1073 - val_mae: 5.0658\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9768 - mse: 0.9768 - mae: 0.7268 - val_loss: 29.1331 - val_mse: 29.1331 - val_mae: 4.7738\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8467 - mse: 0.8467 - mae: 0.7046 - val_loss: 15.7914 - val_mse: 15.7914 - val_mae: 3.7192\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9593 - mse: 0.9593 - mae: 0.7449 - val_loss: 24.1146 - val_mse: 24.1146 - val_mae: 4.3037\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8632 - mse: 0.8632 - mae: 0.7020 - val_loss: 18.4608 - val_mse: 18.4608 - val_mae: 3.8946\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8260 - mse: 0.8260 - mae: 0.6934 - val_loss: 13.5913 - val_mse: 13.5913 - val_mae: 3.4344\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8381 - mse: 0.8381 - mae: 0.6969 - val_loss: 15.6776 - val_mse: 15.6776 - val_mae: 3.5697\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8077 - mse: 0.8077 - mae: 0.6825 - val_loss: 12.9776 - val_mse: 12.9776 - val_mae: 3.3412\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8092 - mse: 0.8092 - mae: 0.6884 - val_loss: 10.9182 - val_mse: 10.9182 - val_mae: 3.0612\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7910 - mse: 0.7910 - mae: 0.6766 - val_loss: 12.1345 - val_mse: 12.1345 - val_mae: 3.1691\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8166 - mse: 0.8166 - mae: 0.6894 - val_loss: 10.2359 - val_mse: 10.2359 - val_mae: 2.8864\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8235 - mse: 0.8235 - mae: 0.6833 - val_loss: 9.4002 - val_mse: 9.4002 - val_mae: 2.8286\n",
      "Epoch 46/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8005 - mse: 0.8005 - mae: 0.6798 - val_loss: 8.7543 - val_mse: 8.7543 - val_mae: 2.6965\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8119 - mse: 0.8119 - mae: 0.6855 - val_loss: 7.6467 - val_mse: 7.6467 - val_mae: 2.5547\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7777 - mse: 0.7777 - mae: 0.6730 - val_loss: 7.8629 - val_mse: 7.8629 - val_mae: 2.5180\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8112 - mse: 0.8112 - mae: 0.6814 - val_loss: 7.0427 - val_mse: 7.0427 - val_mae: 2.4286\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7942 - mse: 0.7942 - mae: 0.6798 - val_loss: 6.2643 - val_mse: 6.2643 - val_mae: 2.2747\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8084 - mse: 0.8084 - mae: 0.6799 - val_loss: 5.7898 - val_mse: 5.7898 - val_mae: 2.2088\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8079 - mse: 0.8079 - mae: 0.6824 - val_loss: 5.2698 - val_mse: 5.2698 - val_mae: 2.1089\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7776 - mse: 0.7776 - mae: 0.6756 - val_loss: 6.4113 - val_mse: 6.4113 - val_mae: 2.1697\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8320 - mse: 0.8320 - mae: 0.6830 - val_loss: 4.7057 - val_mse: 4.7057 - val_mae: 1.9747\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8942 - mse: 0.8942 - mae: 0.7182 - val_loss: 4.1159 - val_mse: 4.1159 - val_mae: 1.8439\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7937 - mse: 0.7937 - mae: 0.6757 - val_loss: 5.1803 - val_mse: 5.1803 - val_mae: 1.9672\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8333 - mse: 0.8333 - mae: 0.6825 - val_loss: 3.7804 - val_mse: 3.7804 - val_mae: 1.7570\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7988 - mse: 0.7988 - mae: 0.6812 - val_loss: 4.0399 - val_mse: 4.0399 - val_mae: 1.7613\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7861 - mse: 0.7861 - mae: 0.6694 - val_loss: 3.3353 - val_mse: 3.3353 - val_mae: 1.6488\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7700 - mse: 0.7700 - mae: 0.6645 - val_loss: 3.2560 - val_mse: 3.2560 - val_mae: 1.6333\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7530 - mse: 0.7530 - mae: 0.6611 - val_loss: 3.2592 - val_mse: 3.2592 - val_mae: 1.6092\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7604 - mse: 0.7604 - mae: 0.6621 - val_loss: 2.7687 - val_mse: 2.7687 - val_mae: 1.4901\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7659 - mse: 0.7659 - mae: 0.6642 - val_loss: 2.6823 - val_mse: 2.6823 - val_mae: 1.4662\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7685 - mse: 0.7685 - mae: 0.6618 - val_loss: 2.6743 - val_mse: 2.6743 - val_mae: 1.4672\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7448 - mse: 0.7448 - mae: 0.6556 - val_loss: 2.5400 - val_mse: 2.5400 - val_mae: 1.3990\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7647 - mse: 0.7647 - mae: 0.6619 - val_loss: 2.2764 - val_mse: 2.2764 - val_mae: 1.3312\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7382 - mse: 0.7382 - mae: 0.6482 - val_loss: 2.1716 - val_mse: 2.1716 - val_mae: 1.3120\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7445 - mse: 0.7445 - mae: 0.6504 - val_loss: 2.1336 - val_mse: 2.1336 - val_mae: 1.3027\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7316 - mse: 0.7316 - mae: 0.6558 - val_loss: 1.7292 - val_mse: 1.7292 - val_mae: 1.1495\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7501 - mse: 0.7501 - mae: 0.6514 - val_loss: 1.8660 - val_mse: 1.8660 - val_mae: 1.2001\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7326 - mse: 0.7326 - mae: 0.6421 - val_loss: 1.8617 - val_mse: 1.8617 - val_mae: 1.2041\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7356 - mse: 0.7356 - mae: 0.6550 - val_loss: 1.6073 - val_mse: 1.6073 - val_mae: 1.1032\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7350 - mse: 0.7350 - mae: 0.6421 - val_loss: 1.8305 - val_mse: 1.8305 - val_mae: 1.1867\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7473 - mse: 0.7473 - mae: 0.6519 - val_loss: 1.6432 - val_mse: 1.6432 - val_mae: 1.1071\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7298 - mse: 0.7298 - mae: 0.6509 - val_loss: 1.3733 - val_mse: 1.3733 - val_mae: 1.0074\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7494 - mse: 0.7494 - mae: 0.6485 - val_loss: 1.4461 - val_mse: 1.4461 - val_mae: 1.0447\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7222 - mse: 0.7222 - mae: 0.6407 - val_loss: 1.5246 - val_mse: 1.5246 - val_mae: 1.0333\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7341 - mse: 0.7341 - mae: 0.6459 - val_loss: 1.3959 - val_mse: 1.3959 - val_mae: 1.0110\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7201 - mse: 0.7201 - mae: 0.6406 - val_loss: 1.3414 - val_mse: 1.3414 - val_mae: 0.9857\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7191 - mse: 0.7191 - mae: 0.6415 - val_loss: 1.2335 - val_mse: 1.2335 - val_mae: 0.9483\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7150 - mse: 0.7150 - mae: 0.6381 - val_loss: 1.2876 - val_mse: 1.2876 - val_mae: 0.9478\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 47s 4ms/sample - loss: 0.7190 - mse: 0.7190 - mae: 0.6377 - val_loss: 1.1804 - val_mse: 1.1804 - val_mae: 0.9246\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 47s 4ms/sample - loss: 0.6996 - mse: 0.6996 - mae: 0.6306 - val_loss: 1.1363 - val_mse: 1.1363 - val_mae: 0.9046\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 47s 4ms/sample - loss: 0.7031 - mse: 0.7031 - mae: 0.6353 - val_loss: 1.1742 - val_mse: 1.1742 - val_mae: 0.8719\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 47s 4ms/sample - loss: 0.7181 - mse: 0.7181 - mae: 0.6323 - val_loss: 1.1921 - val_mse: 1.1921 - val_mae: 0.9229\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7288 - mse: 0.7288 - mae: 0.6437 - val_loss: 1.1094 - val_mse: 1.1094 - val_mae: 0.8765\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 47s 4ms/sample - loss: 0.7375 - mse: 0.7375 - mae: 0.6446 - val_loss: 0.9679 - val_mse: 0.9679 - val_mae: 0.8151\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6938 - mse: 0.6938 - mae: 0.6234 - val_loss: 1.0844 - val_mse: 1.0844 - val_mae: 0.8723\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7074 - mse: 0.7074 - mae: 0.6318 - val_loss: 1.0087 - val_mse: 1.0087 - val_mae: 0.8266\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7037 - mse: 0.7037 - mae: 0.6322 - val_loss: 0.9750 - val_mse: 0.9750 - val_mae: 0.8148\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6832 - mse: 0.6832 - mae: 0.6219 - val_loss: 0.9780 - val_mse: 0.9780 - val_mae: 0.8052\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6969 - mse: 0.6969 - mae: 0.6277 - val_loss: 0.8852 - val_mse: 0.8852 - val_mae: 0.7675\n",
      "Epoch 93/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6710 - mse: 0.6710 - mae: 0.6143 - val_loss: 0.8841 - val_mse: 0.8841 - val_mae: 0.7668\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6634 - mse: 0.6634 - mae: 0.6111 - val_loss: 0.9016 - val_mse: 0.9016 - val_mae: 0.7767\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6665 - mse: 0.6665 - mae: 0.6161 - val_loss: 0.8466 - val_mse: 0.8466 - val_mae: 0.7393\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6768 - mse: 0.6768 - mae: 0.6185 - val_loss: 0.8180 - val_mse: 0.8180 - val_mae: 0.7172\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6631 - mse: 0.6631 - mae: 0.6061 - val_loss: 0.8863 - val_mse: 0.8863 - val_mae: 0.7740\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6580 - mse: 0.6580 - mae: 0.6123 - val_loss: 0.8044 - val_mse: 0.8044 - val_mae: 0.7201\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7001 - mse: 0.7001 - mae: 0.6264 - val_loss: 0.8131 - val_mse: 0.8131 - val_mae: 0.7096\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6843 - mse: 0.6843 - mae: 0.6227 - val_loss: 0.7847 - val_mse: 0.7847 - val_mae: 0.7000\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6880 - mse: 0.6880 - mae: 0.6167 - val_loss: 0.8206 - val_mse: 0.8206 - val_mae: 0.6961\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6579 - mse: 0.6579 - mae: 0.6076 - val_loss: 0.8321 - val_mse: 0.8321 - val_mae: 0.7072\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6621 - mse: 0.6621 - mae: 0.6090 - val_loss: 0.8255 - val_mse: 0.8255 - val_mae: 0.6971\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6574 - mse: 0.6574 - mae: 0.6086 - val_loss: 0.7648 - val_mse: 0.7648 - val_mae: 0.6802\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6920 - mse: 0.6920 - mae: 0.6264 - val_loss: 0.7930 - val_mse: 0.7930 - val_mae: 0.6642\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6938 - mse: 0.6938 - mae: 0.6145 - val_loss: 0.7650 - val_mse: 0.7650 - val_mae: 0.6665\n",
      "Epoch 107/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6867 - mse: 0.6867 - mae: 0.6164 - val_loss: 0.7601 - val_mse: 0.7601 - val_mae: 0.6799\n",
      "Epoch 108/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6754 - mse: 0.6754 - mae: 0.6127 - val_loss: 0.7844 - val_mse: 0.7844 - val_mae: 0.6629\n",
      "Epoch 109/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6273 - mse: 0.6273 - mae: 0.5936 - val_loss: 0.7405 - val_mse: 0.7405 - val_mae: 0.6639\n",
      "Epoch 110/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6306 - mse: 0.6306 - mae: 0.5960 - val_loss: 0.7788 - val_mse: 0.7788 - val_mae: 0.6500\n",
      "Epoch 111/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6314 - mse: 0.6314 - mae: 0.5940 - val_loss: 0.7355 - val_mse: 0.7355 - val_mae: 0.6642\n",
      "Epoch 112/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6530 - mse: 0.6530 - mae: 0.6095 - val_loss: 0.8484 - val_mse: 0.8484 - val_mae: 0.6547\n",
      "Epoch 113/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6662 - mse: 0.6662 - mae: 0.6017 - val_loss: 0.7170 - val_mse: 0.7170 - val_mae: 0.6465\n",
      "Epoch 114/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6393 - mse: 0.6393 - mae: 0.5954 - val_loss: 0.7418 - val_mse: 0.7418 - val_mae: 0.6474\n",
      "Epoch 115/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6337 - mse: 0.6337 - mae: 0.5976 - val_loss: 0.6986 - val_mse: 0.6986 - val_mae: 0.6214\n",
      "Epoch 116/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6217 - mse: 0.6217 - mae: 0.5949 - val_loss: 0.6893 - val_mse: 0.6893 - val_mae: 0.6125\n",
      "Epoch 117/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6128 - mse: 0.6128 - mae: 0.5810 - val_loss: 0.7453 - val_mse: 0.7453 - val_mae: 0.6436\n",
      "Epoch 118/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6049 - mse: 0.6049 - mae: 0.5826 - val_loss: 0.7573 - val_mse: 0.7573 - val_mae: 0.6554\n",
      "Epoch 119/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6223 - mse: 0.6223 - mae: 0.5932 - val_loss: 0.7082 - val_mse: 0.7082 - val_mae: 0.6123\n",
      "Epoch 120/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5990 - mse: 0.5990 - mae: 0.5774 - val_loss: 0.7243 - val_mse: 0.7243 - val_mae: 0.6467\n",
      "Epoch 121/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6086 - mse: 0.6086 - mae: 0.5876 - val_loss: 0.6885 - val_mse: 0.6885 - val_mae: 0.6017\n",
      "Epoch 122/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6088 - mse: 0.6088 - mae: 0.5806 - val_loss: 0.6911 - val_mse: 0.6911 - val_mae: 0.6161\n",
      "Epoch 123/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6140 - mse: 0.6140 - mae: 0.5801 - val_loss: 0.6969 - val_mse: 0.6969 - val_mae: 0.6213\n",
      "Epoch 124/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6171 - mse: 0.6171 - mae: 0.5825 - val_loss: 0.6768 - val_mse: 0.6768 - val_mae: 0.6040\n",
      "Epoch 125/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5847 - mse: 0.5847 - mae: 0.5717 - val_loss: 0.6704 - val_mse: 0.6704 - val_mae: 0.5968\n",
      "Epoch 126/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5731 - mse: 0.5731 - mae: 0.5607 - val_loss: 0.6961 - val_mse: 0.6961 - val_mae: 0.6180\n",
      "Epoch 127/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5904 - mse: 0.5904 - mae: 0.5736 - val_loss: 0.6675 - val_mse: 0.6675 - val_mae: 0.6052\n",
      "Epoch 128/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5832 - mse: 0.5832 - mae: 0.5683 - val_loss: 0.6808 - val_mse: 0.6808 - val_mae: 0.5979\n",
      "Epoch 129/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5796 - mse: 0.5796 - mae: 0.5658 - val_loss: 0.6582 - val_mse: 0.6582 - val_mae: 0.5937\n",
      "Epoch 130/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5645 - mse: 0.5645 - mae: 0.5557 - val_loss: 0.6525 - val_mse: 0.6525 - val_mae: 0.5905\n",
      "Epoch 131/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5589 - mse: 0.5589 - mae: 0.5566 - val_loss: 0.6680 - val_mse: 0.6680 - val_mae: 0.5895\n",
      "Epoch 132/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5709 - mse: 0.5709 - mae: 0.5562 - val_loss: 0.6620 - val_mse: 0.6620 - val_mae: 0.6121\n",
      "Epoch 133/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5602 - mse: 0.5602 - mae: 0.5546 - val_loss: 0.6763 - val_mse: 0.6763 - val_mae: 0.6066\n",
      "Epoch 134/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5517 - mse: 0.5517 - mae: 0.5577 - val_loss: 0.6763 - val_mse: 0.6763 - val_mae: 0.5911\n",
      "Epoch 135/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5523 - mse: 0.5523 - mae: 0.5492 - val_loss: 0.6779 - val_mse: 0.6779 - val_mae: 0.5954\n",
      "Epoch 136/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5511 - mse: 0.5511 - mae: 0.5487 - val_loss: 0.6469 - val_mse: 0.6469 - val_mae: 0.5950\n",
      "Epoch 137/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5466 - mse: 0.5466 - mae: 0.5547 - val_loss: 0.6561 - val_mse: 0.6561 - val_mae: 0.5797\n",
      "Epoch 138/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5354 - mse: 0.5354 - mae: 0.5441 - val_loss: 0.6722 - val_mse: 0.6722 - val_mae: 0.5874\n",
      "Epoch 139/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5230 - mse: 0.5230 - mae: 0.5362 - val_loss: 0.6431 - val_mse: 0.6431 - val_mae: 0.5910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5179 - mse: 0.5179 - mae: 0.5371 - val_loss: 0.7459 - val_mse: 0.7459 - val_mae: 0.6011\n",
      "Epoch 141/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5216 - mse: 0.5216 - mae: 0.5310 - val_loss: 0.6494 - val_mse: 0.6494 - val_mae: 0.6010\n",
      "Epoch 142/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5110 - mse: 0.5110 - mae: 0.5343 - val_loss: 0.6342 - val_mse: 0.6342 - val_mae: 0.5708\n",
      "Epoch 143/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5097 - mse: 0.5097 - mae: 0.5341 - val_loss: 0.6851 - val_mse: 0.6851 - val_mae: 0.5850\n",
      "Epoch 144/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5036 - mse: 0.5036 - mae: 0.5245 - val_loss: 0.6501 - val_mse: 0.6501 - val_mae: 0.5816\n",
      "Epoch 145/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4817 - mse: 0.4817 - mae: 0.5148 - val_loss: 0.6811 - val_mse: 0.6811 - val_mae: 0.5814\n",
      "Epoch 146/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4827 - mse: 0.4827 - mae: 0.5148 - val_loss: 0.6503 - val_mse: 0.6503 - val_mae: 0.5821\n",
      "Epoch 147/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4792 - mse: 0.4792 - mae: 0.5138 - val_loss: 0.6249 - val_mse: 0.6249 - val_mae: 0.5685\n",
      "Epoch 148/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4868 - mse: 0.4868 - mae: 0.5177 - val_loss: 0.6624 - val_mse: 0.6624 - val_mae: 0.5721\n",
      "Epoch 149/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4734 - mse: 0.4734 - mae: 0.5108 - val_loss: 0.6332 - val_mse: 0.6332 - val_mae: 0.5707\n",
      "Epoch 150/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4754 - mse: 0.4754 - mae: 0.5112 - val_loss: 0.6100 - val_mse: 0.6100 - val_mae: 0.5742\n",
      "Epoch 151/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4652 - mse: 0.4652 - mae: 0.5090 - val_loss: 0.6513 - val_mse: 0.6513 - val_mae: 0.5728\n",
      "Epoch 152/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4573 - mse: 0.4573 - mae: 0.5052 - val_loss: 0.6745 - val_mse: 0.6745 - val_mae: 0.5840\n",
      "Epoch 153/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4525 - mse: 0.4525 - mae: 0.5009 - val_loss: 0.6154 - val_mse: 0.6154 - val_mae: 0.5605\n",
      "Epoch 154/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4366 - mse: 0.4366 - mae: 0.4867 - val_loss: 0.6449 - val_mse: 0.6449 - val_mae: 0.5749\n",
      "Epoch 155/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4508 - mse: 0.4508 - mae: 0.5004 - val_loss: 0.6342 - val_mse: 0.6342 - val_mae: 0.5712\n",
      "Epoch 156/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4525 - mse: 0.4525 - mae: 0.4998 - val_loss: 0.7152 - val_mse: 0.7152 - val_mae: 0.5991\n",
      "Epoch 157/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4440 - mse: 0.4440 - mae: 0.4961 - val_loss: 0.6354 - val_mse: 0.6354 - val_mae: 0.5698\n",
      "Epoch 158/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.4376 - mse: 0.4376 - mae: 0.4912 - val_loss: 0.6151 - val_mse: 0.6151 - val_mae: 0.5621\n",
      "Epoch 159/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4164 - mse: 0.4164 - mae: 0.4802 - val_loss: 0.6239 - val_mse: 0.6239 - val_mae: 0.5649\n",
      "Epoch 160/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4231 - mse: 0.4231 - mae: 0.4844 - val_loss: 0.6659 - val_mse: 0.6659 - val_mae: 0.5732\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 47s 4ms/sample - loss: 1859.2170 - mse: 1859.2169 - mae: 23.0850 - val_loss: 7991405568.0000 - val_mse: 7991405568.0000 - val_mae: 77732.3594\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 124.2935 - mse: 124.2935 - mae: 6.4127 - val_loss: 329440096.0000 - val_mse: 329440096.0000 - val_mae: 16066.3105\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 131.1533 - mse: 131.1533 - mae: 7.2632 - val_loss: 8319948.5000 - val_mse: 8319948.5000 - val_mae: 2598.7439\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 26.7050 - mse: 26.7050 - mae: 3.3665 - val_loss: 35873500.0000 - val_mse: 35873500.0000 - val_mae: 4367.4023\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 32.1379 - mse: 32.1379 - mae: 2.7542 - val_loss: 13400456.0000 - val_mse: 13400456.0000 - val_mae: 2699.2197\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 16.1621 - mse: 16.1621 - mae: 2.3107 - val_loss: 1067983.3750 - val_mse: 1067983.3750 - val_mae: 760.5182\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 13.2690 - mse: 13.2690 - mae: 2.6681 - val_loss: 283623.9062 - val_mse: 283623.9062 - val_mae: 400.0954\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 7.1660 - mse: 7.1660 - mae: 2.0329 - val_loss: 514945.8125 - val_mse: 514945.8125 - val_mae: 530.0121\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 7.6291 - mse: 7.6291 - mae: 2.0860 - val_loss: 355011.0625 - val_mse: 355011.0625 - val_mae: 437.1828\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 3.8275 - mse: 3.8275 - mae: 1.3513 - val_loss: 87235.3359 - val_mse: 87235.3359 - val_mae: 220.4048\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 4.0508 - mse: 4.0508 - mae: 1.5679 - val_loss: 35061.1875 - val_mse: 35061.1875 - val_mae: 142.4255\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 2.9301 - mse: 2.9301 - mae: 1.2518 - val_loss: 45009.7539 - val_mse: 45009.7539 - val_mae: 157.9568\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 3.4295 - mse: 3.4295 - mae: 1.4147 - val_loss: 27246.5664 - val_mse: 27246.5664 - val_mae: 123.4336\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.7012 - mse: 1.7012 - mae: 0.9893 - val_loss: 9780.0742 - val_mse: 9780.0742 - val_mae: 75.9807\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.8004 - mse: 1.8004 - mae: 0.9925 - val_loss: 5667.2563 - val_mse: 5667.2563 - val_mae: 58.4188\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.9213 - mse: 1.9213 - mae: 1.0245 - val_loss: 6215.5498 - val_mse: 6215.5498 - val_mae: 59.6459\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.5331 - mse: 1.5331 - mae: 0.8814 - val_loss: 3745.6560 - val_mse: 3745.6560 - val_mae: 47.2777\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.5717 - mse: 1.5717 - mae: 0.9203 - val_loss: 1862.8048 - val_mse: 1862.8048 - val_mae: 34.7313\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0912 - mse: 1.0912 - mae: 0.7881 - val_loss: 1944.0839 - val_mse: 1944.0839 - val_mae: 34.9245\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.0851 - mse: 1.0851 - mae: 0.7682 - val_loss: 1502.4011 - val_mse: 1502.4011 - val_mae: 31.0137\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.1512 - mse: 1.1512 - mae: 0.7612 - val_loss: 882.3688 - val_mse: 882.3688 - val_mae: 24.8952\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0583 - mse: 1.0583 - mae: 0.7606 - val_loss: 659.1300 - val_mse: 659.1300 - val_mae: 21.7976\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.1758 - mse: 1.1758 - mae: 0.7811 - val_loss: 488.5201 - val_mse: 488.5201 - val_mae: 18.9909\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0399 - mse: 1.0399 - mae: 0.7333 - val_loss: 531.2515 - val_mse: 531.2515 - val_mae: 19.0530\n",
      "Epoch 25/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.0295 - mse: 1.0295 - mae: 0.7297 - val_loss: 309.1782 - val_mse: 309.1782 - val_mae: 15.2396\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0299 - mse: 1.0299 - mae: 0.7621 - val_loss: 278.5768 - val_mse: 278.5768 - val_mae: 14.4360\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0086 - mse: 1.0086 - mae: 0.7325 - val_loss: 249.8628 - val_mse: 249.8628 - val_mae: 13.7164\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9284 - mse: 0.9284 - mae: 0.7147 - val_loss: 166.4733 - val_mse: 166.4733 - val_mae: 11.6435\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9383 - mse: 0.9383 - mae: 0.7098 - val_loss: 160.4077 - val_mse: 160.4077 - val_mae: 11.3133\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9489 - mse: 0.9489 - mae: 0.7213 - val_loss: 146.6943 - val_mse: 146.6943 - val_mae: 10.7469\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9120 - mse: 0.9120 - mae: 0.6999 - val_loss: 122.0638 - val_mse: 122.0638 - val_mae: 9.9017\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.9564 - mse: 0.9564 - mae: 0.7172 - val_loss: 92.0328 - val_mse: 92.0328 - val_mae: 8.8136\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8404 - mse: 0.8404 - mae: 0.6886 - val_loss: 92.7994 - val_mse: 92.7994 - val_mae: 8.6729\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9708 - mse: 0.9708 - mae: 0.7080 - val_loss: 79.0815 - val_mse: 79.0815 - val_mae: 8.0304\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0693 - mse: 1.0693 - mae: 0.7369 - val_loss: 52.7831 - val_mse: 52.7831 - val_mae: 6.8698\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0100 - mse: 1.0100 - mae: 0.7366 - val_loss: 79.5878 - val_mse: 79.5878 - val_mae: 7.7545\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0578 - mse: 1.0578 - mae: 0.7184 - val_loss: 44.4787 - val_mse: 44.4787 - val_mae: 6.2748\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.9352 - mse: 0.9352 - mae: 0.7192 - val_loss: 41.1844 - val_mse: 41.1844 - val_mae: 5.9784\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8265 - mse: 0.8265 - mae: 0.6773 - val_loss: 40.1442 - val_mse: 40.1442 - val_mae: 5.9085\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8648 - mse: 0.8648 - mae: 0.6848 - val_loss: 35.2699 - val_mse: 35.2699 - val_mae: 5.5423\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8376 - mse: 0.8376 - mae: 0.6897 - val_loss: 28.0671 - val_mse: 28.0671 - val_mae: 4.9977\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8432 - mse: 0.8432 - mae: 0.6783 - val_loss: 31.8372 - val_mse: 31.8372 - val_mae: 5.1987\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8644 - mse: 0.8644 - mae: 0.6805 - val_loss: 25.8651 - val_mse: 25.8651 - val_mae: 4.7400\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8027 - mse: 0.8027 - mae: 0.6717 - val_loss: 19.8500 - val_mse: 19.8500 - val_mae: 4.2398\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8458 - mse: 0.8458 - mae: 0.6826 - val_loss: 23.0178 - val_mse: 23.0178 - val_mae: 4.4071\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8432 - mse: 0.8432 - mae: 0.6750 - val_loss: 21.5431 - val_mse: 21.5431 - val_mae: 4.3110\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8966 - mse: 0.8966 - mae: 0.7005 - val_loss: 17.0708 - val_mse: 17.0708 - val_mae: 3.8543\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.9162 - mse: 0.9162 - mae: 0.6946 - val_loss: 17.3583 - val_mse: 17.3583 - val_mae: 3.8409\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7992 - mse: 0.7992 - mae: 0.6614 - val_loss: 13.0545 - val_mse: 13.0545 - val_mae: 3.4173\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8411 - mse: 0.8411 - mae: 0.6854 - val_loss: 14.1459 - val_mse: 14.1459 - val_mae: 3.4568\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8375 - mse: 0.8375 - mae: 0.6689 - val_loss: 12.8752 - val_mse: 12.8752 - val_mae: 3.3497\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8781 - mse: 0.8781 - mae: 0.6867 - val_loss: 10.4028 - val_mse: 10.4028 - val_mae: 3.0275\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7964 - mse: 0.7964 - mae: 0.6618 - val_loss: 12.7792 - val_mse: 12.7792 - val_mae: 3.2530\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8030 - mse: 0.8030 - mae: 0.6695 - val_loss: 8.6953 - val_mse: 8.6953 - val_mae: 2.7474\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8767 - mse: 0.8767 - mae: 0.6951 - val_loss: 8.8802 - val_mse: 8.8802 - val_mae: 2.7493\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8155 - mse: 0.8155 - mae: 0.6580 - val_loss: 9.1173 - val_mse: 9.1173 - val_mae: 2.7968\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7640 - mse: 0.7640 - mae: 0.6558 - val_loss: 7.2190 - val_mse: 7.2190 - val_mae: 2.4991\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8340 - mse: 0.8340 - mae: 0.6831 - val_loss: 8.4067 - val_mse: 8.4067 - val_mae: 2.5735\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.9191 - mse: 0.9191 - mae: 0.6852 - val_loss: 6.6848 - val_mse: 6.6848 - val_mae: 2.3824\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.9072 - mse: 0.9072 - mae: 0.6892 - val_loss: 5.8448 - val_mse: 5.8448 - val_mae: 2.2339\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7933 - mse: 0.7933 - mae: 0.6680 - val_loss: 7.3139 - val_mse: 7.3139 - val_mae: 2.3766\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8813 - mse: 0.8813 - mae: 0.6877 - val_loss: 4.6841 - val_mse: 4.6841 - val_mae: 1.9565\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8312 - mse: 0.8312 - mae: 0.6716 - val_loss: 5.8597 - val_mse: 5.8597 - val_mae: 2.2058\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7909 - mse: 0.7909 - mae: 0.6591 - val_loss: 4.7166 - val_mse: 4.7166 - val_mae: 1.9926\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7478 - mse: 0.7478 - mae: 0.6519 - val_loss: 4.2341 - val_mse: 4.2341 - val_mae: 1.8696\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7485 - mse: 0.7485 - mae: 0.6367 - val_loss: 4.2454 - val_mse: 4.2454 - val_mae: 1.8792\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7331 - mse: 0.7331 - mae: 0.6401 - val_loss: 3.7203 - val_mse: 3.7203 - val_mae: 1.7571\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7453 - mse: 0.7453 - mae: 0.6392 - val_loss: 4.3421 - val_mse: 4.3421 - val_mae: 1.8902\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7699 - mse: 0.7699 - mae: 0.6548 - val_loss: 3.1543 - val_mse: 3.1543 - val_mae: 1.5990\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7618 - mse: 0.7618 - mae: 0.6496 - val_loss: 3.3220 - val_mse: 3.3220 - val_mae: 1.6306\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7880 - mse: 0.7880 - mae: 0.6465 - val_loss: 3.2749 - val_mse: 3.2749 - val_mae: 1.6373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7717 - mse: 0.7717 - mae: 0.6554 - val_loss: 2.7751 - val_mse: 2.7751 - val_mae: 1.4936\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7129 - mse: 0.7129 - mae: 0.6319 - val_loss: 3.0668 - val_mse: 3.0668 - val_mae: 1.5530\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7559 - mse: 0.7559 - mae: 0.6443 - val_loss: 2.3791 - val_mse: 2.3791 - val_mae: 1.3720\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7517 - mse: 0.7517 - mae: 0.6409 - val_loss: 2.5784 - val_mse: 2.5784 - val_mae: 1.4334\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7290 - mse: 0.7290 - mae: 0.6325 - val_loss: 2.3627 - val_mse: 2.3627 - val_mae: 1.3714\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7550 - mse: 0.7550 - mae: 0.6435 - val_loss: 2.1240 - val_mse: 2.1240 - val_mae: 1.2948\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7526 - mse: 0.7526 - mae: 0.6345 - val_loss: 2.1382 - val_mse: 2.1382 - val_mae: 1.2925\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7379 - mse: 0.7379 - mae: 0.6356 - val_loss: 1.7832 - val_mse: 1.7832 - val_mae: 1.1723\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7129 - mse: 0.7129 - mae: 0.6231 - val_loss: 2.1721 - val_mse: 2.1721 - val_mae: 1.2992\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7370 - mse: 0.7370 - mae: 0.6343 - val_loss: 1.9068 - val_mse: 1.9068 - val_mae: 1.2189\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6970 - mse: 0.6970 - mae: 0.6306 - val_loss: 1.6234 - val_mse: 1.6234 - val_mae: 1.1026\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7190 - mse: 0.7190 - mae: 0.6247 - val_loss: 1.8306 - val_mse: 1.8306 - val_mae: 1.1916\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7097 - mse: 0.7097 - mae: 0.6269 - val_loss: 1.5017 - val_mse: 1.5017 - val_mae: 1.0660\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7067 - mse: 0.7067 - mae: 0.6277 - val_loss: 1.4616 - val_mse: 1.4616 - val_mae: 1.0527\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7102 - mse: 0.7102 - mae: 0.6194 - val_loss: 1.4610 - val_mse: 1.4610 - val_mae: 1.0526\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6876 - mse: 0.6876 - mae: 0.6187 - val_loss: 1.3248 - val_mse: 1.3248 - val_mae: 0.9919\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6776 - mse: 0.6776 - mae: 0.6132 - val_loss: 1.3062 - val_mse: 1.3062 - val_mae: 0.9860\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6915 - mse: 0.6915 - mae: 0.6158 - val_loss: 1.2923 - val_mse: 1.2923 - val_mae: 0.9780\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6981 - mse: 0.6981 - mae: 0.6216 - val_loss: 1.2370 - val_mse: 1.2370 - val_mae: 0.9539\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7015 - mse: 0.7015 - mae: 0.6171 - val_loss: 1.2423 - val_mse: 1.2423 - val_mae: 0.9574\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6747 - mse: 0.6747 - mae: 0.6133 - val_loss: 1.1070 - val_mse: 1.1070 - val_mae: 0.8875\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6734 - mse: 0.6734 - mae: 0.6097 - val_loss: 1.1376 - val_mse: 1.1376 - val_mae: 0.9074\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6685 - mse: 0.6685 - mae: 0.6066 - val_loss: 1.1471 - val_mse: 1.1471 - val_mae: 0.9072\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6845 - mse: 0.6845 - mae: 0.6147 - val_loss: 1.0465 - val_mse: 1.0465 - val_mae: 0.8613\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6782 - mse: 0.6782 - mae: 0.6105 - val_loss: 1.0352 - val_mse: 1.0352 - val_mae: 0.8563\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6699 - mse: 0.6699 - mae: 0.6094 - val_loss: 1.0240 - val_mse: 1.0240 - val_mae: 0.8506\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6622 - mse: 0.6622 - mae: 0.6095 - val_loss: 0.9951 - val_mse: 0.9951 - val_mae: 0.8165\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6772 - mse: 0.6772 - mae: 0.6076 - val_loss: 0.9720 - val_mse: 0.9720 - val_mae: 0.8234\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6664 - mse: 0.6664 - mae: 0.6070 - val_loss: 0.9155 - val_mse: 0.9155 - val_mae: 0.7908\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6577 - mse: 0.6577 - mae: 0.6074 - val_loss: 0.8216 - val_mse: 0.8216 - val_mae: 0.7339\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6497 - mse: 0.6497 - mae: 0.5961 - val_loss: 0.9690 - val_mse: 0.9690 - val_mae: 0.8088\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6550 - mse: 0.6550 - mae: 0.5973 - val_loss: 0.9162 - val_mse: 0.9162 - val_mae: 0.7938\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6572 - mse: 0.6572 - mae: 0.6033 - val_loss: 0.8062 - val_mse: 0.8062 - val_mae: 0.7208\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6491 - mse: 0.6491 - mae: 0.5978 - val_loss: 0.8289 - val_mse: 0.8289 - val_mae: 0.7402\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6475 - mse: 0.6475 - mae: 0.5962 - val_loss: 0.8582 - val_mse: 0.8582 - val_mae: 0.7472\n",
      "Epoch 107/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6430 - mse: 0.6430 - mae: 0.5944 - val_loss: 0.7639 - val_mse: 0.7639 - val_mae: 0.6986\n",
      "Epoch 108/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6483 - mse: 0.6483 - mae: 0.5932 - val_loss: 0.7916 - val_mse: 0.7916 - val_mae: 0.7135\n",
      "Epoch 109/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6303 - mse: 0.6303 - mae: 0.5860 - val_loss: 0.7944 - val_mse: 0.7944 - val_mae: 0.7119\n",
      "Epoch 110/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6338 - mse: 0.6338 - mae: 0.5912 - val_loss: 0.7448 - val_mse: 0.7448 - val_mae: 0.6861\n",
      "Epoch 111/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6268 - mse: 0.6268 - mae: 0.5880 - val_loss: 0.7479 - val_mse: 0.7479 - val_mae: 0.6851\n",
      "Epoch 112/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6197 - mse: 0.6197 - mae: 0.5804 - val_loss: 0.7570 - val_mse: 0.7570 - val_mae: 0.6949\n",
      "Epoch 113/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6173 - mse: 0.6173 - mae: 0.5845 - val_loss: 0.7273 - val_mse: 0.7273 - val_mae: 0.6713\n",
      "Epoch 114/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6163 - mse: 0.6163 - mae: 0.5831 - val_loss: 0.7343 - val_mse: 0.7343 - val_mae: 0.6674\n",
      "Epoch 115/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6150 - mse: 0.6150 - mae: 0.5769 - val_loss: 0.7220 - val_mse: 0.7220 - val_mae: 0.6726\n",
      "Epoch 116/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6211 - mse: 0.6211 - mae: 0.5832 - val_loss: 0.7249 - val_mse: 0.7249 - val_mae: 0.6680\n",
      "Epoch 117/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6042 - mse: 0.6042 - mae: 0.5756 - val_loss: 0.7144 - val_mse: 0.7144 - val_mae: 0.6667\n",
      "Epoch 118/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6043 - mse: 0.6043 - mae: 0.5781 - val_loss: 0.6956 - val_mse: 0.6956 - val_mae: 0.6505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6025 - mse: 0.6025 - mae: 0.5749 - val_loss: 0.6962 - val_mse: 0.6962 - val_mae: 0.6462\n",
      "Epoch 120/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5948 - mse: 0.5948 - mae: 0.5711 - val_loss: 0.6776 - val_mse: 0.6776 - val_mae: 0.6331\n",
      "Epoch 121/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5882 - mse: 0.5882 - mae: 0.5643 - val_loss: 0.7248 - val_mse: 0.7248 - val_mae: 0.6769\n",
      "Epoch 122/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5904 - mse: 0.5904 - mae: 0.5705 - val_loss: 0.6732 - val_mse: 0.6732 - val_mae: 0.6337\n",
      "Epoch 123/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5775 - mse: 0.5775 - mae: 0.5641 - val_loss: 0.6897 - val_mse: 0.6897 - val_mae: 0.6443\n",
      "Epoch 124/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5716 - mse: 0.5716 - mae: 0.5579 - val_loss: 0.6726 - val_mse: 0.6726 - val_mae: 0.6351\n",
      "Epoch 125/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5735 - mse: 0.5735 - mae: 0.5623 - val_loss: 0.6771 - val_mse: 0.6771 - val_mae: 0.6155\n",
      "Epoch 126/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5771 - mse: 0.5771 - mae: 0.5577 - val_loss: 0.6639 - val_mse: 0.6639 - val_mae: 0.6268\n",
      "Epoch 127/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5789 - mse: 0.5789 - mae: 0.5580 - val_loss: 0.7394 - val_mse: 0.7394 - val_mae: 0.6726\n",
      "Epoch 128/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5698 - mse: 0.5698 - mae: 0.5612 - val_loss: 0.6522 - val_mse: 0.6522 - val_mae: 0.6148\n",
      "Epoch 129/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5611 - mse: 0.5611 - mae: 0.5567 - val_loss: 0.6602 - val_mse: 0.6602 - val_mae: 0.6133\n",
      "Epoch 130/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5444 - mse: 0.5444 - mae: 0.5405 - val_loss: 0.6535 - val_mse: 0.6535 - val_mae: 0.6243\n",
      "Epoch 131/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5446 - mse: 0.5446 - mae: 0.5454 - val_loss: 0.6719 - val_mse: 0.6719 - val_mae: 0.6040\n",
      "Epoch 132/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5514 - mse: 0.5514 - mae: 0.5453 - val_loss: 0.6573 - val_mse: 0.6573 - val_mae: 0.6203\n",
      "Epoch 133/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5588 - mse: 0.5588 - mae: 0.5465 - val_loss: 0.7013 - val_mse: 0.7013 - val_mae: 0.6288\n",
      "Epoch 134/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5638 - mse: 0.5638 - mae: 0.5503 - val_loss: 0.6252 - val_mse: 0.6252 - val_mae: 0.5962\n",
      "Epoch 135/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5283 - mse: 0.5283 - mae: 0.5374 - val_loss: 0.6581 - val_mse: 0.6581 - val_mae: 0.6145\n",
      "Epoch 136/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5209 - mse: 0.5209 - mae: 0.5381 - val_loss: 0.6202 - val_mse: 0.6202 - val_mae: 0.5792\n",
      "Epoch 137/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5329 - mse: 0.5329 - mae: 0.5379 - val_loss: 0.6417 - val_mse: 0.6417 - val_mae: 0.6036\n",
      "Epoch 138/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5295 - mse: 0.5295 - mae: 0.5338 - val_loss: 0.6478 - val_mse: 0.6478 - val_mae: 0.6298\n",
      "Epoch 139/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5284 - mse: 0.5284 - mae: 0.5410 - val_loss: 0.6205 - val_mse: 0.6205 - val_mae: 0.5828\n",
      "Epoch 140/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5204 - mse: 0.5204 - mae: 0.5391 - val_loss: 0.6377 - val_mse: 0.6377 - val_mae: 0.5729\n",
      "Epoch 141/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5255 - mse: 0.5255 - mae: 0.5290 - val_loss: 0.5997 - val_mse: 0.5997 - val_mae: 0.5845\n",
      "Epoch 142/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5045 - mse: 0.5045 - mae: 0.5255 - val_loss: 0.6208 - val_mse: 0.6208 - val_mae: 0.5775\n",
      "Epoch 143/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4979 - mse: 0.4979 - mae: 0.5260 - val_loss: 0.5893 - val_mse: 0.5893 - val_mae: 0.5642\n",
      "Epoch 144/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4855 - mse: 0.4855 - mae: 0.5090 - val_loss: 0.6231 - val_mse: 0.6231 - val_mae: 0.5933\n",
      "Epoch 145/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.4874 - mse: 0.4874 - mae: 0.5169 - val_loss: 0.5836 - val_mse: 0.5836 - val_mae: 0.5706\n",
      "Epoch 146/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4854 - mse: 0.4854 - mae: 0.5186 - val_loss: 0.6043 - val_mse: 0.6043 - val_mae: 0.5631\n",
      "Epoch 147/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4660 - mse: 0.4660 - mae: 0.5022 - val_loss: 0.5730 - val_mse: 0.5730 - val_mae: 0.5661\n",
      "Epoch 148/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4553 - mse: 0.4553 - mae: 0.4981 - val_loss: 0.6060 - val_mse: 0.6060 - val_mae: 0.5625\n",
      "Epoch 149/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4589 - mse: 0.4589 - mae: 0.4985 - val_loss: 0.5633 - val_mse: 0.5633 - val_mae: 0.5546\n",
      "Epoch 150/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4402 - mse: 0.4402 - mae: 0.4890 - val_loss: 0.5761 - val_mse: 0.5761 - val_mae: 0.5520\n",
      "Epoch 151/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4336 - mse: 0.4336 - mae: 0.4851 - val_loss: 0.5658 - val_mse: 0.5658 - val_mae: 0.5478\n",
      "Epoch 152/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4421 - mse: 0.4421 - mae: 0.4880 - val_loss: 0.5717 - val_mse: 0.5717 - val_mae: 0.5633\n",
      "Epoch 153/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4332 - mse: 0.4332 - mae: 0.4926 - val_loss: 0.5738 - val_mse: 0.5738 - val_mae: 0.5419\n",
      "Epoch 154/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4300 - mse: 0.4300 - mae: 0.4854 - val_loss: 0.5794 - val_mse: 0.5794 - val_mae: 0.5530\n",
      "Epoch 155/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4208 - mse: 0.4208 - mae: 0.4766 - val_loss: 0.5613 - val_mse: 0.5613 - val_mae: 0.5539\n",
      "Epoch 156/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4075 - mse: 0.4075 - mae: 0.4760 - val_loss: 0.5748 - val_mse: 0.5748 - val_mae: 0.5451\n",
      "Epoch 157/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3998 - mse: 0.3998 - mae: 0.4696 - val_loss: 0.5519 - val_mse: 0.5519 - val_mae: 0.5393\n",
      "Epoch 158/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4071 - mse: 0.4071 - mae: 0.4702 - val_loss: 0.5664 - val_mse: 0.5664 - val_mae: 0.5392\n",
      "Epoch 159/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.4060 - mse: 0.4060 - mae: 0.4673 - val_loss: 0.5517 - val_mse: 0.5517 - val_mae: 0.5349\n",
      "Epoch 160/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3932 - mse: 0.3932 - mae: 0.4596 - val_loss: 0.5375 - val_mse: 0.5375 - val_mae: 0.5323\n",
      "Epoch 161/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3843 - mse: 0.3843 - mae: 0.4591 - val_loss: 0.5894 - val_mse: 0.5894 - val_mae: 0.5493\n",
      "Epoch 162/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3863 - mse: 0.3863 - mae: 0.4621 - val_loss: 0.5684 - val_mse: 0.5684 - val_mae: 0.5430\n",
      "Epoch 163/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3877 - mse: 0.3877 - mae: 0.4553 - val_loss: 0.5844 - val_mse: 0.5844 - val_mae: 0.5467\n",
      "Epoch 164/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3852 - mse: 0.3852 - mae: 0.4586 - val_loss: 0.6031 - val_mse: 0.6031 - val_mae: 0.5590\n",
      "Epoch 165/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3800 - mse: 0.3800 - mae: 0.4564 - val_loss: 0.6250 - val_mse: 0.6250 - val_mae: 0.5591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3722 - mse: 0.3722 - mae: 0.4517 - val_loss: 0.5247 - val_mse: 0.5247 - val_mae: 0.5233\n",
      "Epoch 167/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3596 - mse: 0.3596 - mae: 0.4448 - val_loss: 0.5922 - val_mse: 0.5922 - val_mae: 0.5518\n",
      "Epoch 168/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3398 - mse: 0.3398 - mae: 0.4359 - val_loss: 0.6070 - val_mse: 0.6070 - val_mae: 0.5557\n",
      "Epoch 169/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3491 - mse: 0.3491 - mae: 0.4409 - val_loss: 0.6099 - val_mse: 0.6099 - val_mae: 0.5653\n",
      "Epoch 170/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3406 - mse: 0.3406 - mae: 0.4374 - val_loss: 0.5131 - val_mse: 0.5131 - val_mae: 0.5209\n",
      "Epoch 171/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3311 - mse: 0.3311 - mae: 0.4309 - val_loss: 0.5621 - val_mse: 0.5621 - val_mae: 0.5395\n",
      "Epoch 172/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3330 - mse: 0.3330 - mae: 0.4335 - val_loss: 0.6827 - val_mse: 0.6827 - val_mae: 0.5861\n",
      "Epoch 173/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3571 - mse: 0.3571 - mae: 0.4447 - val_loss: 0.5363 - val_mse: 0.5363 - val_mae: 0.5313\n",
      "Epoch 174/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3385 - mse: 0.3385 - mae: 0.4304 - val_loss: 0.5341 - val_mse: 0.5341 - val_mae: 0.5350\n",
      "Epoch 175/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3324 - mse: 0.3324 - mae: 0.4297 - val_loss: 0.5502 - val_mse: 0.5502 - val_mae: 0.5301\n",
      "Epoch 176/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3213 - mse: 0.3213 - mae: 0.4222 - val_loss: 0.4820 - val_mse: 0.4820 - val_mae: 0.5018\n",
      "Epoch 177/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3243 - mse: 0.3243 - mae: 0.4211 - val_loss: 0.5808 - val_mse: 0.5808 - val_mae: 0.5479\n",
      "Epoch 178/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3324 - mse: 0.3324 - mae: 0.4309 - val_loss: 0.5304 - val_mse: 0.5304 - val_mae: 0.5211\n",
      "Epoch 179/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3365 - mse: 0.3365 - mae: 0.4276 - val_loss: 0.5537 - val_mse: 0.5537 - val_mae: 0.5328\n",
      "Epoch 180/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3414 - mse: 0.3414 - mae: 0.4315 - val_loss: 0.5578 - val_mse: 0.5578 - val_mae: 0.5449\n",
      "Epoch 181/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3304 - mse: 0.3304 - mae: 0.4318 - val_loss: 0.5309 - val_mse: 0.5309 - val_mae: 0.5291\n",
      "Epoch 182/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3127 - mse: 0.3127 - mae: 0.4204 - val_loss: 0.6616 - val_mse: 0.6616 - val_mae: 0.6077\n",
      "Epoch 183/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.3195 - mse: 0.3195 - mae: 0.4256 - val_loss: 0.5484 - val_mse: 0.5484 - val_mae: 0.5321\n",
      "Epoch 184/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.2968 - mse: 0.2968 - mae: 0.4032 - val_loss: 0.6981 - val_mse: 0.6981 - val_mae: 0.5969\n",
      "Epoch 185/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.2873 - mse: 0.2873 - mae: 0.4050 - val_loss: 0.6295 - val_mse: 0.6295 - val_mae: 0.5786\n",
      "Epoch 186/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.2890 - mse: 0.2890 - mae: 0.3993 - val_loss: 0.6386 - val_mse: 0.6386 - val_mae: 0.5799\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 47s 4ms/sample - loss: 1749.6908 - mse: 1749.6907 - mae: 22.6843 - val_loss: 6622348288.0000 - val_mse: 6622348288.0000 - val_mae: 72528.7656\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 98.2800 - mse: 98.2800 - mae: 6.1698 - val_loss: 450748160.0000 - val_mse: 450748160.0000 - val_mae: 19255.2910\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 126.5127 - mse: 126.5128 - mae: 7.0151 - val_loss: 20943842.0000 - val_mse: 20943842.0000 - val_mae: 4320.6826\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 24.3344 - mse: 24.3344 - mae: 3.1881 - val_loss: 23783268.0000 - val_mse: 23783268.0000 - val_mae: 3640.3743\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 39.0127 - mse: 39.0127 - mae: 3.2821 - val_loss: 8887493.0000 - val_mse: 8887493.0000 - val_mae: 2283.6960\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 16.6355 - mse: 16.6355 - mae: 2.4115 - val_loss: 374982.9375 - val_mse: 374982.9375 - val_mae: 461.4001\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 20.7875 - mse: 20.7875 - mae: 3.0025 - val_loss: 54022.6484 - val_mse: 54022.6484 - val_mae: 180.8742\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 9.6317 - mse: 9.6317 - mae: 1.9332 - val_loss: 323403.9688 - val_mse: 323403.9688 - val_mae: 438.7341\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 9.5118 - mse: 9.5118 - mae: 2.2849 - val_loss: 269304.7812 - val_mse: 269304.7812 - val_mae: 397.5973\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 6.6926 - mse: 6.6926 - mae: 1.6276 - val_loss: 59085.3672 - val_mse: 59085.3672 - val_mae: 188.5440\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 4.9502 - mse: 4.9502 - mae: 1.7374 - val_loss: 22927.9512 - val_mse: 22927.9512 - val_mae: 119.1378\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 3.8515 - mse: 3.8515 - mae: 1.4879 - val_loss: 30501.3984 - val_mse: 30501.3984 - val_mae: 134.5518\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 3.5908 - mse: 3.5908 - mae: 1.3636 - val_loss: 24462.7754 - val_mse: 24462.7754 - val_mae: 119.6129\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 2.6436 - mse: 2.6436 - mae: 1.1496 - val_loss: 6504.7354 - val_mse: 6504.7354 - val_mae: 64.1568\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 2.8066 - mse: 2.8066 - mae: 1.1586 - val_loss: 4441.1689 - val_mse: 4441.1689 - val_mae: 53.1214\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 2.3364 - mse: 2.3364 - mae: 1.0862 - val_loss: 7867.9893 - val_mse: 7867.9893 - val_mae: 67.3092\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 2.7026 - mse: 2.7026 - mae: 0.9459 - val_loss: 3740.6504 - val_mse: 3740.6504 - val_mae: 48.1881\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.6583 - mse: 1.6583 - mae: 0.8939 - val_loss: 1138.8938 - val_mse: 1138.8938 - val_mae: 29.1153\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.7274 - mse: 1.7274 - mae: 0.8839 - val_loss: 1600.3562 - val_mse: 1600.3562 - val_mae: 32.6750\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0752 - mse: 1.0752 - mae: 0.7730 - val_loss: 1759.2871 - val_mse: 1759.2871 - val_mae: 33.1375\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.5095 - mse: 1.5095 - mae: 0.8030 - val_loss: 812.1872 - val_mse: 812.1872 - val_mae: 23.8246\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.6216 - mse: 1.6216 - mae: 0.8746 - val_loss: 556.0919 - val_mse: 556.0919 - val_mae: 20.1919\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.4599 - mse: 1.4599 - mae: 0.8115 - val_loss: 861.0812 - val_mse: 861.0812 - val_mae: 23.2214\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.5287 - mse: 1.5287 - mae: 0.8134 - val_loss: 359.0497 - val_mse: 359.0497 - val_mae: 16.2571\n",
      "Epoch 25/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.4861 - mse: 1.4861 - mae: 0.8590 - val_loss: 299.3113 - val_mse: 299.3113 - val_mae: 14.9533\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8817 - mse: 0.8817 - mae: 0.7119 - val_loss: 375.9727 - val_mse: 375.9727 - val_mae: 15.9973\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.2403 - mse: 1.2403 - mae: 0.7632 - val_loss: 235.3352 - val_mse: 235.3352 - val_mae: 13.2850\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9795 - mse: 0.9795 - mae: 0.7353 - val_loss: 133.5962 - val_mse: 133.5962 - val_mae: 10.5578\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.0103 - mse: 1.0103 - mae: 0.7285 - val_loss: 189.5833 - val_mse: 189.5833 - val_mae: 11.7362\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.4299 - mse: 1.4299 - mae: 0.7794 - val_loss: 173.0842 - val_mse: 173.0842 - val_mae: 11.0400\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 1.2464 - mse: 1.2464 - mae: 0.7730 - val_loss: 84.8574 - val_mse: 84.8574 - val_mae: 8.5092\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9006 - mse: 0.9006 - mae: 0.7071 - val_loss: 105.2766 - val_mse: 105.2766 - val_mae: 9.0374\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9529 - mse: 0.9529 - mae: 0.7055 - val_loss: 89.6659 - val_mse: 89.6659 - val_mae: 8.4370\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.0007 - mse: 1.0007 - mae: 0.7304 - val_loss: 60.2912 - val_mse: 60.2912 - val_mae: 7.2077\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9134 - mse: 0.9134 - mae: 0.7046 - val_loss: 83.0998 - val_mse: 83.0998 - val_mae: 7.9142\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 1.0360 - mse: 1.0360 - mae: 0.7173 - val_loss: 60.6620 - val_mse: 60.6620 - val_mae: 7.0041\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.9400 - mse: 0.9400 - mae: 0.7041 - val_loss: 43.8986 - val_mse: 43.8986 - val_mae: 6.1962\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.9964 - mse: 0.9964 - mae: 0.7352 - val_loss: 53.0547 - val_mse: 53.0547 - val_mae: 6.4363\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8957 - mse: 0.8957 - mae: 0.6869 - val_loss: 35.1221 - val_mse: 35.1221 - val_mae: 5.5312\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.9603 - mse: 0.9603 - mae: 0.7242 - val_loss: 34.3150 - val_mse: 34.3150 - val_mae: 5.3979\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8154 - mse: 0.8154 - mae: 0.6770 - val_loss: 35.8611 - val_mse: 35.8611 - val_mae: 5.4167\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8591 - mse: 0.8591 - mae: 0.6815 - val_loss: 30.5191 - val_mse: 30.5191 - val_mae: 5.0915\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8375 - mse: 0.8375 - mae: 0.6966 - val_loss: 26.6378 - val_mse: 26.6378 - val_mae: 4.7356\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8064 - mse: 0.8064 - mae: 0.6685 - val_loss: 27.5335 - val_mse: 27.5335 - val_mae: 4.7863\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8196 - mse: 0.8196 - mae: 0.6755 - val_loss: 21.0870 - val_mse: 21.0870 - val_mae: 4.2640\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8060 - mse: 0.8060 - mae: 0.6723 - val_loss: 19.5518 - val_mse: 19.5518 - val_mae: 4.0867\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8045 - mse: 0.8045 - mae: 0.6674 - val_loss: 19.8532 - val_mse: 19.8532 - val_mae: 4.0884\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8239 - mse: 0.8239 - mae: 0.6774 - val_loss: 17.5066 - val_mse: 17.5066 - val_mae: 3.8350\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7935 - mse: 0.7935 - mae: 0.6625 - val_loss: 16.6642 - val_mse: 16.6642 - val_mae: 3.7775\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.8315 - mse: 0.8315 - mae: 0.6900 - val_loss: 13.6703 - val_mse: 13.6703 - val_mae: 3.4000\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8560 - mse: 0.8560 - mae: 0.6804 - val_loss: 15.9129 - val_mse: 15.9129 - val_mae: 3.6105\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8342 - mse: 0.8342 - mae: 0.6710 - val_loss: 10.8162 - val_mse: 10.8162 - val_mae: 3.0437\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8393 - mse: 0.8393 - mae: 0.6822 - val_loss: 12.1261 - val_mse: 12.1261 - val_mae: 3.1583\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7943 - mse: 0.7943 - mae: 0.6579 - val_loss: 10.1896 - val_mse: 10.1896 - val_mae: 2.9639\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8118 - mse: 0.8118 - mae: 0.6788 - val_loss: 9.6064 - val_mse: 9.6064 - val_mae: 2.8100\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7573 - mse: 0.7573 - mae: 0.6446 - val_loss: 9.3603 - val_mse: 9.3603 - val_mae: 2.8335\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7914 - mse: 0.7914 - mae: 0.6688 - val_loss: 8.4994 - val_mse: 8.4994 - val_mae: 2.6491\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7781 - mse: 0.7781 - mae: 0.6613 - val_loss: 8.1983 - val_mse: 8.1983 - val_mae: 2.5967\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7503 - mse: 0.7503 - mae: 0.6425 - val_loss: 7.6983 - val_mse: 7.6983 - val_mae: 2.5322\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7552 - mse: 0.7552 - mae: 0.6600 - val_loss: 6.9807 - val_mse: 6.9807 - val_mae: 2.3744\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7782 - mse: 0.7782 - mae: 0.6502 - val_loss: 7.2087 - val_mse: 7.2087 - val_mae: 2.4677\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.8078 - mse: 0.8078 - mae: 0.6781 - val_loss: 5.3885 - val_mse: 5.3885 - val_mae: 2.1065\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7424 - mse: 0.7424 - mae: 0.6469 - val_loss: 6.3690 - val_mse: 6.3690 - val_mae: 2.2400\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7855 - mse: 0.7855 - mae: 0.6520 - val_loss: 5.1583 - val_mse: 5.1583 - val_mae: 2.0611\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7687 - mse: 0.7687 - mae: 0.6613 - val_loss: 5.1824 - val_mse: 5.1824 - val_mae: 2.0308\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7529 - mse: 0.7529 - mae: 0.6462 - val_loss: 4.6908 - val_mse: 4.6908 - val_mae: 1.9680\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7384 - mse: 0.7384 - mae: 0.6439 - val_loss: 4.3971 - val_mse: 4.3971 - val_mae: 1.8661\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7213 - mse: 0.7213 - mae: 0.6357 - val_loss: 4.1411 - val_mse: 4.1411 - val_mae: 1.8349\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7429 - mse: 0.7429 - mae: 0.6400 - val_loss: 4.1419 - val_mse: 4.1419 - val_mae: 1.8221\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.7224 - mse: 0.7224 - mae: 0.6425 - val_loss: 3.2930 - val_mse: 3.2930 - val_mae: 1.6279\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7263 - mse: 0.7263 - mae: 0.6319 - val_loss: 3.9752 - val_mse: 3.9752 - val_mae: 1.7835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7269 - mse: 0.7269 - mae: 0.6421 - val_loss: 3.0389 - val_mse: 3.0389 - val_mae: 1.5547\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7116 - mse: 0.7116 - mae: 0.6299 - val_loss: 3.2796 - val_mse: 3.2796 - val_mae: 1.6153\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7197 - mse: 0.7197 - mae: 0.6286 - val_loss: 3.3778 - val_mse: 3.3778 - val_mae: 1.6534\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7150 - mse: 0.7150 - mae: 0.6411 - val_loss: 2.4959 - val_mse: 2.4959 - val_mae: 1.4041\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7121 - mse: 0.7121 - mae: 0.6233 - val_loss: 2.9954 - val_mse: 2.9954 - val_mae: 1.5406\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.7048 - mse: 0.7048 - mae: 0.6281 - val_loss: 2.5791 - val_mse: 2.5791 - val_mae: 1.4335\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6924 - mse: 0.6924 - mae: 0.6327 - val_loss: 2.2760 - val_mse: 2.2760 - val_mae: 1.3364\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6904 - mse: 0.6904 - mae: 0.6142 - val_loss: 2.6080 - val_mse: 2.6080 - val_mae: 1.4461\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6961 - mse: 0.6961 - mae: 0.6291 - val_loss: 2.2012 - val_mse: 2.2012 - val_mae: 1.3099\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6828 - mse: 0.6828 - mae: 0.6208 - val_loss: 2.2167 - val_mse: 2.2167 - val_mae: 1.3200\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6853 - mse: 0.6853 - mae: 0.6144 - val_loss: 2.2011 - val_mse: 2.2011 - val_mae: 1.3130\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6793 - mse: 0.6793 - mae: 0.6215 - val_loss: 1.9167 - val_mse: 1.9167 - val_mae: 1.2149\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6850 - mse: 0.6850 - mae: 0.6126 - val_loss: 2.0448 - val_mse: 2.0448 - val_mae: 1.2686\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6937 - mse: 0.6937 - mae: 0.6215 - val_loss: 1.7760 - val_mse: 1.7760 - val_mae: 1.1664\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6951 - mse: 0.6951 - mae: 0.6190 - val_loss: 1.8420 - val_mse: 1.8420 - val_mae: 1.2017\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6978 - mse: 0.6978 - mae: 0.6235 - val_loss: 1.7048 - val_mse: 1.7048 - val_mae: 1.1359\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6782 - mse: 0.6782 - mae: 0.6191 - val_loss: 1.6593 - val_mse: 1.6593 - val_mae: 1.1283\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6643 - mse: 0.6643 - mae: 0.6070 - val_loss: 1.5217 - val_mse: 1.5217 - val_mae: 1.0795\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6666 - mse: 0.6666 - mae: 0.6075 - val_loss: 1.5090 - val_mse: 1.5090 - val_mae: 1.0696\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6783 - mse: 0.6783 - mae: 0.6133 - val_loss: 1.5505 - val_mse: 1.5505 - val_mae: 1.0765\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6703 - mse: 0.6703 - mae: 0.6115 - val_loss: 1.4447 - val_mse: 1.4447 - val_mae: 1.0526\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6677 - mse: 0.6677 - mae: 0.6086 - val_loss: 1.3834 - val_mse: 1.3834 - val_mae: 1.0189\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6519 - mse: 0.6519 - mae: 0.5960 - val_loss: 1.4402 - val_mse: 1.4402 - val_mae: 1.0457\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6612 - mse: 0.6612 - mae: 0.6100 - val_loss: 1.2546 - val_mse: 1.2546 - val_mae: 0.9674\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6481 - mse: 0.6481 - mae: 0.6020 - val_loss: 1.2389 - val_mse: 1.2389 - val_mae: 0.9622\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6612 - mse: 0.6612 - mae: 0.6046 - val_loss: 1.2784 - val_mse: 1.2784 - val_mae: 0.9765\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6383 - mse: 0.6383 - mae: 0.5955 - val_loss: 1.2160 - val_mse: 1.2160 - val_mae: 0.9530\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6525 - mse: 0.6525 - mae: 0.6021 - val_loss: 1.2633 - val_mse: 1.2633 - val_mae: 0.9652\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6554 - mse: 0.6554 - mae: 0.6076 - val_loss: 1.0720 - val_mse: 1.0720 - val_mae: 0.8813\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6356 - mse: 0.6356 - mae: 0.5919 - val_loss: 1.1319 - val_mse: 1.1319 - val_mae: 0.9131\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6425 - mse: 0.6425 - mae: 0.5952 - val_loss: 1.1388 - val_mse: 1.1388 - val_mae: 0.9155\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6366 - mse: 0.6366 - mae: 0.5947 - val_loss: 1.0806 - val_mse: 1.0806 - val_mae: 0.8863\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6316 - mse: 0.6316 - mae: 0.5930 - val_loss: 1.0543 - val_mse: 1.0543 - val_mae: 0.8765\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6424 - mse: 0.6424 - mae: 0.5986 - val_loss: 0.9869 - val_mse: 0.9869 - val_mae: 0.8370\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6518 - mse: 0.6518 - mae: 0.5988 - val_loss: 1.0268 - val_mse: 1.0268 - val_mae: 0.8587\n",
      "Epoch 107/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6380 - mse: 0.6380 - mae: 0.5940 - val_loss: 0.9337 - val_mse: 0.9337 - val_mae: 0.8124\n",
      "Epoch 108/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6237 - mse: 0.6237 - mae: 0.5862 - val_loss: 1.0592 - val_mse: 1.0592 - val_mae: 0.8744\n",
      "Epoch 109/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6354 - mse: 0.6354 - mae: 0.5953 - val_loss: 0.9316 - val_mse: 0.9316 - val_mae: 0.8099\n",
      "Epoch 110/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6266 - mse: 0.6266 - mae: 0.5914 - val_loss: 0.9225 - val_mse: 0.9225 - val_mae: 0.8060\n",
      "Epoch 111/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6266 - mse: 0.6266 - mae: 0.5870 - val_loss: 0.9816 - val_mse: 0.9816 - val_mae: 0.8334\n",
      "Epoch 112/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6358 - mse: 0.6358 - mae: 0.5968 - val_loss: 0.8221 - val_mse: 0.8221 - val_mae: 0.7461\n",
      "Epoch 113/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.6240 - mse: 0.6240 - mae: 0.5866 - val_loss: 0.8609 - val_mse: 0.8609 - val_mae: 0.7690\n",
      "Epoch 114/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6395 - mse: 0.6395 - mae: 0.5909 - val_loss: 0.9527 - val_mse: 0.9527 - val_mae: 0.8157\n",
      "Epoch 115/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6255 - mse: 0.6255 - mae: 0.5915 - val_loss: 0.7917 - val_mse: 0.7917 - val_mae: 0.7284\n",
      "Epoch 116/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6176 - mse: 0.6176 - mae: 0.5816 - val_loss: 0.8753 - val_mse: 0.8753 - val_mae: 0.7739\n",
      "Epoch 117/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6060 - mse: 0.6060 - mae: 0.5744 - val_loss: 0.8646 - val_mse: 0.8646 - val_mae: 0.7767\n",
      "Epoch 118/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6046 - mse: 0.6046 - mae: 0.5841 - val_loss: 0.7437 - val_mse: 0.7437 - val_mae: 0.6974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6052 - mse: 0.6052 - mae: 0.5793 - val_loss: 0.7788 - val_mse: 0.7788 - val_mae: 0.7141\n",
      "Epoch 120/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6004 - mse: 0.6004 - mae: 0.5691 - val_loss: 0.8874 - val_mse: 0.8874 - val_mae: 0.7905\n",
      "Epoch 121/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.6067 - mse: 0.6067 - mae: 0.5812 - val_loss: 0.7566 - val_mse: 0.7566 - val_mae: 0.7045\n",
      "Epoch 122/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5914 - mse: 0.5914 - mae: 0.5708 - val_loss: 0.7897 - val_mse: 0.7897 - val_mae: 0.7276\n",
      "Epoch 123/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5984 - mse: 0.5984 - mae: 0.5763 - val_loss: 0.7654 - val_mse: 0.7654 - val_mae: 0.7141\n",
      "Epoch 124/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5823 - mse: 0.5823 - mae: 0.5661 - val_loss: 0.7408 - val_mse: 0.7408 - val_mae: 0.6964\n",
      "Epoch 125/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5828 - mse: 0.5828 - mae: 0.5660 - val_loss: 0.7558 - val_mse: 0.7558 - val_mae: 0.7042\n",
      "Epoch 126/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5850 - mse: 0.5850 - mae: 0.5636 - val_loss: 0.7692 - val_mse: 0.7692 - val_mae: 0.7175\n",
      "Epoch 127/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5830 - mse: 0.5830 - mae: 0.5699 - val_loss: 0.7069 - val_mse: 0.7069 - val_mae: 0.6722\n",
      "Epoch 128/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5825 - mse: 0.5825 - mae: 0.5663 - val_loss: 0.7467 - val_mse: 0.7467 - val_mae: 0.7034\n",
      "Epoch 129/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5825 - mse: 0.5825 - mae: 0.5652 - val_loss: 0.7578 - val_mse: 0.7578 - val_mae: 0.7115\n",
      "Epoch 130/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5792 - mse: 0.5792 - mae: 0.5689 - val_loss: 0.6903 - val_mse: 0.6903 - val_mae: 0.6583\n",
      "Epoch 131/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5682 - mse: 0.5682 - mae: 0.5590 - val_loss: 0.7037 - val_mse: 0.7037 - val_mae: 0.6725\n",
      "Epoch 132/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5628 - mse: 0.5628 - mae: 0.5536 - val_loss: 0.7156 - val_mse: 0.7156 - val_mae: 0.6810\n",
      "Epoch 133/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5568 - mse: 0.5568 - mae: 0.5543 - val_loss: 0.7204 - val_mse: 0.7204 - val_mae: 0.6835\n",
      "Epoch 134/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5541 - mse: 0.5541 - mae: 0.5521 - val_loss: 0.6743 - val_mse: 0.6743 - val_mae: 0.6461\n",
      "Epoch 135/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5578 - mse: 0.5578 - mae: 0.5511 - val_loss: 0.7185 - val_mse: 0.7185 - val_mae: 0.6850\n",
      "Epoch 136/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5479 - mse: 0.5479 - mae: 0.5498 - val_loss: 0.6999 - val_mse: 0.6999 - val_mae: 0.6673\n",
      "Epoch 137/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5647 - mse: 0.5647 - mae: 0.5612 - val_loss: 0.6707 - val_mse: 0.6707 - val_mae: 0.6315\n",
      "Epoch 138/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5862 - mse: 0.5862 - mae: 0.5632 - val_loss: 0.7083 - val_mse: 0.7083 - val_mae: 0.6583\n",
      "Epoch 139/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5862 - mse: 0.5862 - mae: 0.5554 - val_loss: 0.8120 - val_mse: 0.8120 - val_mae: 0.7382\n",
      "Epoch 140/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5761 - mse: 0.5761 - mae: 0.5683 - val_loss: 0.6457 - val_mse: 0.6457 - val_mae: 0.5974\n",
      "Epoch 141/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5834 - mse: 0.5834 - mae: 0.5646 - val_loss: 0.6642 - val_mse: 0.6642 - val_mae: 0.6358\n",
      "Epoch 142/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5571 - mse: 0.5571 - mae: 0.5467 - val_loss: 0.7660 - val_mse: 0.7660 - val_mae: 0.7164\n",
      "Epoch 143/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5573 - mse: 0.5573 - mae: 0.5643 - val_loss: 0.6132 - val_mse: 0.6132 - val_mae: 0.5746\n",
      "Epoch 144/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5518 - mse: 0.5518 - mae: 0.5510 - val_loss: 0.6938 - val_mse: 0.6938 - val_mae: 0.6698\n",
      "Epoch 145/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5564 - mse: 0.5564 - mae: 0.5492 - val_loss: 0.7285 - val_mse: 0.7285 - val_mae: 0.6944\n",
      "Epoch 146/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5388 - mse: 0.5388 - mae: 0.5554 - val_loss: 0.6259 - val_mse: 0.6259 - val_mae: 0.5921\n",
      "Epoch 147/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5309 - mse: 0.5309 - mae: 0.5349 - val_loss: 0.6755 - val_mse: 0.6755 - val_mae: 0.6528\n",
      "Epoch 148/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5119 - mse: 0.5119 - mae: 0.5251 - val_loss: 0.6558 - val_mse: 0.6558 - val_mae: 0.6363\n",
      "Epoch 149/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5144 - mse: 0.5144 - mae: 0.5391 - val_loss: 0.6091 - val_mse: 0.6091 - val_mae: 0.5876\n",
      "Epoch 150/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5068 - mse: 0.5068 - mae: 0.5239 - val_loss: 0.6459 - val_mse: 0.6459 - val_mae: 0.6247\n",
      "Epoch 151/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.5030 - mse: 0.5030 - mae: 0.5266 - val_loss: 0.6054 - val_mse: 0.6054 - val_mae: 0.5956\n",
      "Epoch 152/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5034 - mse: 0.5034 - mae: 0.5282 - val_loss: 0.6319 - val_mse: 0.6319 - val_mae: 0.6100\n",
      "Epoch 153/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.5167 - mse: 0.5167 - mae: 0.5323 - val_loss: 0.6466 - val_mse: 0.6466 - val_mae: 0.6313\n",
      "Epoch 154/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4846 - mse: 0.4846 - mae: 0.5160 - val_loss: 0.6016 - val_mse: 0.6016 - val_mae: 0.5915\n",
      "Epoch 155/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4713 - mse: 0.4713 - mae: 0.5117 - val_loss: 0.5844 - val_mse: 0.5844 - val_mae: 0.5803\n",
      "Epoch 156/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4670 - mse: 0.4670 - mae: 0.5023 - val_loss: 0.6266 - val_mse: 0.6266 - val_mae: 0.6198\n",
      "Epoch 157/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4624 - mse: 0.4624 - mae: 0.5062 - val_loss: 0.5935 - val_mse: 0.5935 - val_mae: 0.5883\n",
      "Epoch 158/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4590 - mse: 0.4590 - mae: 0.5004 - val_loss: 0.5919 - val_mse: 0.5919 - val_mae: 0.5836\n",
      "Epoch 159/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4604 - mse: 0.4604 - mae: 0.4958 - val_loss: 0.6120 - val_mse: 0.6120 - val_mae: 0.6120\n",
      "Epoch 160/3000\n",
      "10663/10663 [==============================] - 46s 4ms/sample - loss: 0.4452 - mse: 0.4452 - mae: 0.5026 - val_loss: 0.5705 - val_mse: 0.5705 - val_mae: 0.5493\n",
      "Epoch 161/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4414 - mse: 0.4414 - mae: 0.4913 - val_loss: 0.6053 - val_mse: 0.6053 - val_mae: 0.6037\n",
      "Epoch 162/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4434 - mse: 0.4434 - mae: 0.4926 - val_loss: 0.5965 - val_mse: 0.5965 - val_mae: 0.5931\n",
      "Epoch 163/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4516 - mse: 0.4516 - mae: 0.5042 - val_loss: 0.5875 - val_mse: 0.5875 - val_mae: 0.5602\n",
      "Epoch 164/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4787 - mse: 0.4787 - mae: 0.5034 - val_loss: 0.6014 - val_mse: 0.6014 - val_mae: 0.6060\n",
      "Epoch 165/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4293 - mse: 0.4293 - mae: 0.4847 - val_loss: 0.5993 - val_mse: 0.5993 - val_mae: 0.5894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4411 - mse: 0.4411 - mae: 0.4908 - val_loss: 0.6323 - val_mse: 0.6323 - val_mae: 0.6168\n",
      "Epoch 167/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4256 - mse: 0.4256 - mae: 0.4802 - val_loss: 0.5986 - val_mse: 0.5986 - val_mae: 0.5971\n",
      "Epoch 168/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4259 - mse: 0.4259 - mae: 0.4842 - val_loss: 0.6179 - val_mse: 0.6179 - val_mae: 0.6059\n",
      "Epoch 169/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4285 - mse: 0.4285 - mae: 0.4774 - val_loss: 0.5984 - val_mse: 0.5984 - val_mae: 0.5890\n",
      "Epoch 170/3000\n",
      "10663/10663 [==============================] - 45s 4ms/sample - loss: 0.4099 - mse: 0.4099 - mae: 0.4705 - val_loss: 0.5999 - val_mse: 0.5999 - val_mae: 0.6074\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 47s 4ms/sample - loss: 1478.5721 - mse: 1478.5723 - mae: 19.2541 - val_loss: 916460608.0000 - val_mse: 916460608.0000 - val_mae: 22935.6719\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 100.2321 - mse: 100.2321 - mae: 6.7081 - val_loss: 199756096.0000 - val_mse: 199756096.0000 - val_mae: 11372.8291\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 150.0184 - mse: 150.0184 - mae: 8.4934 - val_loss: 10130769.0000 - val_mse: 10130769.0000 - val_mae: 2733.0637\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 26.9330 - mse: 26.9330 - mae: 3.6814 - val_loss: 48943052.0000 - val_mse: 48943052.0000 - val_mae: 5615.9590\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 43.4151 - mse: 43.4151 - mae: 3.3088 - val_loss: 9015337.0000 - val_mse: 9015337.0000 - val_mae: 2383.3162\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 15.7754 - mse: 15.7754 - mae: 3.1559 - val_loss: 199238.7656 - val_mse: 199238.7656 - val_mae: 380.7322\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 26.1929 - mse: 26.1929 - mae: 3.6970 - val_loss: 157895.9688 - val_mse: 157895.9688 - val_mae: 333.2871\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 5.9872 - mse: 5.9872 - mae: 1.6510 - val_loss: 580834.7500 - val_mse: 580834.7500 - val_mae: 592.7503\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 12.7267 - mse: 12.7267 - mae: 2.2060 - val_loss: 213957.2656 - val_mse: 213957.2656 - val_mae: 360.4539\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 5.8838 - mse: 5.8838 - mae: 1.7479 - val_loss: 9872.0117 - val_mse: 9872.0117 - val_mae: 84.4769\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 7.3118 - mse: 7.3118 - mae: 1.5730 - val_loss: 9881.6738 - val_mse: 9881.6738 - val_mae: 81.4985\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 2.7246 - mse: 2.7246 - mae: 1.1280 - val_loss: 42710.3242 - val_mse: 42710.3242 - val_mae: 150.2743\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 4.7239 - mse: 4.7239 - mae: 1.3991 - val_loss: 21219.2246 - val_mse: 21219.2246 - val_mae: 104.7564\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 2.3670 - mse: 2.3670 - mae: 1.1606 - val_loss: 2435.5991 - val_mse: 2435.5991 - val_mae: 38.5927\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 2.7999 - mse: 2.7999 - mae: 1.1726 - val_loss: 2216.9199 - val_mse: 2216.9199 - val_mae: 36.4628\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 1.5644 - mse: 1.5644 - mae: 0.9183 - val_loss: 4637.1597 - val_mse: 4637.1597 - val_mae: 49.0096\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 2.2440 - mse: 2.2440 - mae: 1.0469 - val_loss: 1649.0983 - val_mse: 1649.0983 - val_mae: 30.6098\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 1.2888 - mse: 1.2888 - mae: 0.8463 - val_loss: 403.9709 - val_mse: 403.9709 - val_mae: 16.3915\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 1.4842 - mse: 1.4842 - mae: 0.8747 - val_loss: 894.8368 - val_mse: 894.8368 - val_mae: 21.4790\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 1.1373 - mse: 1.1373 - mae: 0.7872 - val_loss: 1044.5848 - val_mse: 1044.5848 - val_mae: 22.0878\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 1.2006 - mse: 1.2006 - mae: 0.8000 - val_loss: 352.3224 - val_mse: 352.3224 - val_mae: 13.9666\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 1.1184 - mse: 1.1184 - mae: 0.7886 - val_loss: 202.2034 - val_mse: 202.2034 - val_mae: 11.2453\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 1.0436 - mse: 1.0436 - mae: 0.7621 - val_loss: 332.3867 - val_mse: 332.3867 - val_mae: 13.3108\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 1.0558 - mse: 1.0558 - mae: 0.7651 - val_loss: 178.6888 - val_mse: 178.6888 - val_mae: 10.2315\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.9470 - mse: 0.9470 - mae: 0.7365 - val_loss: 110.6944 - val_mse: 110.6944 - val_mae: 8.2475\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.9514 - mse: 0.9514 - mae: 0.7281 - val_loss: 143.0541 - val_mse: 143.0541 - val_mae: 8.6908\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.9202 - mse: 0.9202 - mae: 0.7243 - val_loss: 94.3176 - val_mse: 94.3176 - val_mae: 7.3249\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8931 - mse: 0.8931 - mae: 0.7140 - val_loss: 62.0125 - val_mse: 62.0125 - val_mae: 6.2817\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8838 - mse: 0.8838 - mae: 0.7142 - val_loss: 65.8063 - val_mse: 65.8063 - val_mae: 6.2768\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.9203 - mse: 0.9203 - mae: 0.7138 - val_loss: 63.6011 - val_mse: 63.6011 - val_mae: 6.0679\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8764 - mse: 0.8764 - mae: 0.7100 - val_loss: 34.9529 - val_mse: 34.9529 - val_mae: 4.8359\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8894 - mse: 0.8894 - mae: 0.7111 - val_loss: 40.4073 - val_mse: 40.4073 - val_mae: 4.9635\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8652 - mse: 0.8652 - mae: 0.7007 - val_loss: 35.3401 - val_mse: 35.3401 - val_mae: 4.6151\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8610 - mse: 0.8610 - mae: 0.7033 - val_loss: 27.2382 - val_mse: 27.2382 - val_mae: 4.1751\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8419 - mse: 0.8419 - mae: 0.6916 - val_loss: 28.2118 - val_mse: 28.2118 - val_mae: 4.1580\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8397 - mse: 0.8397 - mae: 0.6955 - val_loss: 20.6311 - val_mse: 20.6311 - val_mae: 3.6872\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8309 - mse: 0.8309 - mae: 0.6831 - val_loss: 18.9948 - val_mse: 18.9948 - val_mae: 3.5900\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8302 - mse: 0.8302 - mae: 0.6972 - val_loss: 16.4569 - val_mse: 16.4569 - val_mae: 3.2241\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8338 - mse: 0.8338 - mae: 0.6834 - val_loss: 17.1010 - val_mse: 17.1010 - val_mae: 3.3150\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8138 - mse: 0.8138 - mae: 0.6850 - val_loss: 11.1282 - val_mse: 11.1282 - val_mae: 2.8220\n",
      "Epoch 41/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.8201 - mse: 0.8201 - mae: 0.6894 - val_loss: 12.6433 - val_mse: 12.6433 - val_mae: 2.8994\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8102 - mse: 0.8102 - mae: 0.6738 - val_loss: 13.1242 - val_mse: 13.1242 - val_mae: 2.8924\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8037 - mse: 0.8037 - mae: 0.6874 - val_loss: 7.8685 - val_mse: 7.8685 - val_mae: 2.3612\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.8237 - mse: 0.8237 - mae: 0.6769 - val_loss: 9.2886 - val_mse: 9.2886 - val_mae: 2.5946\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8172 - mse: 0.8172 - mae: 0.6869 - val_loss: 9.3414 - val_mse: 9.3414 - val_mae: 2.4469\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.7957 - mse: 0.7957 - mae: 0.6794 - val_loss: 5.9021 - val_mse: 5.9021 - val_mae: 2.1126\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8023 - mse: 0.8023 - mae: 0.6689 - val_loss: 8.7003 - val_mse: 8.7003 - val_mae: 2.3682\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.8117 - mse: 0.8117 - mae: 0.6882 - val_loss: 6.8300 - val_mse: 6.8300 - val_mae: 2.0751\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.8020 - mse: 0.8020 - mae: 0.6704 - val_loss: 5.2147 - val_mse: 5.2147 - val_mae: 1.9925\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7705 - mse: 0.7705 - mae: 0.6654 - val_loss: 6.0937 - val_mse: 6.0937 - val_mae: 1.9799\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.7847 - mse: 0.7847 - mae: 0.6662 - val_loss: 4.8391 - val_mse: 4.8391 - val_mae: 1.8680\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7765 - mse: 0.7765 - mae: 0.6623 - val_loss: 4.6837 - val_mse: 4.6837 - val_mae: 1.8395\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.7864 - mse: 0.7864 - mae: 0.6693 - val_loss: 4.6817 - val_mse: 4.6817 - val_mae: 1.7694\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7657 - mse: 0.7657 - mae: 0.6568 - val_loss: 3.6427 - val_mse: 3.6427 - val_mae: 1.6676\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7485 - mse: 0.7485 - mae: 0.6567 - val_loss: 4.2407 - val_mse: 4.2407 - val_mae: 1.6500\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7591 - mse: 0.7591 - mae: 0.6535 - val_loss: 3.8818 - val_mse: 3.8818 - val_mae: 1.6524\n",
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.7507 - mse: 0.7507 - mae: 0.6572 - val_loss: 3.0581 - val_mse: 3.0581 - val_mae: 1.5062\n",
      "Epoch 58/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7525 - mse: 0.7525 - mae: 0.6568 - val_loss: 3.1690 - val_mse: 3.1690 - val_mae: 1.5049\n",
      "Epoch 59/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7471 - mse: 0.7471 - mae: 0.6496 - val_loss: 3.2089 - val_mse: 3.2089 - val_mae: 1.5049\n",
      "Epoch 60/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7342 - mse: 0.7342 - mae: 0.6525 - val_loss: 2.7208 - val_mse: 2.7208 - val_mae: 1.3531\n",
      "Epoch 61/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7409 - mse: 0.7409 - mae: 0.6441 - val_loss: 2.7531 - val_mse: 2.7531 - val_mae: 1.4254\n",
      "Epoch 62/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7450 - mse: 0.7450 - mae: 0.6491 - val_loss: 2.6075 - val_mse: 2.6075 - val_mae: 1.3660\n",
      "Epoch 63/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.7587 - mse: 0.7587 - mae: 0.6554 - val_loss: 2.4459 - val_mse: 2.4459 - val_mae: 1.2971\n",
      "Epoch 64/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.7311 - mse: 0.7311 - mae: 0.6401 - val_loss: 2.1030 - val_mse: 2.1030 - val_mae: 1.2655\n",
      "Epoch 65/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7229 - mse: 0.7229 - mae: 0.6450 - val_loss: 2.6384 - val_mse: 2.6384 - val_mae: 1.2822\n",
      "Epoch 66/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7431 - mse: 0.7431 - mae: 0.6477 - val_loss: 1.9944 - val_mse: 1.9944 - val_mae: 1.2011\n",
      "Epoch 67/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7290 - mse: 0.7290 - mae: 0.6394 - val_loss: 1.9022 - val_mse: 1.9022 - val_mae: 1.1779\n",
      "Epoch 68/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7123 - mse: 0.7123 - mae: 0.6377 - val_loss: 1.9541 - val_mse: 1.9541 - val_mae: 1.1654\n",
      "Epoch 69/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7073 - mse: 0.7073 - mae: 0.6356 - val_loss: 1.7311 - val_mse: 1.7311 - val_mae: 1.1005\n",
      "Epoch 70/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.7112 - mse: 0.7112 - mae: 0.6310 - val_loss: 1.8902 - val_mse: 1.8902 - val_mae: 1.1500\n",
      "Epoch 71/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7087 - mse: 0.7087 - mae: 0.6344 - val_loss: 1.6180 - val_mse: 1.6180 - val_mae: 1.0716\n",
      "Epoch 72/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7057 - mse: 0.7057 - mae: 0.6313 - val_loss: 1.6668 - val_mse: 1.6668 - val_mae: 1.1074\n",
      "Epoch 73/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7041 - mse: 0.7041 - mae: 0.6298 - val_loss: 1.5300 - val_mse: 1.5300 - val_mae: 1.0250\n",
      "Epoch 74/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6956 - mse: 0.6956 - mae: 0.6277 - val_loss: 1.4258 - val_mse: 1.4258 - val_mae: 1.0181\n",
      "Epoch 75/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6939 - mse: 0.6939 - mae: 0.6233 - val_loss: 1.6813 - val_mse: 1.6813 - val_mae: 1.0796\n",
      "Epoch 76/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7032 - mse: 0.7032 - mae: 0.6390 - val_loss: 1.2428 - val_mse: 1.2428 - val_mae: 0.9318\n",
      "Epoch 77/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.7075 - mse: 0.7075 - mae: 0.6285 - val_loss: 1.3859 - val_mse: 1.3859 - val_mae: 0.9950\n",
      "Epoch 78/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6842 - mse: 0.6842 - mae: 0.6238 - val_loss: 1.3270 - val_mse: 1.3270 - val_mae: 0.9283\n",
      "Epoch 79/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6857 - mse: 0.6857 - mae: 0.6211 - val_loss: 1.2065 - val_mse: 1.2065 - val_mae: 0.9296\n",
      "Epoch 80/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6926 - mse: 0.6926 - mae: 0.6210 - val_loss: 1.2219 - val_mse: 1.2219 - val_mae: 0.9076\n",
      "Epoch 81/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6990 - mse: 0.6990 - mae: 0.6264 - val_loss: 1.2307 - val_mse: 1.2307 - val_mae: 0.9287\n",
      "Epoch 82/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.6870 - mse: 0.6870 - mae: 0.6209 - val_loss: 1.1411 - val_mse: 1.1411 - val_mae: 0.8889\n",
      "Epoch 83/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6858 - mse: 0.6858 - mae: 0.6183 - val_loss: 1.1704 - val_mse: 1.1704 - val_mae: 0.9033\n",
      "Epoch 84/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6936 - mse: 0.6936 - mae: 0.6239 - val_loss: 1.0748 - val_mse: 1.0748 - val_mae: 0.8355\n",
      "Epoch 85/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6823 - mse: 0.6823 - mae: 0.6178 - val_loss: 1.0831 - val_mse: 1.0831 - val_mae: 0.8748\n",
      "Epoch 86/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6609 - mse: 0.6609 - mae: 0.6112 - val_loss: 1.1081 - val_mse: 1.1081 - val_mae: 0.8518\n",
      "Epoch 87/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6812 - mse: 0.6812 - mae: 0.6231 - val_loss: 0.9149 - val_mse: 0.9149 - val_mae: 0.7927\n",
      "Epoch 88/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6980 - mse: 0.6980 - mae: 0.6180 - val_loss: 1.1450 - val_mse: 1.1450 - val_mae: 0.8860\n",
      "Epoch 89/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6857 - mse: 0.6857 - mae: 0.6237 - val_loss: 0.9905 - val_mse: 0.9905 - val_mae: 0.8087\n",
      "Epoch 90/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.7224 - mse: 0.7224 - mae: 0.6358 - val_loss: 0.8922 - val_mse: 0.8922 - val_mae: 0.7732\n",
      "Epoch 91/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6880 - mse: 0.6880 - mae: 0.6113 - val_loss: 1.0445 - val_mse: 1.0445 - val_mae: 0.8368\n",
      "Epoch 92/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6824 - mse: 0.6824 - mae: 0.6209 - val_loss: 0.7947 - val_mse: 0.7947 - val_mae: 0.7223\n",
      "Epoch 93/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6500 - mse: 0.6500 - mae: 0.6038 - val_loss: 1.0121 - val_mse: 1.0121 - val_mae: 0.8038\n",
      "Epoch 94/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6607 - mse: 0.6607 - mae: 0.6016 - val_loss: 0.8635 - val_mse: 0.8635 - val_mae: 0.7658\n",
      "Epoch 95/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6630 - mse: 0.6630 - mae: 0.6096 - val_loss: 0.8406 - val_mse: 0.8406 - val_mae: 0.7414\n",
      "Epoch 96/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6381 - mse: 0.6381 - mae: 0.5965 - val_loss: 0.8062 - val_mse: 0.8062 - val_mae: 0.7327\n",
      "Epoch 97/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.6566 - mse: 0.6566 - mae: 0.6048 - val_loss: 0.8768 - val_mse: 0.8768 - val_mae: 0.7432\n",
      "Epoch 98/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6383 - mse: 0.6383 - mae: 0.5980 - val_loss: 0.8061 - val_mse: 0.8061 - val_mae: 0.7298\n",
      "Epoch 99/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6449 - mse: 0.6449 - mae: 0.5979 - val_loss: 0.8425 - val_mse: 0.8425 - val_mae: 0.7427\n",
      "Epoch 100/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6441 - mse: 0.6441 - mae: 0.6037 - val_loss: 0.7994 - val_mse: 0.7994 - val_mae: 0.7240\n",
      "Epoch 101/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6374 - mse: 0.6374 - mae: 0.5971 - val_loss: 0.7738 - val_mse: 0.7738 - val_mae: 0.7091\n",
      "Epoch 102/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.6303 - mse: 0.6303 - mae: 0.5927 - val_loss: 0.7656 - val_mse: 0.7656 - val_mae: 0.6984\n",
      "Epoch 103/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6275 - mse: 0.6275 - mae: 0.5919 - val_loss: 0.7784 - val_mse: 0.7784 - val_mae: 0.7113\n",
      "Epoch 104/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.6322 - mse: 0.6322 - mae: 0.5920 - val_loss: 0.7522 - val_mse: 0.7522 - val_mae: 0.6997\n",
      "Epoch 105/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.6311 - mse: 0.6311 - mae: 0.5944 - val_loss: 0.7024 - val_mse: 0.7024 - val_mae: 0.6617\n",
      "Epoch 106/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6327 - mse: 0.6327 - mae: 0.5943 - val_loss: 0.7110 - val_mse: 0.7110 - val_mae: 0.6672\n",
      "Epoch 107/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6159 - mse: 0.6159 - mae: 0.5813 - val_loss: 0.7837 - val_mse: 0.7837 - val_mae: 0.7231\n",
      "Epoch 108/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.6130 - mse: 0.6130 - mae: 0.5902 - val_loss: 0.7144 - val_mse: 0.7144 - val_mae: 0.6609\n",
      "Epoch 109/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6202 - mse: 0.6202 - mae: 0.5888 - val_loss: 0.7100 - val_mse: 0.7100 - val_mae: 0.6687\n",
      "Epoch 110/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6094 - mse: 0.6094 - mae: 0.5801 - val_loss: 0.7378 - val_mse: 0.7378 - val_mae: 0.6892\n",
      "Epoch 111/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.6159 - mse: 0.6159 - mae: 0.5887 - val_loss: 0.6727 - val_mse: 0.6727 - val_mae: 0.6357\n",
      "Epoch 112/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6106 - mse: 0.6106 - mae: 0.5834 - val_loss: 0.7073 - val_mse: 0.7073 - val_mae: 0.6650\n",
      "Epoch 113/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6085 - mse: 0.6085 - mae: 0.5770 - val_loss: 0.7130 - val_mse: 0.7130 - val_mae: 0.6763\n",
      "Epoch 114/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.5998 - mse: 0.5998 - mae: 0.5858 - val_loss: 0.6644 - val_mse: 0.6644 - val_mae: 0.6268\n",
      "Epoch 115/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6191 - mse: 0.6191 - mae: 0.5787 - val_loss: 0.7695 - val_mse: 0.7695 - val_mae: 0.7112\n",
      "Epoch 116/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6378 - mse: 0.6378 - mae: 0.5958 - val_loss: 0.6505 - val_mse: 0.6505 - val_mae: 0.6187\n",
      "Epoch 117/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6417 - mse: 0.6417 - mae: 0.6036 - val_loss: 0.6687 - val_mse: 0.6687 - val_mae: 0.6180\n",
      "Epoch 118/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6494 - mse: 0.6494 - mae: 0.5895 - val_loss: 0.7832 - val_mse: 0.7832 - val_mae: 0.7214\n",
      "Epoch 119/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6742 - mse: 0.6742 - mae: 0.6134 - val_loss: 0.6668 - val_mse: 0.6668 - val_mae: 0.6244\n",
      "Epoch 120/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6442 - mse: 0.6442 - mae: 0.5972 - val_loss: 0.6544 - val_mse: 0.6544 - val_mae: 0.6245\n",
      "Epoch 121/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6379 - mse: 0.6379 - mae: 0.5817 - val_loss: 0.6777 - val_mse: 0.6777 - val_mae: 0.6361\n",
      "Epoch 122/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6531 - mse: 0.6531 - mae: 0.5903 - val_loss: 0.6544 - val_mse: 0.6544 - val_mae: 0.6226\n",
      "Epoch 123/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6382 - mse: 0.6382 - mae: 0.5925 - val_loss: 0.6580 - val_mse: 0.6580 - val_mae: 0.6242\n",
      "Epoch 124/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.6435 - mse: 0.6435 - mae: 0.5826 - val_loss: 0.7423 - val_mse: 0.7423 - val_mae: 0.6874\n",
      "Epoch 125/3000\n",
      "10664/10664 [==============================] - 46s 4ms/sample - loss: 0.6195 - mse: 0.6195 - mae: 0.5893 - val_loss: 0.7569 - val_mse: 0.7569 - val_mae: 0.6960\n",
      "Epoch 126/3000\n",
      "10664/10664 [==============================] - 45s 4ms/sample - loss: 0.6163 - mse: 0.6163 - mae: 0.5831 - val_loss: 0.8684 - val_mse: 0.8684 - val_mae: 0.7574\n",
      "Avg. MAE: 0.490276\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 169us/sample - loss: 1.9719 - mse: 1.9719 - mae: 0.9862 - val_loss: 1.4212 - val_mse: 1.4212 - val_mae: 0.8643\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.8846 - mse: 0.8846 - mae: 0.7084 - val_loss: 1.3214 - val_mse: 1.3214 - val_mae: 0.9645\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.6984 - mse: 0.6984 - mae: 0.6293 - val_loss: 1.0863 - val_mse: 1.0863 - val_mae: 0.8310\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.5884 - mse: 0.5884 - mae: 0.5806 - val_loss: 1.0131 - val_mse: 1.0131 - val_mae: 0.7886\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.5317 - mse: 0.5317 - mae: 0.5512 - val_loss: 1.1543 - val_mse: 1.1543 - val_mae: 0.8963\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.4850 - mse: 0.4850 - mae: 0.5257 - val_loss: 1.0272 - val_mse: 1.0272 - val_mae: 0.8162\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4476 - mse: 0.4476 - mae: 0.5032 - val_loss: 1.0143 - val_mse: 1.0143 - val_mae: 0.8091\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4128 - mse: 0.4128 - mae: 0.4830 - val_loss: 0.9998 - val_mse: 0.9998 - val_mae: 0.7964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3872 - mse: 0.3872 - mae: 0.4665 - val_loss: 0.9815 - val_mse: 0.9815 - val_mae: 0.7888\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3698 - mse: 0.3698 - mae: 0.4572 - val_loss: 0.9854 - val_mse: 0.9854 - val_mae: 0.7980\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3440 - mse: 0.3440 - mae: 0.4398 - val_loss: 0.9449 - val_mse: 0.9449 - val_mae: 0.7686\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3283 - mse: 0.3283 - mae: 0.4278 - val_loss: 0.9287 - val_mse: 0.9287 - val_mae: 0.7550\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3181 - mse: 0.3181 - mae: 0.4210 - val_loss: 0.9207 - val_mse: 0.9207 - val_mae: 0.7570\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2995 - mse: 0.2995 - mae: 0.4094 - val_loss: 0.9072 - val_mse: 0.9072 - val_mae: 0.7466\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2901 - mse: 0.2901 - mae: 0.4037 - val_loss: 0.8894 - val_mse: 0.8894 - val_mae: 0.7376\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2784 - mse: 0.2784 - mae: 0.3959 - val_loss: 0.8856 - val_mse: 0.8856 - val_mae: 0.7307\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2637 - mse: 0.2637 - mae: 0.3841 - val_loss: 0.8730 - val_mse: 0.8730 - val_mae: 0.7218\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2566 - mse: 0.2566 - mae: 0.3781 - val_loss: 0.8651 - val_mse: 0.8651 - val_mae: 0.7148\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2463 - mse: 0.2463 - mae: 0.3720 - val_loss: 0.8562 - val_mse: 0.8562 - val_mae: 0.7099\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2364 - mse: 0.2364 - mae: 0.3657 - val_loss: 0.8326 - val_mse: 0.8326 - val_mae: 0.6998\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2312 - mse: 0.2312 - mae: 0.3624 - val_loss: 0.8127 - val_mse: 0.8127 - val_mae: 0.6959\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2193 - mse: 0.2193 - mae: 0.3508 - val_loss: 0.8206 - val_mse: 0.8206 - val_mae: 0.6923\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2169 - mse: 0.2169 - mae: 0.3499 - val_loss: 0.7886 - val_mse: 0.7886 - val_mae: 0.6832\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2125 - mse: 0.2125 - mae: 0.3453 - val_loss: 0.8083 - val_mse: 0.8083 - val_mae: 0.6864\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2069 - mse: 0.2069 - mae: 0.3424 - val_loss: 0.7781 - val_mse: 0.7781 - val_mae: 0.6776\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2010 - mse: 0.2010 - mae: 0.3378 - val_loss: 0.7706 - val_mse: 0.7706 - val_mae: 0.6705\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1917 - mse: 0.1917 - mae: 0.3287 - val_loss: 0.7726 - val_mse: 0.7726 - val_mae: 0.6735\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1895 - mse: 0.1895 - mae: 0.3282 - val_loss: 0.7336 - val_mse: 0.7336 - val_mae: 0.6566\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1825 - mse: 0.1825 - mae: 0.3221 - val_loss: 0.7263 - val_mse: 0.7263 - val_mae: 0.6554\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1792 - mse: 0.1792 - mae: 0.3189 - val_loss: 0.7125 - val_mse: 0.7125 - val_mae: 0.6448\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1707 - mse: 0.1707 - mae: 0.3108 - val_loss: 0.7267 - val_mse: 0.7267 - val_mae: 0.6490\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1724 - mse: 0.1724 - mae: 0.3130 - val_loss: 0.6839 - val_mse: 0.6839 - val_mae: 0.6290\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1649 - mse: 0.1649 - mae: 0.3068 - val_loss: 0.6866 - val_mse: 0.6866 - val_mae: 0.6273\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1600 - mse: 0.1600 - mae: 0.3038 - val_loss: 0.6711 - val_mse: 0.6711 - val_mae: 0.6217\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1578 - mse: 0.1578 - mae: 0.3015 - val_loss: 0.6644 - val_mse: 0.6644 - val_mae: 0.6150\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1533 - mse: 0.1533 - mae: 0.2961 - val_loss: 0.6677 - val_mse: 0.6677 - val_mae: 0.6149\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1528 - mse: 0.1528 - mae: 0.2959 - val_loss: 0.6283 - val_mse: 0.6283 - val_mae: 0.5984\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1470 - mse: 0.1470 - mae: 0.2921 - val_loss: 0.6282 - val_mse: 0.6282 - val_mae: 0.5998\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1436 - mse: 0.1436 - mae: 0.2865 - val_loss: 0.6423 - val_mse: 0.6423 - val_mae: 0.5997\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1435 - mse: 0.1435 - mae: 0.2870 - val_loss: 0.6059 - val_mse: 0.6059 - val_mae: 0.5882\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1396 - mse: 0.1396 - mae: 0.2852 - val_loss: 0.5897 - val_mse: 0.5897 - val_mae: 0.5809\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1407 - mse: 0.1407 - mae: 0.2851 - val_loss: 0.5941 - val_mse: 0.5941 - val_mae: 0.5782\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1305 - mse: 0.1305 - mae: 0.2731 - val_loss: 0.5984 - val_mse: 0.5984 - val_mae: 0.5813\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1316 - mse: 0.1316 - mae: 0.2749 - val_loss: 0.5727 - val_mse: 0.5727 - val_mae: 0.5701\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1348 - mse: 0.1348 - mae: 0.2802 - val_loss: 0.5996 - val_mse: 0.5996 - val_mae: 0.5794\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1347 - mse: 0.1347 - mae: 0.2789 - val_loss: 0.5807 - val_mse: 0.5807 - val_mae: 0.5716\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1267 - mse: 0.1267 - mae: 0.2713 - val_loss: 0.5496 - val_mse: 0.5496 - val_mae: 0.5574\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1276 - mse: 0.1276 - mae: 0.2712 - val_loss: 0.5727 - val_mse: 0.5727 - val_mae: 0.5661\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1254 - mse: 0.1254 - mae: 0.2684 - val_loss: 0.5493 - val_mse: 0.5493 - val_mae: 0.5574\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1173 - mse: 0.1173 - mae: 0.2605 - val_loss: 0.5463 - val_mse: 0.5463 - val_mae: 0.5518\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1125 - mse: 0.1125 - mae: 0.2561 - val_loss: 0.5534 - val_mse: 0.5534 - val_mae: 0.5543\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1150 - mse: 0.1150 - mae: 0.2554 - val_loss: 0.5287 - val_mse: 0.5287 - val_mae: 0.5451\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1152 - mse: 0.1152 - mae: 0.2577 - val_loss: 0.5493 - val_mse: 0.5493 - val_mae: 0.5482\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1136 - mse: 0.1136 - mae: 0.2550 - val_loss: 0.5318 - val_mse: 0.5318 - val_mae: 0.5453\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1149 - mse: 0.1149 - mae: 0.2568 - val_loss: 0.5222 - val_mse: 0.5222 - val_mae: 0.5359\n",
      "Epoch 56/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1175 - mse: 0.1175 - mae: 0.2592 - val_loss: 0.5455 - val_mse: 0.5455 - val_mae: 0.5524\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1144 - mse: 0.1144 - mae: 0.2575 - val_loss: 0.5281 - val_mse: 0.5281 - val_mae: 0.5389\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1078 - mse: 0.1078 - mae: 0.2485 - val_loss: 0.5113 - val_mse: 0.5113 - val_mae: 0.5308\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1071 - mse: 0.1071 - mae: 0.2486 - val_loss: 0.5135 - val_mse: 0.5135 - val_mae: 0.5319\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1076 - mse: 0.1076 - mae: 0.2472 - val_loss: 0.5258 - val_mse: 0.5258 - val_mae: 0.5371\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1080 - mse: 0.1080 - mae: 0.2504 - val_loss: 0.5155 - val_mse: 0.5155 - val_mae: 0.5346\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1073 - mse: 0.1073 - mae: 0.2489 - val_loss: 0.5023 - val_mse: 0.5023 - val_mae: 0.5250\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0961 - mse: 0.0961 - mae: 0.2376 - val_loss: 0.5068 - val_mse: 0.5068 - val_mae: 0.5240\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0971 - mse: 0.0971 - mae: 0.2373 - val_loss: 0.5015 - val_mse: 0.5015 - val_mae: 0.5239\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0980 - mse: 0.0980 - mae: 0.2388 - val_loss: 0.5058 - val_mse: 0.5058 - val_mae: 0.5253\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0957 - mse: 0.0957 - mae: 0.2352 - val_loss: 0.4997 - val_mse: 0.4997 - val_mae: 0.5225\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0938 - mse: 0.0938 - mae: 0.2324 - val_loss: 0.5124 - val_mse: 0.5124 - val_mae: 0.5254\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.1017 - mse: 0.1017 - mae: 0.2404 - val_loss: 0.4965 - val_mse: 0.4965 - val_mae: 0.5208\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1020 - mse: 0.1020 - mae: 0.2424 - val_loss: 0.5103 - val_mse: 0.5103 - val_mae: 0.5262\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0997 - mse: 0.0997 - mae: 0.2399 - val_loss: 0.5063 - val_mse: 0.5063 - val_mae: 0.5267\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0970 - mse: 0.0970 - mae: 0.2335 - val_loss: 0.5011 - val_mse: 0.5011 - val_mae: 0.5194\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0934 - mse: 0.0934 - mae: 0.2307 - val_loss: 0.5031 - val_mse: 0.5031 - val_mae: 0.5263\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0986 - mse: 0.0986 - mae: 0.2371 - val_loss: 0.5105 - val_mse: 0.5105 - val_mae: 0.5241\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0986 - mse: 0.0986 - mae: 0.2365 - val_loss: 0.4893 - val_mse: 0.4893 - val_mae: 0.5165\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0949 - mse: 0.0949 - mae: 0.2331 - val_loss: 0.4927 - val_mse: 0.4927 - val_mae: 0.5182\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0940 - mse: 0.0940 - mae: 0.2336 - val_loss: 0.4926 - val_mse: 0.4926 - val_mae: 0.5147\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0884 - mse: 0.0884 - mae: 0.2257 - val_loss: 0.4856 - val_mse: 0.4856 - val_mae: 0.5103\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0889 - mse: 0.0889 - mae: 0.2253 - val_loss: 0.4802 - val_mse: 0.4802 - val_mae: 0.5136\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0841 - mse: 0.0841 - mae: 0.2213 - val_loss: 0.4816 - val_mse: 0.4816 - val_mae: 0.5108\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0853 - mse: 0.0853 - mae: 0.2217 - val_loss: 0.4860 - val_mse: 0.4860 - val_mae: 0.5105\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0812 - mse: 0.0812 - mae: 0.2171 - val_loss: 0.4869 - val_mse: 0.4869 - val_mae: 0.5154\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0813 - mse: 0.0813 - mae: 0.2179 - val_loss: 0.4875 - val_mse: 0.4875 - val_mae: 0.5092\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0812 - mse: 0.0812 - mae: 0.2174 - val_loss: 0.4953 - val_mse: 0.4953 - val_mae: 0.5190\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0814 - mse: 0.0814 - mae: 0.2170 - val_loss: 0.4889 - val_mse: 0.4889 - val_mae: 0.5109\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0781 - mse: 0.0781 - mae: 0.2134 - val_loss: 0.4935 - val_mse: 0.4935 - val_mae: 0.5145\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0806 - mse: 0.0806 - mae: 0.2171 - val_loss: 0.4850 - val_mse: 0.4850 - val_mae: 0.5121\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0780 - mse: 0.0780 - mae: 0.2118 - val_loss: 0.4758 - val_mse: 0.4758 - val_mae: 0.5059\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0808 - mse: 0.0808 - mae: 0.2166 - val_loss: 0.4893 - val_mse: 0.4893 - val_mae: 0.5111\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0800 - mse: 0.0800 - mae: 0.2144 - val_loss: 0.4898 - val_mse: 0.4898 - val_mae: 0.5105\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0773 - mse: 0.0773 - mae: 0.2107 - val_loss: 0.4897 - val_mse: 0.4897 - val_mae: 0.5117\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0747 - mse: 0.0747 - mae: 0.2069 - val_loss: 0.4892 - val_mse: 0.4892 - val_mae: 0.5095\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0689 - mse: 0.0689 - mae: 0.1999 - val_loss: 0.4920 - val_mse: 0.4920 - val_mae: 0.5116\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0693 - mse: 0.0693 - mae: 0.2012 - val_loss: 0.4987 - val_mse: 0.4987 - val_mae: 0.5117\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0678 - mse: 0.0678 - mae: 0.1983 - val_loss: 0.4875 - val_mse: 0.4875 - val_mae: 0.5061\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0688 - mse: 0.0688 - mae: 0.1998 - val_loss: 0.4846 - val_mse: 0.4846 - val_mae: 0.5069\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0688 - mse: 0.0688 - mae: 0.1998 - val_loss: 0.4858 - val_mse: 0.4858 - val_mae: 0.5097\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0728 - mse: 0.0728 - mae: 0.2045 - val_loss: 0.4898 - val_mse: 0.4898 - val_mae: 0.5085\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 130us/sample - loss: 1.9227 - mse: 1.9227 - mae: 0.9787 - val_loss: 1.9542 - val_mse: 1.9542 - val_mae: 1.0015\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.9079 - mse: 0.9079 - mae: 0.7248 - val_loss: 1.2230 - val_mse: 1.2230 - val_mae: 0.8870\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.7013 - mse: 0.7013 - mae: 0.6371 - val_loss: 1.1131 - val_mse: 1.1131 - val_mae: 0.8121\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.5867 - mse: 0.5867 - mae: 0.5840 - val_loss: 1.0666 - val_mse: 1.0666 - val_mae: 0.7776\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.5223 - mse: 0.5223 - mae: 0.5481 - val_loss: 1.0355 - val_mse: 1.0355 - val_mae: 0.7816\n",
      "Epoch 6/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4779 - mse: 0.4779 - mae: 0.5215 - val_loss: 1.0214 - val_mse: 1.0214 - val_mae: 0.7816\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4357 - mse: 0.4357 - mae: 0.4966 - val_loss: 1.0206 - val_mse: 1.0206 - val_mae: 0.7721\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4094 - mse: 0.4094 - mae: 0.4795 - val_loss: 1.0109 - val_mse: 1.0109 - val_mae: 0.7674\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3840 - mse: 0.3840 - mae: 0.4645 - val_loss: 1.0036 - val_mse: 1.0036 - val_mae: 0.7604\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3689 - mse: 0.3689 - mae: 0.4546 - val_loss: 1.0065 - val_mse: 1.0065 - val_mae: 0.7707\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3465 - mse: 0.3465 - mae: 0.4437 - val_loss: 1.0066 - val_mse: 1.0066 - val_mae: 0.7645\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3254 - mse: 0.3254 - mae: 0.4271 - val_loss: 0.9767 - val_mse: 0.9767 - val_mae: 0.7508\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3129 - mse: 0.3129 - mae: 0.4188 - val_loss: 0.9780 - val_mse: 0.9780 - val_mae: 0.7412\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2968 - mse: 0.2968 - mae: 0.4090 - val_loss: 0.9263 - val_mse: 0.9263 - val_mae: 0.7296\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2817 - mse: 0.2817 - mae: 0.3980 - val_loss: 0.9184 - val_mse: 0.9184 - val_mae: 0.7223\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2773 - mse: 0.2773 - mae: 0.3962 - val_loss: 0.8819 - val_mse: 0.8819 - val_mae: 0.7147\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2732 - mse: 0.2732 - mae: 0.3903 - val_loss: 0.8926 - val_mse: 0.8926 - val_mae: 0.7145\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2571 - mse: 0.2571 - mae: 0.3842 - val_loss: 0.8724 - val_mse: 0.8724 - val_mae: 0.7130\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2457 - mse: 0.2457 - mae: 0.3728 - val_loss: 0.8623 - val_mse: 0.8623 - val_mae: 0.6994\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2404 - mse: 0.2404 - mae: 0.3684 - val_loss: 0.8318 - val_mse: 0.8318 - val_mae: 0.6937\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2315 - mse: 0.2315 - mae: 0.3626 - val_loss: 0.8191 - val_mse: 0.8191 - val_mae: 0.6882\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2211 - mse: 0.2211 - mae: 0.3549 - val_loss: 0.7882 - val_mse: 0.7882 - val_mae: 0.6711\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2106 - mse: 0.2106 - mae: 0.3439 - val_loss: 0.7896 - val_mse: 0.7896 - val_mae: 0.6644\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2031 - mse: 0.2031 - mae: 0.3369 - val_loss: 0.7701 - val_mse: 0.7701 - val_mae: 0.6590\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1954 - mse: 0.1954 - mae: 0.3327 - val_loss: 0.7599 - val_mse: 0.7599 - val_mae: 0.6530\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1901 - mse: 0.1901 - mae: 0.3279 - val_loss: 0.7464 - val_mse: 0.7464 - val_mae: 0.6458\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1845 - mse: 0.1845 - mae: 0.3222 - val_loss: 0.7384 - val_mse: 0.7384 - val_mae: 0.6422\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1808 - mse: 0.1808 - mae: 0.3206 - val_loss: 0.7348 - val_mse: 0.7348 - val_mae: 0.6385\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1807 - mse: 0.1807 - mae: 0.3192 - val_loss: 0.7031 - val_mse: 0.7031 - val_mae: 0.6272\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1715 - mse: 0.1715 - mae: 0.3125 - val_loss: 0.7132 - val_mse: 0.7132 - val_mae: 0.6221\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1679 - mse: 0.1679 - mae: 0.3088 - val_loss: 0.7016 - val_mse: 0.7016 - val_mae: 0.6217\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1637 - mse: 0.1637 - mae: 0.3038 - val_loss: 0.6837 - val_mse: 0.6837 - val_mae: 0.6139\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1574 - mse: 0.1574 - mae: 0.2987 - val_loss: 0.6858 - val_mse: 0.6858 - val_mae: 0.6137\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1559 - mse: 0.1559 - mae: 0.2964 - val_loss: 0.6816 - val_mse: 0.6816 - val_mae: 0.6082\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1521 - mse: 0.1521 - mae: 0.2918 - val_loss: 0.6720 - val_mse: 0.6720 - val_mae: 0.6076\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1500 - mse: 0.1500 - mae: 0.2917 - val_loss: 0.6535 - val_mse: 0.6535 - val_mae: 0.5985\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1533 - mse: 0.1533 - mae: 0.2954 - val_loss: 0.6466 - val_mse: 0.6466 - val_mae: 0.5980\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1508 - mse: 0.1508 - mae: 0.2938 - val_loss: 0.6398 - val_mse: 0.6398 - val_mae: 0.5940\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1451 - mse: 0.1451 - mae: 0.2869 - val_loss: 0.6462 - val_mse: 0.6462 - val_mae: 0.5949\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1433 - mse: 0.1433 - mae: 0.2860 - val_loss: 0.6410 - val_mse: 0.6410 - val_mae: 0.5878\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1393 - mse: 0.1393 - mae: 0.2810 - val_loss: 0.6307 - val_mse: 0.6307 - val_mae: 0.5894\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1410 - mse: 0.1410 - mae: 0.2825 - val_loss: 0.6109 - val_mse: 0.6109 - val_mae: 0.5760\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1347 - mse: 0.1347 - mae: 0.2769 - val_loss: 0.6156 - val_mse: 0.6156 - val_mae: 0.5835\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1365 - mse: 0.1365 - mae: 0.2786 - val_loss: 0.5928 - val_mse: 0.5928 - val_mae: 0.5687\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1297 - mse: 0.1297 - mae: 0.2706 - val_loss: 0.5867 - val_mse: 0.5867 - val_mae: 0.5674\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1262 - mse: 0.1262 - mae: 0.2681 - val_loss: 0.6019 - val_mse: 0.6019 - val_mae: 0.5762\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1207 - mse: 0.1207 - mae: 0.2616 - val_loss: 0.5793 - val_mse: 0.5793 - val_mae: 0.5633\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1206 - mse: 0.1206 - mae: 0.2636 - val_loss: 0.5799 - val_mse: 0.5799 - val_mae: 0.5644\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1183 - mse: 0.1183 - mae: 0.2607 - val_loss: 0.5815 - val_mse: 0.5815 - val_mae: 0.5641\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1148 - mse: 0.1148 - mae: 0.2562 - val_loss: 0.5558 - val_mse: 0.5558 - val_mae: 0.5498\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1141 - mse: 0.1141 - mae: 0.2550 - val_loss: 0.5528 - val_mse: 0.5528 - val_mae: 0.5506\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1136 - mse: 0.1136 - mae: 0.2548 - val_loss: 0.5677 - val_mse: 0.5677 - val_mae: 0.5577\n",
      "Epoch 53/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1144 - mse: 0.1144 - mae: 0.2562 - val_loss: 0.5491 - val_mse: 0.5491 - val_mae: 0.5470\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1118 - mse: 0.1118 - mae: 0.2534 - val_loss: 0.5540 - val_mse: 0.5540 - val_mae: 0.5499\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1062 - mse: 0.1062 - mae: 0.2454 - val_loss: 0.5518 - val_mse: 0.5518 - val_mae: 0.5494\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1066 - mse: 0.1066 - mae: 0.2481 - val_loss: 0.5496 - val_mse: 0.5496 - val_mae: 0.5503\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1073 - mse: 0.1073 - mae: 0.2483 - val_loss: 0.5430 - val_mse: 0.5430 - val_mae: 0.5418\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1046 - mse: 0.1046 - mae: 0.2444 - val_loss: 0.5416 - val_mse: 0.5416 - val_mae: 0.5417\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1021 - mse: 0.1021 - mae: 0.2418 - val_loss: 0.5461 - val_mse: 0.5461 - val_mae: 0.5476\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0999 - mse: 0.0999 - mae: 0.2382 - val_loss: 0.5344 - val_mse: 0.5344 - val_mae: 0.5400\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1021 - mse: 0.1021 - mae: 0.2406 - val_loss: 0.5272 - val_mse: 0.5272 - val_mae: 0.5352\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0998 - mse: 0.0998 - mae: 0.2384 - val_loss: 0.5327 - val_mse: 0.5327 - val_mae: 0.5384\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1019 - mse: 0.1019 - mae: 0.2411 - val_loss: 0.5219 - val_mse: 0.5219 - val_mae: 0.5318\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.0985 - mse: 0.0985 - mae: 0.2366 - val_loss: 0.5158 - val_mse: 0.5158 - val_mae: 0.5269\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0986 - mse: 0.0986 - mae: 0.2373 - val_loss: 0.5235 - val_mse: 0.5235 - val_mae: 0.5328\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0988 - mse: 0.0988 - mae: 0.2374 - val_loss: 0.5297 - val_mse: 0.5297 - val_mae: 0.5286\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0941 - mse: 0.0941 - mae: 0.2329 - val_loss: 0.5202 - val_mse: 0.5202 - val_mae: 0.5283\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0954 - mse: 0.0954 - mae: 0.2320 - val_loss: 0.5127 - val_mse: 0.5127 - val_mae: 0.5228\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0902 - mse: 0.0902 - mae: 0.2281 - val_loss: 0.5159 - val_mse: 0.5159 - val_mae: 0.5254\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0899 - mse: 0.0899 - mae: 0.2281 - val_loss: 0.5203 - val_mse: 0.5203 - val_mae: 0.5277\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0844 - mse: 0.0844 - mae: 0.2188 - val_loss: 0.5110 - val_mse: 0.5110 - val_mae: 0.5215\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0854 - mse: 0.0854 - mae: 0.2196 - val_loss: 0.5106 - val_mse: 0.5106 - val_mae: 0.5204\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0828 - mse: 0.0828 - mae: 0.2169 - val_loss: 0.5100 - val_mse: 0.5100 - val_mae: 0.5174\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0840 - mse: 0.0840 - mae: 0.2190 - val_loss: 0.5104 - val_mse: 0.5104 - val_mae: 0.5185\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0816 - mse: 0.0816 - mae: 0.2167 - val_loss: 0.5090 - val_mse: 0.5090 - val_mae: 0.5165\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0836 - mse: 0.0836 - mae: 0.2198 - val_loss: 0.5081 - val_mse: 0.5081 - val_mae: 0.5164\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0833 - mse: 0.0833 - mae: 0.2189 - val_loss: 0.5061 - val_mse: 0.5061 - val_mae: 0.5170\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0846 - mse: 0.0846 - mae: 0.2196 - val_loss: 0.5015 - val_mse: 0.5015 - val_mae: 0.5118\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0799 - mse: 0.0799 - mae: 0.2145 - val_loss: 0.5069 - val_mse: 0.5069 - val_mae: 0.5095\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0775 - mse: 0.0775 - mae: 0.2100 - val_loss: 0.4978 - val_mse: 0.4978 - val_mae: 0.5075\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0803 - mse: 0.0803 - mae: 0.2132 - val_loss: 0.5077 - val_mse: 0.5077 - val_mae: 0.5060\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0807 - mse: 0.0807 - mae: 0.2141 - val_loss: 0.5050 - val_mse: 0.5050 - val_mae: 0.5168\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0784 - mse: 0.0784 - mae: 0.2113 - val_loss: 0.4976 - val_mse: 0.4976 - val_mae: 0.5098\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0803 - mse: 0.0803 - mae: 0.2150 - val_loss: 0.4933 - val_mse: 0.4933 - val_mae: 0.5056\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0751 - mse: 0.0751 - mae: 0.2074 - val_loss: 0.4965 - val_mse: 0.4965 - val_mae: 0.5055\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0802 - mse: 0.0802 - mae: 0.2141 - val_loss: 0.4951 - val_mse: 0.4951 - val_mae: 0.5061\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0779 - mse: 0.0779 - mae: 0.2111 - val_loss: 0.5050 - val_mse: 0.5050 - val_mae: 0.5147\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0820 - mse: 0.0820 - mae: 0.2182 - val_loss: 0.5045 - val_mse: 0.5045 - val_mae: 0.5092\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0820 - mse: 0.0820 - mae: 0.2172 - val_loss: 0.4976 - val_mse: 0.4976 - val_mae: 0.5057\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0811 - mse: 0.0811 - mae: 0.2142 - val_loss: 0.5160 - val_mse: 0.5160 - val_mae: 0.5152\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0880 - mse: 0.0880 - mae: 0.2239 - val_loss: 0.4976 - val_mse: 0.4976 - val_mae: 0.5066\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0823 - mse: 0.0823 - mae: 0.2156 - val_loss: 0.4962 - val_mse: 0.4962 - val_mae: 0.5064\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0817 - mse: 0.0817 - mae: 0.2158 - val_loss: 0.5011 - val_mse: 0.5011 - val_mae: 0.5078\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0778 - mse: 0.0778 - mae: 0.2114 - val_loss: 0.4895 - val_mse: 0.4895 - val_mae: 0.5007\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0754 - mse: 0.0754 - mae: 0.2073 - val_loss: 0.4925 - val_mse: 0.4925 - val_mae: 0.4984\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0733 - mse: 0.0733 - mae: 0.2044 - val_loss: 0.4945 - val_mse: 0.4945 - val_mae: 0.5018\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0765 - mse: 0.0765 - mae: 0.2093 - val_loss: 0.4839 - val_mse: 0.4839 - val_mae: 0.4924\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0727 - mse: 0.0727 - mae: 0.2030 - val_loss: 0.4839 - val_mse: 0.4839 - val_mae: 0.4951\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0747 - mse: 0.0747 - mae: 0.2064 - val_loss: 0.4841 - val_mse: 0.4841 - val_mae: 0.4937\n",
      "Epoch 100/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0718 - mse: 0.0718 - mae: 0.2035 - val_loss: 0.4899 - val_mse: 0.4899 - val_mae: 0.4992\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0702 - mse: 0.0702 - mae: 0.2015 - val_loss: 0.4834 - val_mse: 0.4834 - val_mae: 0.4949\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0742 - mse: 0.0742 - mae: 0.2065 - val_loss: 0.4759 - val_mse: 0.4759 - val_mae: 0.4902\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0750 - mse: 0.0750 - mae: 0.2059 - val_loss: 0.4810 - val_mse: 0.4810 - val_mae: 0.4927\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0722 - mse: 0.0722 - mae: 0.2035 - val_loss: 0.4886 - val_mse: 0.4886 - val_mae: 0.4984\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0714 - mse: 0.0714 - mae: 0.2019 - val_loss: 0.4908 - val_mse: 0.4908 - val_mae: 0.5006\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0695 - mse: 0.0695 - mae: 0.2004 - val_loss: 0.4770 - val_mse: 0.4770 - val_mae: 0.4938\n",
      "Epoch 107/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0682 - mse: 0.0682 - mae: 0.1973 - val_loss: 0.4821 - val_mse: 0.4821 - val_mae: 0.4919\n",
      "Epoch 108/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0650 - mse: 0.0650 - mae: 0.1915 - val_loss: 0.4813 - val_mse: 0.4813 - val_mae: 0.4945\n",
      "Epoch 109/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0682 - mse: 0.0682 - mae: 0.1959 - val_loss: 0.4874 - val_mse: 0.4874 - val_mae: 0.4987\n",
      "Epoch 110/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0675 - mse: 0.0675 - mae: 0.1979 - val_loss: 0.4812 - val_mse: 0.4812 - val_mae: 0.4980\n",
      "Epoch 111/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0688 - mse: 0.0688 - mae: 0.1976 - val_loss: 0.4780 - val_mse: 0.4780 - val_mae: 0.4927\n",
      "Epoch 112/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0686 - mse: 0.0686 - mae: 0.1980 - val_loss: 0.4915 - val_mse: 0.4915 - val_mae: 0.4992\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 132us/sample - loss: 2.0018 - mse: 2.0018 - mae: 0.9991 - val_loss: 1.6049 - val_mse: 1.6049 - val_mae: 0.9084\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.8704 - mse: 0.8704 - mae: 0.7126 - val_loss: 1.1206 - val_mse: 1.1206 - val_mae: 0.8177\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.6774 - mse: 0.6774 - mae: 0.6213 - val_loss: 1.1829 - val_mse: 1.1829 - val_mae: 0.8088\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.5902 - mse: 0.5902 - mae: 0.5806 - val_loss: 1.1284 - val_mse: 1.1284 - val_mae: 0.8231\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.5280 - mse: 0.5280 - mae: 0.5449 - val_loss: 1.0917 - val_mse: 1.0917 - val_mae: 0.7830\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4828 - mse: 0.4828 - mae: 0.5194 - val_loss: 1.0953 - val_mse: 1.0953 - val_mae: 0.7782\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4525 - mse: 0.4525 - mae: 0.5066 - val_loss: 1.0410 - val_mse: 1.0410 - val_mae: 0.7756\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4207 - mse: 0.4207 - mae: 0.4884 - val_loss: 1.0167 - val_mse: 1.0167 - val_mae: 0.7677\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3977 - mse: 0.3977 - mae: 0.4728 - val_loss: 1.0119 - val_mse: 1.0119 - val_mae: 0.7643\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3787 - mse: 0.3787 - mae: 0.4608 - val_loss: 1.0043 - val_mse: 1.0043 - val_mae: 0.7620\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3580 - mse: 0.3580 - mae: 0.4473 - val_loss: 0.9843 - val_mse: 0.9843 - val_mae: 0.7467\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3361 - mse: 0.3361 - mae: 0.4348 - val_loss: 0.9735 - val_mse: 0.9735 - val_mae: 0.7432\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3233 - mse: 0.3233 - mae: 0.4267 - val_loss: 0.9515 - val_mse: 0.9515 - val_mae: 0.7333\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3071 - mse: 0.3071 - mae: 0.4163 - val_loss: 0.9118 - val_mse: 0.9118 - val_mae: 0.7248\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3002 - mse: 0.3002 - mae: 0.4129 - val_loss: 0.9077 - val_mse: 0.9077 - val_mae: 0.7206\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2929 - mse: 0.2929 - mae: 0.4083 - val_loss: 0.8838 - val_mse: 0.8838 - val_mae: 0.7128\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2765 - mse: 0.2765 - mae: 0.3943 - val_loss: 0.8636 - val_mse: 0.8636 - val_mae: 0.7043\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2661 - mse: 0.2661 - mae: 0.3882 - val_loss: 0.8505 - val_mse: 0.8505 - val_mae: 0.7013\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2594 - mse: 0.2594 - mae: 0.3847 - val_loss: 0.8510 - val_mse: 0.8510 - val_mae: 0.6973\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2471 - mse: 0.2471 - mae: 0.3753 - val_loss: 0.8326 - val_mse: 0.8326 - val_mae: 0.6892\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - ETA: 0s - loss: 0.2395 - mse: 0.2395 - mae: 0.368 - 0s 9us/sample - loss: 0.2396 - mse: 0.2396 - mae: 0.3685 - val_loss: 0.8320 - val_mse: 0.8320 - val_mae: 0.6859\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2299 - mse: 0.2299 - mae: 0.3607 - val_loss: 0.8045 - val_mse: 0.8045 - val_mae: 0.6780\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2262 - mse: 0.2262 - mae: 0.3584 - val_loss: 0.7991 - val_mse: 0.7991 - val_mae: 0.6699\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2193 - mse: 0.2193 - mae: 0.3526 - val_loss: 0.7819 - val_mse: 0.7819 - val_mae: 0.6677\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2093 - mse: 0.2093 - mae: 0.3458 - val_loss: 0.7726 - val_mse: 0.7726 - val_mae: 0.6604\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2033 - mse: 0.2033 - mae: 0.3400 - val_loss: 0.7738 - val_mse: 0.7738 - val_mae: 0.6600\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1978 - mse: 0.1978 - mae: 0.3378 - val_loss: 0.7505 - val_mse: 0.7505 - val_mae: 0.6501\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1979 - mse: 0.1979 - mae: 0.3360 - val_loss: 0.7576 - val_mse: 0.7576 - val_mae: 0.6504\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1910 - mse: 0.1910 - mae: 0.3295 - val_loss: 0.7251 - val_mse: 0.7251 - val_mae: 0.6418\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1846 - mse: 0.1846 - mae: 0.3254 - val_loss: 0.7161 - val_mse: 0.7161 - val_mae: 0.6363\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1817 - mse: 0.1817 - mae: 0.3236 - val_loss: 0.7075 - val_mse: 0.7075 - val_mae: 0.6290\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1732 - mse: 0.1732 - mae: 0.3160 - val_loss: 0.6873 - val_mse: 0.6873 - val_mae: 0.6185\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1757 - mse: 0.1757 - mae: 0.3160 - val_loss: 0.6765 - val_mse: 0.6765 - val_mae: 0.6187\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1658 - mse: 0.1658 - mae: 0.3082 - val_loss: 0.6671 - val_mse: 0.6671 - val_mae: 0.6131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1625 - mse: 0.1625 - mae: 0.3076 - val_loss: 0.6565 - val_mse: 0.6565 - val_mae: 0.6063\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1616 - mse: 0.1616 - mae: 0.3045 - val_loss: 0.6630 - val_mse: 0.6630 - val_mae: 0.6089\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1579 - mse: 0.1579 - mae: 0.3022 - val_loss: 0.6321 - val_mse: 0.6321 - val_mae: 0.5942\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1528 - mse: 0.1528 - mae: 0.2966 - val_loss: 0.6341 - val_mse: 0.6341 - val_mae: 0.5956\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1496 - mse: 0.1496 - mae: 0.2948 - val_loss: 0.6246 - val_mse: 0.6246 - val_mae: 0.5917\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1475 - mse: 0.1475 - mae: 0.2921 - val_loss: 0.5984 - val_mse: 0.5984 - val_mae: 0.5774\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1452 - mse: 0.1452 - mae: 0.2887 - val_loss: 0.5935 - val_mse: 0.5935 - val_mae: 0.5767\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1413 - mse: 0.1413 - mae: 0.2854 - val_loss: 0.5942 - val_mse: 0.5942 - val_mae: 0.5715\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.1426 - mse: 0.1426 - mae: 0.2871 - val_loss: 0.5866 - val_mse: 0.5866 - val_mae: 0.5712\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1404 - mse: 0.1404 - mae: 0.2871 - val_loss: 0.5894 - val_mse: 0.5894 - val_mae: 0.5724\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1368 - mse: 0.1368 - mae: 0.2814 - val_loss: 0.5656 - val_mse: 0.5656 - val_mae: 0.5598\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1370 - mse: 0.1370 - mae: 0.2820 - val_loss: 0.5568 - val_mse: 0.5568 - val_mae: 0.5530\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1320 - mse: 0.1320 - mae: 0.2760 - val_loss: 0.5553 - val_mse: 0.5553 - val_mae: 0.5557\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1307 - mse: 0.1307 - mae: 0.2739 - val_loss: 0.5387 - val_mse: 0.5387 - val_mae: 0.5468\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1313 - mse: 0.1313 - mae: 0.2743 - val_loss: 0.5332 - val_mse: 0.5332 - val_mae: 0.5419\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1235 - mse: 0.1235 - mae: 0.2677 - val_loss: 0.5181 - val_mse: 0.5181 - val_mae: 0.5360\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1200 - mse: 0.1200 - mae: 0.2647 - val_loss: 0.5233 - val_mse: 0.5233 - val_mae: 0.5365\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1210 - mse: 0.1210 - mae: 0.2647 - val_loss: 0.5149 - val_mse: 0.5149 - val_mae: 0.5325\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1162 - mse: 0.1162 - mae: 0.2612 - val_loss: 0.5329 - val_mse: 0.5329 - val_mae: 0.5405\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1140 - mse: 0.1140 - mae: 0.2586 - val_loss: 0.5180 - val_mse: 0.5180 - val_mae: 0.5302\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1125 - mse: 0.1125 - mae: 0.2549 - val_loss: 0.5112 - val_mse: 0.5112 - val_mae: 0.5233\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1088 - mse: 0.1088 - mae: 0.2518 - val_loss: 0.5288 - val_mse: 0.5288 - val_mae: 0.5344\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1101 - mse: 0.1101 - mae: 0.2521 - val_loss: 0.5004 - val_mse: 0.5004 - val_mae: 0.5208\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1175 - mse: 0.1175 - mae: 0.2604 - val_loss: 0.5142 - val_mse: 0.5142 - val_mae: 0.5275\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1072 - mse: 0.1072 - mae: 0.2513 - val_loss: 0.5007 - val_mse: 0.5007 - val_mae: 0.5201\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1056 - mse: 0.1056 - mae: 0.2470 - val_loss: 0.5015 - val_mse: 0.5015 - val_mae: 0.5241\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1051 - mse: 0.1051 - mae: 0.2481 - val_loss: 0.5060 - val_mse: 0.5060 - val_mae: 0.5224\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1103 - mse: 0.1103 - mae: 0.2543 - val_loss: 0.4974 - val_mse: 0.4974 - val_mae: 0.5172\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1022 - mse: 0.1022 - mae: 0.2428 - val_loss: 0.5079 - val_mse: 0.5079 - val_mae: 0.5210\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1015 - mse: 0.1015 - mae: 0.2445 - val_loss: 0.4965 - val_mse: 0.4965 - val_mae: 0.5154\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0988 - mse: 0.0988 - mae: 0.2404 - val_loss: 0.4928 - val_mse: 0.4928 - val_mae: 0.5150\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0998 - mse: 0.0998 - mae: 0.2426 - val_loss: 0.4973 - val_mse: 0.4973 - val_mae: 0.5151\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0964 - mse: 0.0964 - mae: 0.2377 - val_loss: 0.4868 - val_mse: 0.4868 - val_mae: 0.5104\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0948 - mse: 0.0948 - mae: 0.2350 - val_loss: 0.4953 - val_mse: 0.4953 - val_mae: 0.5130\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0985 - mse: 0.0985 - mae: 0.2390 - val_loss: 0.4828 - val_mse: 0.4828 - val_mae: 0.5070\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0929 - mse: 0.0929 - mae: 0.2339 - val_loss: 0.5071 - val_mse: 0.5071 - val_mae: 0.5180\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0922 - mse: 0.0922 - mae: 0.2326 - val_loss: 0.4877 - val_mse: 0.4877 - val_mae: 0.5063\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0886 - mse: 0.0886 - mae: 0.2275 - val_loss: 0.4836 - val_mse: 0.4836 - val_mae: 0.5060\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0877 - mse: 0.0877 - mae: 0.2255 - val_loss: 0.4888 - val_mse: 0.4888 - val_mae: 0.5072\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0887 - mse: 0.0887 - mae: 0.2289 - val_loss: 0.4766 - val_mse: 0.4766 - val_mae: 0.5004\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0882 - mse: 0.0882 - mae: 0.2279 - val_loss: 0.5063 - val_mse: 0.5063 - val_mae: 0.5161\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0837 - mse: 0.0837 - mae: 0.2212 - val_loss: 0.4753 - val_mse: 0.4753 - val_mae: 0.5008\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0840 - mse: 0.0840 - mae: 0.2222 - val_loss: 0.4908 - val_mse: 0.4908 - val_mae: 0.5074\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0842 - mse: 0.0842 - mae: 0.2215 - val_loss: 0.4850 - val_mse: 0.4850 - val_mae: 0.5043\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0859 - mse: 0.0859 - mae: 0.2240 - val_loss: 0.4896 - val_mse: 0.4896 - val_mae: 0.5064\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0814 - mse: 0.0814 - mae: 0.2179 - val_loss: 0.4794 - val_mse: 0.4794 - val_mae: 0.4999\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0776 - mse: 0.0776 - mae: 0.2129 - val_loss: 0.4873 - val_mse: 0.4873 - val_mae: 0.5038\n",
      "Epoch 82/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0807 - mse: 0.0807 - mae: 0.2179 - val_loss: 0.4879 - val_mse: 0.4879 - val_mae: 0.5056\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0773 - mse: 0.0773 - mae: 0.2127 - val_loss: 0.4893 - val_mse: 0.4893 - val_mae: 0.5008\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0809 - mse: 0.0809 - mae: 0.2178 - val_loss: 0.4858 - val_mse: 0.4858 - val_mae: 0.5013\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0794 - mse: 0.0794 - mae: 0.2159 - val_loss: 0.4887 - val_mse: 0.4887 - val_mae: 0.5062\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0858 - mse: 0.0858 - mae: 0.2234 - val_loss: 0.4881 - val_mse: 0.4881 - val_mae: 0.5069\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 151us/sample - loss: 2.0215 - mse: 2.0215 - mae: 0.9993 - val_loss: 1.3203 - val_mse: 1.3203 - val_mae: 0.8147\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.8777 - mse: 0.8777 - mae: 0.7103 - val_loss: 1.5023 - val_mse: 1.5023 - val_mae: 1.0444\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.7116 - mse: 0.7116 - mae: 0.6401 - val_loss: 1.2045 - val_mse: 1.2045 - val_mae: 0.9209\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.5989 - mse: 0.5989 - mae: 0.5933 - val_loss: 1.0287 - val_mse: 1.0287 - val_mae: 0.8234\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.5320 - mse: 0.5320 - mae: 0.5531 - val_loss: 1.0877 - val_mse: 1.0877 - val_mae: 0.8644\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4894 - mse: 0.4894 - mae: 0.5248 - val_loss: 1.0897 - val_mse: 1.0897 - val_mae: 0.8648\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4541 - mse: 0.4541 - mae: 0.5046 - val_loss: 1.0247 - val_mse: 1.0247 - val_mae: 0.8253\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4221 - mse: 0.4221 - mae: 0.4865 - val_loss: 1.0350 - val_mse: 1.0350 - val_mae: 0.8328\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3959 - mse: 0.3959 - mae: 0.4735 - val_loss: 1.0425 - val_mse: 1.0425 - val_mae: 0.8381\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3762 - mse: 0.3762 - mae: 0.4625 - val_loss: 1.0087 - val_mse: 1.0087 - val_mae: 0.8158\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3501 - mse: 0.3501 - mae: 0.4430 - val_loss: 1.0143 - val_mse: 1.0143 - val_mae: 0.8206\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3390 - mse: 0.3390 - mae: 0.4356 - val_loss: 0.9892 - val_mse: 0.9892 - val_mae: 0.8053\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.3301 - mse: 0.3301 - mae: 0.4295 - val_loss: 0.9572 - val_mse: 0.9572 - val_mae: 0.7875\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3112 - mse: 0.3112 - mae: 0.4191 - val_loss: 0.9281 - val_mse: 0.9281 - val_mae: 0.7662\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.3009 - mse: 0.3009 - mae: 0.4111 - val_loss: 0.9054 - val_mse: 0.9054 - val_mae: 0.7536\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2913 - mse: 0.2913 - mae: 0.4034 - val_loss: 0.8918 - val_mse: 0.8918 - val_mae: 0.7387\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2748 - mse: 0.2748 - mae: 0.3929 - val_loss: 0.8759 - val_mse: 0.8759 - val_mae: 0.7324\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.2645 - mse: 0.2645 - mae: 0.3849 - val_loss: 0.8606 - val_mse: 0.8606 - val_mae: 0.7269\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2554 - mse: 0.2554 - mae: 0.3784 - val_loss: 0.8467 - val_mse: 0.8468 - val_mae: 0.7196\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2457 - mse: 0.2457 - mae: 0.3711 - val_loss: 0.8333 - val_mse: 0.8333 - val_mae: 0.7153\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2414 - mse: 0.2414 - mae: 0.3672 - val_loss: 0.8311 - val_mse: 0.8311 - val_mae: 0.7118\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2333 - mse: 0.2333 - mae: 0.3641 - val_loss: 0.8216 - val_mse: 0.8216 - val_mae: 0.7116\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2306 - mse: 0.2306 - mae: 0.3591 - val_loss: 0.8077 - val_mse: 0.8077 - val_mae: 0.7008\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2195 - mse: 0.2195 - mae: 0.3510 - val_loss: 0.8150 - val_mse: 0.8150 - val_mae: 0.7041\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2145 - mse: 0.2145 - mae: 0.3481 - val_loss: 0.7862 - val_mse: 0.7862 - val_mae: 0.6932\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2045 - mse: 0.2045 - mae: 0.3387 - val_loss: 0.7768 - val_mse: 0.7768 - val_mae: 0.6855\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2011 - mse: 0.2011 - mae: 0.3349 - val_loss: 0.7493 - val_mse: 0.7493 - val_mae: 0.6677\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1950 - mse: 0.1950 - mae: 0.3304 - val_loss: 0.7430 - val_mse: 0.7430 - val_mae: 0.6699\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1866 - mse: 0.1866 - mae: 0.3262 - val_loss: 0.7379 - val_mse: 0.7379 - val_mae: 0.6683\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1845 - mse: 0.1845 - mae: 0.3245 - val_loss: 0.7422 - val_mse: 0.7422 - val_mae: 0.6649\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1807 - mse: 0.1807 - mae: 0.3209 - val_loss: 0.7134 - val_mse: 0.7134 - val_mae: 0.6482\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1796 - mse: 0.1796 - mae: 0.3155 - val_loss: 0.6965 - val_mse: 0.6965 - val_mae: 0.6451\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1744 - mse: 0.1744 - mae: 0.3103 - val_loss: 0.6822 - val_mse: 0.6822 - val_mae: 0.6379\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1772 - mse: 0.1772 - mae: 0.3159 - val_loss: 0.6749 - val_mse: 0.6749 - val_mae: 0.6328\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1714 - mse: 0.1714 - mae: 0.3119 - val_loss: 0.6818 - val_mse: 0.6818 - val_mae: 0.6397\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1631 - mse: 0.1631 - mae: 0.3049 - val_loss: 0.6564 - val_mse: 0.6564 - val_mae: 0.6229\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1589 - mse: 0.1589 - mae: 0.3021 - val_loss: 0.6585 - val_mse: 0.6585 - val_mae: 0.6237\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1532 - mse: 0.1532 - mae: 0.2959 - val_loss: 0.6424 - val_mse: 0.6424 - val_mae: 0.6132\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1541 - mse: 0.1541 - mae: 0.2967 - val_loss: 0.6322 - val_mse: 0.6322 - val_mae: 0.6058\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1434 - mse: 0.1434 - mae: 0.2855 - val_loss: 0.6209 - val_mse: 0.6209 - val_mae: 0.5990\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1445 - mse: 0.1445 - mae: 0.2864 - val_loss: 0.6169 - val_mse: 0.6169 - val_mae: 0.5951\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1432 - mse: 0.1432 - mae: 0.2851 - val_loss: 0.6151 - val_mse: 0.6151 - val_mae: 0.5957\n",
      "Epoch 43/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1320 - mse: 0.1320 - mae: 0.2741 - val_loss: 0.5867 - val_mse: 0.5867 - val_mae: 0.5781\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1351 - mse: 0.1351 - mae: 0.2778 - val_loss: 0.5774 - val_mse: 0.5774 - val_mae: 0.5744\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.1306 - mse: 0.1306 - mae: 0.2725 - val_loss: 0.5652 - val_mse: 0.5652 - val_mae: 0.5658\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1282 - mse: 0.1282 - mae: 0.2697 - val_loss: 0.5647 - val_mse: 0.5647 - val_mae: 0.5683\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.1279 - mse: 0.1279 - mae: 0.2707 - val_loss: 0.5523 - val_mse: 0.5523 - val_mae: 0.5569\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1260 - mse: 0.1260 - mae: 0.2668 - val_loss: 0.5665 - val_mse: 0.5665 - val_mae: 0.5670\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1245 - mse: 0.1245 - mae: 0.2668 - val_loss: 0.5454 - val_mse: 0.5454 - val_mae: 0.5532\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1188 - mse: 0.1188 - mae: 0.2606 - val_loss: 0.5437 - val_mse: 0.5437 - val_mae: 0.5546\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1204 - mse: 0.1204 - mae: 0.2606 - val_loss: 0.5314 - val_mse: 0.5314 - val_mae: 0.5464\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1171 - mse: 0.1171 - mae: 0.2592 - val_loss: 0.5275 - val_mse: 0.5275 - val_mae: 0.5408\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1199 - mse: 0.1199 - mae: 0.2603 - val_loss: 0.5481 - val_mse: 0.5481 - val_mae: 0.5511\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1161 - mse: 0.1161 - mae: 0.2580 - val_loss: 0.5326 - val_mse: 0.5326 - val_mae: 0.5431\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1151 - mse: 0.1151 - mae: 0.2563 - val_loss: 0.5282 - val_mse: 0.5282 - val_mae: 0.5443\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1092 - mse: 0.1092 - mae: 0.2497 - val_loss: 0.5112 - val_mse: 0.5112 - val_mae: 0.5289\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1108 - mse: 0.1108 - mae: 0.2518 - val_loss: 0.5220 - val_mse: 0.5220 - val_mae: 0.5371\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.1076 - mse: 0.1076 - mae: 0.2482 - val_loss: 0.5099 - val_mse: 0.5099 - val_mae: 0.5311\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1069 - mse: 0.1069 - mae: 0.2476 - val_loss: 0.5055 - val_mse: 0.5055 - val_mae: 0.5313\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1107 - mse: 0.1107 - mae: 0.2512 - val_loss: 0.5016 - val_mse: 0.5016 - val_mae: 0.5260\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1116 - mse: 0.1116 - mae: 0.2519 - val_loss: 0.5094 - val_mse: 0.5094 - val_mae: 0.5303\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1072 - mse: 0.1072 - mae: 0.2486 - val_loss: 0.4948 - val_mse: 0.4948 - val_mae: 0.5227\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1101 - mse: 0.1101 - mae: 0.2512 - val_loss: 0.5027 - val_mse: 0.5027 - val_mae: 0.5244\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1072 - mse: 0.1072 - mae: 0.2477 - val_loss: 0.5013 - val_mse: 0.5013 - val_mae: 0.5178\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1125 - mse: 0.1125 - mae: 0.2531 - val_loss: 0.4851 - val_mse: 0.4851 - val_mae: 0.5140\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1058 - mse: 0.1058 - mae: 0.2464 - val_loss: 0.4943 - val_mse: 0.4943 - val_mae: 0.5189\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1012 - mse: 0.1012 - mae: 0.2397 - val_loss: 0.4965 - val_mse: 0.4965 - val_mae: 0.5191\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1002 - mse: 0.1002 - mae: 0.2398 - val_loss: 0.4953 - val_mse: 0.4953 - val_mae: 0.5166\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0988 - mse: 0.0988 - mae: 0.2372 - val_loss: 0.5012 - val_mse: 0.5012 - val_mae: 0.5181\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1099 - mse: 0.1099 - mae: 0.2482 - val_loss: 0.5077 - val_mse: 0.5077 - val_mae: 0.5252\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1097 - mse: 0.1097 - mae: 0.2496 - val_loss: 0.4840 - val_mse: 0.4840 - val_mae: 0.5102\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1094 - mse: 0.1094 - mae: 0.2499 - val_loss: 0.4947 - val_mse: 0.4947 - val_mae: 0.5190\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0995 - mse: 0.0995 - mae: 0.2396 - val_loss: 0.4852 - val_mse: 0.4852 - val_mae: 0.5058\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0961 - mse: 0.0961 - mae: 0.2333 - val_loss: 0.4789 - val_mse: 0.4789 - val_mae: 0.5044\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0929 - mse: 0.0929 - mae: 0.2296 - val_loss: 0.4915 - val_mse: 0.4915 - val_mae: 0.5131\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0926 - mse: 0.0926 - mae: 0.2302 - val_loss: 0.4880 - val_mse: 0.4880 - val_mae: 0.5026\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0934 - mse: 0.0934 - mae: 0.2310 - val_loss: 0.4802 - val_mse: 0.4802 - val_mae: 0.5011\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0869 - mse: 0.0869 - mae: 0.2219 - val_loss: 0.4915 - val_mse: 0.4915 - val_mae: 0.5119\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0869 - mse: 0.0869 - mae: 0.2234 - val_loss: 0.4751 - val_mse: 0.4751 - val_mae: 0.4989\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0829 - mse: 0.0829 - mae: 0.2166 - val_loss: 0.4867 - val_mse: 0.4867 - val_mae: 0.5043\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0868 - mse: 0.0868 - mae: 0.2213 - val_loss: 0.4789 - val_mse: 0.4789 - val_mae: 0.5014\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0807 - mse: 0.0807 - mae: 0.2149 - val_loss: 0.4709 - val_mse: 0.4709 - val_mae: 0.4974\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0847 - mse: 0.0847 - mae: 0.2191 - val_loss: 0.4628 - val_mse: 0.4628 - val_mae: 0.4941\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0805 - mse: 0.0805 - mae: 0.2137 - val_loss: 0.4642 - val_mse: 0.4642 - val_mae: 0.4937\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0795 - mse: 0.0795 - mae: 0.2107 - val_loss: 0.4678 - val_mse: 0.4678 - val_mae: 0.4970\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0796 - mse: 0.0796 - mae: 0.2124 - val_loss: 0.4622 - val_mse: 0.4622 - val_mae: 0.4936\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0790 - mse: 0.0790 - mae: 0.2128 - val_loss: 0.4701 - val_mse: 0.4701 - val_mae: 0.4985\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0794 - mse: 0.0794 - mae: 0.2132 - val_loss: 0.4772 - val_mse: 0.4772 - val_mae: 0.5052\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0838 - mse: 0.0838 - mae: 0.2188 - val_loss: 0.4684 - val_mse: 0.4684 - val_mae: 0.4934\n",
      "Epoch 90/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0824 - mse: 0.0824 - mae: 0.2164 - val_loss: 0.4704 - val_mse: 0.4704 - val_mae: 0.4987\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.0921 - mse: 0.0921 - mae: 0.2271 - val_loss: 0.4793 - val_mse: 0.4793 - val_mae: 0.5011\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0859 - mse: 0.0859 - mae: 0.2221 - val_loss: 0.4659 - val_mse: 0.4659 - val_mae: 0.4928\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0766 - mse: 0.0766 - mae: 0.2118 - val_loss: 0.4672 - val_mse: 0.4672 - val_mae: 0.4952\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0712 - mse: 0.0712 - mae: 0.2029 - val_loss: 0.4722 - val_mse: 0.4722 - val_mae: 0.4957\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0737 - mse: 0.0737 - mae: 0.2058 - val_loss: 0.4588 - val_mse: 0.4588 - val_mae: 0.4871\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0725 - mse: 0.0725 - mae: 0.2055 - val_loss: 0.4549 - val_mse: 0.4549 - val_mae: 0.4889\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.0740 - mse: 0.0740 - mae: 0.2054 - val_loss: 0.4628 - val_mse: 0.4628 - val_mae: 0.4917\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0721 - mse: 0.0721 - mae: 0.2028 - val_loss: 0.4641 - val_mse: 0.4641 - val_mae: 0.4926\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0758 - mse: 0.0758 - mae: 0.2067 - val_loss: 0.4645 - val_mse: 0.4645 - val_mae: 0.4913\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0722 - mse: 0.0722 - mae: 0.2024 - val_loss: 0.4683 - val_mse: 0.4683 - val_mae: 0.4964\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0676 - mse: 0.0676 - mae: 0.1972 - val_loss: 0.4612 - val_mse: 0.4612 - val_mae: 0.4890\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0700 - mse: 0.0700 - mae: 0.1992 - val_loss: 0.4564 - val_mse: 0.4564 - val_mae: 0.4869\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0760 - mse: 0.0760 - mae: 0.2078 - val_loss: 0.4700 - val_mse: 0.4700 - val_mae: 0.5009\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0757 - mse: 0.0757 - mae: 0.2058 - val_loss: 0.4684 - val_mse: 0.4684 - val_mae: 0.4938\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.0749 - mse: 0.0749 - mae: 0.2053 - val_loss: 0.4771 - val_mse: 0.4771 - val_mae: 0.4990\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.0768 - mse: 0.0768 - mae: 0.2094 - val_loss: 0.4729 - val_mse: 0.4729 - val_mae: 0.5018\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 130us/sample - loss: 1.9768 - mse: 1.9768 - mae: 1.0082 - val_loss: 2.7369 - val_mse: 2.7369 - val_mae: 1.3052\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.8282 - mse: 0.8282 - mae: 0.6908 - val_loss: 1.2534 - val_mse: 1.2534 - val_mae: 0.7961\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.6882 - mse: 0.6882 - mae: 0.6282 - val_loss: 1.5702 - val_mse: 1.5702 - val_mae: 0.8882\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.5892 - mse: 0.5892 - mae: 0.5832 - val_loss: 1.5579 - val_mse: 1.5579 - val_mae: 0.8885\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.5176 - mse: 0.5176 - mae: 0.5446 - val_loss: 1.2830 - val_mse: 1.2830 - val_mae: 0.8042\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.4741 - mse: 0.4741 - mae: 0.5195 - val_loss: 1.2306 - val_mse: 1.2306 - val_mae: 0.7914\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.4443 - mse: 0.4443 - mae: 0.5008 - val_loss: 1.2022 - val_mse: 1.2022 - val_mae: 0.7893\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.4198 - mse: 0.4198 - mae: 0.4845 - val_loss: 1.2273 - val_mse: 1.2273 - val_mae: 0.8013\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.3905 - mse: 0.3905 - mae: 0.4713 - val_loss: 1.2240 - val_mse: 1.2240 - val_mae: 0.8032\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.3688 - mse: 0.3688 - mae: 0.4570 - val_loss: 1.1988 - val_mse: 1.1988 - val_mae: 0.7996\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.3503 - mse: 0.3503 - mae: 0.4441 - val_loss: 1.1506 - val_mse: 1.1506 - val_mae: 0.7858\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.3321 - mse: 0.3321 - mae: 0.4330 - val_loss: 1.1549 - val_mse: 1.1549 - val_mae: 0.7868\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.3165 - mse: 0.3165 - mae: 0.4217 - val_loss: 1.1378 - val_mse: 1.1378 - val_mae: 0.7834\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.3024 - mse: 0.3024 - mae: 0.4139 - val_loss: 1.1142 - val_mse: 1.1142 - val_mae: 0.7767\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2914 - mse: 0.2914 - mae: 0.4054 - val_loss: 1.1108 - val_mse: 1.1108 - val_mae: 0.7771\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.2821 - mse: 0.2821 - mae: 0.3985 - val_loss: 1.0960 - val_mse: 1.0960 - val_mae: 0.7724\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 10us/sample - loss: 0.2796 - mse: 0.2796 - mae: 0.3945 - val_loss: 1.1132 - val_mse: 1.1132 - val_mae: 0.7754\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.2653 - mse: 0.2653 - mae: 0.3884 - val_loss: 1.0517 - val_mse: 1.0517 - val_mae: 0.7603\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2606 - mse: 0.2606 - mae: 0.3841 - val_loss: 1.0486 - val_mse: 1.0486 - val_mae: 0.7561\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2425 - mse: 0.2425 - mae: 0.3709 - val_loss: 1.0081 - val_mse: 1.0081 - val_mae: 0.7436\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2388 - mse: 0.2388 - mae: 0.3681 - val_loss: 1.0049 - val_mse: 1.0049 - val_mae: 0.7416\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.2285 - mse: 0.2285 - mae: 0.3606 - val_loss: 0.9652 - val_mse: 0.9652 - val_mae: 0.7299\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 10us/sample - loss: 0.2224 - mse: 0.2224 - mae: 0.3552 - val_loss: 0.9825 - val_mse: 0.9825 - val_mae: 0.7321\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 10us/sample - loss: 0.2214 - mse: 0.2214 - mae: 0.3536 - val_loss: 0.9141 - val_mse: 0.9141 - val_mae: 0.7145\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2247 - mse: 0.2247 - mae: 0.3529 - val_loss: 0.9354 - val_mse: 0.9354 - val_mae: 0.7191\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.2102 - mse: 0.2102 - mae: 0.3474 - val_loss: 0.8950 - val_mse: 0.8950 - val_mae: 0.7054\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1971 - mse: 0.1971 - mae: 0.3345 - val_loss: 0.8985 - val_mse: 0.8985 - val_mae: 0.7081\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1905 - mse: 0.1905 - mae: 0.3294 - val_loss: 0.8469 - val_mse: 0.8469 - val_mae: 0.6910\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1838 - mse: 0.1838 - mae: 0.3234 - val_loss: 0.8590 - val_mse: 0.8590 - val_mae: 0.6972\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1804 - mse: 0.1804 - mae: 0.3224 - val_loss: 0.8227 - val_mse: 0.8227 - val_mae: 0.6809\n",
      "Epoch 31/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1803 - mse: 0.1803 - mae: 0.3194 - val_loss: 0.8279 - val_mse: 0.8279 - val_mae: 0.6854\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1713 - mse: 0.1713 - mae: 0.3127 - val_loss: 0.7771 - val_mse: 0.7771 - val_mae: 0.6632\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1729 - mse: 0.1729 - mae: 0.3151 - val_loss: 0.7956 - val_mse: 0.7956 - val_mae: 0.6723\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1649 - mse: 0.1649 - mae: 0.3076 - val_loss: 0.7730 - val_mse: 0.7730 - val_mae: 0.6600\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1638 - mse: 0.1638 - mae: 0.3087 - val_loss: 0.7585 - val_mse: 0.7585 - val_mae: 0.6590\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - ETA: 0s - loss: 0.1596 - mse: 0.1596 - mae: 0.301 - 0s 9us/sample - loss: 0.1607 - mse: 0.1607 - mae: 0.3025 - val_loss: 0.7379 - val_mse: 0.7379 - val_mae: 0.6495\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1557 - mse: 0.1557 - mae: 0.2981 - val_loss: 0.7154 - val_mse: 0.7154 - val_mae: 0.6407\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1497 - mse: 0.1497 - mae: 0.2927 - val_loss: 0.7166 - val_mse: 0.7166 - val_mae: 0.6400\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1496 - mse: 0.1496 - mae: 0.2934 - val_loss: 0.6768 - val_mse: 0.6768 - val_mae: 0.6212\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1465 - mse: 0.1465 - mae: 0.2898 - val_loss: 0.6819 - val_mse: 0.6819 - val_mae: 0.6233\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1430 - mse: 0.1430 - mae: 0.2873 - val_loss: 0.6680 - val_mse: 0.6680 - val_mae: 0.6196\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1410 - mse: 0.1410 - mae: 0.2855 - val_loss: 0.6403 - val_mse: 0.6403 - val_mae: 0.6018\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1357 - mse: 0.1357 - mae: 0.2777 - val_loss: 0.6556 - val_mse: 0.6556 - val_mae: 0.6086\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1349 - mse: 0.1349 - mae: 0.2776 - val_loss: 0.6122 - val_mse: 0.6122 - val_mae: 0.5888\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1337 - mse: 0.1337 - mae: 0.2761 - val_loss: 0.6102 - val_mse: 0.6102 - val_mae: 0.5901\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1302 - mse: 0.1302 - mae: 0.2748 - val_loss: 0.6067 - val_mse: 0.6067 - val_mae: 0.5855\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1300 - mse: 0.1300 - mae: 0.2736 - val_loss: 0.6125 - val_mse: 0.6125 - val_mae: 0.5893\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1241 - mse: 0.1241 - mae: 0.2684 - val_loss: 0.5932 - val_mse: 0.5932 - val_mae: 0.5749\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1193 - mse: 0.1193 - mae: 0.2630 - val_loss: 0.5910 - val_mse: 0.5910 - val_mae: 0.5753\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1163 - mse: 0.1163 - mae: 0.2579 - val_loss: 0.5810 - val_mse: 0.5810 - val_mae: 0.5634\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1186 - mse: 0.1186 - mae: 0.2612 - val_loss: 0.5834 - val_mse: 0.5834 - val_mae: 0.5680\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1119 - mse: 0.1119 - mae: 0.2545 - val_loss: 0.5623 - val_mse: 0.5623 - val_mae: 0.5613\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1142 - mse: 0.1142 - mae: 0.2569 - val_loss: 0.5604 - val_mse: 0.5604 - val_mae: 0.5614\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1092 - mse: 0.1092 - mae: 0.2504 - val_loss: 0.5463 - val_mse: 0.5463 - val_mae: 0.5512\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1070 - mse: 0.1070 - mae: 0.2484 - val_loss: 0.5492 - val_mse: 0.5492 - val_mae: 0.5500\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1074 - mse: 0.1074 - mae: 0.2491 - val_loss: 0.5253 - val_mse: 0.5253 - val_mae: 0.5388\n",
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1064 - mse: 0.1064 - mae: 0.2483 - val_loss: 0.5574 - val_mse: 0.5574 - val_mae: 0.5573\n",
      "Epoch 58/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1115 - mse: 0.1115 - mae: 0.2534 - val_loss: 0.5365 - val_mse: 0.5365 - val_mae: 0.5403\n",
      "Epoch 59/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1058 - mse: 0.1058 - mae: 0.2466 - val_loss: 0.5175 - val_mse: 0.5175 - val_mae: 0.5307\n",
      "Epoch 60/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1096 - mse: 0.1096 - mae: 0.2520 - val_loss: 0.5246 - val_mse: 0.5246 - val_mae: 0.5369\n",
      "Epoch 61/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1072 - mse: 0.1072 - mae: 0.2475 - val_loss: 0.5260 - val_mse: 0.5260 - val_mae: 0.5285\n",
      "Epoch 62/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1164 - mse: 0.1164 - mae: 0.2557 - val_loss: 0.5320 - val_mse: 0.5320 - val_mae: 0.5371\n",
      "Epoch 63/3000\n",
      "10664/10664 [==============================] - 0s 10us/sample - loss: 0.1081 - mse: 0.1081 - mae: 0.2491 - val_loss: 0.5158 - val_mse: 0.5158 - val_mae: 0.5298\n",
      "Epoch 64/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1068 - mse: 0.1068 - mae: 0.2497 - val_loss: 0.5164 - val_mse: 0.5164 - val_mae: 0.5267\n",
      "Epoch 65/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1007 - mse: 0.1007 - mae: 0.2405 - val_loss: 0.5063 - val_mse: 0.5063 - val_mae: 0.5214\n",
      "Epoch 66/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0995 - mse: 0.0995 - mae: 0.2383 - val_loss: 0.5058 - val_mse: 0.5058 - val_mae: 0.5206\n",
      "Epoch 67/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.0982 - mse: 0.0982 - mae: 0.2387 - val_loss: 0.4916 - val_mse: 0.4916 - val_mae: 0.5128\n",
      "Epoch 68/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.0994 - mse: 0.0994 - mae: 0.2395 - val_loss: 0.4874 - val_mse: 0.4874 - val_mae: 0.5081\n",
      "Epoch 69/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0983 - mse: 0.0983 - mae: 0.2397 - val_loss: 0.5007 - val_mse: 0.5007 - val_mae: 0.5148\n",
      "Epoch 70/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0971 - mse: 0.0971 - mae: 0.2356 - val_loss: 0.5007 - val_mse: 0.5007 - val_mae: 0.5159\n",
      "Epoch 71/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0935 - mse: 0.0935 - mae: 0.2317 - val_loss: 0.4960 - val_mse: 0.4960 - val_mae: 0.5125\n",
      "Epoch 72/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0968 - mse: 0.0968 - mae: 0.2372 - val_loss: 0.4835 - val_mse: 0.4835 - val_mae: 0.5034\n",
      "Epoch 73/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0922 - mse: 0.0922 - mae: 0.2312 - val_loss: 0.4889 - val_mse: 0.4889 - val_mae: 0.5072\n",
      "Epoch 74/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0937 - mse: 0.0937 - mae: 0.2322 - val_loss: 0.4865 - val_mse: 0.4865 - val_mae: 0.4996\n",
      "Epoch 75/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0935 - mse: 0.0935 - mae: 0.2334 - val_loss: 0.4907 - val_mse: 0.4907 - val_mae: 0.5082\n",
      "Epoch 76/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0902 - mse: 0.0902 - mae: 0.2275 - val_loss: 0.4831 - val_mse: 0.4831 - val_mae: 0.5053\n",
      "Epoch 77/3000\n",
      "10664/10664 [==============================] - 0s 10us/sample - loss: 0.0897 - mse: 0.0897 - mae: 0.2280 - val_loss: 0.4846 - val_mse: 0.4846 - val_mae: 0.5022\n",
      "Epoch 78/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0897 - mse: 0.0897 - mae: 0.2280 - val_loss: 0.4855 - val_mse: 0.4855 - val_mae: 0.5073\n",
      "Epoch 79/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0897 - mse: 0.0897 - mae: 0.2270 - val_loss: 0.4975 - val_mse: 0.4975 - val_mae: 0.5116\n",
      "Epoch 80/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0917 - mse: 0.0917 - mae: 0.2308 - val_loss: 0.4809 - val_mse: 0.4809 - val_mae: 0.4955\n",
      "Epoch 81/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0909 - mse: 0.0909 - mae: 0.2301 - val_loss: 0.4881 - val_mse: 0.4881 - val_mae: 0.5036\n",
      "Epoch 82/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0893 - mse: 0.0893 - mae: 0.2258 - val_loss: 0.4869 - val_mse: 0.4869 - val_mae: 0.5046\n",
      "Epoch 83/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0856 - mse: 0.0856 - mae: 0.2219 - val_loss: 0.4867 - val_mse: 0.4867 - val_mae: 0.5022\n",
      "Epoch 84/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0876 - mse: 0.0876 - mae: 0.2262 - val_loss: 0.4743 - val_mse: 0.4743 - val_mae: 0.4948\n",
      "Epoch 85/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.0843 - mse: 0.0843 - mae: 0.2207 - val_loss: 0.4812 - val_mse: 0.4812 - val_mae: 0.4981\n",
      "Epoch 86/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0834 - mse: 0.0834 - mae: 0.2187 - val_loss: 0.4794 - val_mse: 0.4794 - val_mae: 0.4953\n",
      "Epoch 87/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0786 - mse: 0.0786 - mae: 0.2129 - val_loss: 0.4794 - val_mse: 0.4794 - val_mae: 0.4982\n",
      "Epoch 88/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0769 - mse: 0.0769 - mae: 0.2100 - val_loss: 0.4737 - val_mse: 0.4737 - val_mae: 0.4953\n",
      "Epoch 89/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0806 - mse: 0.0806 - mae: 0.2164 - val_loss: 0.4688 - val_mse: 0.4688 - val_mae: 0.4901\n",
      "Epoch 90/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.0741 - mse: 0.0741 - mae: 0.2056 - val_loss: 0.4760 - val_mse: 0.4760 - val_mae: 0.4930\n",
      "Epoch 91/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0757 - mse: 0.0757 - mae: 0.2097 - val_loss: 0.4752 - val_mse: 0.4752 - val_mae: 0.4926\n",
      "Epoch 92/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0784 - mse: 0.0784 - mae: 0.2127 - val_loss: 0.4728 - val_mse: 0.4728 - val_mae: 0.4871\n",
      "Epoch 93/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0781 - mse: 0.0781 - mae: 0.2124 - val_loss: 0.4709 - val_mse: 0.4709 - val_mae: 0.4887\n",
      "Epoch 94/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0766 - mse: 0.0766 - mae: 0.2100 - val_loss: 0.4663 - val_mse: 0.4663 - val_mae: 0.4879\n",
      "Epoch 95/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0775 - mse: 0.0775 - mae: 0.2110 - val_loss: 0.4849 - val_mse: 0.4849 - val_mae: 0.4982\n",
      "Epoch 96/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0751 - mse: 0.0751 - mae: 0.2081 - val_loss: 0.4654 - val_mse: 0.4654 - val_mae: 0.4868\n",
      "Epoch 97/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0734 - mse: 0.0734 - mae: 0.2060 - val_loss: 0.4772 - val_mse: 0.4772 - val_mae: 0.4936\n",
      "Epoch 98/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0750 - mse: 0.0750 - mae: 0.2062 - val_loss: 0.4701 - val_mse: 0.4701 - val_mae: 0.4865\n",
      "Epoch 99/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0757 - mse: 0.0757 - mae: 0.2075 - val_loss: 0.4784 - val_mse: 0.4784 - val_mae: 0.4932\n",
      "Epoch 100/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0790 - mse: 0.0790 - mae: 0.2118 - val_loss: 0.4797 - val_mse: 0.4797 - val_mae: 0.4928\n",
      "Epoch 101/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0788 - mse: 0.0788 - mae: 0.2117 - val_loss: 0.4805 - val_mse: 0.4805 - val_mae: 0.4969\n",
      "Epoch 102/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0866 - mse: 0.0866 - mae: 0.2229 - val_loss: 0.4851 - val_mse: 0.4851 - val_mae: 0.4944\n",
      "Epoch 103/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0818 - mse: 0.0818 - mae: 0.2169 - val_loss: 0.4763 - val_mse: 0.4763 - val_mae: 0.4886\n",
      "Epoch 104/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0810 - mse: 0.0810 - mae: 0.2161 - val_loss: 0.4920 - val_mse: 0.4920 - val_mae: 0.4986\n",
      "Epoch 105/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.0792 - mse: 0.0792 - mae: 0.2145 - val_loss: 0.4764 - val_mse: 0.4764 - val_mae: 0.4931\n",
      "Epoch 106/3000\n",
      "10664/10664 [==============================] - 0s 10us/sample - loss: 0.0818 - mse: 0.0818 - mae: 0.2177 - val_loss: 0.4895 - val_mse: 0.4895 - val_mae: 0.4966\n",
      "Avg. MAE: 0.435920\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 6s 593us/sample - loss: 152.6530 - mse: 152.6530 - mae: 7.0581 - val_loss: 90980.2454 - val_mse: 90980.2422 - val_mae: 281.9976\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 4s 415us/sample - loss: 5.0050 - mse: 5.0050 - mae: 1.7190 - val_loss: 24739.7073 - val_mse: 24739.7070 - val_mae: 140.4989\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 4s 415us/sample - loss: 1.4389 - mse: 1.4389 - mae: 0.9309 - val_loss: 490.8787 - val_mse: 490.8787 - val_mae: 15.7926\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 4s 413us/sample - loss: 1.0900 - mse: 1.0900 - mae: 0.8032 - val_loss: 60.5273 - val_mse: 60.5273 - val_mae: 6.8393\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.8698 - mse: 0.8698 - mae: 0.7138 - val_loss: 4.6031 - val_mse: 4.6031 - val_mae: 1.7047\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.7917 - mse: 0.7917 - mae: 0.6752 - val_loss: 2.1446 - val_mse: 2.1446 - val_mae: 1.0872\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.7503 - mse: 0.7503 - mae: 0.6595 - val_loss: 1.3431 - val_mse: 1.3431 - val_mae: 0.8965\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.7265 - mse: 0.7265 - mae: 0.6439 - val_loss: 1.1717 - val_mse: 1.1717 - val_mae: 0.8498\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 4s 412us/sample - loss: 0.7003 - mse: 0.7003 - mae: 0.6296 - val_loss: 1.0975 - val_mse: 1.0975 - val_mae: 0.8386\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.6858 - mse: 0.6858 - mae: 0.6283 - val_loss: 0.9748 - val_mse: 0.9748 - val_mae: 0.7877\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.6655 - mse: 0.6655 - mae: 0.6140 - val_loss: 0.9657 - val_mse: 0.9657 - val_mae: 0.7932\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.6514 - mse: 0.6514 - mae: 0.6052 - val_loss: 0.9183 - val_mse: 0.9183 - val_mae: 0.7735\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.6300 - mse: 0.6300 - mae: 0.5977 - val_loss: 0.8970 - val_mse: 0.8970 - val_mae: 0.7619\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.6121 - mse: 0.6121 - mae: 0.5889 - val_loss: 0.8292 - val_mse: 0.8292 - val_mae: 0.7216\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.6020 - mse: 0.6020 - mae: 0.5825 - val_loss: 0.8187 - val_mse: 0.8187 - val_mae: 0.7172\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.5831 - mse: 0.5831 - mae: 0.5686 - val_loss: 0.8212 - val_mse: 0.8212 - val_mae: 0.7255\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 4s 412us/sample - loss: 0.5704 - mse: 0.5704 - mae: 0.5638 - val_loss: 0.7736 - val_mse: 0.7736 - val_mae: 0.6958\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 4s 412us/sample - loss: 0.5602 - mse: 0.5602 - mae: 0.5601 - val_loss: 0.7321 - val_mse: 0.7321 - val_mae: 0.6698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.5499 - mse: 0.5499 - mae: 0.5503 - val_loss: 0.7301 - val_mse: 0.7301 - val_mae: 0.6748\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.5324 - mse: 0.5324 - mae: 0.5421 - val_loss: 0.7192 - val_mse: 0.7192 - val_mae: 0.6651\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.5270 - mse: 0.5270 - mae: 0.5386 - val_loss: 0.6897 - val_mse: 0.6897 - val_mae: 0.6518\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.5109 - mse: 0.5109 - mae: 0.5298 - val_loss: 0.6938 - val_mse: 0.6938 - val_mae: 0.6508\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.5023 - mse: 0.5023 - mae: 0.5273 - val_loss: 0.6432 - val_mse: 0.6432 - val_mae: 0.6179\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.4860 - mse: 0.4860 - mae: 0.5163 - val_loss: 0.6702 - val_mse: 0.6702 - val_mae: 0.6386\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.4742 - mse: 0.4742 - mae: 0.5088 - val_loss: 0.6280 - val_mse: 0.6280 - val_mae: 0.6156\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.4618 - mse: 0.4618 - mae: 0.5043 - val_loss: 0.6408 - val_mse: 0.6408 - val_mae: 0.6215\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.4491 - mse: 0.4491 - mae: 0.4961 - val_loss: 0.6093 - val_mse: 0.6093 - val_mae: 0.6023\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.4416 - mse: 0.4416 - mae: 0.4921 - val_loss: 0.5880 - val_mse: 0.5880 - val_mae: 0.5906\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.4259 - mse: 0.4259 - mae: 0.4862 - val_loss: 0.6009 - val_mse: 0.6009 - val_mae: 0.5900\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.4116 - mse: 0.4116 - mae: 0.4767 - val_loss: 0.5842 - val_mse: 0.5842 - val_mae: 0.5843\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 4s 413us/sample - loss: 0.3941 - mse: 0.3941 - mae: 0.4669 - val_loss: 0.5776 - val_mse: 0.5776 - val_mae: 0.5804\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 4s 415us/sample - loss: 0.3865 - mse: 0.3865 - mae: 0.4629 - val_loss: 0.5500 - val_mse: 0.5500 - val_mae: 0.5644\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 5s 435us/sample - loss: 0.3650 - mse: 0.3650 - mae: 0.4476 - val_loss: 0.5508 - val_mse: 0.5508 - val_mae: 0.5691\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 5s 455us/sample - loss: 0.3546 - mse: 0.3546 - mae: 0.4435 - val_loss: 0.5458 - val_mse: 0.5458 - val_mae: 0.5598\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 4s 417us/sample - loss: 0.3422 - mse: 0.3422 - mae: 0.4374 - val_loss: 0.5188 - val_mse: 0.5188 - val_mae: 0.5406\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.3296 - mse: 0.3296 - mae: 0.4284 - val_loss: 0.5319 - val_mse: 0.5319 - val_mae: 0.5513\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.3202 - mse: 0.3202 - mae: 0.4221 - val_loss: 0.5186 - val_mse: 0.5186 - val_mae: 0.5436\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.3005 - mse: 0.3005 - mae: 0.4103 - val_loss: 0.5345 - val_mse: 0.5345 - val_mae: 0.5469\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.2950 - mse: 0.2950 - mae: 0.4068 - val_loss: 0.5347 - val_mse: 0.5347 - val_mae: 0.5559\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.2803 - mse: 0.2803 - mae: 0.3939 - val_loss: 0.5146 - val_mse: 0.5146 - val_mae: 0.5491\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 4s 404us/sample - loss: 0.2754 - mse: 0.2754 - mae: 0.3906 - val_loss: 0.5212 - val_mse: 0.5212 - val_mae: 0.5440\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.2566 - mse: 0.2566 - mae: 0.3816 - val_loss: 0.5020 - val_mse: 0.5020 - val_mae: 0.5392\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.2495 - mse: 0.2495 - mae: 0.3728 - val_loss: 0.4697 - val_mse: 0.4697 - val_mae: 0.5168\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.2392 - mse: 0.2392 - mae: 0.3676 - val_loss: 0.4808 - val_mse: 0.4808 - val_mae: 0.5214\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 4s 415us/sample - loss: 0.2279 - mse: 0.2279 - mae: 0.3603 - val_loss: 0.5084 - val_mse: 0.5084 - val_mae: 0.5330\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.2231 - mse: 0.2231 - mae: 0.3557 - val_loss: 0.5283 - val_mse: 0.5283 - val_mae: 0.5529\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.2108 - mse: 0.2108 - mae: 0.3455 - val_loss: 0.4648 - val_mse: 0.4648 - val_mae: 0.5117\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 4s 412us/sample - loss: 0.2019 - mse: 0.2019 - mae: 0.3402 - val_loss: 0.4394 - val_mse: 0.4394 - val_mae: 0.4993\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.2020 - mse: 0.2020 - mae: 0.3390 - val_loss: 0.4424 - val_mse: 0.4424 - val_mae: 0.4939\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 4s 416us/sample - loss: 0.2069 - mse: 0.2069 - mae: 0.3422 - val_loss: 0.4797 - val_mse: 0.4797 - val_mae: 0.5236\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 4s 414us/sample - loss: 0.1891 - mse: 0.1891 - mae: 0.3302 - val_loss: 0.4399 - val_mse: 0.4399 - val_mae: 0.5000\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.1784 - mse: 0.1784 - mae: 0.3183 - val_loss: 0.4626 - val_mse: 0.4626 - val_mae: 0.5120\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.1786 - mse: 0.1786 - mae: 0.3202 - val_loss: 0.4743 - val_mse: 0.4743 - val_mae: 0.5268\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1782 - mse: 0.1782 - mae: 0.3193 - val_loss: 0.4639 - val_mse: 0.4639 - val_mae: 0.5166\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 4s 413us/sample - loss: 0.1757 - mse: 0.1757 - mae: 0.3167 - val_loss: 0.4288 - val_mse: 0.4288 - val_mae: 0.4913\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.1676 - mse: 0.1676 - mae: 0.3098 - val_loss: 0.4118 - val_mse: 0.4118 - val_mae: 0.4718\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.1675 - mse: 0.1675 - mae: 0.3122 - val_loss: 0.4387 - val_mse: 0.4387 - val_mae: 0.4962\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1585 - mse: 0.1585 - mae: 0.3026 - val_loss: 0.4326 - val_mse: 0.4326 - val_mae: 0.4963\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 4s 415us/sample - loss: 0.1578 - mse: 0.1578 - mae: 0.2989 - val_loss: 0.3989 - val_mse: 0.3989 - val_mae: 0.4710\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1551 - mse: 0.1551 - mae: 0.2967 - val_loss: 0.4021 - val_mse: 0.4021 - val_mae: 0.4617\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.1398 - mse: 0.1398 - mae: 0.2849 - val_loss: 0.4369 - val_mse: 0.4369 - val_mae: 0.4987\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1430 - mse: 0.1430 - mae: 0.2873 - val_loss: 0.4990 - val_mse: 0.4990 - val_mae: 0.5418\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.1494 - mse: 0.1494 - mae: 0.2929 - val_loss: 0.4212 - val_mse: 0.4212 - val_mae: 0.4825\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 4s 405us/sample - loss: 0.1346 - mse: 0.1346 - mae: 0.2789 - val_loss: 0.4112 - val_mse: 0.4112 - val_mae: 0.4665\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1376 - mse: 0.1376 - mae: 0.2804 - val_loss: 0.4090 - val_mse: 0.4090 - val_mae: 0.4651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 4s 406us/sample - loss: 0.1267 - mse: 0.1267 - mae: 0.2707 - val_loss: 0.4142 - val_mse: 0.4142 - val_mae: 0.4773\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1333 - mse: 0.1333 - mae: 0.2764 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4675\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1409 - mse: 0.1409 - mae: 0.2844 - val_loss: 0.4495 - val_mse: 0.4495 - val_mae: 0.4979\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1311 - mse: 0.1311 - mae: 0.2720 - val_loss: 0.4235 - val_mse: 0.4235 - val_mae: 0.4706\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 6s 572us/sample - loss: 132.4649 - mse: 132.4649 - mae: 6.1540 - val_loss: 827403.6072 - val_mse: 827403.6250 - val_mae: 684.7676\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 3.6962 - mse: 3.6962 - mae: 1.4389 - val_loss: 1299.5181 - val_mse: 1299.5181 - val_mae: 26.4085\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 1.6479 - mse: 1.6479 - mae: 1.0090 - val_loss: 269.4650 - val_mse: 269.4650 - val_mae: 11.2217\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 4s 416us/sample - loss: 1.0213 - mse: 1.0213 - mae: 0.7810 - val_loss: 34.7570 - val_mse: 34.7570 - val_mae: 3.4083\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.8826 - mse: 0.8826 - mae: 0.7159 - val_loss: 2.5450 - val_mse: 2.5450 - val_mae: 1.2780\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 4s 406us/sample - loss: 0.8030 - mse: 0.8030 - mae: 0.6793 - val_loss: 6.8538 - val_mse: 6.8538 - val_mae: 1.2766\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.7744 - mse: 0.7744 - mae: 0.6625 - val_loss: 3.8097 - val_mse: 3.8097 - val_mae: 1.0306\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.7501 - mse: 0.7501 - mae: 0.6543 - val_loss: 1.2757 - val_mse: 1.2757 - val_mae: 0.8454\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.7291 - mse: 0.7291 - mae: 0.6401 - val_loss: 1.6452 - val_mse: 1.6452 - val_mae: 0.8609\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.7081 - mse: 0.7081 - mae: 0.6331 - val_loss: 1.1467 - val_mse: 1.1467 - val_mae: 0.8212\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.6931 - mse: 0.6931 - mae: 0.6246 - val_loss: 1.0714 - val_mse: 1.0714 - val_mae: 0.8036\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.6760 - mse: 0.6760 - mae: 0.6175 - val_loss: 1.0496 - val_mse: 1.0496 - val_mae: 0.7841\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.6609 - mse: 0.6609 - mae: 0.6104 - val_loss: 0.9898 - val_mse: 0.9898 - val_mae: 0.7625\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.6461 - mse: 0.6461 - mae: 0.6029 - val_loss: 0.9899 - val_mse: 0.9899 - val_mae: 0.7612\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.6324 - mse: 0.6324 - mae: 0.5951 - val_loss: 0.9011 - val_mse: 0.9011 - val_mae: 0.7567\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.6175 - mse: 0.6175 - mae: 0.5854 - val_loss: 1.0384 - val_mse: 1.0384 - val_mae: 0.7851\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.6112 - mse: 0.6112 - mae: 0.5826 - val_loss: 0.8300 - val_mse: 0.8300 - val_mae: 0.7242\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 4s 418us/sample - loss: 0.5924 - mse: 0.5924 - mae: 0.5787 - val_loss: 0.7689 - val_mse: 0.7689 - val_mae: 0.6746\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.5828 - mse: 0.5828 - mae: 0.5662 - val_loss: 0.8712 - val_mse: 0.8712 - val_mae: 0.7256\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.5734 - mse: 0.5734 - mae: 0.5623 - val_loss: 0.7500 - val_mse: 0.7500 - val_mae: 0.6845\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.5595 - mse: 0.5595 - mae: 0.5590 - val_loss: 0.7224 - val_mse: 0.7224 - val_mae: 0.6581\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.5459 - mse: 0.5459 - mae: 0.5502 - val_loss: 0.6964 - val_mse: 0.6964 - val_mae: 0.6513\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.5324 - mse: 0.5324 - mae: 0.5427 - val_loss: 0.6882 - val_mse: 0.6882 - val_mae: 0.6380\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 5s 425us/sample - loss: 0.5259 - mse: 0.5259 - mae: 0.5381 - val_loss: 0.6977 - val_mse: 0.6977 - val_mae: 0.6405\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 4s 418us/sample - loss: 0.5133 - mse: 0.5133 - mae: 0.5346 - val_loss: 0.6601 - val_mse: 0.6601 - val_mae: 0.6201\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.4979 - mse: 0.4979 - mae: 0.5242 - val_loss: 0.6541 - val_mse: 0.6541 - val_mae: 0.6266\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 4s 413us/sample - loss: 0.4922 - mse: 0.4922 - mae: 0.5198 - val_loss: 0.6355 - val_mse: 0.6355 - val_mae: 0.6041\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.4782 - mse: 0.4782 - mae: 0.5151 - val_loss: 0.6258 - val_mse: 0.6258 - val_mae: 0.5899\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.4658 - mse: 0.4658 - mae: 0.5092 - val_loss: 0.6274 - val_mse: 0.6274 - val_mae: 0.5879\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.4502 - mse: 0.4502 - mae: 0.4981 - val_loss: 0.6279 - val_mse: 0.6279 - val_mae: 0.5921\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.4372 - mse: 0.4372 - mae: 0.4916 - val_loss: 0.5997 - val_mse: 0.5997 - val_mae: 0.5773\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 5s 423us/sample - loss: 0.4239 - mse: 0.4239 - mae: 0.4839 - val_loss: 0.5771 - val_mse: 0.5771 - val_mae: 0.5607\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.4147 - mse: 0.4147 - mae: 0.4788 - val_loss: 0.5760 - val_mse: 0.5760 - val_mae: 0.5644\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.3953 - mse: 0.3953 - mae: 0.4684 - val_loss: 0.6079 - val_mse: 0.6079 - val_mae: 0.5485\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.3845 - mse: 0.3845 - mae: 0.4592 - val_loss: 0.5862 - val_mse: 0.5862 - val_mae: 0.5610\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.3706 - mse: 0.3706 - mae: 0.4539 - val_loss: 0.5715 - val_mse: 0.5715 - val_mae: 0.5598\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.3618 - mse: 0.3618 - mae: 0.4483 - val_loss: 0.5565 - val_mse: 0.5565 - val_mae: 0.5437\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.3514 - mse: 0.3514 - mae: 0.4425 - val_loss: 0.5535 - val_mse: 0.5535 - val_mae: 0.5389\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 4s 406us/sample - loss: 0.3362 - mse: 0.3362 - mae: 0.4330 - val_loss: 0.5746 - val_mse: 0.5746 - val_mae: 0.5519\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.3256 - mse: 0.3256 - mae: 0.4247 - val_loss: 0.5721 - val_mse: 0.5721 - val_mae: 0.5503\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.3183 - mse: 0.3183 - mae: 0.4205 - val_loss: 0.5418 - val_mse: 0.5418 - val_mae: 0.5356\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.3061 - mse: 0.3061 - mae: 0.4135 - val_loss: 0.5464 - val_mse: 0.5464 - val_mae: 0.5372\n",
      "Epoch 43/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 4s 406us/sample - loss: 0.2973 - mse: 0.2973 - mae: 0.4064 - val_loss: 0.5182 - val_mse: 0.5182 - val_mae: 0.5242\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.2871 - mse: 0.2871 - mae: 0.4023 - val_loss: 0.5772 - val_mse: 0.5772 - val_mae: 0.5407\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.2833 - mse: 0.2833 - mae: 0.3987 - val_loss: 0.5526 - val_mse: 0.5526 - val_mae: 0.5326\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 4s 419us/sample - loss: 0.2675 - mse: 0.2675 - mae: 0.3883 - val_loss: 0.5649 - val_mse: 0.5649 - val_mae: 0.5284\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 4s 419us/sample - loss: 0.2583 - mse: 0.2583 - mae: 0.3802 - val_loss: 0.5126 - val_mse: 0.5126 - val_mae: 0.5135\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 4s 415us/sample - loss: 0.2554 - mse: 0.2554 - mae: 0.3802 - val_loss: 0.5530 - val_mse: 0.5530 - val_mae: 0.5297\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.2459 - mse: 0.2459 - mae: 0.3738 - val_loss: 0.5612 - val_mse: 0.5612 - val_mae: 0.5329\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.2418 - mse: 0.2418 - mae: 0.3680 - val_loss: 0.5177 - val_mse: 0.5177 - val_mae: 0.5173\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.2344 - mse: 0.2344 - mae: 0.3634 - val_loss: 0.5318 - val_mse: 0.5318 - val_mae: 0.5058\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.2327 - mse: 0.2327 - mae: 0.3636 - val_loss: 0.5266 - val_mse: 0.5266 - val_mae: 0.5205\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.2197 - mse: 0.2197 - mae: 0.3542 - val_loss: 0.4977 - val_mse: 0.4977 - val_mae: 0.5018\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 4s 412us/sample - loss: 0.2164 - mse: 0.2164 - mae: 0.3495 - val_loss: 0.4971 - val_mse: 0.4971 - val_mae: 0.5031\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.2003 - mse: 0.2003 - mae: 0.3375 - val_loss: 0.4916 - val_mse: 0.4916 - val_mae: 0.4959\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1995 - mse: 0.1995 - mae: 0.3375 - val_loss: 0.4976 - val_mse: 0.4976 - val_mae: 0.5009\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.1858 - mse: 0.1858 - mae: 0.3247 - val_loss: 0.5906 - val_mse: 0.5906 - val_mae: 0.5447\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1896 - mse: 0.1896 - mae: 0.3258 - val_loss: 0.5462 - val_mse: 0.5462 - val_mae: 0.5055\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1901 - mse: 0.1901 - mae: 0.3277 - val_loss: 0.7031 - val_mse: 0.7031 - val_mae: 0.5421\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 4s 416us/sample - loss: 0.1854 - mse: 0.1854 - mae: 0.3234 - val_loss: 0.4657 - val_mse: 0.4657 - val_mae: 0.4801\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1842 - mse: 0.1842 - mae: 0.3210 - val_loss: 0.5078 - val_mse: 0.5078 - val_mae: 0.4975\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.1770 - mse: 0.1770 - mae: 0.3167 - val_loss: 0.5108 - val_mse: 0.5108 - val_mae: 0.5134\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 4s 415us/sample - loss: 0.1724 - mse: 0.1724 - mae: 0.3147 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.4880\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 4s 412us/sample - loss: 0.1571 - mse: 0.1571 - mae: 0.2985 - val_loss: 0.5039 - val_mse: 0.5039 - val_mae: 0.5067\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.1553 - mse: 0.1553 - mae: 0.2982 - val_loss: 0.5178 - val_mse: 0.5178 - val_mae: 0.5093\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.1502 - mse: 0.1502 - mae: 0.2926 - val_loss: 0.4597 - val_mse: 0.4597 - val_mae: 0.4776\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.1527 - mse: 0.1527 - mae: 0.2929 - val_loss: 0.4734 - val_mse: 0.4734 - val_mae: 0.4960\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1525 - mse: 0.1525 - mae: 0.2924 - val_loss: 0.4329 - val_mse: 0.4329 - val_mae: 0.4663\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1434 - mse: 0.1434 - mae: 0.2846 - val_loss: 0.4739 - val_mse: 0.4739 - val_mae: 0.4910\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1440 - mse: 0.1440 - mae: 0.2862 - val_loss: 0.4567 - val_mse: 0.4567 - val_mae: 0.4716\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1359 - mse: 0.1359 - mae: 0.2774 - val_loss: 0.4405 - val_mse: 0.4405 - val_mae: 0.4578\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.1242 - mse: 0.1242 - mae: 0.2645 - val_loss: 0.4317 - val_mse: 0.4317 - val_mae: 0.4634\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1260 - mse: 0.1260 - mae: 0.2677 - val_loss: 0.5203 - val_mse: 0.5203 - val_mae: 0.5073\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 4s 417us/sample - loss: 0.1310 - mse: 0.1310 - mae: 0.2745 - val_loss: 0.4134 - val_mse: 0.4134 - val_mae: 0.4480\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.1208 - mse: 0.1208 - mae: 0.2608 - val_loss: 0.4242 - val_mse: 0.4242 - val_mae: 0.4564\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 4s 414us/sample - loss: 0.1186 - mse: 0.1186 - mae: 0.2584 - val_loss: 0.4502 - val_mse: 0.4502 - val_mae: 0.4658\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1261 - mse: 0.1261 - mae: 0.2643 - val_loss: 0.4760 - val_mse: 0.4760 - val_mae: 0.4885\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.1388 - mse: 0.1388 - mae: 0.2786 - val_loss: 0.4332 - val_mse: 0.4332 - val_mae: 0.4625\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.1347 - mse: 0.1347 - mae: 0.2765 - val_loss: 0.4227 - val_mse: 0.4227 - val_mae: 0.4598\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1238 - mse: 0.1238 - mae: 0.2674 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.4657\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1127 - mse: 0.1127 - mae: 0.2531 - val_loss: 0.4233 - val_mse: 0.4233 - val_mae: 0.4602\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1078 - mse: 0.1078 - mae: 0.2473 - val_loss: 0.4184 - val_mse: 0.4184 - val_mae: 0.4522\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.1056 - mse: 0.1056 - mae: 0.2459 - val_loss: 0.4095 - val_mse: 0.4095 - val_mae: 0.4472\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1111 - mse: 0.1111 - mae: 0.2519 - val_loss: 0.5083 - val_mse: 0.5083 - val_mae: 0.4864\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 4s 405us/sample - loss: 0.1104 - mse: 0.1104 - mae: 0.2495 - val_loss: 0.4476 - val_mse: 0.4476 - val_mae: 0.4570\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.1005 - mse: 0.1005 - mae: 0.2379 - val_loss: 0.4078 - val_mse: 0.4078 - val_mae: 0.4414\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 4s 405us/sample - loss: 0.0963 - mse: 0.0963 - mae: 0.2334 - val_loss: 0.4357 - val_mse: 0.4357 - val_mae: 0.4594\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 4s 415us/sample - loss: 0.0942 - mse: 0.0942 - mae: 0.2311 - val_loss: 0.4101 - val_mse: 0.4101 - val_mae: 0.4433\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2256 - val_loss: 0.3943 - val_mse: 0.3943 - val_mae: 0.4314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.0849 - mse: 0.0849 - mae: 0.2183 - val_loss: 0.4363 - val_mse: 0.4363 - val_mae: 0.4484\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.0899 - mse: 0.0899 - mae: 0.2248 - val_loss: 0.4235 - val_mse: 0.4235 - val_mae: 0.4369\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.0942 - mse: 0.0942 - mae: 0.2319 - val_loss: 0.4310 - val_mse: 0.4310 - val_mae: 0.4539\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.0925 - mse: 0.0925 - mae: 0.2281 - val_loss: 0.4036 - val_mse: 0.4036 - val_mae: 0.4409\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 4s 406us/sample - loss: 0.0898 - mse: 0.0898 - mae: 0.2248 - val_loss: 0.5040 - val_mse: 0.5040 - val_mae: 0.4531\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.0849 - mse: 0.0849 - mae: 0.2188 - val_loss: 0.4987 - val_mse: 0.4987 - val_mae: 0.4792\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.0870 - mse: 0.0870 - mae: 0.2211 - val_loss: 0.4202 - val_mse: 0.4202 - val_mae: 0.4528\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.0896 - mse: 0.0896 - mae: 0.2251 - val_loss: 0.4616 - val_mse: 0.4616 - val_mae: 0.4789\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.0927 - mse: 0.0927 - mae: 0.2291 - val_loss: 0.4168 - val_mse: 0.4168 - val_mae: 0.4526\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.0837 - mse: 0.0837 - mae: 0.2162 - val_loss: 0.5046 - val_mse: 0.5046 - val_mae: 0.4642\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 6s 554us/sample - loss: 146.6520 - mse: 146.6520 - mae: 6.7169 - val_loss: 45784.2116 - val_mse: 45784.2109 - val_mae: 194.8153\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 4s 418us/sample - loss: 3.7104 - mse: 3.7104 - mae: 1.5099 - val_loss: 6747.6035 - val_mse: 6747.6040 - val_mae: 70.1858\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 4s 406us/sample - loss: 1.5295 - mse: 1.5295 - mae: 0.9526 - val_loss: 92.6628 - val_mse: 92.6628 - val_mae: 8.0224\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 1.0773 - mse: 1.0773 - mae: 0.7919 - val_loss: 101.3709 - val_mse: 101.3709 - val_mae: 7.6743\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 4s 413us/sample - loss: 0.8737 - mse: 0.8737 - mae: 0.7098 - val_loss: 5.8958 - val_mse: 5.8958 - val_mae: 1.5631\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 4s 413us/sample - loss: 0.7712 - mse: 0.7712 - mae: 0.6642 - val_loss: 1.4481 - val_mse: 1.4481 - val_mae: 0.9367\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.7326 - mse: 0.7326 - mae: 0.6466 - val_loss: 1.1031 - val_mse: 1.1031 - val_mae: 0.8546\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 4s 406us/sample - loss: 0.7074 - mse: 0.7074 - mae: 0.6332 - val_loss: 1.1091 - val_mse: 1.1091 - val_mae: 0.8686\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.6861 - mse: 0.6861 - mae: 0.6219 - val_loss: 1.2610 - val_mse: 1.2610 - val_mae: 0.9440\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.6681 - mse: 0.6681 - mae: 0.6131 - val_loss: 1.2048 - val_mse: 1.2048 - val_mae: 0.9099\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.6508 - mse: 0.6508 - mae: 0.6059 - val_loss: 1.0291 - val_mse: 1.0291 - val_mae: 0.8297\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.6394 - mse: 0.6394 - mae: 0.5984 - val_loss: 0.9586 - val_mse: 0.9586 - val_mae: 0.7940\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.6230 - mse: 0.6230 - mae: 0.5915 - val_loss: 0.9319 - val_mse: 0.9319 - val_mae: 0.7856\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.6098 - mse: 0.6098 - mae: 0.5850 - val_loss: 0.8306 - val_mse: 0.8306 - val_mae: 0.7303\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 4s 412us/sample - loss: 0.5992 - mse: 0.5992 - mae: 0.5775 - val_loss: 0.8083 - val_mse: 0.8083 - val_mae: 0.7158\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 4s 418us/sample - loss: 0.5904 - mse: 0.5904 - mae: 0.5742 - val_loss: 0.7806 - val_mse: 0.7806 - val_mae: 0.7057\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 4s 414us/sample - loss: 0.5754 - mse: 0.5754 - mae: 0.5616 - val_loss: 0.7814 - val_mse: 0.7814 - val_mae: 0.7061\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 4s 416us/sample - loss: 0.5670 - mse: 0.5670 - mae: 0.5614 - val_loss: 0.7182 - val_mse: 0.7182 - val_mae: 0.6689\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 4s 413us/sample - loss: 0.5541 - mse: 0.5541 - mae: 0.5531 - val_loss: 0.6909 - val_mse: 0.6909 - val_mae: 0.6539\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.5416 - mse: 0.5416 - mae: 0.5479 - val_loss: 0.6615 - val_mse: 0.6615 - val_mae: 0.6308\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.5304 - mse: 0.5304 - mae: 0.5440 - val_loss: 0.6369 - val_mse: 0.6369 - val_mae: 0.6146\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.5207 - mse: 0.5207 - mae: 0.5340 - val_loss: 0.6624 - val_mse: 0.6624 - val_mae: 0.6336\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.5096 - mse: 0.5096 - mae: 0.5269 - val_loss: 0.6267 - val_mse: 0.6267 - val_mae: 0.6121\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.4969 - mse: 0.4969 - mae: 0.5241 - val_loss: 0.6212 - val_mse: 0.6212 - val_mae: 0.6001\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.4825 - mse: 0.4825 - mae: 0.5144 - val_loss: 0.6035 - val_mse: 0.6035 - val_mae: 0.6024\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.4635 - mse: 0.4635 - mae: 0.5068 - val_loss: 0.5801 - val_mse: 0.5801 - val_mae: 0.5798\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 4s 406us/sample - loss: 0.4509 - mse: 0.4509 - mae: 0.5003 - val_loss: 0.5721 - val_mse: 0.5721 - val_mae: 0.5767\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.4338 - mse: 0.4338 - mae: 0.4894 - val_loss: 0.5635 - val_mse: 0.5635 - val_mae: 0.5655\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.4183 - mse: 0.4183 - mae: 0.4804 - val_loss: 0.5755 - val_mse: 0.5755 - val_mae: 0.5836\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 4s 415us/sample - loss: 0.3995 - mse: 0.3995 - mae: 0.4689 - val_loss: 0.5823 - val_mse: 0.5823 - val_mae: 0.5877\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.3864 - mse: 0.3864 - mae: 0.4623 - val_loss: 0.5674 - val_mse: 0.5674 - val_mae: 0.5735\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.3622 - mse: 0.3622 - mae: 0.4483 - val_loss: 0.5443 - val_mse: 0.5443 - val_mae: 0.5577\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.3476 - mse: 0.3476 - mae: 0.4379 - val_loss: 0.5518 - val_mse: 0.5518 - val_mae: 0.5580\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.3327 - mse: 0.3327 - mae: 0.4315 - val_loss: 0.5666 - val_mse: 0.5666 - val_mae: 0.5585\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.3272 - mse: 0.3272 - mae: 0.4251 - val_loss: 0.5325 - val_mse: 0.5325 - val_mae: 0.5503\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.3175 - mse: 0.3175 - mae: 0.4207 - val_loss: 0.5241 - val_mse: 0.5241 - val_mae: 0.5499\n",
      "Epoch 37/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.3002 - mse: 0.3002 - mae: 0.4089 - val_loss: 0.5450 - val_mse: 0.5450 - val_mae: 0.5687\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.2913 - mse: 0.2913 - mae: 0.4051 - val_loss: 0.5093 - val_mse: 0.5093 - val_mae: 0.5318\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 4s 406us/sample - loss: 0.2875 - mse: 0.2875 - mae: 0.3990 - val_loss: 0.5217 - val_mse: 0.5217 - val_mae: 0.5367\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.2737 - mse: 0.2737 - mae: 0.3908 - val_loss: 0.5129 - val_mse: 0.5129 - val_mae: 0.5364\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.2644 - mse: 0.2644 - mae: 0.3877 - val_loss: 0.4912 - val_mse: 0.4912 - val_mae: 0.5193\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.2570 - mse: 0.2570 - mae: 0.3808 - val_loss: 0.5074 - val_mse: 0.5074 - val_mae: 0.5274\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.2438 - mse: 0.2438 - mae: 0.3706 - val_loss: 0.4846 - val_mse: 0.4846 - val_mae: 0.5164\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 4s 417us/sample - loss: 0.2320 - mse: 0.2320 - mae: 0.3623 - val_loss: 0.4649 - val_mse: 0.4649 - val_mae: 0.5067\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.2232 - mse: 0.2232 - mae: 0.3566 - val_loss: 0.5062 - val_mse: 0.5062 - val_mae: 0.5222\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 4s 413us/sample - loss: 0.2332 - mse: 0.2332 - mae: 0.3598 - val_loss: 0.4492 - val_mse: 0.4492 - val_mae: 0.5010\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.2174 - mse: 0.2174 - mae: 0.3485 - val_loss: 0.4409 - val_mse: 0.4409 - val_mae: 0.4949\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 4s 406us/sample - loss: 0.2072 - mse: 0.2072 - mae: 0.3423 - val_loss: 0.4907 - val_mse: 0.4907 - val_mae: 0.5246\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.2024 - mse: 0.2024 - mae: 0.3409 - val_loss: 0.4518 - val_mse: 0.4518 - val_mae: 0.4936\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.1854 - mse: 0.1854 - mae: 0.3261 - val_loss: 0.4509 - val_mse: 0.4509 - val_mae: 0.4955\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1911 - mse: 0.1911 - mae: 0.3276 - val_loss: 0.4251 - val_mse: 0.4251 - val_mae: 0.4735\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1929 - mse: 0.1929 - mae: 0.3314 - val_loss: 0.4256 - val_mse: 0.4256 - val_mae: 0.4778\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1739 - mse: 0.1739 - mae: 0.3140 - val_loss: 0.4207 - val_mse: 0.4207 - val_mae: 0.4808\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1794 - mse: 0.1794 - mae: 0.3205 - val_loss: 0.4382 - val_mse: 0.4382 - val_mae: 0.4870\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 4s 404us/sample - loss: 0.1691 - mse: 0.1691 - mae: 0.3130 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.4854\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1618 - mse: 0.1618 - mae: 0.3030 - val_loss: 0.4143 - val_mse: 0.4143 - val_mae: 0.4649\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1563 - mse: 0.1563 - mae: 0.2986 - val_loss: 0.4803 - val_mse: 0.4803 - val_mae: 0.5219\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 4s 416us/sample - loss: 0.1604 - mse: 0.1604 - mae: 0.3033 - val_loss: 0.4137 - val_mse: 0.4137 - val_mae: 0.4711\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.1465 - mse: 0.1465 - mae: 0.2898 - val_loss: 0.4145 - val_mse: 0.4145 - val_mae: 0.4640\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1493 - mse: 0.1493 - mae: 0.2918 - val_loss: 0.5461 - val_mse: 0.5461 - val_mae: 0.5292\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 4s 405us/sample - loss: 0.1637 - mse: 0.1637 - mae: 0.3081 - val_loss: 0.4491 - val_mse: 0.4491 - val_mae: 0.4907\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1532 - mse: 0.1532 - mae: 0.2967 - val_loss: 0.4577 - val_mse: 0.4577 - val_mae: 0.4900\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 5s 423us/sample - loss: 0.1400 - mse: 0.1400 - mae: 0.2843 - val_loss: 0.4189 - val_mse: 0.4189 - val_mae: 0.4602\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 4s 414us/sample - loss: 0.1349 - mse: 0.1349 - mae: 0.2788 - val_loss: 0.4201 - val_mse: 0.4201 - val_mae: 0.4665\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.1336 - mse: 0.1336 - mae: 0.2813 - val_loss: 0.4243 - val_mse: 0.4243 - val_mae: 0.4663\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1237 - mse: 0.1237 - mae: 0.2674 - val_loss: 0.4056 - val_mse: 0.4056 - val_mae: 0.4539\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1225 - mse: 0.1225 - mae: 0.2657 - val_loss: 0.4150 - val_mse: 0.4150 - val_mae: 0.4615\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 4s 406us/sample - loss: 0.1271 - mse: 0.1271 - mae: 0.2690 - val_loss: 0.4716 - val_mse: 0.4716 - val_mae: 0.5128\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 4s 406us/sample - loss: 0.1339 - mse: 0.1339 - mae: 0.2772 - val_loss: 0.4910 - val_mse: 0.4910 - val_mae: 0.5082\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1314 - mse: 0.1314 - mae: 0.2749 - val_loss: 0.4371 - val_mse: 0.4371 - val_mae: 0.4807\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1249 - mse: 0.1249 - mae: 0.2662 - val_loss: 0.4242 - val_mse: 0.4242 - val_mae: 0.4693\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 4s 415us/sample - loss: 0.1177 - mse: 0.1177 - mae: 0.2615 - val_loss: 0.4284 - val_mse: 0.4284 - val_mae: 0.4722\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.1158 - mse: 0.1158 - mae: 0.2584 - val_loss: 0.4369 - val_mse: 0.4369 - val_mae: 0.4759\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1008 - mse: 0.1008 - mae: 0.2424 - val_loss: 0.4158 - val_mse: 0.4158 - val_mae: 0.4621\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1122 - mse: 0.1122 - mae: 0.2545 - val_loss: 0.5110 - val_mse: 0.5110 - val_mae: 0.5147\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1237 - mse: 0.1237 - mae: 0.2702 - val_loss: 0.4079 - val_mse: 0.4079 - val_mae: 0.4580\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 6s 569us/sample - loss: 145.2434 - mse: 145.2434 - mae: 6.6940 - val_loss: 147319.1013 - val_mse: 147319.0938 - val_mae: 358.6192\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 3.8690 - mse: 3.8690 - mae: 1.5779 - val_loss: 3617.4309 - val_mse: 3617.4307 - val_mae: 53.3190\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 1.4790 - mse: 1.4790 - mae: 0.9486 - val_loss: 198.1826 - val_mse: 198.1826 - val_mae: 12.5226\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 1.0403 - mse: 1.0403 - mae: 0.7869 - val_loss: 156.4999 - val_mse: 156.4999 - val_mae: 10.4097\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.8890 - mse: 0.8890 - mae: 0.7253 - val_loss: 7.3151 - val_mse: 7.3151 - val_mae: 2.1580\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.7905 - mse: 0.7905 - mae: 0.6757 - val_loss: 3.3557 - val_mse: 3.3557 - val_mae: 1.4080\n",
      "Epoch 7/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.7461 - mse: 0.7461 - mae: 0.6555 - val_loss: 1.5034 - val_mse: 1.5034 - val_mae: 0.9425\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.7277 - mse: 0.7277 - mae: 0.6466 - val_loss: 1.2405 - val_mse: 1.2405 - val_mae: 0.8309\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.7096 - mse: 0.7096 - mae: 0.6418 - val_loss: 1.0143 - val_mse: 1.0143 - val_mae: 0.7679\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 4s 418us/sample - loss: 0.6937 - mse: 0.6937 - mae: 0.6309 - val_loss: 0.9142 - val_mse: 0.9142 - val_mae: 0.7293\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 4s 413us/sample - loss: 0.6777 - mse: 0.6777 - mae: 0.6229 - val_loss: 0.8858 - val_mse: 0.8858 - val_mae: 0.7304\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.6693 - mse: 0.6693 - mae: 0.6175 - val_loss: 0.8626 - val_mse: 0.8626 - val_mae: 0.7205\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.6571 - mse: 0.6571 - mae: 0.6134 - val_loss: 0.7956 - val_mse: 0.7956 - val_mae: 0.6825\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.6473 - mse: 0.6473 - mae: 0.6075 - val_loss: 0.8349 - val_mse: 0.8349 - val_mae: 0.7064\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.6363 - mse: 0.6363 - mae: 0.5994 - val_loss: 0.7786 - val_mse: 0.7786 - val_mae: 0.6844\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.6222 - mse: 0.6222 - mae: 0.5953 - val_loss: 0.7339 - val_mse: 0.7339 - val_mae: 0.6610\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.6118 - mse: 0.6118 - mae: 0.5888 - val_loss: 0.7062 - val_mse: 0.7062 - val_mae: 0.6409\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.6040 - mse: 0.6040 - mae: 0.5880 - val_loss: 0.6822 - val_mse: 0.6822 - val_mae: 0.6318\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.5912 - mse: 0.5912 - mae: 0.5755 - val_loss: 0.6831 - val_mse: 0.6831 - val_mae: 0.6341\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.5784 - mse: 0.5784 - mae: 0.5701 - val_loss: 0.6586 - val_mse: 0.6586 - val_mae: 0.6240\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 4s 412us/sample - loss: 0.5684 - mse: 0.5684 - mae: 0.5655 - val_loss: 0.6427 - val_mse: 0.6427 - val_mae: 0.6126\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.5595 - mse: 0.5595 - mae: 0.5610 - val_loss: 0.6353 - val_mse: 0.6353 - val_mae: 0.6115\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.5493 - mse: 0.5493 - mae: 0.5534 - val_loss: 0.6288 - val_mse: 0.6288 - val_mae: 0.6069\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 4s 419us/sample - loss: 0.5408 - mse: 0.5408 - mae: 0.5512 - val_loss: 0.5991 - val_mse: 0.5991 - val_mae: 0.5861\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.5268 - mse: 0.5268 - mae: 0.5411 - val_loss: 0.6073 - val_mse: 0.6073 - val_mae: 0.5932\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.5171 - mse: 0.5171 - mae: 0.5366 - val_loss: 0.5832 - val_mse: 0.5832 - val_mae: 0.5774\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.5123 - mse: 0.5123 - mae: 0.5316 - val_loss: 0.5779 - val_mse: 0.5779 - val_mae: 0.5757\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.5057 - mse: 0.5057 - mae: 0.5265 - val_loss: 0.5829 - val_mse: 0.5829 - val_mae: 0.5803\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.4934 - mse: 0.4934 - mae: 0.5228 - val_loss: 0.5768 - val_mse: 0.5768 - val_mae: 0.5767\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 4s 412us/sample - loss: 0.4824 - mse: 0.4824 - mae: 0.5161 - val_loss: 0.5713 - val_mse: 0.5713 - val_mae: 0.5708\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.4705 - mse: 0.4705 - mae: 0.5101 - val_loss: 0.5890 - val_mse: 0.5890 - val_mae: 0.5795\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.4599 - mse: 0.4599 - mae: 0.5037 - val_loss: 0.5631 - val_mse: 0.5631 - val_mae: 0.5694\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.4544 - mse: 0.4544 - mae: 0.4985 - val_loss: 0.5665 - val_mse: 0.5665 - val_mae: 0.5745\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.4373 - mse: 0.4373 - mae: 0.4904 - val_loss: 0.5655 - val_mse: 0.5655 - val_mae: 0.5708\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 4s 412us/sample - loss: 0.4251 - mse: 0.4251 - mae: 0.4844 - val_loss: 0.5541 - val_mse: 0.5541 - val_mae: 0.5615\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.4128 - mse: 0.4128 - mae: 0.4781 - val_loss: 0.5588 - val_mse: 0.5588 - val_mae: 0.5654\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.4035 - mse: 0.4035 - mae: 0.4725 - val_loss: 0.5456 - val_mse: 0.5456 - val_mae: 0.5564\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 4s 414us/sample - loss: 0.3914 - mse: 0.3914 - mae: 0.4678 - val_loss: 0.5658 - val_mse: 0.5658 - val_mae: 0.5591\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 4s 405us/sample - loss: 0.3782 - mse: 0.3782 - mae: 0.4585 - val_loss: 0.5866 - val_mse: 0.5866 - val_mae: 0.5721\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.3685 - mse: 0.3685 - mae: 0.4506 - val_loss: 0.5875 - val_mse: 0.5875 - val_mae: 0.5758\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.3567 - mse: 0.3567 - mae: 0.4449 - val_loss: 0.5948 - val_mse: 0.5948 - val_mae: 0.5737\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.3447 - mse: 0.3447 - mae: 0.4366 - val_loss: 0.5471 - val_mse: 0.5471 - val_mae: 0.5516\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.3310 - mse: 0.3310 - mae: 0.4280 - val_loss: 0.5578 - val_mse: 0.5578 - val_mae: 0.5546\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.3157 - mse: 0.3157 - mae: 0.4175 - val_loss: 0.5871 - val_mse: 0.5871 - val_mae: 0.5692\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.3039 - mse: 0.3039 - mae: 0.4098 - val_loss: 0.5330 - val_mse: 0.5330 - val_mae: 0.5379\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.2988 - mse: 0.2988 - mae: 0.4084 - val_loss: 0.5677 - val_mse: 0.5677 - val_mae: 0.5559\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.2818 - mse: 0.2818 - mae: 0.3953 - val_loss: 0.5014 - val_mse: 0.5014 - val_mae: 0.5159\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.2749 - mse: 0.2749 - mae: 0.3914 - val_loss: 0.5627 - val_mse: 0.5627 - val_mae: 0.5523\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.2665 - mse: 0.2665 - mae: 0.3849 - val_loss: 0.5338 - val_mse: 0.5338 - val_mae: 0.5359\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.2571 - mse: 0.2571 - mae: 0.3803 - val_loss: 0.5955 - val_mse: 0.5955 - val_mae: 0.5684\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.2494 - mse: 0.2494 - mae: 0.3737 - val_loss: 0.5287 - val_mse: 0.5287 - val_mae: 0.5329\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 4s 421us/sample - loss: 0.2355 - mse: 0.2355 - mae: 0.3637 - val_loss: 0.5002 - val_mse: 0.5002 - val_mae: 0.5118\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.2379 - mse: 0.2379 - mae: 0.3663 - val_loss: 0.4754 - val_mse: 0.4754 - val_mae: 0.5030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 4s 411us/sample - loss: 0.2286 - mse: 0.2286 - mae: 0.3589 - val_loss: 0.4586 - val_mse: 0.4586 - val_mae: 0.4881\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.2190 - mse: 0.2190 - mae: 0.3504 - val_loss: 0.4969 - val_mse: 0.4969 - val_mae: 0.5098\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.2173 - mse: 0.2173 - mae: 0.3501 - val_loss: 0.4701 - val_mse: 0.4701 - val_mae: 0.5061\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.2141 - mse: 0.2141 - mae: 0.3486 - val_loss: 0.5021 - val_mse: 0.5021 - val_mae: 0.5217\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.2115 - mse: 0.2115 - mae: 0.3464 - val_loss: 0.4645 - val_mse: 0.4645 - val_mae: 0.4899\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1919 - mse: 0.1919 - mae: 0.3288 - val_loss: 0.4783 - val_mse: 0.4783 - val_mae: 0.5104\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.2045 - mse: 0.2045 - mae: 0.3420 - val_loss: 0.4870 - val_mse: 0.4870 - val_mae: 0.5095\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.1996 - mse: 0.1996 - mae: 0.3362 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.4931\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 4s 413us/sample - loss: 0.1904 - mse: 0.1904 - mae: 0.3271 - val_loss: 0.4347 - val_mse: 0.4347 - val_mae: 0.4797\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.1766 - mse: 0.1766 - mae: 0.3157 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4791\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1783 - mse: 0.1783 - mae: 0.3186 - val_loss: 0.4358 - val_mse: 0.4358 - val_mae: 0.4756\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1711 - mse: 0.1711 - mae: 0.3107 - val_loss: 0.4265 - val_mse: 0.4265 - val_mae: 0.4713\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 4s 417us/sample - loss: 0.1633 - mse: 0.1633 - mae: 0.3026 - val_loss: 0.4502 - val_mse: 0.4502 - val_mae: 0.4893\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 4s 406us/sample - loss: 0.1519 - mse: 0.1519 - mae: 0.2932 - val_loss: 0.4298 - val_mse: 0.4298 - val_mae: 0.4732\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.1450 - mse: 0.1450 - mae: 0.2881 - val_loss: 0.4625 - val_mse: 0.4625 - val_mae: 0.5046\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 4s 415us/sample - loss: 0.1587 - mse: 0.1587 - mae: 0.3010 - val_loss: 0.4049 - val_mse: 0.4049 - val_mae: 0.4544\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.1505 - mse: 0.1505 - mae: 0.2941 - val_loss: 0.4050 - val_mse: 0.4050 - val_mae: 0.4572\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 4s 410us/sample - loss: 0.1468 - mse: 0.1468 - mae: 0.2879 - val_loss: 0.3938 - val_mse: 0.3938 - val_mae: 0.4507\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 4s 407us/sample - loss: 0.1405 - mse: 0.1405 - mae: 0.2807 - val_loss: 0.3957 - val_mse: 0.3957 - val_mae: 0.4504\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1413 - mse: 0.1413 - mae: 0.2841 - val_loss: 0.4240 - val_mse: 0.4240 - val_mae: 0.4668\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 4s 405us/sample - loss: 0.1418 - mse: 0.1418 - mae: 0.2830 - val_loss: 0.4290 - val_mse: 0.4290 - val_mae: 0.4834\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 0.1293 - mse: 0.1293 - mae: 0.2707 - val_loss: 0.3954 - val_mse: 0.3954 - val_mae: 0.4527\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1211 - mse: 0.1211 - mae: 0.2621 - val_loss: 0.4113 - val_mse: 0.4113 - val_mae: 0.4554\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 4s 408us/sample - loss: 0.1231 - mse: 0.1231 - mae: 0.2635 - val_loss: 0.4099 - val_mse: 0.4099 - val_mae: 0.4573\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 5s 422us/sample - loss: 0.1162 - mse: 0.1162 - mae: 0.2562 - val_loss: 0.4139 - val_mse: 0.4139 - val_mae: 0.4592\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 5s 423us/sample - loss: 0.1220 - mse: 0.1220 - mae: 0.2623 - val_loss: 0.4404 - val_mse: 0.4404 - val_mae: 0.4720\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 5s 428us/sample - loss: 0.1241 - mse: 0.1241 - mae: 0.2630 - val_loss: 0.3951 - val_mse: 0.3951 - val_mae: 0.4551\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 4s 417us/sample - loss: 0.1172 - mse: 0.1172 - mae: 0.2574 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4688\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 6s 575us/sample - loss: 133.5505 - mse: 133.5505 - mae: 6.0630 - val_loss: 1193740.8737 - val_mse: 1193741.0000 - val_mae: 983.3990\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 4s 410us/sample - loss: 1.9788 - mse: 1.9788 - mae: 1.0946 - val_loss: 61.2790 - val_mse: 61.2790 - val_mae: 6.7492\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 4s 409us/sample - loss: 1.2210 - mse: 1.2210 - mae: 0.8461 - val_loss: 63.2431 - val_mse: 63.2431 - val_mae: 4.3740\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 4s 407us/sample - loss: 0.8700 - mse: 0.8700 - mae: 0.6998 - val_loss: 419.6569 - val_mse: 419.6569 - val_mae: 13.5287\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 4s 409us/sample - loss: 0.8187 - mse: 0.8187 - mae: 0.6771 - val_loss: 19.4115 - val_mse: 19.4115 - val_mae: 2.3399\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 4s 409us/sample - loss: 0.7680 - mse: 0.7680 - mae: 0.6587 - val_loss: 15.7748 - val_mse: 15.7748 - val_mae: 2.1049\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 4s 408us/sample - loss: 0.7441 - mse: 0.7441 - mae: 0.6451 - val_loss: 1.6587 - val_mse: 1.6587 - val_mae: 0.9350\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 4s 409us/sample - loss: 0.7258 - mse: 0.7258 - mae: 0.6381 - val_loss: 2.1160 - val_mse: 2.1160 - val_mae: 1.0066\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 4s 410us/sample - loss: 0.7067 - mse: 0.7067 - mae: 0.6285 - val_loss: 1.5917 - val_mse: 1.5917 - val_mae: 0.9377\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 4s 409us/sample - loss: 0.6857 - mse: 0.6857 - mae: 0.6165 - val_loss: 1.2348 - val_mse: 1.2348 - val_mae: 0.8487\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 4s 407us/sample - loss: 0.6731 - mse: 0.6731 - mae: 0.6093 - val_loss: 1.0288 - val_mse: 1.0288 - val_mae: 0.7804\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 4s 416us/sample - loss: 0.6533 - mse: 0.6533 - mae: 0.6021 - val_loss: 0.8813 - val_mse: 0.8813 - val_mae: 0.7169\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 4s 408us/sample - loss: 0.6379 - mse: 0.6379 - mae: 0.5887 - val_loss: 0.8208 - val_mse: 0.8208 - val_mae: 0.7019\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 4s 412us/sample - loss: 0.6217 - mse: 0.6217 - mae: 0.5837 - val_loss: 0.7513 - val_mse: 0.7513 - val_mae: 0.6637\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 4s 409us/sample - loss: 0.6129 - mse: 0.6129 - mae: 0.5804 - val_loss: 0.7163 - val_mse: 0.7163 - val_mae: 0.6448\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 4s 408us/sample - loss: 0.5941 - mse: 0.5941 - mae: 0.5690 - val_loss: 0.6904 - val_mse: 0.6904 - val_mae: 0.6295\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 4s 409us/sample - loss: 0.5845 - mse: 0.5845 - mae: 0.5661 - val_loss: 0.6693 - val_mse: 0.6693 - val_mae: 0.6175\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 4s 411us/sample - loss: 0.5738 - mse: 0.5738 - mae: 0.5571 - val_loss: 0.6642 - val_mse: 0.6642 - val_mae: 0.6200\n",
      "Epoch 19/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 4s 407us/sample - loss: 0.5680 - mse: 0.5680 - mae: 0.5547 - val_loss: 0.6880 - val_mse: 0.6880 - val_mae: 0.6102\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 4s 410us/sample - loss: 0.5478 - mse: 0.5478 - mae: 0.5477 - val_loss: 0.6310 - val_mse: 0.6310 - val_mae: 0.6016\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 4s 407us/sample - loss: 0.5363 - mse: 0.5363 - mae: 0.5369 - val_loss: 0.6575 - val_mse: 0.6575 - val_mae: 0.6123\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 4s 410us/sample - loss: 0.5207 - mse: 0.5207 - mae: 0.5318 - val_loss: 0.6146 - val_mse: 0.6146 - val_mae: 0.5884\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 4s 406us/sample - loss: 0.5103 - mse: 0.5103 - mae: 0.5251 - val_loss: 0.6368 - val_mse: 0.6368 - val_mae: 0.5956\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 4s 409us/sample - loss: 0.4984 - mse: 0.4984 - mae: 0.5207 - val_loss: 0.6090 - val_mse: 0.6090 - val_mae: 0.5854\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 4s 411us/sample - loss: 0.4932 - mse: 0.4932 - mae: 0.5206 - val_loss: 0.6202 - val_mse: 0.6202 - val_mae: 0.5718\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 4s 416us/sample - loss: 0.4729 - mse: 0.4729 - mae: 0.5076 - val_loss: 0.6030 - val_mse: 0.6030 - val_mae: 0.5665\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 4s 409us/sample - loss: 0.4690 - mse: 0.4690 - mae: 0.5039 - val_loss: 0.6403 - val_mse: 0.6403 - val_mae: 0.5932\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 4s 411us/sample - loss: 0.4477 - mse: 0.4477 - mae: 0.4933 - val_loss: 0.5793 - val_mse: 0.5793 - val_mae: 0.5652\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 5s 423us/sample - loss: 0.4331 - mse: 0.4331 - mae: 0.4866 - val_loss: 0.6413 - val_mse: 0.6413 - val_mae: 0.5748\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 4s 418us/sample - loss: 0.4206 - mse: 0.4206 - mae: 0.4808 - val_loss: 0.6137 - val_mse: 0.6137 - val_mae: 0.5677\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 4s 410us/sample - loss: 0.4065 - mse: 0.4065 - mae: 0.4725 - val_loss: 0.6517 - val_mse: 0.6517 - val_mae: 0.5779\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 4s 409us/sample - loss: 0.3929 - mse: 0.3929 - mae: 0.4649 - val_loss: 0.6208 - val_mse: 0.6208 - val_mae: 0.5646\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 4s 408us/sample - loss: 0.3821 - mse: 0.3821 - mae: 0.4576 - val_loss: 0.6417 - val_mse: 0.6417 - val_mae: 0.5647\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 4s 409us/sample - loss: 0.3745 - mse: 0.3745 - mae: 0.4539 - val_loss: 0.6608 - val_mse: 0.6608 - val_mae: 0.5712\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 4s 412us/sample - loss: 0.3555 - mse: 0.3555 - mae: 0.4413 - val_loss: 0.6969 - val_mse: 0.6969 - val_mae: 0.5864\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 4s 407us/sample - loss: 0.3429 - mse: 0.3429 - mae: 0.4354 - val_loss: 0.7369 - val_mse: 0.7369 - val_mae: 0.5952\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 4s 408us/sample - loss: 0.3363 - mse: 0.3363 - mae: 0.4304 - val_loss: 0.6246 - val_mse: 0.6246 - val_mae: 0.5671\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 4s 407us/sample - loss: 0.3280 - mse: 0.3280 - mae: 0.4245 - val_loss: 0.7539 - val_mse: 0.7539 - val_mae: 0.5925\n",
      "Avg. MAE: 0.418207\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 69us/sample - loss: 2.2314 - mse: 2.2314 - mae: 1.1403 - val_loss: 6.7793 - val_mse: 6.7793 - val_mae: 2.2467\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 1.3766 - mse: 1.3766 - mae: 0.8985 - val_loss: 4.0959 - val_mse: 4.0959 - val_mae: 1.7263\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 1.0623 - mse: 1.0623 - mae: 0.7840 - val_loss: 3.5324 - val_mse: 3.5324 - val_mae: 1.6186\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.9140 - mse: 0.9140 - mae: 0.7214 - val_loss: 2.7685 - val_mse: 2.7685 - val_mae: 1.4252\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.8234 - mse: 0.8234 - mae: 0.6837 - val_loss: 2.7620 - val_mse: 2.7620 - val_mae: 1.4369\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.7577 - mse: 0.7577 - mae: 0.6563 - val_loss: 2.5655 - val_mse: 2.5655 - val_mae: 1.3883\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.7158 - mse: 0.7158 - mae: 0.6378 - val_loss: 2.3730 - val_mse: 2.3730 - val_mae: 1.3358\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6755 - mse: 0.6755 - mae: 0.6177 - val_loss: 2.0478 - val_mse: 2.0478 - val_mae: 1.2342\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6514 - mse: 0.6514 - mae: 0.6057 - val_loss: 1.8329 - val_mse: 1.8329 - val_mae: 1.1642\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6254 - mse: 0.6254 - mae: 0.5951 - val_loss: 1.6750 - val_mse: 1.6750 - val_mae: 1.1107\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6129 - mse: 0.6129 - mae: 0.5888 - val_loss: 1.4820 - val_mse: 1.4820 - val_mae: 1.0373\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5921 - mse: 0.5921 - mae: 0.5778 - val_loss: 1.3677 - val_mse: 1.3677 - val_mae: 0.9952\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5749 - mse: 0.5749 - mae: 0.5678 - val_loss: 1.2194 - val_mse: 1.2194 - val_mae: 0.9297\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5625 - mse: 0.5625 - mae: 0.5637 - val_loss: 1.0888 - val_mse: 1.0888 - val_mae: 0.8717\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5510 - mse: 0.5510 - mae: 0.5578 - val_loss: 0.9961 - val_mse: 0.9961 - val_mae: 0.8262\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5382 - mse: 0.5382 - mae: 0.5501 - val_loss: 0.9215 - val_mse: 0.9215 - val_mae: 0.7886\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5307 - mse: 0.5307 - mae: 0.5474 - val_loss: 0.8527 - val_mse: 0.8527 - val_mae: 0.7505\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5148 - mse: 0.5148 - mae: 0.5381 - val_loss: 0.7891 - val_mse: 0.7891 - val_mae: 0.7152\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5087 - mse: 0.5087 - mae: 0.5344 - val_loss: 0.7476 - val_mse: 0.7476 - val_mae: 0.6912\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5047 - mse: 0.5047 - mae: 0.5324 - val_loss: 0.7151 - val_mse: 0.7151 - val_mae: 0.6726\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5023 - mse: 0.5023 - mae: 0.5307 - val_loss: 0.6930 - val_mse: 0.6930 - val_mae: 0.6582\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4883 - mse: 0.4883 - mae: 0.5233 - val_loss: 0.6640 - val_mse: 0.6640 - val_mae: 0.6391\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4824 - mse: 0.4824 - mae: 0.5214 - val_loss: 0.6489 - val_mse: 0.6489 - val_mae: 0.6298\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4758 - mse: 0.4758 - mae: 0.5175 - val_loss: 0.6262 - val_mse: 0.6262 - val_mae: 0.6143\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4696 - mse: 0.4696 - mae: 0.5124 - val_loss: 0.6192 - val_mse: 0.6192 - val_mae: 0.6084\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4658 - mse: 0.4658 - mae: 0.5122 - val_loss: 0.6050 - val_mse: 0.6050 - val_mae: 0.5998\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4576 - mse: 0.4576 - mae: 0.5070 - val_loss: 0.5940 - val_mse: 0.5940 - val_mae: 0.5927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4545 - mse: 0.4545 - mae: 0.5054 - val_loss: 0.5856 - val_mse: 0.5856 - val_mae: 0.5846\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4521 - mse: 0.4521 - mae: 0.5051 - val_loss: 0.5848 - val_mse: 0.5848 - val_mae: 0.5860\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4431 - mse: 0.4431 - mae: 0.4995 - val_loss: 0.5667 - val_mse: 0.5667 - val_mae: 0.5754\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4379 - mse: 0.4379 - mae: 0.4952 - val_loss: 0.5625 - val_mse: 0.5625 - val_mae: 0.5709\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4363 - mse: 0.4363 - mae: 0.4945 - val_loss: 0.5587 - val_mse: 0.5587 - val_mae: 0.5680\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4292 - mse: 0.4292 - mae: 0.4906 - val_loss: 0.5507 - val_mse: 0.5507 - val_mae: 0.5635\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4274 - mse: 0.4274 - mae: 0.4906 - val_loss: 0.5489 - val_mse: 0.5489 - val_mae: 0.5646\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4212 - mse: 0.4212 - mae: 0.4864 - val_loss: 0.5423 - val_mse: 0.5423 - val_mae: 0.5589\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4173 - mse: 0.4173 - mae: 0.4830 - val_loss: 0.5387 - val_mse: 0.5387 - val_mae: 0.5550\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4172 - mse: 0.4172 - mae: 0.4840 - val_loss: 0.5344 - val_mse: 0.5344 - val_mae: 0.5545\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4105 - mse: 0.4105 - mae: 0.4806 - val_loss: 0.5320 - val_mse: 0.5320 - val_mae: 0.5514\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4086 - mse: 0.4086 - mae: 0.4788 - val_loss: 0.5295 - val_mse: 0.5295 - val_mae: 0.5489\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4029 - mse: 0.4029 - mae: 0.4754 - val_loss: 0.5234 - val_mse: 0.5234 - val_mae: 0.5453\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4031 - mse: 0.4031 - mae: 0.4757 - val_loss: 0.5219 - val_mse: 0.5219 - val_mae: 0.5473\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3958 - mse: 0.3958 - mae: 0.4714 - val_loss: 0.5170 - val_mse: 0.5170 - val_mae: 0.5425\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3935 - mse: 0.3935 - mae: 0.4685 - val_loss: 0.5206 - val_mse: 0.5206 - val_mae: 0.5432\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3914 - mse: 0.3914 - mae: 0.4676 - val_loss: 0.5161 - val_mse: 0.5161 - val_mae: 0.5419\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3875 - mse: 0.3875 - mae: 0.4660 - val_loss: 0.5126 - val_mse: 0.5126 - val_mae: 0.5411\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3849 - mse: 0.3849 - mae: 0.4646 - val_loss: 0.5130 - val_mse: 0.5130 - val_mae: 0.5387\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3807 - mse: 0.3807 - mae: 0.4622 - val_loss: 0.5056 - val_mse: 0.5056 - val_mae: 0.5360\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3795 - mse: 0.3795 - mae: 0.4613 - val_loss: 0.5092 - val_mse: 0.5092 - val_mae: 0.5349\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3751 - mse: 0.3751 - mae: 0.4590 - val_loss: 0.5011 - val_mse: 0.5011 - val_mae: 0.5326\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3691 - mse: 0.3691 - mae: 0.4557 - val_loss: 0.5028 - val_mse: 0.5028 - val_mae: 0.5324\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3705 - mse: 0.3705 - mae: 0.4568 - val_loss: 0.4964 - val_mse: 0.4964 - val_mae: 0.5281\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3687 - mse: 0.3687 - mae: 0.4545 - val_loss: 0.4974 - val_mse: 0.4974 - val_mae: 0.5281\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3654 - mse: 0.3654 - mae: 0.4534 - val_loss: 0.4985 - val_mse: 0.4985 - val_mae: 0.5291\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3665 - mse: 0.3665 - mae: 0.4546 - val_loss: 0.4926 - val_mse: 0.4926 - val_mae: 0.5253\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3673 - mse: 0.3673 - mae: 0.4550 - val_loss: 0.5018 - val_mse: 0.5018 - val_mae: 0.5299\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3617 - mse: 0.3617 - mae: 0.4528 - val_loss: 0.4934 - val_mse: 0.4934 - val_mae: 0.5245\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3594 - mse: 0.3594 - mae: 0.4502 - val_loss: 0.4960 - val_mse: 0.4960 - val_mae: 0.5276\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3549 - mse: 0.3549 - mae: 0.4473 - val_loss: 0.4901 - val_mse: 0.4901 - val_mae: 0.5239\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3503 - mse: 0.3503 - mae: 0.4436 - val_loss: 0.4892 - val_mse: 0.4892 - val_mae: 0.5226\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3515 - mse: 0.3515 - mae: 0.4450 - val_loss: 0.4872 - val_mse: 0.4872 - val_mae: 0.5218\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3485 - mse: 0.3485 - mae: 0.4435 - val_loss: 0.4843 - val_mse: 0.4843 - val_mae: 0.5221\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3454 - mse: 0.3454 - mae: 0.4409 - val_loss: 0.4795 - val_mse: 0.4795 - val_mae: 0.5180\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3404 - mse: 0.3404 - mae: 0.4386 - val_loss: 0.4849 - val_mse: 0.4849 - val_mae: 0.5195\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3402 - mse: 0.3402 - mae: 0.4377 - val_loss: 0.4842 - val_mse: 0.4842 - val_mae: 0.5198\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3410 - mse: 0.3410 - mae: 0.4378 - val_loss: 0.4826 - val_mse: 0.4826 - val_mae: 0.5182\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3371 - mse: 0.3371 - mae: 0.4353 - val_loss: 0.4799 - val_mse: 0.4799 - val_mae: 0.5164\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3332 - mse: 0.3332 - mae: 0.4319 - val_loss: 0.4837 - val_mse: 0.4837 - val_mae: 0.5166\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3370 - mse: 0.3370 - mae: 0.4349 - val_loss: 0.4792 - val_mse: 0.4792 - val_mae: 0.5158\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3340 - mse: 0.3340 - mae: 0.4324 - val_loss: 0.4778 - val_mse: 0.4778 - val_mae: 0.5170\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3406 - mse: 0.3406 - mae: 0.4368 - val_loss: 0.4763 - val_mse: 0.4763 - val_mae: 0.5182\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3326 - mse: 0.3326 - mae: 0.4335 - val_loss: 0.4795 - val_mse: 0.4795 - val_mae: 0.5170\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3333 - mse: 0.3333 - mae: 0.4343 - val_loss: 0.4764 - val_mse: 0.4764 - val_mae: 0.5151\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3275 - mse: 0.3275 - mae: 0.4298 - val_loss: 0.4783 - val_mse: 0.4783 - val_mae: 0.5149\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3228 - mse: 0.3228 - mae: 0.4267 - val_loss: 0.4763 - val_mse: 0.4763 - val_mae: 0.5131\n",
      "Epoch 75/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3239 - mse: 0.3239 - mae: 0.4269 - val_loss: 0.4762 - val_mse: 0.4762 - val_mae: 0.5143\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3195 - mse: 0.3195 - mae: 0.4239 - val_loss: 0.4785 - val_mse: 0.4785 - val_mae: 0.5137\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3233 - mse: 0.3233 - mae: 0.4276 - val_loss: 0.4854 - val_mse: 0.4854 - val_mae: 0.5164\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3192 - mse: 0.3192 - mae: 0.4246 - val_loss: 0.4728 - val_mse: 0.4728 - val_mae: 0.5118\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3156 - mse: 0.3156 - mae: 0.4222 - val_loss: 0.4743 - val_mse: 0.4743 - val_mae: 0.5109\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3153 - mse: 0.3153 - mae: 0.4215 - val_loss: 0.4680 - val_mse: 0.4680 - val_mae: 0.5091\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3139 - mse: 0.3139 - mae: 0.4210 - val_loss: 0.4736 - val_mse: 0.4736 - val_mae: 0.5118\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3149 - mse: 0.3149 - mae: 0.4213 - val_loss: 0.4729 - val_mse: 0.4729 - val_mae: 0.5109\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3131 - mse: 0.3131 - mae: 0.4215 - val_loss: 0.4656 - val_mse: 0.4656 - val_mae: 0.5102\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3086 - mse: 0.3086 - mae: 0.4169 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.5104\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3084 - mse: 0.3084 - mae: 0.4169 - val_loss: 0.4723 - val_mse: 0.4723 - val_mae: 0.5113\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3097 - mse: 0.3097 - mae: 0.4181 - val_loss: 0.4671 - val_mse: 0.4671 - val_mae: 0.5112\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3047 - mse: 0.3047 - mae: 0.4132 - val_loss: 0.4658 - val_mse: 0.4658 - val_mae: 0.5084\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3056 - mse: 0.3056 - mae: 0.4176 - val_loss: 0.4660 - val_mse: 0.4660 - val_mae: 0.5085\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3040 - mse: 0.3040 - mae: 0.4139 - val_loss: 0.4682 - val_mse: 0.4682 - val_mae: 0.5077\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3001 - mse: 0.3001 - mae: 0.4107 - val_loss: 0.4666 - val_mse: 0.4666 - val_mae: 0.5093\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3007 - mse: 0.3007 - mae: 0.4114 - val_loss: 0.4680 - val_mse: 0.4680 - val_mae: 0.5100\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2996 - mse: 0.2996 - mae: 0.4113 - val_loss: 0.4640 - val_mse: 0.4640 - val_mae: 0.5092\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2981 - mse: 0.2981 - mae: 0.4095 - val_loss: 0.4665 - val_mse: 0.4665 - val_mae: 0.5091\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2934 - mse: 0.2934 - mae: 0.4067 - val_loss: 0.4635 - val_mse: 0.4635 - val_mae: 0.5065\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2974 - mse: 0.2974 - mae: 0.4093 - val_loss: 0.4686 - val_mse: 0.4686 - val_mae: 0.5077\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2956 - mse: 0.2956 - mae: 0.4094 - val_loss: 0.4695 - val_mse: 0.4695 - val_mae: 0.5108\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.2943 - mse: 0.2943 - mae: 0.4084 - val_loss: 0.4658 - val_mse: 0.4658 - val_mae: 0.5065\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2944 - mse: 0.2944 - mae: 0.4077 - val_loss: 0.4678 - val_mse: 0.4678 - val_mae: 0.5099\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2910 - mse: 0.2910 - mae: 0.4057 - val_loss: 0.4606 - val_mse: 0.4606 - val_mae: 0.5067\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.2914 - mse: 0.2914 - mae: 0.4063 - val_loss: 0.4619 - val_mse: 0.4619 - val_mae: 0.5066\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2867 - mse: 0.2867 - mae: 0.4020 - val_loss: 0.4636 - val_mse: 0.4636 - val_mae: 0.5068\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2911 - mse: 0.2911 - mae: 0.4052 - val_loss: 0.4587 - val_mse: 0.4587 - val_mae: 0.5037\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2888 - mse: 0.2888 - mae: 0.4047 - val_loss: 0.4681 - val_mse: 0.4681 - val_mae: 0.5093\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.2869 - mse: 0.2869 - mae: 0.4028 - val_loss: 0.4608 - val_mse: 0.4608 - val_mae: 0.5047\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2869 - mse: 0.2869 - mae: 0.4028 - val_loss: 0.4614 - val_mse: 0.4614 - val_mae: 0.5046\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2845 - mse: 0.2845 - mae: 0.3998 - val_loss: 0.4676 - val_mse: 0.4676 - val_mae: 0.5087\n",
      "Epoch 107/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2846 - mse: 0.2846 - mae: 0.4021 - val_loss: 0.4654 - val_mse: 0.4654 - val_mae: 0.5080\n",
      "Epoch 108/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2820 - mse: 0.2820 - mae: 0.4002 - val_loss: 0.4623 - val_mse: 0.4623 - val_mae: 0.5048\n",
      "Epoch 109/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2835 - mse: 0.2835 - mae: 0.3993 - val_loss: 0.4634 - val_mse: 0.4634 - val_mae: 0.5086\n",
      "Epoch 110/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2804 - mse: 0.2804 - mae: 0.3995 - val_loss: 0.4618 - val_mse: 0.4618 - val_mae: 0.5062\n",
      "Epoch 111/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2848 - mse: 0.2848 - mae: 0.4007 - val_loss: 0.4613 - val_mse: 0.4613 - val_mae: 0.5053\n",
      "Epoch 112/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2821 - mse: 0.2821 - mae: 0.4018 - val_loss: 0.4658 - val_mse: 0.4658 - val_mae: 0.5083\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 2.2700 - mse: 2.2700 - mae: 1.1199 - val_loss: 9.2737 - val_mse: 9.2737 - val_mae: 2.7035\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 1.3728 - mse: 1.3728 - mae: 0.8827 - val_loss: 6.3510 - val_mse: 6.3510 - val_mae: 2.2234\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 1.0575 - mse: 1.0575 - mae: 0.7764 - val_loss: 4.8691 - val_mse: 4.8691 - val_mae: 1.9415\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.8982 - mse: 0.8982 - mae: 0.7169 - val_loss: 4.0859 - val_mse: 4.0859 - val_mae: 1.7696\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.7963 - mse: 0.7963 - mae: 0.6765 - val_loss: 3.7697 - val_mse: 3.7697 - val_mae: 1.7108\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.7362 - mse: 0.7362 - mae: 0.6490 - val_loss: 3.3864 - val_mse: 3.3864 - val_mae: 1.6201\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6937 - mse: 0.6937 - mae: 0.6290 - val_loss: 2.9482 - val_mse: 2.9482 - val_mae: 1.5040\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6640 - mse: 0.6640 - mae: 0.6151 - val_loss: 2.5618 - val_mse: 2.5618 - val_mae: 1.3942\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6442 - mse: 0.6442 - mae: 0.6049 - val_loss: 2.2458 - val_mse: 2.2458 - val_mae: 1.2978\n",
      "Epoch 10/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6227 - mse: 0.6227 - mae: 0.5943 - val_loss: 1.9739 - val_mse: 1.9739 - val_mae: 1.2088\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.6010 - mse: 0.6010 - mae: 0.5837 - val_loss: 1.7610 - val_mse: 1.7610 - val_mae: 1.1348\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5842 - mse: 0.5842 - mae: 0.5770 - val_loss: 1.5334 - val_mse: 1.5334 - val_mae: 1.0522\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5739 - mse: 0.5739 - mae: 0.5713 - val_loss: 1.3352 - val_mse: 1.3352 - val_mae: 0.9708\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5620 - mse: 0.5620 - mae: 0.5645 - val_loss: 1.1990 - val_mse: 1.1990 - val_mae: 0.9122\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5511 - mse: 0.5511 - mae: 0.5593 - val_loss: 1.0809 - val_mse: 1.0809 - val_mae: 0.8558\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5435 - mse: 0.5435 - mae: 0.5555 - val_loss: 0.9845 - val_mse: 0.9845 - val_mae: 0.8065\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5327 - mse: 0.5327 - mae: 0.5493 - val_loss: 0.9095 - val_mse: 0.9095 - val_mae: 0.7690\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5214 - mse: 0.5214 - mae: 0.5445 - val_loss: 0.8505 - val_mse: 0.8505 - val_mae: 0.7363\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5137 - mse: 0.5137 - mae: 0.5396 - val_loss: 0.7999 - val_mse: 0.7999 - val_mae: 0.7079\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5056 - mse: 0.5056 - mae: 0.5350 - val_loss: 0.7632 - val_mse: 0.7632 - val_mae: 0.6826\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4987 - mse: 0.4987 - mae: 0.5326 - val_loss: 0.7396 - val_mse: 0.7396 - val_mae: 0.6701\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4899 - mse: 0.4899 - mae: 0.5292 - val_loss: 0.7105 - val_mse: 0.7105 - val_mae: 0.6539\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4850 - mse: 0.4850 - mae: 0.5251 - val_loss: 0.6910 - val_mse: 0.6910 - val_mae: 0.6378\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4800 - mse: 0.4800 - mae: 0.5207 - val_loss: 0.6729 - val_mse: 0.6729 - val_mae: 0.6265\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4710 - mse: 0.4710 - mae: 0.5172 - val_loss: 0.6539 - val_mse: 0.6539 - val_mae: 0.6134\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4672 - mse: 0.4672 - mae: 0.5150 - val_loss: 0.6416 - val_mse: 0.6416 - val_mae: 0.6072\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4578 - mse: 0.4578 - mae: 0.5093 - val_loss: 0.6263 - val_mse: 0.6263 - val_mae: 0.5964\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4496 - mse: 0.4496 - mae: 0.5073 - val_loss: 0.6178 - val_mse: 0.6178 - val_mae: 0.5933\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4483 - mse: 0.4483 - mae: 0.5051 - val_loss: 0.6134 - val_mse: 0.6134 - val_mae: 0.5856\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4422 - mse: 0.4422 - mae: 0.5022 - val_loss: 0.5997 - val_mse: 0.5997 - val_mae: 0.5795\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4382 - mse: 0.4382 - mae: 0.4998 - val_loss: 0.5983 - val_mse: 0.5983 - val_mae: 0.5758\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4347 - mse: 0.4347 - mae: 0.4977 - val_loss: 0.5968 - val_mse: 0.5968 - val_mae: 0.5735\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.4313 - mse: 0.4313 - mae: 0.4954 - val_loss: 0.5875 - val_mse: 0.5875 - val_mae: 0.5668\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4294 - mse: 0.4294 - mae: 0.4954 - val_loss: 0.5834 - val_mse: 0.5834 - val_mae: 0.5681\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4198 - mse: 0.4198 - mae: 0.4890 - val_loss: 0.5795 - val_mse: 0.5795 - val_mae: 0.5625\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4154 - mse: 0.4154 - mae: 0.4868 - val_loss: 0.5766 - val_mse: 0.5766 - val_mae: 0.5597\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4150 - mse: 0.4150 - mae: 0.4864 - val_loss: 0.5748 - val_mse: 0.5748 - val_mae: 0.5574\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4111 - mse: 0.4111 - mae: 0.4827 - val_loss: 0.5677 - val_mse: 0.5677 - val_mae: 0.5537\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.4070 - mse: 0.4070 - mae: 0.4819 - val_loss: 0.5634 - val_mse: 0.5634 - val_mae: 0.5535\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4012 - mse: 0.4012 - mae: 0.4779 - val_loss: 0.5611 - val_mse: 0.5611 - val_mae: 0.5483\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3963 - mse: 0.3963 - mae: 0.4753 - val_loss: 0.5623 - val_mse: 0.5623 - val_mae: 0.5477\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3969 - mse: 0.3969 - mae: 0.4749 - val_loss: 0.5552 - val_mse: 0.5552 - val_mae: 0.5458\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3911 - mse: 0.3911 - mae: 0.4713 - val_loss: 0.5509 - val_mse: 0.5509 - val_mae: 0.5444\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3900 - mse: 0.3900 - mae: 0.4716 - val_loss: 0.5539 - val_mse: 0.5539 - val_mae: 0.5453\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3854 - mse: 0.3854 - mae: 0.4701 - val_loss: 0.5416 - val_mse: 0.5416 - val_mae: 0.5380\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3824 - mse: 0.3824 - mae: 0.4646 - val_loss: 0.5457 - val_mse: 0.5457 - val_mae: 0.5405\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3791 - mse: 0.3791 - mae: 0.4640 - val_loss: 0.5493 - val_mse: 0.5493 - val_mae: 0.5415\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3756 - mse: 0.3756 - mae: 0.4633 - val_loss: 0.5360 - val_mse: 0.5360 - val_mae: 0.5360\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3733 - mse: 0.3733 - mae: 0.4617 - val_loss: 0.5391 - val_mse: 0.5391 - val_mae: 0.5367\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3711 - mse: 0.3711 - mae: 0.4601 - val_loss: 0.5365 - val_mse: 0.5365 - val_mae: 0.5311\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3675 - mse: 0.3675 - mae: 0.4576 - val_loss: 0.5351 - val_mse: 0.5351 - val_mae: 0.5311\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3669 - mse: 0.3669 - mae: 0.4570 - val_loss: 0.5333 - val_mse: 0.5333 - val_mae: 0.5304\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3623 - mse: 0.3623 - mae: 0.4559 - val_loss: 0.5279 - val_mse: 0.5279 - val_mae: 0.5294\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3617 - mse: 0.3617 - mae: 0.4549 - val_loss: 0.5302 - val_mse: 0.5302 - val_mae: 0.5314\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3616 - mse: 0.3616 - mae: 0.4541 - val_loss: 0.5333 - val_mse: 0.5333 - val_mae: 0.5302\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3533 - mse: 0.3533 - mae: 0.4498 - val_loss: 0.5243 - val_mse: 0.5243 - val_mae: 0.5237\n",
      "Epoch 57/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3563 - mse: 0.3563 - mae: 0.4502 - val_loss: 0.5332 - val_mse: 0.5332 - val_mae: 0.5298\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3511 - mse: 0.3511 - mae: 0.4460 - val_loss: 0.5209 - val_mse: 0.5209 - val_mae: 0.5260\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3507 - mse: 0.3507 - mae: 0.4471 - val_loss: 0.5272 - val_mse: 0.5272 - val_mae: 0.5229\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3482 - mse: 0.3482 - mae: 0.4466 - val_loss: 0.5221 - val_mse: 0.5221 - val_mae: 0.5244\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3461 - mse: 0.3461 - mae: 0.4433 - val_loss: 0.5199 - val_mse: 0.5199 - val_mae: 0.5260\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3451 - mse: 0.3451 - mae: 0.4432 - val_loss: 0.5227 - val_mse: 0.5227 - val_mae: 0.5253\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3439 - mse: 0.3439 - mae: 0.4443 - val_loss: 0.5170 - val_mse: 0.5170 - val_mae: 0.5195\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3403 - mse: 0.3403 - mae: 0.4413 - val_loss: 0.5222 - val_mse: 0.5222 - val_mae: 0.5219\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3371 - mse: 0.3371 - mae: 0.4387 - val_loss: 0.5195 - val_mse: 0.5195 - val_mae: 0.5233\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3396 - mse: 0.3396 - mae: 0.4411 - val_loss: 0.5258 - val_mse: 0.5258 - val_mae: 0.5210\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3352 - mse: 0.3352 - mae: 0.4373 - val_loss: 0.5219 - val_mse: 0.5219 - val_mae: 0.5223\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3348 - mse: 0.3348 - mae: 0.4372 - val_loss: 0.5171 - val_mse: 0.5171 - val_mae: 0.5192\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3295 - mse: 0.3295 - mae: 0.4344 - val_loss: 0.5128 - val_mse: 0.5128 - val_mae: 0.5188\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3326 - mse: 0.3326 - mae: 0.4358 - val_loss: 0.5211 - val_mse: 0.5211 - val_mae: 0.5203\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3297 - mse: 0.3297 - mae: 0.4330 - val_loss: 0.5197 - val_mse: 0.5197 - val_mae: 0.5223\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3290 - mse: 0.3290 - mae: 0.4354 - val_loss: 0.5148 - val_mse: 0.5148 - val_mae: 0.5222\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3231 - mse: 0.3231 - mae: 0.4302 - val_loss: 0.5166 - val_mse: 0.5166 - val_mae: 0.5200\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3217 - mse: 0.3217 - mae: 0.4285 - val_loss: 0.5092 - val_mse: 0.5092 - val_mae: 0.5159\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3181 - mse: 0.3181 - mae: 0.4260 - val_loss: 0.5111 - val_mse: 0.5111 - val_mae: 0.5198\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3180 - mse: 0.3180 - mae: 0.4269 - val_loss: 0.5181 - val_mse: 0.5181 - val_mae: 0.5215\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3168 - mse: 0.3168 - mae: 0.4272 - val_loss: 0.5043 - val_mse: 0.5043 - val_mae: 0.5146\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - ETA: 0s - loss: 0.3229 - mse: 0.3229 - mae: 0.427 - 0s 4us/sample - loss: 0.3192 - mse: 0.3192 - mae: 0.4276 - val_loss: 0.5108 - val_mse: 0.5108 - val_mae: 0.5170\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3125 - mse: 0.3125 - mae: 0.4241 - val_loss: 0.5200 - val_mse: 0.5200 - val_mae: 0.5196\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 4us/sample - loss: 0.3136 - mse: 0.3136 - mae: 0.4242 - val_loss: 0.5134 - val_mse: 0.5134 - val_mae: 0.5180\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3137 - mse: 0.3137 - mae: 0.4235 - val_loss: 0.5197 - val_mse: 0.5197 - val_mae: 0.5185\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3136 - mse: 0.3136 - mae: 0.4235 - val_loss: 0.5162 - val_mse: 0.5162 - val_mae: 0.5184\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3109 - mse: 0.3109 - mae: 0.4226 - val_loss: 0.5194 - val_mse: 0.5194 - val_mae: 0.5181\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3083 - mse: 0.3083 - mae: 0.4219 - val_loss: 0.5245 - val_mse: 0.5245 - val_mae: 0.5202\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3101 - mse: 0.3101 - mae: 0.4216 - val_loss: 0.5095 - val_mse: 0.5095 - val_mae: 0.5162\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3105 - mse: 0.3105 - mae: 0.4229 - val_loss: 0.5161 - val_mse: 0.5161 - val_mae: 0.5177\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3048 - mse: 0.3048 - mae: 0.4183 - val_loss: 0.5127 - val_mse: 0.5127 - val_mae: 0.5180\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 97us/sample - loss: 2.2407 - mse: 2.2407 - mae: 1.1204 - val_loss: 9.8599 - val_mse: 9.8599 - val_mae: 2.7639\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 1.3382 - mse: 1.3382 - mae: 0.8798 - val_loss: 5.6317 - val_mse: 5.6317 - val_mae: 2.0534\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 1.0556 - mse: 1.0556 - mae: 0.7752 - val_loss: 4.6020 - val_mse: 4.6020 - val_mae: 1.8762\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.9002 - mse: 0.9002 - mae: 0.7159 - val_loss: 3.7239 - val_mse: 3.7239 - val_mae: 1.6820\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.8048 - mse: 0.8048 - mae: 0.6776 - val_loss: 3.4669 - val_mse: 3.4669 - val_mae: 1.6300\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.7468 - mse: 0.7468 - mae: 0.6488 - val_loss: 3.1119 - val_mse: 3.1119 - val_mae: 1.5440\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.7059 - mse: 0.7059 - mae: 0.6312 - val_loss: 2.7456 - val_mse: 2.7456 - val_mae: 1.4472\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6712 - mse: 0.6712 - mae: 0.6161 - val_loss: 2.5244 - val_mse: 2.5244 - val_mae: 1.3887\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6511 - mse: 0.6511 - mae: 0.6057 - val_loss: 2.2388 - val_mse: 2.2388 - val_mae: 1.3059\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6275 - mse: 0.6275 - mae: 0.5942 - val_loss: 1.9618 - val_mse: 1.9618 - val_mae: 1.2146\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6135 - mse: 0.6135 - mae: 0.5879 - val_loss: 1.6949 - val_mse: 1.6949 - val_mae: 1.1223\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5891 - mse: 0.5891 - mae: 0.5758 - val_loss: 1.4719 - val_mse: 1.4719 - val_mae: 1.0382\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5798 - mse: 0.5798 - mae: 0.5712 - val_loss: 1.2788 - val_mse: 1.2788 - val_mae: 0.9611\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5726 - mse: 0.5726 - mae: 0.5669 - val_loss: 1.1738 - val_mse: 1.1738 - val_mae: 0.9167\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5583 - mse: 0.5583 - mae: 0.5604 - val_loss: 1.0432 - val_mse: 1.0432 - val_mae: 0.8572\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5534 - mse: 0.5534 - mae: 0.5588 - val_loss: 0.9614 - val_mse: 0.9614 - val_mae: 0.8171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5407 - mse: 0.5407 - mae: 0.5517 - val_loss: 0.8734 - val_mse: 0.8734 - val_mae: 0.7715\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5307 - mse: 0.5307 - mae: 0.5464 - val_loss: 0.8225 - val_mse: 0.8225 - val_mae: 0.7442\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5224 - mse: 0.5224 - mae: 0.5428 - val_loss: 0.7716 - val_mse: 0.7716 - val_mae: 0.7153\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5147 - mse: 0.5147 - mae: 0.5386 - val_loss: 0.7342 - val_mse: 0.7342 - val_mae: 0.6945\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5060 - mse: 0.5060 - mae: 0.5356 - val_loss: 0.6876 - val_mse: 0.6876 - val_mae: 0.6646\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5022 - mse: 0.5022 - mae: 0.5319 - val_loss: 0.6591 - val_mse: 0.6591 - val_mae: 0.6468\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4989 - mse: 0.4989 - mae: 0.5303 - val_loss: 0.6445 - val_mse: 0.6445 - val_mae: 0.6370\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4907 - mse: 0.4907 - mae: 0.5258 - val_loss: 0.6278 - val_mse: 0.6278 - val_mae: 0.6255\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4840 - mse: 0.4840 - mae: 0.5229 - val_loss: 0.6021 - val_mse: 0.6021 - val_mae: 0.6091\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4786 - mse: 0.4786 - mae: 0.5187 - val_loss: 0.5958 - val_mse: 0.5958 - val_mae: 0.6037\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4709 - mse: 0.4709 - mae: 0.5159 - val_loss: 0.5808 - val_mse: 0.5808 - val_mae: 0.5924\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4660 - mse: 0.4660 - mae: 0.5132 - val_loss: 0.5702 - val_mse: 0.5702 - val_mae: 0.5845\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4562 - mse: 0.4562 - mae: 0.5069 - val_loss: 0.5639 - val_mse: 0.5639 - val_mae: 0.5787\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4545 - mse: 0.4545 - mae: 0.5062 - val_loss: 0.5554 - val_mse: 0.5554 - val_mae: 0.5729\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4498 - mse: 0.4498 - mae: 0.5032 - val_loss: 0.5469 - val_mse: 0.5469 - val_mae: 0.5689\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4429 - mse: 0.4429 - mae: 0.5007 - val_loss: 0.5433 - val_mse: 0.5433 - val_mae: 0.5633\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4402 - mse: 0.4402 - mae: 0.4976 - val_loss: 0.5359 - val_mse: 0.5359 - val_mae: 0.5578\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4375 - mse: 0.4375 - mae: 0.4975 - val_loss: 0.5290 - val_mse: 0.5290 - val_mae: 0.5553\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4324 - mse: 0.4324 - mae: 0.4939 - val_loss: 0.5288 - val_mse: 0.5288 - val_mae: 0.5520\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4315 - mse: 0.4315 - mae: 0.4933 - val_loss: 0.5222 - val_mse: 0.5222 - val_mae: 0.5482\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4253 - mse: 0.4253 - mae: 0.4907 - val_loss: 0.5208 - val_mse: 0.5208 - val_mae: 0.5460\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.4203 - mse: 0.4203 - mae: 0.4867 - val_loss: 0.5166 - val_mse: 0.5166 - val_mae: 0.5441\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4182 - mse: 0.4182 - mae: 0.4862 - val_loss: 0.5120 - val_mse: 0.5120 - val_mae: 0.5408\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4118 - mse: 0.4118 - mae: 0.4816 - val_loss: 0.5101 - val_mse: 0.5101 - val_mae: 0.5391\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4109 - mse: 0.4109 - mae: 0.4810 - val_loss: 0.5074 - val_mse: 0.5074 - val_mae: 0.5377\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4040 - mse: 0.4040 - mae: 0.4783 - val_loss: 0.5014 - val_mse: 0.5014 - val_mae: 0.5335\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4015 - mse: 0.4015 - mae: 0.4759 - val_loss: 0.4985 - val_mse: 0.4985 - val_mae: 0.5313\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3976 - mse: 0.3976 - mae: 0.4732 - val_loss: 0.4958 - val_mse: 0.4958 - val_mae: 0.5288\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3961 - mse: 0.3961 - mae: 0.4749 - val_loss: 0.4985 - val_mse: 0.4985 - val_mae: 0.5314\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3952 - mse: 0.3952 - mae: 0.4718 - val_loss: 0.4934 - val_mse: 0.4934 - val_mae: 0.5251\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3913 - mse: 0.3913 - mae: 0.4678 - val_loss: 0.4888 - val_mse: 0.4888 - val_mae: 0.5237\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3901 - mse: 0.3901 - mae: 0.4693 - val_loss: 0.4904 - val_mse: 0.4904 - val_mae: 0.5268\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3855 - mse: 0.3855 - mae: 0.4665 - val_loss: 0.4870 - val_mse: 0.4870 - val_mae: 0.5213\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3809 - mse: 0.3809 - mae: 0.4657 - val_loss: 0.4849 - val_mse: 0.4849 - val_mae: 0.5212\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3770 - mse: 0.3770 - mae: 0.4605 - val_loss: 0.4802 - val_mse: 0.4802 - val_mae: 0.5180\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3742 - mse: 0.3742 - mae: 0.4598 - val_loss: 0.4790 - val_mse: 0.4790 - val_mae: 0.5165\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3726 - mse: 0.3726 - mae: 0.4584 - val_loss: 0.4827 - val_mse: 0.4827 - val_mae: 0.5182\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3730 - mse: 0.3730 - mae: 0.4591 - val_loss: 0.4742 - val_mse: 0.4742 - val_mae: 0.5155\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3688 - mse: 0.3688 - mae: 0.4582 - val_loss: 0.4788 - val_mse: 0.4788 - val_mae: 0.5165\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3672 - mse: 0.3672 - mae: 0.4550 - val_loss: 0.4729 - val_mse: 0.4729 - val_mae: 0.5138\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3638 - mse: 0.3638 - mae: 0.4529 - val_loss: 0.4801 - val_mse: 0.4801 - val_mae: 0.5162\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3616 - mse: 0.3616 - mae: 0.4528 - val_loss: 0.4706 - val_mse: 0.4706 - val_mae: 0.5113\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3583 - mse: 0.3583 - mae: 0.4492 - val_loss: 0.4759 - val_mse: 0.4759 - val_mae: 0.5159\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3575 - mse: 0.3575 - mae: 0.4497 - val_loss: 0.4709 - val_mse: 0.4709 - val_mae: 0.5100\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3527 - mse: 0.3527 - mae: 0.4460 - val_loss: 0.4725 - val_mse: 0.4725 - val_mae: 0.5129\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3533 - mse: 0.3533 - mae: 0.4472 - val_loss: 0.4688 - val_mse: 0.4688 - val_mae: 0.5099\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3519 - mse: 0.3519 - mae: 0.4462 - val_loss: 0.4677 - val_mse: 0.4677 - val_mae: 0.5091\n",
      "Epoch 64/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3496 - mse: 0.3496 - mae: 0.4455 - val_loss: 0.4766 - val_mse: 0.4766 - val_mae: 0.5115\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3464 - mse: 0.3464 - mae: 0.4430 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.5080\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3437 - mse: 0.3437 - mae: 0.4422 - val_loss: 0.4726 - val_mse: 0.4726 - val_mae: 0.5108\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3403 - mse: 0.3403 - mae: 0.4395 - val_loss: 0.4662 - val_mse: 0.4662 - val_mae: 0.5072\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3426 - mse: 0.3426 - mae: 0.4394 - val_loss: 0.4722 - val_mse: 0.4722 - val_mae: 0.5087\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3420 - mse: 0.3420 - mae: 0.4402 - val_loss: 0.4702 - val_mse: 0.4702 - val_mae: 0.5059\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3389 - mse: 0.3389 - mae: 0.4385 - val_loss: 0.4679 - val_mse: 0.4679 - val_mae: 0.5061\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3347 - mse: 0.3347 - mae: 0.4349 - val_loss: 0.4684 - val_mse: 0.4684 - val_mae: 0.5074\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3316 - mse: 0.3316 - mae: 0.4336 - val_loss: 0.4656 - val_mse: 0.4656 - val_mae: 0.5048\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3303 - mse: 0.3303 - mae: 0.4325 - val_loss: 0.4652 - val_mse: 0.4652 - val_mae: 0.5049\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3304 - mse: 0.3304 - mae: 0.4345 - val_loss: 0.4655 - val_mse: 0.4655 - val_mae: 0.5036\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3255 - mse: 0.3255 - mae: 0.4295 - val_loss: 0.4645 - val_mse: 0.4645 - val_mae: 0.5035\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3260 - mse: 0.3260 - mae: 0.4302 - val_loss: 0.4666 - val_mse: 0.4666 - val_mae: 0.5042\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3247 - mse: 0.3247 - mae: 0.4294 - val_loss: 0.4643 - val_mse: 0.4643 - val_mae: 0.5031\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3232 - mse: 0.3232 - mae: 0.4292 - val_loss: 0.4661 - val_mse: 0.4661 - val_mae: 0.5046\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3250 - mse: 0.3250 - mae: 0.4290 - val_loss: 0.4654 - val_mse: 0.4654 - val_mae: 0.5034\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3203 - mse: 0.3203 - mae: 0.4258 - val_loss: 0.4680 - val_mse: 0.4680 - val_mae: 0.5029\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3174 - mse: 0.3174 - mae: 0.4239 - val_loss: 0.4664 - val_mse: 0.4664 - val_mae: 0.5021\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3176 - mse: 0.3176 - mae: 0.4244 - val_loss: 0.4677 - val_mse: 0.4677 - val_mae: 0.5027\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3184 - mse: 0.3184 - mae: 0.4255 - val_loss: 0.4645 - val_mse: 0.4645 - val_mae: 0.5022\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3123 - mse: 0.3123 - mae: 0.4218 - val_loss: 0.4616 - val_mse: 0.4616 - val_mae: 0.5009\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3120 - mse: 0.3120 - mae: 0.4218 - val_loss: 0.4615 - val_mse: 0.4615 - val_mae: 0.5004\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3140 - mse: 0.3140 - mae: 0.4235 - val_loss: 0.4674 - val_mse: 0.4674 - val_mae: 0.5052\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3110 - mse: 0.3110 - mae: 0.4220 - val_loss: 0.4582 - val_mse: 0.4582 - val_mae: 0.5001\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 4us/sample - loss: 0.3110 - mse: 0.3110 - mae: 0.4201 - val_loss: 0.4679 - val_mse: 0.4679 - val_mae: 0.5023\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3069 - mse: 0.3069 - mae: 0.4183 - val_loss: 0.4704 - val_mse: 0.4704 - val_mae: 0.5024\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3089 - mse: 0.3089 - mae: 0.4195 - val_loss: 0.4683 - val_mse: 0.4683 - val_mae: 0.5050\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3134 - mse: 0.3134 - mae: 0.4186 - val_loss: 0.4660 - val_mse: 0.4660 - val_mae: 0.5052\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3097 - mse: 0.3097 - mae: 0.4190 - val_loss: 0.4634 - val_mse: 0.4634 - val_mae: 0.5021\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3077 - mse: 0.3077 - mae: 0.4189 - val_loss: 0.4706 - val_mse: 0.4706 - val_mae: 0.5042\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3052 - mse: 0.3052 - mae: 0.4179 - val_loss: 0.4634 - val_mse: 0.4634 - val_mae: 0.5015\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3024 - mse: 0.3024 - mae: 0.4165 - val_loss: 0.4666 - val_mse: 0.4666 - val_mae: 0.4999\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3011 - mse: 0.3011 - mae: 0.4144 - val_loss: 0.4633 - val_mse: 0.4633 - val_mae: 0.5011\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3009 - mse: 0.3009 - mae: 0.4166 - val_loss: 0.4602 - val_mse: 0.4602 - val_mae: 0.5006\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 69us/sample - loss: 2.2415 - mse: 2.2415 - mae: 1.1338 - val_loss: 5.8986 - val_mse: 5.8986 - val_mae: 2.0970\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 1.3801 - mse: 1.3801 - mae: 0.8928 - val_loss: 3.4145 - val_mse: 3.4145 - val_mae: 1.5740\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 1.0614 - mse: 1.0614 - mae: 0.7821 - val_loss: 3.1648 - val_mse: 3.1648 - val_mae: 1.5386\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.9063 - mse: 0.9063 - mae: 0.7212 - val_loss: 2.7120 - val_mse: 2.7120 - val_mae: 1.4235\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.8191 - mse: 0.8191 - mae: 0.6843 - val_loss: 2.6104 - val_mse: 2.6104 - val_mae: 1.4022\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.7530 - mse: 0.7530 - mae: 0.6552 - val_loss: 2.4500 - val_mse: 2.4500 - val_mae: 1.3579\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.7160 - mse: 0.7160 - mae: 0.6377 - val_loss: 2.2166 - val_mse: 2.2166 - val_mae: 1.2901\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6772 - mse: 0.6772 - mae: 0.6184 - val_loss: 1.9648 - val_mse: 1.9648 - val_mae: 1.2072\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6474 - mse: 0.6474 - mae: 0.6074 - val_loss: 1.7644 - val_mse: 1.7644 - val_mae: 1.1403\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6285 - mse: 0.6285 - mae: 0.5982 - val_loss: 1.5674 - val_mse: 1.5674 - val_mae: 1.0674\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6030 - mse: 0.6030 - mae: 0.5851 - val_loss: 1.4107 - val_mse: 1.4107 - val_mae: 1.0089\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5904 - mse: 0.5904 - mae: 0.5778 - val_loss: 1.2730 - val_mse: 1.2730 - val_mae: 0.9522\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5791 - mse: 0.5791 - mae: 0.5724 - val_loss: 1.1304 - val_mse: 1.1304 - val_mae: 0.8904\n",
      "Epoch 14/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5574 - mse: 0.5574 - mae: 0.5633 - val_loss: 1.0448 - val_mse: 1.0448 - val_mae: 0.8507\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5492 - mse: 0.5492 - mae: 0.5581 - val_loss: 0.9594 - val_mse: 0.9594 - val_mae: 0.8107\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5427 - mse: 0.5427 - mae: 0.5539 - val_loss: 0.8860 - val_mse: 0.8860 - val_mae: 0.7723\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5307 - mse: 0.5307 - mae: 0.5479 - val_loss: 0.8343 - val_mse: 0.8343 - val_mae: 0.7465\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5186 - mse: 0.5186 - mae: 0.5427 - val_loss: 0.8027 - val_mse: 0.8027 - val_mae: 0.7279\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5120 - mse: 0.5120 - mae: 0.5381 - val_loss: 0.7541 - val_mse: 0.7541 - val_mae: 0.6991\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4997 - mse: 0.4997 - mae: 0.5317 - val_loss: 0.7204 - val_mse: 0.7204 - val_mae: 0.6797\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4924 - mse: 0.4924 - mae: 0.5287 - val_loss: 0.6972 - val_mse: 0.6972 - val_mae: 0.6649\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4855 - mse: 0.4855 - mae: 0.5248 - val_loss: 0.6718 - val_mse: 0.6718 - val_mae: 0.6495\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4792 - mse: 0.4792 - mae: 0.5202 - val_loss: 0.6519 - val_mse: 0.6519 - val_mae: 0.6359\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4753 - mse: 0.4753 - mae: 0.5184 - val_loss: 0.6312 - val_mse: 0.6312 - val_mae: 0.6225\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4703 - mse: 0.4703 - mae: 0.5155 - val_loss: 0.6219 - val_mse: 0.6219 - val_mae: 0.6161\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4609 - mse: 0.4609 - mae: 0.5100 - val_loss: 0.5996 - val_mse: 0.5996 - val_mae: 0.6011\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4594 - mse: 0.4594 - mae: 0.5091 - val_loss: 0.5927 - val_mse: 0.5927 - val_mae: 0.5948\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4550 - mse: 0.4550 - mae: 0.5074 - val_loss: 0.5802 - val_mse: 0.5802 - val_mae: 0.5866\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4451 - mse: 0.4451 - mae: 0.5010 - val_loss: 0.5767 - val_mse: 0.5767 - val_mae: 0.5847\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4397 - mse: 0.4397 - mae: 0.4985 - val_loss: 0.5693 - val_mse: 0.5693 - val_mae: 0.5797\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4366 - mse: 0.4366 - mae: 0.4979 - val_loss: 0.5594 - val_mse: 0.5594 - val_mae: 0.5716\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4335 - mse: 0.4335 - mae: 0.4943 - val_loss: 0.5532 - val_mse: 0.5532 - val_mae: 0.5664\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4317 - mse: 0.4317 - mae: 0.4927 - val_loss: 0.5483 - val_mse: 0.5483 - val_mae: 0.5646\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4253 - mse: 0.4253 - mae: 0.4899 - val_loss: 0.5432 - val_mse: 0.5432 - val_mae: 0.5586\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4219 - mse: 0.4219 - mae: 0.4874 - val_loss: 0.5395 - val_mse: 0.5395 - val_mae: 0.5568\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4161 - mse: 0.4161 - mae: 0.4850 - val_loss: 0.5359 - val_mse: 0.5359 - val_mae: 0.5549\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4103 - mse: 0.4103 - mae: 0.4813 - val_loss: 0.5310 - val_mse: 0.5310 - val_mae: 0.5513\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.4115 - mse: 0.4115 - mae: 0.4829 - val_loss: 0.5251 - val_mse: 0.5251 - val_mae: 0.5462\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4034 - mse: 0.4034 - mae: 0.4764 - val_loss: 0.5245 - val_mse: 0.5245 - val_mae: 0.5462\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4012 - mse: 0.4012 - mae: 0.4765 - val_loss: 0.5189 - val_mse: 0.5189 - val_mae: 0.5408\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3993 - mse: 0.3993 - mae: 0.4750 - val_loss: 0.5125 - val_mse: 0.5125 - val_mae: 0.5362\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3998 - mse: 0.3998 - mae: 0.4739 - val_loss: 0.5159 - val_mse: 0.5159 - val_mae: 0.5377\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3956 - mse: 0.3956 - mae: 0.4721 - val_loss: 0.5150 - val_mse: 0.5150 - val_mae: 0.5399\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3948 - mse: 0.3948 - mae: 0.4711 - val_loss: 0.5073 - val_mse: 0.5073 - val_mae: 0.5332\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3898 - mse: 0.3898 - mae: 0.4688 - val_loss: 0.5042 - val_mse: 0.5042 - val_mae: 0.5301\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3872 - mse: 0.3872 - mae: 0.4674 - val_loss: 0.5075 - val_mse: 0.5075 - val_mae: 0.5354\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3833 - mse: 0.3833 - mae: 0.4651 - val_loss: 0.4970 - val_mse: 0.4970 - val_mae: 0.5268\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3803 - mse: 0.3803 - mae: 0.4627 - val_loss: 0.4990 - val_mse: 0.4990 - val_mae: 0.5274\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3800 - mse: 0.3800 - mae: 0.4633 - val_loss: 0.5021 - val_mse: 0.5021 - val_mae: 0.5300\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3761 - mse: 0.3761 - mae: 0.4619 - val_loss: 0.4964 - val_mse: 0.4964 - val_mae: 0.5258\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3720 - mse: 0.3720 - mae: 0.4588 - val_loss: 0.4970 - val_mse: 0.4970 - val_mae: 0.5272\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3729 - mse: 0.3729 - mae: 0.4608 - val_loss: 0.4955 - val_mse: 0.4955 - val_mae: 0.5239\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3702 - mse: 0.3702 - mae: 0.4580 - val_loss: 0.4900 - val_mse: 0.4900 - val_mae: 0.5212\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3650 - mse: 0.3650 - mae: 0.4551 - val_loss: 0.4953 - val_mse: 0.4953 - val_mae: 0.5235\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3655 - mse: 0.3655 - mae: 0.4552 - val_loss: 0.4906 - val_mse: 0.4906 - val_mae: 0.5230\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3594 - mse: 0.3594 - mae: 0.4507 - val_loss: 0.4929 - val_mse: 0.4929 - val_mae: 0.5237\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3572 - mse: 0.3572 - mae: 0.4496 - val_loss: 0.4891 - val_mse: 0.4891 - val_mae: 0.5208\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3541 - mse: 0.3541 - mae: 0.4484 - val_loss: 0.4905 - val_mse: 0.4905 - val_mae: 0.5198\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3547 - mse: 0.3547 - mae: 0.4490 - val_loss: 0.4872 - val_mse: 0.4872 - val_mae: 0.5187\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3558 - mse: 0.3558 - mae: 0.4505 - val_loss: 0.4871 - val_mse: 0.4871 - val_mae: 0.5185\n",
      "Epoch 61/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3530 - mse: 0.3530 - mae: 0.4475 - val_loss: 0.4926 - val_mse: 0.4926 - val_mae: 0.5237\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3501 - mse: 0.3501 - mae: 0.4454 - val_loss: 0.4848 - val_mse: 0.4848 - val_mae: 0.5164\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3469 - mse: 0.3469 - mae: 0.4451 - val_loss: 0.4855 - val_mse: 0.4855 - val_mae: 0.5141\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3476 - mse: 0.3476 - mae: 0.4458 - val_loss: 0.4886 - val_mse: 0.4886 - val_mae: 0.5222\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3420 - mse: 0.3420 - mae: 0.4407 - val_loss: 0.4889 - val_mse: 0.4889 - val_mae: 0.5178\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3402 - mse: 0.3402 - mae: 0.4399 - val_loss: 0.4843 - val_mse: 0.4843 - val_mae: 0.5158\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3360 - mse: 0.3360 - mae: 0.4378 - val_loss: 0.4804 - val_mse: 0.4804 - val_mae: 0.5132\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3381 - mse: 0.3381 - mae: 0.4385 - val_loss: 0.4790 - val_mse: 0.4790 - val_mae: 0.5124\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3350 - mse: 0.3350 - mae: 0.4363 - val_loss: 0.4816 - val_mse: 0.4816 - val_mae: 0.5143\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3346 - mse: 0.3346 - mae: 0.4387 - val_loss: 0.4796 - val_mse: 0.4796 - val_mae: 0.5143\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3321 - mse: 0.3321 - mae: 0.4366 - val_loss: 0.4841 - val_mse: 0.4841 - val_mae: 0.5141\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3344 - mse: 0.3344 - mae: 0.4372 - val_loss: 0.4865 - val_mse: 0.4865 - val_mae: 0.5173\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3272 - mse: 0.3272 - mae: 0.4327 - val_loss: 0.4814 - val_mse: 0.4814 - val_mae: 0.5147\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3258 - mse: 0.3258 - mae: 0.4303 - val_loss: 0.4834 - val_mse: 0.4834 - val_mae: 0.5139\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3246 - mse: 0.3246 - mae: 0.4314 - val_loss: 0.4870 - val_mse: 0.4870 - val_mae: 0.5185\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3209 - mse: 0.3209 - mae: 0.4280 - val_loss: 0.4857 - val_mse: 0.4857 - val_mae: 0.5130\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3245 - mse: 0.3245 - mae: 0.4294 - val_loss: 0.4851 - val_mse: 0.4851 - val_mae: 0.5121\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3167 - mse: 0.3167 - mae: 0.4251 - val_loss: 0.4848 - val_mse: 0.4848 - val_mae: 0.5160\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 68us/sample - loss: 2.4754 - mse: 2.4754 - mae: 1.1485 - val_loss: 14.9818 - val_mse: 14.9818 - val_mae: 3.6013\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 1.4032 - mse: 1.4032 - mae: 0.8891 - val_loss: 7.0041 - val_mse: 7.0041 - val_mae: 2.3663\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 1.0755 - mse: 1.0755 - mae: 0.7793 - val_loss: 5.2054 - val_mse: 5.2054 - val_mae: 2.0247\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.9046 - mse: 0.9046 - mae: 0.7161 - val_loss: 4.3110 - val_mse: 4.3110 - val_mae: 1.8312\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.8054 - mse: 0.8054 - mae: 0.6771 - val_loss: 3.7646 - val_mse: 3.7646 - val_mae: 1.7038\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.7438 - mse: 0.7438 - mae: 0.6507 - val_loss: 3.3084 - val_mse: 3.3084 - val_mae: 1.5887\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.7052 - mse: 0.7052 - mae: 0.6324 - val_loss: 3.0519 - val_mse: 3.0519 - val_mae: 1.5192\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.6735 - mse: 0.6735 - mae: 0.6191 - val_loss: 2.7728 - val_mse: 2.7728 - val_mae: 1.4421\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.6503 - mse: 0.6503 - mae: 0.6094 - val_loss: 2.4306 - val_mse: 2.4306 - val_mae: 1.3385\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.6298 - mse: 0.6298 - mae: 0.5993 - val_loss: 2.1468 - val_mse: 2.1468 - val_mae: 1.2498\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.6094 - mse: 0.6094 - mae: 0.5895 - val_loss: 1.9290 - val_mse: 1.9290 - val_mae: 1.1736\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5881 - mse: 0.5881 - mae: 0.5794 - val_loss: 1.7378 - val_mse: 1.7378 - val_mae: 1.1102\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5766 - mse: 0.5766 - mae: 0.5719 - val_loss: 1.5156 - val_mse: 1.5156 - val_mae: 1.0254\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5612 - mse: 0.5612 - mae: 0.5638 - val_loss: 1.3922 - val_mse: 1.3922 - val_mae: 0.9812\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5542 - mse: 0.5542 - mae: 0.5602 - val_loss: 1.2774 - val_mse: 1.2774 - val_mae: 0.9345\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5413 - mse: 0.5413 - mae: 0.5553 - val_loss: 1.1896 - val_mse: 1.1896 - val_mae: 0.8995\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5321 - mse: 0.5321 - mae: 0.5494 - val_loss: 1.0747 - val_mse: 1.0747 - val_mae: 0.8486\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5231 - mse: 0.5231 - mae: 0.5432 - val_loss: 0.9945 - val_mse: 0.9945 - val_mae: 0.8109\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5145 - mse: 0.5145 - mae: 0.5402 - val_loss: 0.9265 - val_mse: 0.9265 - val_mae: 0.7788\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5063 - mse: 0.5063 - mae: 0.5344 - val_loss: 0.8611 - val_mse: 0.8611 - val_mae: 0.7463\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 4us/sample - loss: 0.5010 - mse: 0.5010 - mae: 0.5318 - val_loss: 0.8188 - val_mse: 0.8188 - val_mae: 0.7220\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.4905 - mse: 0.4905 - mae: 0.5250 - val_loss: 0.7790 - val_mse: 0.7790 - val_mae: 0.6995\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4851 - mse: 0.4851 - mae: 0.5223 - val_loss: 0.7395 - val_mse: 0.7395 - val_mae: 0.6774\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4795 - mse: 0.4795 - mae: 0.5202 - val_loss: 0.7100 - val_mse: 0.7100 - val_mae: 0.6583\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4732 - mse: 0.4732 - mae: 0.5170 - val_loss: 0.6861 - val_mse: 0.6861 - val_mae: 0.6462\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4670 - mse: 0.4670 - mae: 0.5127 - val_loss: 0.6592 - val_mse: 0.6592 - val_mae: 0.6259\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4580 - mse: 0.4580 - mae: 0.5073 - val_loss: 0.6413 - val_mse: 0.6413 - val_mae: 0.6152\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4538 - mse: 0.4538 - mae: 0.5056 - val_loss: 0.6148 - val_mse: 0.6148 - val_mae: 0.5962\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4480 - mse: 0.4480 - mae: 0.5013 - val_loss: 0.6113 - val_mse: 0.6113 - val_mae: 0.5927\n",
      "Epoch 30/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4439 - mse: 0.4439 - mae: 0.4995 - val_loss: 0.5959 - val_mse: 0.5959 - val_mae: 0.5812\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4381 - mse: 0.4381 - mae: 0.4971 - val_loss: 0.5851 - val_mse: 0.5851 - val_mae: 0.5724\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4323 - mse: 0.4323 - mae: 0.4928 - val_loss: 0.5798 - val_mse: 0.5798 - val_mae: 0.5687\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4306 - mse: 0.4306 - mae: 0.4915 - val_loss: 0.5739 - val_mse: 0.5739 - val_mae: 0.5653\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4267 - mse: 0.4267 - mae: 0.4896 - val_loss: 0.5647 - val_mse: 0.5647 - val_mae: 0.5580\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4189 - mse: 0.4189 - mae: 0.4856 - val_loss: 0.5552 - val_mse: 0.5552 - val_mae: 0.5527\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4183 - mse: 0.4183 - mae: 0.4843 - val_loss: 0.5525 - val_mse: 0.5525 - val_mae: 0.5488\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.4133 - mse: 0.4133 - mae: 0.4821 - val_loss: 0.5456 - val_mse: 0.5456 - val_mae: 0.5443\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4116 - mse: 0.4116 - mae: 0.4798 - val_loss: 0.5437 - val_mse: 0.5437 - val_mae: 0.5407\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.4085 - mse: 0.4085 - mae: 0.4790 - val_loss: 0.5420 - val_mse: 0.5420 - val_mae: 0.5395\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.4039 - mse: 0.4039 - mae: 0.4773 - val_loss: 0.5318 - val_mse: 0.5318 - val_mae: 0.5337\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4012 - mse: 0.4012 - mae: 0.4750 - val_loss: 0.5288 - val_mse: 0.5288 - val_mae: 0.5312\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4010 - mse: 0.4010 - mae: 0.4746 - val_loss: 0.5250 - val_mse: 0.5250 - val_mae: 0.5276\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 0s 4us/sample - loss: 0.3930 - mse: 0.3930 - mae: 0.4709 - val_loss: 0.5302 - val_mse: 0.5302 - val_mae: 0.5315\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.3901 - mse: 0.3901 - mae: 0.4682 - val_loss: 0.5224 - val_mse: 0.5224 - val_mae: 0.5246\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 0s 4us/sample - loss: 0.3881 - mse: 0.3881 - mae: 0.4675 - val_loss: 0.5235 - val_mse: 0.5235 - val_mae: 0.5265\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.3836 - mse: 0.3836 - mae: 0.4664 - val_loss: 0.5137 - val_mse: 0.5137 - val_mae: 0.5204\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3825 - mse: 0.3825 - mae: 0.4653 - val_loss: 0.5124 - val_mse: 0.5124 - val_mae: 0.5188\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3766 - mse: 0.3766 - mae: 0.4615 - val_loss: 0.5136 - val_mse: 0.5136 - val_mae: 0.5186\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3757 - mse: 0.3757 - mae: 0.4617 - val_loss: 0.5108 - val_mse: 0.5108 - val_mae: 0.5181\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3757 - mse: 0.3757 - mae: 0.4610 - val_loss: 0.5125 - val_mse: 0.5125 - val_mae: 0.5168\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 0s 4us/sample - loss: 0.3737 - mse: 0.3737 - mae: 0.4586 - val_loss: 0.5115 - val_mse: 0.5115 - val_mae: 0.5167\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3697 - mse: 0.3697 - mae: 0.4574 - val_loss: 0.5048 - val_mse: 0.5048 - val_mae: 0.5120\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 0s 4us/sample - loss: 0.3654 - mse: 0.3654 - mae: 0.4548 - val_loss: 0.5124 - val_mse: 0.5124 - val_mae: 0.5173\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.3664 - mse: 0.3664 - mae: 0.4549 - val_loss: 0.5043 - val_mse: 0.5043 - val_mae: 0.5117\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3620 - mse: 0.3620 - mae: 0.4531 - val_loss: 0.5038 - val_mse: 0.5038 - val_mae: 0.5113\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3588 - mse: 0.3588 - mae: 0.4500 - val_loss: 0.5015 - val_mse: 0.5015 - val_mae: 0.5082\n",
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.3571 - mse: 0.3571 - mae: 0.4490 - val_loss: 0.4969 - val_mse: 0.4969 - val_mae: 0.5079\n",
      "Epoch 58/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.3548 - mse: 0.3548 - mae: 0.4471 - val_loss: 0.4983 - val_mse: 0.4983 - val_mae: 0.5086\n",
      "Epoch 59/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3541 - mse: 0.3541 - mae: 0.4476 - val_loss: 0.4954 - val_mse: 0.4954 - val_mae: 0.5054\n",
      "Epoch 60/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3498 - mse: 0.3498 - mae: 0.4445 - val_loss: 0.4923 - val_mse: 0.4923 - val_mae: 0.5053\n",
      "Epoch 61/3000\n",
      "10664/10664 [==============================] - 0s 4us/sample - loss: 0.3483 - mse: 0.3483 - mae: 0.4438 - val_loss: 0.4970 - val_mse: 0.4970 - val_mae: 0.5049\n",
      "Epoch 62/3000\n",
      "10664/10664 [==============================] - 0s 4us/sample - loss: 0.3483 - mse: 0.3483 - mae: 0.4431 - val_loss: 0.4966 - val_mse: 0.4966 - val_mae: 0.5047\n",
      "Epoch 63/3000\n",
      "10664/10664 [==============================] - 0s 4us/sample - loss: 0.3433 - mse: 0.3433 - mae: 0.4412 - val_loss: 0.4920 - val_mse: 0.4920 - val_mae: 0.5050\n",
      "Epoch 64/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.3410 - mse: 0.3410 - mae: 0.4397 - val_loss: 0.4876 - val_mse: 0.4876 - val_mae: 0.5035\n",
      "Epoch 65/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3387 - mse: 0.3387 - mae: 0.4391 - val_loss: 0.4954 - val_mse: 0.4954 - val_mae: 0.5053\n",
      "Epoch 66/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3390 - mse: 0.3390 - mae: 0.4391 - val_loss: 0.4900 - val_mse: 0.4900 - val_mae: 0.5039\n",
      "Epoch 67/3000\n",
      "10664/10664 [==============================] - ETA: 0s - loss: 0.3285 - mse: 0.3285 - mae: 0.433 - 0s 5us/sample - loss: 0.3387 - mse: 0.3387 - mae: 0.4380 - val_loss: 0.4966 - val_mse: 0.4966 - val_mae: 0.5059\n",
      "Epoch 68/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3363 - mse: 0.3363 - mae: 0.4382 - val_loss: 0.4886 - val_mse: 0.4886 - val_mae: 0.5033\n",
      "Epoch 69/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3345 - mse: 0.3345 - mae: 0.4366 - val_loss: 0.4940 - val_mse: 0.4940 - val_mae: 0.5049\n",
      "Epoch 70/3000\n",
      "10664/10664 [==============================] - 0s 4us/sample - loss: 0.3308 - mse: 0.3308 - mae: 0.4346 - val_loss: 0.4940 - val_mse: 0.4940 - val_mae: 0.5043\n",
      "Epoch 71/3000\n",
      "10664/10664 [==============================] - 0s 4us/sample - loss: 0.3320 - mse: 0.3320 - mae: 0.4338 - val_loss: 0.4980 - val_mse: 0.4980 - val_mae: 0.5060\n",
      "Epoch 72/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3324 - mse: 0.3324 - mae: 0.4348 - val_loss: 0.4930 - val_mse: 0.4930 - val_mae: 0.5040\n",
      "Epoch 73/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.3288 - mse: 0.3288 - mae: 0.4327 - val_loss: 0.4849 - val_mse: 0.4849 - val_mae: 0.5019\n",
      "Epoch 74/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.3253 - mse: 0.3253 - mae: 0.4303 - val_loss: 0.4938 - val_mse: 0.4938 - val_mae: 0.5037\n",
      "Epoch 75/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.3279 - mse: 0.3279 - mae: 0.4314 - val_loss: 0.4876 - val_mse: 0.4876 - val_mae: 0.5006\n",
      "Epoch 76/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3201 - mse: 0.3201 - mae: 0.4272 - val_loss: 0.4925 - val_mse: 0.4925 - val_mae: 0.5001\n",
      "Epoch 77/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3238 - mse: 0.3238 - mae: 0.4293 - val_loss: 0.4906 - val_mse: 0.4906 - val_mae: 0.5026\n",
      "Epoch 78/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3164 - mse: 0.3164 - mae: 0.4252 - val_loss: 0.4861 - val_mse: 0.4861 - val_mae: 0.4981\n",
      "Epoch 79/3000\n",
      "10664/10664 [==============================] - 0s 4us/sample - loss: 0.3192 - mse: 0.3192 - mae: 0.4268 - val_loss: 0.4888 - val_mse: 0.4888 - val_mae: 0.5005\n",
      "Epoch 80/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3191 - mse: 0.3191 - mae: 0.4255 - val_loss: 0.4977 - val_mse: 0.4977 - val_mae: 0.5042\n",
      "Epoch 81/3000\n",
      "10664/10664 [==============================] - 0s 4us/sample - loss: 0.3156 - mse: 0.3156 - mae: 0.4236 - val_loss: 0.4895 - val_mse: 0.4895 - val_mae: 0.5020\n",
      "Epoch 82/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.3138 - mse: 0.3138 - mae: 0.4240 - val_loss: 0.4906 - val_mse: 0.4906 - val_mae: 0.5009\n",
      "Epoch 83/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3151 - mse: 0.3151 - mae: 0.4234 - val_loss: 0.4854 - val_mse: 0.4854 - val_mae: 0.4991\n",
      "Avg. MAE: 0.446507\n",
      "Starting Optimizer!\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 1.1986 - mse: 1.1986 - mae: 0.7893 - val_loss: 1.9746 - val_mse: 1.9746 - val_mae: 1.1780\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.5449 - mse: 0.5449 - mae: 0.5517 - val_loss: 0.9838 - val_mse: 0.9838 - val_mae: 0.8182\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.4895 - mse: 0.4895 - mae: 0.5199 - val_loss: 0.8243 - val_mse: 0.8243 - val_mae: 0.7406\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4682 - mse: 0.4682 - mae: 0.5106 - val_loss: 0.7215 - val_mse: 0.7215 - val_mae: 0.6844\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4296 - mse: 0.4296 - mae: 0.4899 - val_loss: 0.6084 - val_mse: 0.6084 - val_mae: 0.6179\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4052 - mse: 0.4052 - mae: 0.4780 - val_loss: 0.5693 - val_mse: 0.5693 - val_mae: 0.5901\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3894 - mse: 0.3894 - mae: 0.4696 - val_loss: 0.5033 - val_mse: 0.5033 - val_mae: 0.5456\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3645 - mse: 0.3645 - mae: 0.4509 - val_loss: 0.4805 - val_mse: 0.4805 - val_mae: 0.5291\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3600 - mse: 0.3600 - mae: 0.4512 - val_loss: 0.4960 - val_mse: 0.4960 - val_mae: 0.5412\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3423 - mse: 0.3423 - mae: 0.4406 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.5146\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3324 - mse: 0.3324 - mae: 0.4331 - val_loss: 0.5294 - val_mse: 0.5294 - val_mae: 0.5496\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3266 - mse: 0.3266 - mae: 0.4298 - val_loss: 0.4734 - val_mse: 0.4734 - val_mae: 0.5260\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3130 - mse: 0.3130 - mae: 0.4239 - val_loss: 0.4727 - val_mse: 0.4727 - val_mae: 0.5061\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2950 - mse: 0.2950 - mae: 0.4089 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.5108\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2978 - mse: 0.2978 - mae: 0.4146 - val_loss: 0.4615 - val_mse: 0.4615 - val_mae: 0.5001\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2887 - mse: 0.2887 - mae: 0.4066 - val_loss: 0.4331 - val_mse: 0.4331 - val_mae: 0.4925\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2759 - mse: 0.2759 - mae: 0.3995 - val_loss: 0.4432 - val_mse: 0.4432 - val_mae: 0.4972\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2901 - mse: 0.2901 - mae: 0.4082 - val_loss: 0.4335 - val_mse: 0.4335 - val_mae: 0.4971\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2750 - mse: 0.2750 - mae: 0.3954 - val_loss: 0.4127 - val_mse: 0.4127 - val_mae: 0.4829\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2620 - mse: 0.2620 - mae: 0.3855 - val_loss: 0.4534 - val_mse: 0.4534 - val_mae: 0.5050\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2588 - mse: 0.2588 - mae: 0.3853 - val_loss: 0.4483 - val_mse: 0.4483 - val_mae: 0.4938\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2516 - mse: 0.2516 - mae: 0.3810 - val_loss: 0.4404 - val_mse: 0.4404 - val_mae: 0.4915\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2488 - mse: 0.2488 - mae: 0.3789 - val_loss: 0.4347 - val_mse: 0.4347 - val_mae: 0.4824\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2378 - mse: 0.2378 - mae: 0.3687 - val_loss: 0.4384 - val_mse: 0.4384 - val_mae: 0.5030\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2544 - mse: 0.2544 - mae: 0.3815 - val_loss: 0.4825 - val_mse: 0.4825 - val_mae: 0.5094\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2376 - mse: 0.2376 - mae: 0.3712 - val_loss: 0.4513 - val_mse: 0.4513 - val_mae: 0.4964\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2289 - mse: 0.2289 - mae: 0.3650 - val_loss: 0.4365 - val_mse: 0.4365 - val_mae: 0.4853\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2261 - mse: 0.2261 - mae: 0.3617 - val_loss: 0.4572 - val_mse: 0.4572 - val_mae: 0.5186\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2302 - mse: 0.2302 - mae: 0.3658 - val_loss: 0.4186 - val_mse: 0.4186 - val_mae: 0.4766\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 76us/sample - loss: 1.2349 - mse: 1.2349 - mae: 0.7919 - val_loss: 4.1399 - val_mse: 4.1399 - val_mae: 1.8110\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.5625 - mse: 0.5625 - mae: 0.5652 - val_loss: 1.4322 - val_mse: 1.4322 - val_mae: 0.9984\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4908 - mse: 0.4908 - mae: 0.5262 - val_loss: 1.0986 - val_mse: 1.0986 - val_mae: 0.8573\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4536 - mse: 0.4536 - mae: 0.5070 - val_loss: 0.7887 - val_mse: 0.7887 - val_mae: 0.7234\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4284 - mse: 0.4284 - mae: 0.4912 - val_loss: 0.6746 - val_mse: 0.6746 - val_mae: 0.6537\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4015 - mse: 0.4015 - mae: 0.4785 - val_loss: 0.5625 - val_mse: 0.5625 - val_mae: 0.5678\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3915 - mse: 0.3915 - mae: 0.4717 - val_loss: 0.5523 - val_mse: 0.5523 - val_mae: 0.5422\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3733 - mse: 0.3733 - mae: 0.4611 - val_loss: 0.5452 - val_mse: 0.5452 - val_mae: 0.5524\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3556 - mse: 0.3556 - mae: 0.4494 - val_loss: 0.5775 - val_mse: 0.5775 - val_mae: 0.5628\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3547 - mse: 0.3547 - mae: 0.4503 - val_loss: 0.5018 - val_mse: 0.5018 - val_mae: 0.5365\n",
      "Epoch 11/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3296 - mse: 0.3296 - mae: 0.4334 - val_loss: 0.5069 - val_mse: 0.5069 - val_mae: 0.5249\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3268 - mse: 0.3268 - mae: 0.4314 - val_loss: 0.4918 - val_mse: 0.4918 - val_mae: 0.5217\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3107 - mse: 0.3107 - mae: 0.4231 - val_loss: 0.5165 - val_mse: 0.5165 - val_mae: 0.5171\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3148 - mse: 0.3148 - mae: 0.4259 - val_loss: 0.4822 - val_mse: 0.4822 - val_mae: 0.5085\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2934 - mse: 0.2934 - mae: 0.4100 - val_loss: 0.5109 - val_mse: 0.5109 - val_mae: 0.5133\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2896 - mse: 0.2896 - mae: 0.4071 - val_loss: 0.4675 - val_mse: 0.4675 - val_mae: 0.4996\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2877 - mse: 0.2877 - mae: 0.4074 - val_loss: 0.4535 - val_mse: 0.4535 - val_mae: 0.4902\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2789 - mse: 0.2789 - mae: 0.4029 - val_loss: 0.4401 - val_mse: 0.4401 - val_mae: 0.4823\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2665 - mse: 0.2665 - mae: 0.3889 - val_loss: 0.4906 - val_mse: 0.4906 - val_mae: 0.5040\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2625 - mse: 0.2625 - mae: 0.3881 - val_loss: 0.4389 - val_mse: 0.4389 - val_mae: 0.4914\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2588 - mse: 0.2588 - mae: 0.3861 - val_loss: 0.4686 - val_mse: 0.4686 - val_mae: 0.5046\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2536 - mse: 0.2536 - mae: 0.3845 - val_loss: 0.4684 - val_mse: 0.4684 - val_mae: 0.4927\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2568 - mse: 0.2568 - mae: 0.3852 - val_loss: 0.4581 - val_mse: 0.4581 - val_mae: 0.4939\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2520 - mse: 0.2520 - mae: 0.3814 - val_loss: 0.5051 - val_mse: 0.5051 - val_mae: 0.5112\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2429 - mse: 0.2429 - mae: 0.3751 - val_loss: 0.4381 - val_mse: 0.4381 - val_mae: 0.4798\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2324 - mse: 0.2324 - mae: 0.3662 - val_loss: 0.4369 - val_mse: 0.4369 - val_mae: 0.4825\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2332 - mse: 0.2332 - mae: 0.3677 - val_loss: 0.4371 - val_mse: 0.4371 - val_mae: 0.4786\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2192 - mse: 0.2192 - mae: 0.3555 - val_loss: 0.5045 - val_mse: 0.5045 - val_mae: 0.4990\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2288 - mse: 0.2288 - mae: 0.3666 - val_loss: 0.4724 - val_mse: 0.4724 - val_mae: 0.5027\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2214 - mse: 0.2214 - mae: 0.3591 - val_loss: 0.4671 - val_mse: 0.4671 - val_mae: 0.4777\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2148 - mse: 0.2148 - mae: 0.3528 - val_loss: 0.4462 - val_mse: 0.4462 - val_mae: 0.4834\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2110 - mse: 0.2110 - mae: 0.3494 - val_loss: 0.4652 - val_mse: 0.4652 - val_mae: 0.4904\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2212 - mse: 0.2212 - mae: 0.3580 - val_loss: 0.4450 - val_mse: 0.4450 - val_mae: 0.4810\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2128 - mse: 0.2128 - mae: 0.3515 - val_loss: 0.4555 - val_mse: 0.4555 - val_mae: 0.4754\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2020 - mse: 0.2020 - mae: 0.3426 - val_loss: 0.4547 - val_mse: 0.4547 - val_mae: 0.4863\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2055 - mse: 0.2055 - mae: 0.3444 - val_loss: 0.4395 - val_mse: 0.4395 - val_mae: 0.4778\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 75us/sample - loss: 1.1885 - mse: 1.1885 - mae: 0.7896 - val_loss: 3.5543 - val_mse: 3.5543 - val_mae: 1.6788\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.5734 - mse: 0.5734 - mae: 0.5664 - val_loss: 1.8036 - val_mse: 1.8036 - val_mae: 1.1821\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.5065 - mse: 0.5065 - mae: 0.5312 - val_loss: 1.0515 - val_mse: 1.0515 - val_mae: 0.8763\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4619 - mse: 0.4619 - mae: 0.5080 - val_loss: 0.8227 - val_mse: 0.8227 - val_mae: 0.7571\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4408 - mse: 0.4408 - mae: 0.4997 - val_loss: 0.6488 - val_mse: 0.6488 - val_mae: 0.6391\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.4047 - mse: 0.4047 - mae: 0.4760 - val_loss: 0.5726 - val_mse: 0.5726 - val_mae: 0.6016\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3943 - mse: 0.3943 - mae: 0.4716 - val_loss: 0.5363 - val_mse: 0.5363 - val_mae: 0.5691\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3633 - mse: 0.3633 - mae: 0.4529 - val_loss: 0.5066 - val_mse: 0.5066 - val_mae: 0.5487\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3536 - mse: 0.3536 - mae: 0.4484 - val_loss: 0.5046 - val_mse: 0.5046 - val_mae: 0.5369\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3590 - mse: 0.3590 - mae: 0.4490 - val_loss: 0.6105 - val_mse: 0.6105 - val_mae: 0.5362\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3480 - mse: 0.3480 - mae: 0.4402 - val_loss: 0.4570 - val_mse: 0.4570 - val_mae: 0.5010\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3314 - mse: 0.3314 - mae: 0.4362 - val_loss: 0.4728 - val_mse: 0.4728 - val_mae: 0.5113\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3254 - mse: 0.3254 - mae: 0.4294 - val_loss: 0.4691 - val_mse: 0.4691 - val_mae: 0.4988\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3127 - mse: 0.3127 - mae: 0.4209 - val_loss: 0.4507 - val_mse: 0.4507 - val_mae: 0.4922\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2960 - mse: 0.2960 - mae: 0.4107 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.5028\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3181 - mse: 0.3181 - mae: 0.4256 - val_loss: 0.4594 - val_mse: 0.4594 - val_mae: 0.4889\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2859 - mse: 0.2859 - mae: 0.4029 - val_loss: 0.4589 - val_mse: 0.4589 - val_mae: 0.5021\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2797 - mse: 0.2797 - mae: 0.4008 - val_loss: 0.4678 - val_mse: 0.4678 - val_mae: 0.5001\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2704 - mse: 0.2704 - mae: 0.3952 - val_loss: 0.4747 - val_mse: 0.4747 - val_mae: 0.4977\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2739 - mse: 0.2739 - mae: 0.3964 - val_loss: 0.4431 - val_mse: 0.4431 - val_mae: 0.4867\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2619 - mse: 0.2619 - mae: 0.3883 - val_loss: 0.4674 - val_mse: 0.4674 - val_mae: 0.4938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2565 - mse: 0.2565 - mae: 0.3849 - val_loss: 0.4941 - val_mse: 0.4941 - val_mae: 0.5090\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2645 - mse: 0.2645 - mae: 0.3918 - val_loss: 0.4896 - val_mse: 0.4896 - val_mae: 0.5081\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2507 - mse: 0.2507 - mae: 0.3802 - val_loss: 0.4779 - val_mse: 0.4779 - val_mae: 0.4919\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2560 - mse: 0.2560 - mae: 0.3808 - val_loss: 0.4715 - val_mse: 0.4715 - val_mae: 0.5071\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2446 - mse: 0.2446 - mae: 0.3766 - val_loss: 0.4646 - val_mse: 0.4646 - val_mae: 0.4947\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2449 - mse: 0.2449 - mae: 0.3758 - val_loss: 0.4771 - val_mse: 0.4771 - val_mae: 0.4842\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2431 - mse: 0.2431 - mae: 0.3738 - val_loss: 0.4476 - val_mse: 0.4476 - val_mae: 0.4905\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2316 - mse: 0.2316 - mae: 0.3641 - val_loss: 0.4486 - val_mse: 0.4486 - val_mae: 0.4895\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2276 - mse: 0.2276 - mae: 0.3615 - val_loss: 0.4689 - val_mse: 0.4689 - val_mae: 0.4805\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 75us/sample - loss: 1.1295 - mse: 1.1295 - mae: 0.7668 - val_loss: 3.0733 - val_mse: 3.0733 - val_mae: 1.5210\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.5470 - mse: 0.5470 - mae: 0.5518 - val_loss: 1.7462 - val_mse: 1.7462 - val_mae: 1.1519\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.4899 - mse: 0.4899 - mae: 0.5239 - val_loss: 0.8074 - val_mse: 0.8074 - val_mae: 0.7392\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4506 - mse: 0.4506 - mae: 0.5030 - val_loss: 0.7931 - val_mse: 0.7931 - val_mae: 0.7233\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.4256 - mse: 0.4256 - mae: 0.4881 - val_loss: 0.6256 - val_mse: 0.6256 - val_mae: 0.6130\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.4118 - mse: 0.4118 - mae: 0.4814 - val_loss: 0.5851 - val_mse: 0.5851 - val_mae: 0.5869\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3936 - mse: 0.3936 - mae: 0.4720 - val_loss: 0.5354 - val_mse: 0.5354 - val_mae: 0.5566\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3661 - mse: 0.3661 - mae: 0.4553 - val_loss: 0.5360 - val_mse: 0.5360 - val_mae: 0.5556\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3598 - mse: 0.3598 - mae: 0.4508 - val_loss: 0.5112 - val_mse: 0.5112 - val_mae: 0.5413\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3418 - mse: 0.3418 - mae: 0.4421 - val_loss: 0.5346 - val_mse: 0.5346 - val_mae: 0.5450\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3308 - mse: 0.3308 - mae: 0.4338 - val_loss: 0.4841 - val_mse: 0.4841 - val_mae: 0.5189\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3354 - mse: 0.3354 - mae: 0.4388 - val_loss: 0.4722 - val_mse: 0.4722 - val_mae: 0.4991\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3042 - mse: 0.3042 - mae: 0.4170 - val_loss: 0.4746 - val_mse: 0.4746 - val_mae: 0.4962\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3051 - mse: 0.3051 - mae: 0.4142 - val_loss: 0.4503 - val_mse: 0.4503 - val_mae: 0.4899\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2938 - mse: 0.2938 - mae: 0.4088 - val_loss: 0.4511 - val_mse: 0.4511 - val_mae: 0.4898\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2914 - mse: 0.2914 - mae: 0.4061 - val_loss: 0.4551 - val_mse: 0.4551 - val_mae: 0.4922\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2936 - mse: 0.2936 - mae: 0.4082 - val_loss: 0.4570 - val_mse: 0.4570 - val_mae: 0.4919\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2778 - mse: 0.2778 - mae: 0.3984 - val_loss: 0.4541 - val_mse: 0.4541 - val_mae: 0.4943\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2755 - mse: 0.2755 - mae: 0.3967 - val_loss: 0.4696 - val_mse: 0.4696 - val_mae: 0.4900\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2667 - mse: 0.2667 - mae: 0.3901 - val_loss: 0.4930 - val_mse: 0.4930 - val_mae: 0.4994\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2579 - mse: 0.2579 - mae: 0.3831 - val_loss: 0.4557 - val_mse: 0.4557 - val_mae: 0.4959\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2543 - mse: 0.2543 - mae: 0.3824 - val_loss: 0.4523 - val_mse: 0.4523 - val_mae: 0.4875\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2403 - mse: 0.2403 - mae: 0.3725 - val_loss: 0.4579 - val_mse: 0.4579 - val_mae: 0.4938\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2529 - mse: 0.2529 - mae: 0.3806 - val_loss: 0.4695 - val_mse: 0.4695 - val_mae: 0.4975\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 78us/sample - loss: 1.1375 - mse: 1.1375 - mae: 0.7755 - val_loss: 1.5522 - val_mse: 1.5522 - val_mae: 1.0671\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.5483 - mse: 0.5483 - mae: 0.5552 - val_loss: 1.0969 - val_mse: 1.0969 - val_mae: 0.8831\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.4803 - mse: 0.4803 - mae: 0.5220 - val_loss: 0.9741 - val_mse: 0.9741 - val_mae: 0.8152\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 15us/sample - loss: 0.4517 - mse: 0.4517 - mae: 0.5031 - val_loss: 0.7587 - val_mse: 0.7587 - val_mae: 0.7060\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.4251 - mse: 0.4251 - mae: 0.4896 - val_loss: 0.5970 - val_mse: 0.5970 - val_mae: 0.6063\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.4012 - mse: 0.4012 - mae: 0.4770 - val_loss: 0.5451 - val_mse: 0.5451 - val_mae: 0.5618\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.3909 - mse: 0.3909 - mae: 0.4689 - val_loss: 0.5626 - val_mse: 0.5626 - val_mae: 0.5828\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.3763 - mse: 0.3763 - mae: 0.4618 - val_loss: 0.5082 - val_mse: 0.5082 - val_mae: 0.5397\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.3572 - mse: 0.3572 - mae: 0.4493 - val_loss: 0.4737 - val_mse: 0.4737 - val_mae: 0.5142\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.3480 - mse: 0.3480 - mae: 0.4474 - val_loss: 0.4608 - val_mse: 0.4608 - val_mae: 0.5017\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.3457 - mse: 0.3457 - mae: 0.4419 - val_loss: 0.5023 - val_mse: 0.5023 - val_mae: 0.5163\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.3265 - mse: 0.3265 - mae: 0.4325 - val_loss: 0.4537 - val_mse: 0.4537 - val_mae: 0.4847\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.3137 - mse: 0.3137 - mae: 0.4226 - val_loss: 0.4545 - val_mse: 0.4545 - val_mae: 0.4915\n",
      "Epoch 14/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.3062 - mse: 0.3062 - mae: 0.4169 - val_loss: 0.4535 - val_mse: 0.4535 - val_mae: 0.4837\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.3015 - mse: 0.3015 - mae: 0.4123 - val_loss: 0.4391 - val_mse: 0.4391 - val_mae: 0.4762\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2886 - mse: 0.2886 - mae: 0.4052 - val_loss: 0.4524 - val_mse: 0.4524 - val_mae: 0.4745\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.2793 - mse: 0.2793 - mae: 0.4002 - val_loss: 0.4539 - val_mse: 0.4539 - val_mae: 0.4844\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2788 - mse: 0.2788 - mae: 0.4002 - val_loss: 0.4656 - val_mse: 0.4656 - val_mae: 0.4924\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2734 - mse: 0.2734 - mae: 0.3965 - val_loss: 0.4441 - val_mse: 0.4441 - val_mae: 0.4778\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2677 - mse: 0.2677 - mae: 0.3905 - val_loss: 0.4565 - val_mse: 0.4565 - val_mae: 0.4805\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2638 - mse: 0.2638 - mae: 0.3853 - val_loss: 0.4305 - val_mse: 0.4305 - val_mae: 0.4655\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2581 - mse: 0.2581 - mae: 0.3839 - val_loss: 0.4532 - val_mse: 0.4532 - val_mae: 0.4914\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2523 - mse: 0.2523 - mae: 0.3795 - val_loss: 0.4613 - val_mse: 0.4613 - val_mae: 0.4925\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2542 - mse: 0.2542 - mae: 0.3791 - val_loss: 0.4441 - val_mse: 0.4441 - val_mae: 0.4949\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2457 - mse: 0.2457 - mae: 0.3756 - val_loss: 0.4449 - val_mse: 0.4449 - val_mae: 0.4727\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2416 - mse: 0.2416 - mae: 0.3714 - val_loss: 0.4284 - val_mse: 0.4284 - val_mae: 0.4661\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2501 - mse: 0.2501 - mae: 0.3757 - val_loss: 0.4548 - val_mse: 0.4548 - val_mae: 0.4782\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2406 - mse: 0.2406 - mae: 0.3693 - val_loss: 0.4384 - val_mse: 0.4384 - val_mae: 0.4656\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2311 - mse: 0.2311 - mae: 0.3651 - val_loss: 0.4519 - val_mse: 0.4519 - val_mae: 0.4753\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2234 - mse: 0.2234 - mae: 0.3570 - val_loss: 0.4249 - val_mse: 0.4249 - val_mae: 0.4673\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2170 - mse: 0.2170 - mae: 0.3533 - val_loss: 0.4606 - val_mse: 0.4606 - val_mae: 0.4817\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2216 - mse: 0.2216 - mae: 0.3568 - val_loss: 0.4392 - val_mse: 0.4392 - val_mae: 0.4730\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2182 - mse: 0.2182 - mae: 0.3548 - val_loss: 0.4534 - val_mse: 0.4534 - val_mae: 0.4865\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2163 - mse: 0.2163 - mae: 0.3513 - val_loss: 0.4547 - val_mse: 0.4547 - val_mae: 0.4985\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 0s 15us/sample - loss: 0.2118 - mse: 0.2118 - mae: 0.3473 - val_loss: 0.4493 - val_mse: 0.4493 - val_mae: 0.4752\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 0s 15us/sample - loss: 0.2003 - mse: 0.2003 - mae: 0.3396 - val_loss: 0.4304 - val_mse: 0.4304 - val_mae: 0.4656\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 15us/sample - loss: 0.2046 - mse: 0.2046 - mae: 0.3438 - val_loss: 0.4619 - val_mse: 0.4619 - val_mae: 0.4883\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2086 - mse: 0.2086 - mae: 0.3472 - val_loss: 0.4261 - val_mse: 0.4261 - val_mae: 0.4649\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.2067 - mse: 0.2067 - mae: 0.3460 - val_loss: 0.4453 - val_mse: 0.4453 - val_mae: 0.4801\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1993 - mse: 0.1993 - mae: 0.3388 - val_loss: 0.4401 - val_mse: 0.4401 - val_mae: 0.4743\n",
      "Avg. MAE: 0.424751\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 126us/sample - loss: 1.0500 - mse: 1.0500 - mae: 0.7403 - val_loss: 4.8439 - val_mse: 4.8439 - val_mae: 2.0341\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.5026 - mse: 0.5026 - mae: 0.5300 - val_loss: 1.5169 - val_mse: 1.5169 - val_mae: 1.0701\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.4189 - mse: 0.4189 - mae: 0.4839 - val_loss: 0.9330 - val_mse: 0.9330 - val_mae: 0.8029\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3991 - mse: 0.3991 - mae: 0.4728 - val_loss: 0.7617 - val_mse: 0.7617 - val_mae: 0.7065\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3455 - mse: 0.3455 - mae: 0.4408 - val_loss: 0.6489 - val_mse: 0.6489 - val_mae: 0.6483\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3137 - mse: 0.3137 - mae: 0.4217 - val_loss: 0.5533 - val_mse: 0.5533 - val_mae: 0.5876\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2799 - mse: 0.2799 - mae: 0.3951 - val_loss: 0.4616 - val_mse: 0.4616 - val_mae: 0.5204\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2678 - mse: 0.2678 - mae: 0.3875 - val_loss: 0.4328 - val_mse: 0.4328 - val_mae: 0.4918\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2621 - mse: 0.2621 - mae: 0.3860 - val_loss: 0.4306 - val_mse: 0.4306 - val_mae: 0.4855\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2562 - mse: 0.2562 - mae: 0.3799 - val_loss: 0.4526 - val_mse: 0.4526 - val_mae: 0.5077\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2352 - mse: 0.2352 - mae: 0.3624 - val_loss: 0.4281 - val_mse: 0.4281 - val_mae: 0.4827\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2177 - mse: 0.2177 - mae: 0.3510 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4746\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2092 - mse: 0.2092 - mae: 0.3435 - val_loss: 0.4302 - val_mse: 0.4302 - val_mae: 0.4674\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1907 - mse: 0.1907 - mae: 0.3273 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.4674\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1921 - mse: 0.1921 - mae: 0.3305 - val_loss: 0.4257 - val_mse: 0.4257 - val_mae: 0.4750\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1816 - mse: 0.1816 - mae: 0.3229 - val_loss: 0.4126 - val_mse: 0.4126 - val_mae: 0.4701\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1749 - mse: 0.1749 - mae: 0.3154 - val_loss: 0.4154 - val_mse: 0.4154 - val_mae: 0.4669\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1717 - mse: 0.1717 - mae: 0.3126 - val_loss: 0.4353 - val_mse: 0.4353 - val_mae: 0.4771\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1573 - mse: 0.1573 - mae: 0.3012 - val_loss: 0.4121 - val_mse: 0.4121 - val_mae: 0.4681\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1556 - mse: 0.1556 - mae: 0.2988 - val_loss: 0.4147 - val_mse: 0.4147 - val_mae: 0.4666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1516 - mse: 0.1516 - mae: 0.2929 - val_loss: 0.4120 - val_mse: 0.4120 - val_mae: 0.4659\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1520 - mse: 0.1520 - mae: 0.2952 - val_loss: 0.4333 - val_mse: 0.4333 - val_mae: 0.4719\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1434 - mse: 0.1434 - mae: 0.2878 - val_loss: 0.4327 - val_mse: 0.4327 - val_mae: 0.4691\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1408 - mse: 0.1408 - mae: 0.2846 - val_loss: 0.4210 - val_mse: 0.4210 - val_mae: 0.4657\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1368 - mse: 0.1368 - mae: 0.2807 - val_loss: 0.4207 - val_mse: 0.4207 - val_mae: 0.4667\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1282 - mse: 0.1282 - mae: 0.2720 - val_loss: 0.4463 - val_mse: 0.4463 - val_mae: 0.4737\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1279 - mse: 0.1279 - mae: 0.2702 - val_loss: 0.4235 - val_mse: 0.4235 - val_mae: 0.4650\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1203 - mse: 0.1203 - mae: 0.2638 - val_loss: 0.4076 - val_mse: 0.4076 - val_mae: 0.4564\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1173 - mse: 0.1173 - mae: 0.2604 - val_loss: 0.3963 - val_mse: 0.3963 - val_mae: 0.4522\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1186 - mse: 0.1186 - mae: 0.2597 - val_loss: 0.4382 - val_mse: 0.4382 - val_mae: 0.4740\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1169 - mse: 0.1169 - mae: 0.2586 - val_loss: 0.4063 - val_mse: 0.4063 - val_mae: 0.4554\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1159 - mse: 0.1159 - mae: 0.2581 - val_loss: 0.4053 - val_mse: 0.4053 - val_mae: 0.4559\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1083 - mse: 0.1083 - mae: 0.2489 - val_loss: 0.4068 - val_mse: 0.4068 - val_mae: 0.4564\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1043 - mse: 0.1043 - mae: 0.2459 - val_loss: 0.3966 - val_mse: 0.3966 - val_mae: 0.4487\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1065 - mse: 0.1065 - mae: 0.2458 - val_loss: 0.4045 - val_mse: 0.4045 - val_mae: 0.4560\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1005 - mse: 0.1005 - mae: 0.2401 - val_loss: 0.4066 - val_mse: 0.4066 - val_mae: 0.4532\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0985 - mse: 0.0985 - mae: 0.2383 - val_loss: 0.4064 - val_mse: 0.4064 - val_mae: 0.4539\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1036 - mse: 0.1036 - mae: 0.2453 - val_loss: 0.3969 - val_mse: 0.3969 - val_mae: 0.4459\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1003 - mse: 0.1003 - mae: 0.2392 - val_loss: 0.3952 - val_mse: 0.3952 - val_mae: 0.4525\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0980 - mse: 0.0980 - mae: 0.2347 - val_loss: 0.4103 - val_mse: 0.4103 - val_mae: 0.4515\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0972 - mse: 0.0972 - mae: 0.2368 - val_loss: 0.4114 - val_mse: 0.4114 - val_mae: 0.4582\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0976 - mse: 0.0976 - mae: 0.2374 - val_loss: 0.4304 - val_mse: 0.4304 - val_mae: 0.4665\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0896 - mse: 0.0896 - mae: 0.2256 - val_loss: 0.4106 - val_mse: 0.4106 - val_mae: 0.4540\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0913 - mse: 0.0913 - mae: 0.2280 - val_loss: 0.4110 - val_mse: 0.4110 - val_mae: 0.4524\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0921 - mse: 0.0921 - mae: 0.2317 - val_loss: 0.4016 - val_mse: 0.4016 - val_mae: 0.4494\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0862 - mse: 0.0862 - mae: 0.2233 - val_loss: 0.3939 - val_mse: 0.3939 - val_mae: 0.4396\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0845 - mse: 0.0845 - mae: 0.2210 - val_loss: 0.3868 - val_mse: 0.3868 - val_mae: 0.4390\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0840 - mse: 0.0840 - mae: 0.2171 - val_loss: 0.3907 - val_mse: 0.3907 - val_mae: 0.4390\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0858 - mse: 0.0858 - mae: 0.2201 - val_loss: 0.4192 - val_mse: 0.4192 - val_mae: 0.4581\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0851 - mse: 0.0851 - mae: 0.2196 - val_loss: 0.4108 - val_mse: 0.4108 - val_mae: 0.4525\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0821 - mse: 0.0821 - mae: 0.2176 - val_loss: 0.3927 - val_mse: 0.3927 - val_mae: 0.4485\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0811 - mse: 0.0811 - mae: 0.2144 - val_loss: 0.4213 - val_mse: 0.4213 - val_mae: 0.4569\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0827 - mse: 0.0827 - mae: 0.2180 - val_loss: 0.4026 - val_mse: 0.4026 - val_mae: 0.4478\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0771 - mse: 0.0771 - mae: 0.2101 - val_loss: 0.3997 - val_mse: 0.3997 - val_mae: 0.4489\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0710 - mse: 0.0710 - mae: 0.2001 - val_loss: 0.3907 - val_mse: 0.3907 - val_mae: 0.4445\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0752 - mse: 0.0752 - mae: 0.2059 - val_loss: 0.4069 - val_mse: 0.4069 - val_mae: 0.4599\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0775 - mse: 0.0775 - mae: 0.2100 - val_loss: 0.4108 - val_mse: 0.4108 - val_mae: 0.4482\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 146us/sample - loss: 1.0614 - mse: 1.0614 - mae: 0.7459 - val_loss: 5.3218 - val_mse: 5.3218 - val_mae: 2.0480\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.4967 - mse: 0.4967 - mae: 0.5281 - val_loss: 1.2302 - val_mse: 1.2302 - val_mae: 0.9017\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4092 - mse: 0.4092 - mae: 0.4811 - val_loss: 1.0122 - val_mse: 1.0122 - val_mae: 0.8081\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3597 - mse: 0.3597 - mae: 0.4498 - val_loss: 0.7703 - val_mse: 0.7703 - val_mae: 0.7000\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3411 - mse: 0.3411 - mae: 0.4371 - val_loss: 0.6757 - val_mse: 0.6757 - val_mae: 0.6496\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3110 - mse: 0.3110 - mae: 0.4194 - val_loss: 0.5306 - val_mse: 0.5306 - val_mae: 0.5241\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2887 - mse: 0.2887 - mae: 0.4060 - val_loss: 0.5100 - val_mse: 0.5100 - val_mae: 0.5170\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2763 - mse: 0.2763 - mae: 0.3984 - val_loss: 0.4693 - val_mse: 0.4693 - val_mae: 0.4951\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2489 - mse: 0.2489 - mae: 0.3787 - val_loss: 0.5173 - val_mse: 0.5173 - val_mae: 0.5144\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2470 - mse: 0.2470 - mae: 0.3756 - val_loss: 0.4558 - val_mse: 0.4558 - val_mae: 0.4885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2272 - mse: 0.2272 - mae: 0.3616 - val_loss: 0.4343 - val_mse: 0.4343 - val_mae: 0.4756\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2094 - mse: 0.2094 - mae: 0.3462 - val_loss: 0.4386 - val_mse: 0.4386 - val_mae: 0.4688\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2030 - mse: 0.2030 - mae: 0.3415 - val_loss: 0.4624 - val_mse: 0.4624 - val_mae: 0.4740\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1972 - mse: 0.1972 - mae: 0.3382 - val_loss: 0.4605 - val_mse: 0.4605 - val_mae: 0.4741\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1858 - mse: 0.1858 - mae: 0.3267 - val_loss: 0.4243 - val_mse: 0.4243 - val_mae: 0.4623\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1772 - mse: 0.1772 - mae: 0.3176 - val_loss: 0.4468 - val_mse: 0.4468 - val_mae: 0.4671\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1848 - mse: 0.1848 - mae: 0.3255 - val_loss: 0.4407 - val_mse: 0.4407 - val_mae: 0.4740\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1781 - mse: 0.1781 - mae: 0.3188 - val_loss: 0.4132 - val_mse: 0.4132 - val_mae: 0.4537\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1611 - mse: 0.1611 - mae: 0.3034 - val_loss: 0.4147 - val_mse: 0.4147 - val_mae: 0.4583\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1473 - mse: 0.1473 - mae: 0.2903 - val_loss: 0.4308 - val_mse: 0.4308 - val_mae: 0.4657\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1431 - mse: 0.1431 - mae: 0.2854 - val_loss: 0.4101 - val_mse: 0.4101 - val_mae: 0.4523\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1400 - mse: 0.1400 - mae: 0.2822 - val_loss: 0.4415 - val_mse: 0.4415 - val_mae: 0.4667\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1442 - mse: 0.1442 - mae: 0.2867 - val_loss: 0.4532 - val_mse: 0.4532 - val_mae: 0.4740\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1378 - mse: 0.1378 - mae: 0.2799 - val_loss: 0.4294 - val_mse: 0.4294 - val_mae: 0.4597\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1335 - mse: 0.1335 - mae: 0.2760 - val_loss: 0.4137 - val_mse: 0.4137 - val_mae: 0.4532\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1291 - mse: 0.1291 - mae: 0.2720 - val_loss: 0.4350 - val_mse: 0.4350 - val_mae: 0.4604\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1290 - mse: 0.1290 - mae: 0.2723 - val_loss: 0.4409 - val_mse: 0.4409 - val_mae: 0.4692\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1240 - mse: 0.1240 - mae: 0.2665 - val_loss: 0.4180 - val_mse: 0.4180 - val_mae: 0.4516\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1259 - mse: 0.1259 - mae: 0.2686 - val_loss: 0.4340 - val_mse: 0.4340 - val_mae: 0.4613\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1248 - mse: 0.1248 - mae: 0.2671 - val_loss: 0.4157 - val_mse: 0.4157 - val_mae: 0.4435\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1064 - mse: 0.1064 - mae: 0.2479 - val_loss: 0.4062 - val_mse: 0.4062 - val_mae: 0.4478\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1089 - mse: 0.1089 - mae: 0.2504 - val_loss: 0.4039 - val_mse: 0.4039 - val_mae: 0.4492\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1096 - mse: 0.1096 - mae: 0.2491 - val_loss: 0.4141 - val_mse: 0.4141 - val_mae: 0.4528\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1094 - mse: 0.1094 - mae: 0.2502 - val_loss: 0.4191 - val_mse: 0.4191 - val_mae: 0.4594\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1076 - mse: 0.1076 - mae: 0.2479 - val_loss: 0.3978 - val_mse: 0.3978 - val_mae: 0.4415\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0990 - mse: 0.0990 - mae: 0.2387 - val_loss: 0.4101 - val_mse: 0.4101 - val_mae: 0.4435\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1016 - mse: 0.1016 - mae: 0.2418 - val_loss: 0.4135 - val_mse: 0.4135 - val_mae: 0.4489\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0998 - mse: 0.0998 - mae: 0.2393 - val_loss: 0.4130 - val_mse: 0.4130 - val_mae: 0.4507\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0939 - mse: 0.0939 - mae: 0.2331 - val_loss: 0.4198 - val_mse: 0.4198 - val_mae: 0.4570\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0992 - mse: 0.0992 - mae: 0.2360 - val_loss: 0.4194 - val_mse: 0.4194 - val_mae: 0.4552\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0990 - mse: 0.0990 - mae: 0.2373 - val_loss: 0.3945 - val_mse: 0.3945 - val_mae: 0.4445\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0979 - mse: 0.0979 - mae: 0.2361 - val_loss: 0.4139 - val_mse: 0.4139 - val_mae: 0.4423\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0890 - mse: 0.0890 - mae: 0.2244 - val_loss: 0.4203 - val_mse: 0.4203 - val_mae: 0.4513\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0875 - mse: 0.0875 - mae: 0.2219 - val_loss: 0.4095 - val_mse: 0.4095 - val_mae: 0.4400\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0898 - mse: 0.0898 - mae: 0.2246 - val_loss: 0.4000 - val_mse: 0.4000 - val_mae: 0.4405\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0878 - mse: 0.0878 - mae: 0.2237 - val_loss: 0.4063 - val_mse: 0.4063 - val_mae: 0.4412\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0850 - mse: 0.0850 - mae: 0.2209 - val_loss: 0.4020 - val_mse: 0.4020 - val_mae: 0.4371\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0845 - mse: 0.0845 - mae: 0.2198 - val_loss: 0.4138 - val_mse: 0.4138 - val_mae: 0.4415\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0853 - mse: 0.0853 - mae: 0.2211 - val_loss: 0.3889 - val_mse: 0.3889 - val_mae: 0.4382\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0848 - mse: 0.0848 - mae: 0.2186 - val_loss: 0.4057 - val_mse: 0.4057 - val_mae: 0.4470\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0856 - mse: 0.0856 - mae: 0.2229 - val_loss: 0.4492 - val_mse: 0.4492 - val_mae: 0.4538\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0884 - mse: 0.0884 - mae: 0.2261 - val_loss: 0.4050 - val_mse: 0.4050 - val_mae: 0.4449\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0819 - mse: 0.0819 - mae: 0.2157 - val_loss: 0.3980 - val_mse: 0.3980 - val_mae: 0.4412\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0861 - mse: 0.0861 - mae: 0.2223 - val_loss: 0.4087 - val_mse: 0.4087 - val_mae: 0.4482\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0795 - mse: 0.0795 - mae: 0.2136 - val_loss: 0.4093 - val_mse: 0.4093 - val_mae: 0.4480\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0800 - mse: 0.0800 - mae: 0.2146 - val_loss: 0.3977 - val_mse: 0.3977 - val_mae: 0.4437\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0750 - mse: 0.0750 - mae: 0.2066 - val_loss: 0.3985 - val_mse: 0.3985 - val_mae: 0.4417\n",
      "Epoch 58/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0734 - mse: 0.0734 - mae: 0.2040 - val_loss: 0.4093 - val_mse: 0.4093 - val_mae: 0.4435\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0727 - mse: 0.0727 - mae: 0.2045 - val_loss: 0.3966 - val_mse: 0.3966 - val_mae: 0.4413\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 125us/sample - loss: 1.0931 - mse: 1.0931 - mae: 0.7541 - val_loss: 1.1860 - val_mse: 1.1860 - val_mae: 0.8659\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.5130 - mse: 0.5130 - mae: 0.5371 - val_loss: 1.1230 - val_mse: 1.1230 - val_mae: 0.8817\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4274 - mse: 0.4274 - mae: 0.4894 - val_loss: 0.8199 - val_mse: 0.8199 - val_mae: 0.7308\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3860 - mse: 0.3860 - mae: 0.4662 - val_loss: 0.7170 - val_mse: 0.7170 - val_mae: 0.6805\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3540 - mse: 0.3540 - mae: 0.4463 - val_loss: 0.5853 - val_mse: 0.5853 - val_mae: 0.5953\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3273 - mse: 0.3273 - mae: 0.4279 - val_loss: 0.5059 - val_mse: 0.5059 - val_mae: 0.5488\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3012 - mse: 0.3012 - mae: 0.4133 - val_loss: 0.4702 - val_mse: 0.4702 - val_mae: 0.5108\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2870 - mse: 0.2870 - mae: 0.4015 - val_loss: 0.4703 - val_mse: 0.4703 - val_mae: 0.5061\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2742 - mse: 0.2742 - mae: 0.3944 - val_loss: 0.4646 - val_mse: 0.4646 - val_mae: 0.5145\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2556 - mse: 0.2556 - mae: 0.3794 - val_loss: 0.4307 - val_mse: 0.4307 - val_mae: 0.4793\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2580 - mse: 0.2580 - mae: 0.3815 - val_loss: 0.4480 - val_mse: 0.4480 - val_mae: 0.4852\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2430 - mse: 0.2430 - mae: 0.3696 - val_loss: 0.4323 - val_mse: 0.4323 - val_mae: 0.4690\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2152 - mse: 0.2152 - mae: 0.3485 - val_loss: 0.4334 - val_mse: 0.4334 - val_mae: 0.4797\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2002 - mse: 0.2002 - mae: 0.3364 - val_loss: 0.4036 - val_mse: 0.4036 - val_mae: 0.4540\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1936 - mse: 0.1936 - mae: 0.3333 - val_loss: 0.4277 - val_mse: 0.4277 - val_mae: 0.4647\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1963 - mse: 0.1963 - mae: 0.3347 - val_loss: 0.4330 - val_mse: 0.4330 - val_mae: 0.4719\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1821 - mse: 0.1821 - mae: 0.3219 - val_loss: 0.4184 - val_mse: 0.4184 - val_mae: 0.4688\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1684 - mse: 0.1684 - mae: 0.3093 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4607\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1629 - mse: 0.1629 - mae: 0.3048 - val_loss: 0.4170 - val_mse: 0.4170 - val_mae: 0.4708\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1600 - mse: 0.1600 - mae: 0.3044 - val_loss: 0.4422 - val_mse: 0.4422 - val_mae: 0.4719\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1575 - mse: 0.1575 - mae: 0.3007 - val_loss: 0.4079 - val_mse: 0.4079 - val_mae: 0.4581\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1518 - mse: 0.1518 - mae: 0.2951 - val_loss: 0.4259 - val_mse: 0.4259 - val_mae: 0.4717\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1462 - mse: 0.1462 - mae: 0.2890 - val_loss: 0.4027 - val_mse: 0.4027 - val_mae: 0.4520\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1401 - mse: 0.1401 - mae: 0.2846 - val_loss: 0.4021 - val_mse: 0.4021 - val_mae: 0.4582\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1350 - mse: 0.1350 - mae: 0.2784 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4659\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.1272 - mse: 0.1272 - mae: 0.2710 - val_loss: 0.4166 - val_mse: 0.4166 - val_mae: 0.4669\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1255 - mse: 0.1255 - mae: 0.2701 - val_loss: 0.3997 - val_mse: 0.3997 - val_mae: 0.4525\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1289 - mse: 0.1289 - mae: 0.2721 - val_loss: 0.3991 - val_mse: 0.3991 - val_mae: 0.4497\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1212 - mse: 0.1212 - mae: 0.2637 - val_loss: 0.4020 - val_mse: 0.4020 - val_mae: 0.4506\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1252 - mse: 0.1252 - mae: 0.2678 - val_loss: 0.4174 - val_mse: 0.4174 - val_mae: 0.4629\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1240 - mse: 0.1240 - mae: 0.2681 - val_loss: 0.4188 - val_mse: 0.4188 - val_mae: 0.4665\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1142 - mse: 0.1142 - mae: 0.2581 - val_loss: 0.4105 - val_mse: 0.4105 - val_mae: 0.4522\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1091 - mse: 0.1091 - mae: 0.2523 - val_loss: 0.4194 - val_mse: 0.4194 - val_mae: 0.4556\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1079 - mse: 0.1079 - mae: 0.2491 - val_loss: 0.3985 - val_mse: 0.3985 - val_mae: 0.4449\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1084 - mse: 0.1084 - mae: 0.2508 - val_loss: 0.3936 - val_mse: 0.3936 - val_mae: 0.4439\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1019 - mse: 0.1019 - mae: 0.2439 - val_loss: 0.4217 - val_mse: 0.4217 - val_mae: 0.4562\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1053 - mse: 0.1053 - mae: 0.2454 - val_loss: 0.3968 - val_mse: 0.3968 - val_mae: 0.4411\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1051 - mse: 0.1051 - mae: 0.2457 - val_loss: 0.3912 - val_mse: 0.3912 - val_mae: 0.4404\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1042 - mse: 0.1042 - mae: 0.2461 - val_loss: 0.3823 - val_mse: 0.3823 - val_mae: 0.4360\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0979 - mse: 0.0979 - mae: 0.2390 - val_loss: 0.4101 - val_mse: 0.4101 - val_mae: 0.4532\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0967 - mse: 0.0967 - mae: 0.2365 - val_loss: 0.4050 - val_mse: 0.4050 - val_mae: 0.4552\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.0956 - mse: 0.0956 - mae: 0.2356 - val_loss: 0.3933 - val_mse: 0.3933 - val_mae: 0.4388\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0944 - mse: 0.0944 - mae: 0.2337 - val_loss: 0.3922 - val_mse: 0.3922 - val_mae: 0.4427\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0873 - mse: 0.0873 - mae: 0.2255 - val_loss: 0.3836 - val_mse: 0.3836 - val_mae: 0.4363\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0873 - mse: 0.0873 - mae: 0.2251 - val_loss: 0.3929 - val_mse: 0.3929 - val_mae: 0.4412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0836 - mse: 0.0836 - mae: 0.2195 - val_loss: 0.4047 - val_mse: 0.4047 - val_mae: 0.4590\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0886 - mse: 0.0886 - mae: 0.2275 - val_loss: 0.4009 - val_mse: 0.4009 - val_mae: 0.4513\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0868 - mse: 0.0868 - mae: 0.2236 - val_loss: 0.4137 - val_mse: 0.4137 - val_mae: 0.4525\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0840 - mse: 0.0840 - mae: 0.2209 - val_loss: 0.4120 - val_mse: 0.4120 - val_mae: 0.4543\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 147us/sample - loss: 0.9834 - mse: 0.9834 - mae: 0.7234 - val_loss: 1.6465 - val_mse: 1.6465 - val_mae: 1.0538\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.4901 - mse: 0.4901 - mae: 0.5200 - val_loss: 0.9042 - val_mse: 0.9042 - val_mae: 0.7892\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4325 - mse: 0.4325 - mae: 0.4916 - val_loss: 0.7148 - val_mse: 0.7148 - val_mae: 0.6826\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3687 - mse: 0.3687 - mae: 0.4539 - val_loss: 0.6968 - val_mse: 0.6968 - val_mae: 0.6666\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3413 - mse: 0.3413 - mae: 0.4347 - val_loss: 0.6071 - val_mse: 0.6071 - val_mae: 0.6044\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3233 - mse: 0.3233 - mae: 0.4259 - val_loss: 0.5804 - val_mse: 0.5804 - val_mae: 0.5875\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3017 - mse: 0.3017 - mae: 0.4094 - val_loss: 0.4750 - val_mse: 0.4750 - val_mae: 0.5139\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2676 - mse: 0.2676 - mae: 0.3891 - val_loss: 0.4303 - val_mse: 0.4303 - val_mae: 0.4862\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2576 - mse: 0.2576 - mae: 0.3815 - val_loss: 0.4282 - val_mse: 0.4282 - val_mae: 0.4820\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2477 - mse: 0.2477 - mae: 0.3755 - val_loss: 0.4328 - val_mse: 0.4328 - val_mae: 0.4888\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2250 - mse: 0.2250 - mae: 0.3571 - val_loss: 0.4315 - val_mse: 0.4315 - val_mae: 0.4748\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2211 - mse: 0.2211 - mae: 0.3540 - val_loss: 0.4168 - val_mse: 0.4168 - val_mae: 0.4737\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2085 - mse: 0.2085 - mae: 0.3436 - val_loss: 0.4198 - val_mse: 0.4198 - val_mae: 0.4697\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2020 - mse: 0.2020 - mae: 0.3371 - val_loss: 0.3990 - val_mse: 0.3990 - val_mae: 0.4600\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1831 - mse: 0.1831 - mae: 0.3222 - val_loss: 0.4072 - val_mse: 0.4072 - val_mae: 0.4624\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1794 - mse: 0.1794 - mae: 0.3165 - val_loss: 0.4176 - val_mse: 0.4176 - val_mae: 0.4672\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1787 - mse: 0.1787 - mae: 0.3151 - val_loss: 0.3942 - val_mse: 0.3942 - val_mae: 0.4546\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1764 - mse: 0.1764 - mae: 0.3170 - val_loss: 0.4154 - val_mse: 0.4154 - val_mae: 0.4673\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1615 - mse: 0.1615 - mae: 0.3055 - val_loss: 0.4252 - val_mse: 0.4252 - val_mae: 0.4651\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1581 - mse: 0.1581 - mae: 0.2996 - val_loss: 0.4318 - val_mse: 0.4318 - val_mae: 0.4574\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1509 - mse: 0.1509 - mae: 0.2921 - val_loss: 0.4512 - val_mse: 0.4512 - val_mae: 0.4686\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1513 - mse: 0.1513 - mae: 0.2947 - val_loss: 0.4399 - val_mse: 0.4399 - val_mae: 0.4672\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1439 - mse: 0.1439 - mae: 0.2871 - val_loss: 0.4200 - val_mse: 0.4200 - val_mae: 0.4680\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1416 - mse: 0.1416 - mae: 0.2845 - val_loss: 0.4411 - val_mse: 0.4411 - val_mae: 0.4666\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1379 - mse: 0.1379 - mae: 0.2827 - val_loss: 0.4110 - val_mse: 0.4110 - val_mae: 0.4589\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1326 - mse: 0.1326 - mae: 0.2737 - val_loss: 0.3938 - val_mse: 0.3938 - val_mae: 0.4490\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1296 - mse: 0.1296 - mae: 0.2740 - val_loss: 0.4228 - val_mse: 0.4228 - val_mae: 0.4626\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1247 - mse: 0.1247 - mae: 0.2673 - val_loss: 0.4098 - val_mse: 0.4098 - val_mae: 0.4547\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1279 - mse: 0.1279 - mae: 0.2702 - val_loss: 0.4275 - val_mse: 0.4275 - val_mae: 0.4628\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1164 - mse: 0.1164 - mae: 0.2566 - val_loss: 0.4149 - val_mse: 0.4149 - val_mae: 0.4503\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1138 - mse: 0.1138 - mae: 0.2557 - val_loss: 0.4034 - val_mse: 0.4034 - val_mae: 0.4538\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1212 - mse: 0.1212 - mae: 0.2605 - val_loss: 0.4032 - val_mse: 0.4032 - val_mae: 0.4519\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1124 - mse: 0.1124 - mae: 0.2549 - val_loss: 0.4099 - val_mse: 0.4099 - val_mae: 0.4481\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1067 - mse: 0.1067 - mae: 0.2462 - val_loss: 0.4377 - val_mse: 0.4377 - val_mae: 0.4613\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1074 - mse: 0.1074 - mae: 0.2466 - val_loss: 0.4135 - val_mse: 0.4135 - val_mae: 0.4436\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1041 - mse: 0.1041 - mae: 0.2425 - val_loss: 0.4036 - val_mse: 0.4036 - val_mae: 0.4475\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 1.0270 - mse: 1.0270 - mae: 0.7349 - val_loss: 0.8913 - val_mse: 0.8913 - val_mae: 0.7209\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.5056 - mse: 0.5056 - mae: 0.5316 - val_loss: 1.0778 - val_mse: 1.0778 - val_mae: 0.8699\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.4184 - mse: 0.4184 - mae: 0.4844 - val_loss: 1.0100 - val_mse: 1.0100 - val_mae: 0.8176\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.3810 - mse: 0.3810 - mae: 0.4629 - val_loss: 0.9860 - val_mse: 0.9860 - val_mae: 0.8119\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.3491 - mse: 0.3491 - mae: 0.4461 - val_loss: 0.6490 - val_mse: 0.6490 - val_mae: 0.6295\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.3238 - mse: 0.3238 - mae: 0.4261 - val_loss: 0.6041 - val_mse: 0.6041 - val_mae: 0.5978\n",
      "Epoch 7/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.3037 - mse: 0.3037 - mae: 0.4118 - val_loss: 0.5333 - val_mse: 0.5333 - val_mae: 0.5585\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.2818 - mse: 0.2818 - mae: 0.3987 - val_loss: 0.4984 - val_mse: 0.4984 - val_mae: 0.5358\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 20us/sample - loss: 0.2602 - mse: 0.2602 - mae: 0.3810 - val_loss: 0.4575 - val_mse: 0.4575 - val_mae: 0.4951\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2477 - mse: 0.2477 - mae: 0.3770 - val_loss: 0.4537 - val_mse: 0.4537 - val_mae: 0.4851\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2376 - mse: 0.2376 - mae: 0.3676 - val_loss: 0.4876 - val_mse: 0.4876 - val_mae: 0.5124\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2283 - mse: 0.2283 - mae: 0.3609 - val_loss: 0.4300 - val_mse: 0.4300 - val_mae: 0.4756\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 20us/sample - loss: 0.2098 - mse: 0.2098 - mae: 0.3442 - val_loss: 0.4211 - val_mse: 0.4211 - val_mae: 0.4641\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1995 - mse: 0.1995 - mae: 0.3377 - val_loss: 0.4444 - val_mse: 0.4444 - val_mae: 0.4798\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1990 - mse: 0.1990 - mae: 0.3357 - val_loss: 0.4090 - val_mse: 0.4090 - val_mae: 0.4518\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 24us/sample - loss: 0.1874 - mse: 0.1874 - mae: 0.3279 - val_loss: 0.4009 - val_mse: 0.4009 - val_mae: 0.4522\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.1804 - mse: 0.1804 - mae: 0.3222 - val_loss: 0.4222 - val_mse: 0.4222 - val_mae: 0.4621\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1694 - mse: 0.1694 - mae: 0.3126 - val_loss: 0.4144 - val_mse: 0.4144 - val_mae: 0.4532\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1614 - mse: 0.1614 - mae: 0.3047 - val_loss: 0.4101 - val_mse: 0.4101 - val_mae: 0.4500\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1567 - mse: 0.1567 - mae: 0.2998 - val_loss: 0.4047 - val_mse: 0.4047 - val_mae: 0.4506\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1490 - mse: 0.1490 - mae: 0.2912 - val_loss: 0.4041 - val_mse: 0.4041 - val_mae: 0.4485\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1422 - mse: 0.1422 - mae: 0.2860 - val_loss: 0.4057 - val_mse: 0.4057 - val_mae: 0.4494\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1395 - mse: 0.1395 - mae: 0.2833 - val_loss: 0.4399 - val_mse: 0.4399 - val_mae: 0.4867\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1452 - mse: 0.1452 - mae: 0.2888 - val_loss: 0.4036 - val_mse: 0.4036 - val_mae: 0.4557\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1328 - mse: 0.1328 - mae: 0.2759 - val_loss: 0.3856 - val_mse: 0.3856 - val_mae: 0.4336\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1294 - mse: 0.1294 - mae: 0.2708 - val_loss: 0.3930 - val_mse: 0.3930 - val_mae: 0.4456\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1288 - mse: 0.1288 - mae: 0.2728 - val_loss: 0.4032 - val_mse: 0.4032 - val_mae: 0.4480\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.1226 - mse: 0.1226 - mae: 0.2650 - val_loss: 0.3833 - val_mse: 0.3833 - val_mae: 0.4326\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1211 - mse: 0.1211 - mae: 0.2642 - val_loss: 0.3931 - val_mse: 0.3931 - val_mae: 0.4456\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1157 - mse: 0.1157 - mae: 0.2576 - val_loss: 0.3924 - val_mse: 0.3924 - val_mae: 0.4404\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1089 - mse: 0.1089 - mae: 0.2512 - val_loss: 0.4026 - val_mse: 0.4026 - val_mae: 0.4493\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 20us/sample - loss: 0.1066 - mse: 0.1066 - mae: 0.2499 - val_loss: 0.3898 - val_mse: 0.3898 - val_mae: 0.4396\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1120 - mse: 0.1120 - mae: 0.2542 - val_loss: 0.3983 - val_mse: 0.3983 - val_mae: 0.4407\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1119 - mse: 0.1119 - mae: 0.2536 - val_loss: 0.3907 - val_mse: 0.3907 - val_mae: 0.4378\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1112 - mse: 0.1112 - mae: 0.2529 - val_loss: 0.4054 - val_mse: 0.4054 - val_mae: 0.4484\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1047 - mse: 0.1047 - mae: 0.2459 - val_loss: 0.3854 - val_mse: 0.3854 - val_mae: 0.4319\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 20us/sample - loss: 0.1073 - mse: 0.1073 - mae: 0.2490 - val_loss: 0.3988 - val_mse: 0.3988 - val_mae: 0.4401\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1129 - mse: 0.1129 - mae: 0.2542 - val_loss: 0.3868 - val_mse: 0.3868 - val_mae: 0.4322\n",
      "Avg. MAE: 0.386946\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 197us/sample - loss: 0.9326 - mse: 0.9326 - mae: 0.7190 - val_loss: 1.4011 - val_mse: 1.4011 - val_mae: 0.9972\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.4991 - mse: 0.4991 - mae: 0.5270 - val_loss: 1.0702 - val_mse: 1.0702 - val_mae: 0.8155\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.4228 - mse: 0.4228 - mae: 0.4827 - val_loss: 0.9304 - val_mse: 0.9304 - val_mae: 0.7838\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.3924 - mse: 0.3924 - mae: 0.4635 - val_loss: 0.6837 - val_mse: 0.6837 - val_mae: 0.6546\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.3324 - mse: 0.3324 - mae: 0.4288 - val_loss: 0.6000 - val_mse: 0.6000 - val_mae: 0.5978\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.3078 - mse: 0.3078 - mae: 0.4169 - val_loss: 0.5116 - val_mse: 0.5116 - val_mae: 0.5522\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2786 - mse: 0.2786 - mae: 0.3941 - val_loss: 0.4508 - val_mse: 0.4508 - val_mae: 0.5035\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2724 - mse: 0.2724 - mae: 0.3903 - val_loss: 0.4465 - val_mse: 0.4465 - val_mae: 0.4894\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2559 - mse: 0.2559 - mae: 0.3780 - val_loss: 0.4463 - val_mse: 0.4463 - val_mae: 0.4872\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.2356 - mse: 0.2356 - mae: 0.3649 - val_loss: 0.4766 - val_mse: 0.4766 - val_mae: 0.5052\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.2157 - mse: 0.2157 - mae: 0.3497 - val_loss: 0.4289 - val_mse: 0.4289 - val_mae: 0.4735\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2087 - mse: 0.2087 - mae: 0.3425 - val_loss: 0.4158 - val_mse: 0.4158 - val_mae: 0.4714\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1972 - mse: 0.1972 - mae: 0.3324 - val_loss: 0.4157 - val_mse: 0.4157 - val_mae: 0.4659\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1747 - mse: 0.1747 - mae: 0.3164 - val_loss: 0.4174 - val_mse: 0.4174 - val_mae: 0.4655\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1660 - mse: 0.1660 - mae: 0.3059 - val_loss: 0.4165 - val_mse: 0.4165 - val_mae: 0.4693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1687 - mse: 0.1687 - mae: 0.3086 - val_loss: 0.4002 - val_mse: 0.4002 - val_mae: 0.4597\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1683 - mse: 0.1683 - mae: 0.3090 - val_loss: 0.4275 - val_mse: 0.4275 - val_mae: 0.4747\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1605 - mse: 0.1605 - mae: 0.3006 - val_loss: 0.4122 - val_mse: 0.4122 - val_mae: 0.4659\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1537 - mse: 0.1537 - mae: 0.2939 - val_loss: 0.3934 - val_mse: 0.3934 - val_mae: 0.4578\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1443 - mse: 0.1443 - mae: 0.2870 - val_loss: 0.4078 - val_mse: 0.4078 - val_mae: 0.4580\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1370 - mse: 0.1370 - mae: 0.2775 - val_loss: 0.4269 - val_mse: 0.4269 - val_mae: 0.4708\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1371 - mse: 0.1371 - mae: 0.2769 - val_loss: 0.4111 - val_mse: 0.4111 - val_mae: 0.4644\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1386 - mse: 0.1386 - mae: 0.2773 - val_loss: 0.4186 - val_mse: 0.4186 - val_mae: 0.4699\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1248 - mse: 0.1248 - mae: 0.2658 - val_loss: 0.4175 - val_mse: 0.4175 - val_mae: 0.4644\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1183 - mse: 0.1183 - mae: 0.2585 - val_loss: 0.3994 - val_mse: 0.3994 - val_mae: 0.4515\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1207 - mse: 0.1207 - mae: 0.2611 - val_loss: 0.4056 - val_mse: 0.4056 - val_mae: 0.4568\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1151 - mse: 0.1151 - mae: 0.2532 - val_loss: 0.3897 - val_mse: 0.3897 - val_mae: 0.4507\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1169 - mse: 0.1169 - mae: 0.2528 - val_loss: 0.3993 - val_mse: 0.3993 - val_mae: 0.4510\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1112 - mse: 0.1112 - mae: 0.2476 - val_loss: 0.3987 - val_mse: 0.3987 - val_mae: 0.4636\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1090 - mse: 0.1090 - mae: 0.2474 - val_loss: 0.4321 - val_mse: 0.4321 - val_mae: 0.4700\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1099 - mse: 0.1099 - mae: 0.2465 - val_loss: 0.3935 - val_mse: 0.3935 - val_mae: 0.4427\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1013 - mse: 0.1013 - mae: 0.2375 - val_loss: 0.3842 - val_mse: 0.3842 - val_mae: 0.4468\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0959 - mse: 0.0959 - mae: 0.2320 - val_loss: 0.3957 - val_mse: 0.3957 - val_mae: 0.4482\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0967 - mse: 0.0967 - mae: 0.2343 - val_loss: 0.3839 - val_mse: 0.3839 - val_mae: 0.4432\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.0921 - mse: 0.0921 - mae: 0.2269 - val_loss: 0.4046 - val_mse: 0.4046 - val_mae: 0.4577\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0863 - mse: 0.0863 - mae: 0.2216 - val_loss: 0.3853 - val_mse: 0.3853 - val_mae: 0.4462\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0900 - mse: 0.0900 - mae: 0.2255 - val_loss: 0.3842 - val_mse: 0.3842 - val_mae: 0.4425\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0942 - mse: 0.0942 - mae: 0.2295 - val_loss: 0.3933 - val_mse: 0.3933 - val_mae: 0.4499\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0941 - mse: 0.0941 - mae: 0.2300 - val_loss: 0.3837 - val_mse: 0.3837 - val_mae: 0.4462\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.0848 - mse: 0.0848 - mae: 0.2179 - val_loss: 0.3977 - val_mse: 0.3977 - val_mae: 0.4514\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0893 - mse: 0.0893 - mae: 0.2244 - val_loss: 0.3856 - val_mse: 0.3856 - val_mae: 0.4436\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0856 - mse: 0.0856 - mae: 0.2204 - val_loss: 0.3866 - val_mse: 0.3866 - val_mae: 0.4449\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0848 - mse: 0.0848 - mae: 0.2172 - val_loss: 0.3733 - val_mse: 0.3733 - val_mae: 0.4352\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0791 - mse: 0.0791 - mae: 0.2110 - val_loss: 0.3868 - val_mse: 0.3868 - val_mae: 0.4450\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0824 - mse: 0.0824 - mae: 0.2144 - val_loss: 0.3696 - val_mse: 0.3696 - val_mae: 0.4332\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0806 - mse: 0.0806 - mae: 0.2125 - val_loss: 0.3835 - val_mse: 0.3835 - val_mae: 0.4421\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.0803 - mse: 0.0803 - mae: 0.2115 - val_loss: 0.3872 - val_mse: 0.3872 - val_mae: 0.4414\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0789 - mse: 0.0789 - mae: 0.2081 - val_loss: 0.3768 - val_mse: 0.3768 - val_mae: 0.4376\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0767 - mse: 0.0767 - mae: 0.2039 - val_loss: 0.3823 - val_mse: 0.3823 - val_mae: 0.4392\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0796 - mse: 0.0796 - mae: 0.2081 - val_loss: 0.3932 - val_mse: 0.3932 - val_mae: 0.4453\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0764 - mse: 0.0764 - mae: 0.2068 - val_loss: 0.3658 - val_mse: 0.3658 - val_mae: 0.4330\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0753 - mse: 0.0753 - mae: 0.2044 - val_loss: 0.3881 - val_mse: 0.3881 - val_mae: 0.4429\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0758 - mse: 0.0758 - mae: 0.2077 - val_loss: 0.3619 - val_mse: 0.3619 - val_mae: 0.4288\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0720 - mse: 0.0720 - mae: 0.1999 - val_loss: 0.3827 - val_mse: 0.3827 - val_mae: 0.4407\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.0706 - mse: 0.0706 - mae: 0.1973 - val_loss: 0.3700 - val_mse: 0.3700 - val_mae: 0.4322\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.0760 - mse: 0.0760 - mae: 0.2027 - val_loss: 0.3737 - val_mse: 0.3737 - val_mae: 0.4369\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0774 - mse: 0.0774 - mae: 0.2070 - val_loss: 0.3788 - val_mse: 0.3788 - val_mae: 0.4382\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0705 - mse: 0.0705 - mae: 0.1962 - val_loss: 0.3947 - val_mse: 0.3947 - val_mae: 0.4461\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0658 - mse: 0.0658 - mae: 0.1935 - val_loss: 0.3824 - val_mse: 0.3824 - val_mae: 0.4379\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0718 - mse: 0.0718 - mae: 0.1983 - val_loss: 0.3804 - val_mse: 0.3804 - val_mae: 0.4366\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.0652 - mse: 0.0652 - mae: 0.1905 - val_loss: 0.3981 - val_mse: 0.3981 - val_mae: 0.4499\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0635 - mse: 0.0635 - mae: 0.1873 - val_loss: 0.3720 - val_mse: 0.3720 - val_mae: 0.4321\n",
      "Epoch 63/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0647 - mse: 0.0647 - mae: 0.1889 - val_loss: 0.3752 - val_mse: 0.3752 - val_mae: 0.4401\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 172us/sample - loss: 0.8920 - mse: 0.8920 - mae: 0.7078 - val_loss: 1.2864 - val_mse: 1.2864 - val_mae: 0.8327\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.5105 - mse: 0.5105 - mae: 0.5376 - val_loss: 1.0404 - val_mse: 1.0404 - val_mae: 0.7245\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.4183 - mse: 0.4183 - mae: 0.4832 - val_loss: 0.9154 - val_mse: 0.9154 - val_mae: 0.7222\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.3731 - mse: 0.3731 - mae: 0.4551 - val_loss: 0.7050 - val_mse: 0.7050 - val_mae: 0.6638\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.3460 - mse: 0.3460 - mae: 0.4422 - val_loss: 0.6454 - val_mse: 0.6454 - val_mae: 0.6122\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.3156 - mse: 0.3156 - mae: 0.4194 - val_loss: 0.6207 - val_mse: 0.6207 - val_mae: 0.5712\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.2919 - mse: 0.2919 - mae: 0.4038 - val_loss: 0.5353 - val_mse: 0.5353 - val_mae: 0.5272\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.2799 - mse: 0.2799 - mae: 0.3976 - val_loss: 0.5163 - val_mse: 0.5163 - val_mae: 0.5203\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.2430 - mse: 0.2430 - mae: 0.3706 - val_loss: 0.5688 - val_mse: 0.5688 - val_mae: 0.5176\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.2504 - mse: 0.2504 - mae: 0.3747 - val_loss: 0.4927 - val_mse: 0.4927 - val_mae: 0.5094\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.2213 - mse: 0.2213 - mae: 0.3533 - val_loss: 0.4831 - val_mse: 0.4831 - val_mae: 0.4837\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.2065 - mse: 0.2065 - mae: 0.3405 - val_loss: 0.4586 - val_mse: 0.4586 - val_mae: 0.4813\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1888 - mse: 0.1888 - mae: 0.3261 - val_loss: 0.4849 - val_mse: 0.4849 - val_mae: 0.4821\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1859 - mse: 0.1859 - mae: 0.3241 - val_loss: 0.5191 - val_mse: 0.5191 - val_mae: 0.4805\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1788 - mse: 0.1788 - mae: 0.3188 - val_loss: 0.4978 - val_mse: 0.4978 - val_mae: 0.4818\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1654 - mse: 0.1654 - mae: 0.3052 - val_loss: 0.4459 - val_mse: 0.4459 - val_mae: 0.4686\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1698 - mse: 0.1698 - mae: 0.3090 - val_loss: 0.4680 - val_mse: 0.4680 - val_mae: 0.4859\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1652 - mse: 0.1652 - mae: 0.3056 - val_loss: 0.4444 - val_mse: 0.4444 - val_mae: 0.4659\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1536 - mse: 0.1536 - mae: 0.2932 - val_loss: 0.4500 - val_mse: 0.4500 - val_mae: 0.4790\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1416 - mse: 0.1416 - mae: 0.2828 - val_loss: 0.4829 - val_mse: 0.4829 - val_mae: 0.4843\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.1386 - mse: 0.1386 - mae: 0.2804 - val_loss: 0.4401 - val_mse: 0.4401 - val_mae: 0.4653\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1390 - mse: 0.1390 - mae: 0.2788 - val_loss: 0.4271 - val_mse: 0.4271 - val_mae: 0.4591\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.1369 - mse: 0.1369 - mae: 0.2768 - val_loss: 0.4604 - val_mse: 0.4604 - val_mae: 0.4822\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.1301 - mse: 0.1301 - mae: 0.2718 - val_loss: 0.4502 - val_mse: 0.4502 - val_mae: 0.4672\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.1239 - mse: 0.1239 - mae: 0.2673 - val_loss: 0.4384 - val_mse: 0.4384 - val_mae: 0.4579\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.1202 - mse: 0.1202 - mae: 0.2591 - val_loss: 0.4507 - val_mse: 0.4507 - val_mae: 0.4677\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1200 - mse: 0.1200 - mae: 0.2608 - val_loss: 0.4248 - val_mse: 0.4248 - val_mae: 0.4577\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1099 - mse: 0.1099 - mae: 0.2498 - val_loss: 0.4324 - val_mse: 0.4324 - val_mae: 0.4564\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.1118 - mse: 0.1118 - mae: 0.2519 - val_loss: 0.4311 - val_mse: 0.4311 - val_mae: 0.4527\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.1132 - mse: 0.1132 - mae: 0.2525 - val_loss: 0.4092 - val_mse: 0.4092 - val_mae: 0.4461\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.1028 - mse: 0.1028 - mae: 0.2407 - val_loss: 0.4290 - val_mse: 0.4290 - val_mae: 0.4571\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1008 - mse: 0.1008 - mae: 0.2401 - val_loss: 0.4135 - val_mse: 0.4135 - val_mae: 0.4430\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1037 - mse: 0.1037 - mae: 0.2411 - val_loss: 0.4304 - val_mse: 0.4304 - val_mae: 0.4518\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0991 - mse: 0.0991 - mae: 0.2366 - val_loss: 0.4421 - val_mse: 0.4421 - val_mae: 0.4554\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1041 - mse: 0.1041 - mae: 0.2394 - val_loss: 0.4393 - val_mse: 0.4393 - val_mae: 0.4589\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0977 - mse: 0.0977 - mae: 0.2343 - val_loss: 0.4069 - val_mse: 0.4069 - val_mae: 0.4461\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0960 - mse: 0.0960 - mae: 0.2304 - val_loss: 0.4247 - val_mse: 0.4247 - val_mae: 0.4516\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.0931 - mse: 0.0931 - mae: 0.2288 - val_loss: 0.4412 - val_mse: 0.4412 - val_mae: 0.4612\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.0907 - mse: 0.0907 - mae: 0.2262 - val_loss: 0.4276 - val_mse: 0.4276 - val_mae: 0.4539\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0972 - mse: 0.0972 - mae: 0.2317 - val_loss: 0.4098 - val_mse: 0.4098 - val_mae: 0.4435\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.0933 - mse: 0.0933 - mae: 0.2301 - val_loss: 0.4274 - val_mse: 0.4274 - val_mae: 0.4609\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.0905 - mse: 0.0905 - mae: 0.2247 - val_loss: 0.4279 - val_mse: 0.4279 - val_mae: 0.4534\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.0806 - mse: 0.0806 - mae: 0.2097 - val_loss: 0.4187 - val_mse: 0.4187 - val_mae: 0.4480\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.0802 - mse: 0.0802 - mae: 0.2109 - val_loss: 0.4149 - val_mse: 0.4149 - val_mae: 0.4388\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0806 - mse: 0.0806 - mae: 0.2121 - val_loss: 0.4103 - val_mse: 0.4103 - val_mae: 0.4469\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0808 - mse: 0.0808 - mae: 0.2116 - val_loss: 0.4256 - val_mse: 0.4256 - val_mae: 0.4462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 201us/sample - loss: 0.8783 - mse: 0.8783 - mae: 0.6985 - val_loss: 1.0462 - val_mse: 1.0462 - val_mae: 0.8316\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.4967 - mse: 0.4967 - mae: 0.5279 - val_loss: 1.0031 - val_mse: 1.0031 - val_mae: 0.8169\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.4127 - mse: 0.4127 - mae: 0.4800 - val_loss: 0.9384 - val_mse: 0.9384 - val_mae: 0.7762\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.3771 - mse: 0.3771 - mae: 0.4589 - val_loss: 0.6965 - val_mse: 0.6965 - val_mae: 0.6568\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.3483 - mse: 0.3483 - mae: 0.4409 - val_loss: 0.5502 - val_mse: 0.5502 - val_mae: 0.5756\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2989 - mse: 0.2989 - mae: 0.4100 - val_loss: 0.4901 - val_mse: 0.4901 - val_mae: 0.5331\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.2860 - mse: 0.2860 - mae: 0.3988 - val_loss: 0.4745 - val_mse: 0.4745 - val_mae: 0.5122\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.2759 - mse: 0.2759 - mae: 0.3942 - val_loss: 0.4717 - val_mse: 0.4717 - val_mae: 0.4971\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2589 - mse: 0.2589 - mae: 0.3800 - val_loss: 0.4570 - val_mse: 0.4570 - val_mae: 0.5109\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2402 - mse: 0.2402 - mae: 0.3680 - val_loss: 0.4163 - val_mse: 0.4163 - val_mae: 0.4623\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2258 - mse: 0.2258 - mae: 0.3549 - val_loss: 0.4367 - val_mse: 0.4367 - val_mae: 0.4750\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.2159 - mse: 0.2159 - mae: 0.3452 - val_loss: 0.4196 - val_mse: 0.4196 - val_mae: 0.4663\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.2019 - mse: 0.2019 - mae: 0.3361 - val_loss: 0.4370 - val_mse: 0.4370 - val_mae: 0.4736\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1788 - mse: 0.1788 - mae: 0.3174 - val_loss: 0.4084 - val_mse: 0.4084 - val_mae: 0.4554\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1784 - mse: 0.1784 - mae: 0.3183 - val_loss: 0.4093 - val_mse: 0.4093 - val_mae: 0.4604\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1739 - mse: 0.1739 - mae: 0.3133 - val_loss: 0.4161 - val_mse: 0.4161 - val_mae: 0.4641\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1637 - mse: 0.1637 - mae: 0.3053 - val_loss: 0.4109 - val_mse: 0.4109 - val_mae: 0.4611\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1537 - mse: 0.1537 - mae: 0.2961 - val_loss: 0.4114 - val_mse: 0.4114 - val_mae: 0.4552\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1503 - mse: 0.1503 - mae: 0.2888 - val_loss: 0.4155 - val_mse: 0.4155 - val_mae: 0.4560\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1382 - mse: 0.1382 - mae: 0.2813 - val_loss: 0.4027 - val_mse: 0.4027 - val_mae: 0.4486\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1400 - mse: 0.1400 - mae: 0.2834 - val_loss: 0.4169 - val_mse: 0.4169 - val_mae: 0.4572\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1358 - mse: 0.1358 - mae: 0.2766 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4648\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1323 - mse: 0.1323 - mae: 0.2730 - val_loss: 0.4326 - val_mse: 0.4326 - val_mae: 0.4633\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1279 - mse: 0.1279 - mae: 0.2711 - val_loss: 0.4057 - val_mse: 0.4057 - val_mae: 0.4554\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1226 - mse: 0.1226 - mae: 0.2645 - val_loss: 0.4134 - val_mse: 0.4134 - val_mae: 0.4605\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1162 - mse: 0.1162 - mae: 0.2587 - val_loss: 0.3943 - val_mse: 0.3943 - val_mae: 0.4471\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1172 - mse: 0.1172 - mae: 0.2594 - val_loss: 0.4014 - val_mse: 0.4014 - val_mae: 0.4433\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1162 - mse: 0.1162 - mae: 0.2565 - val_loss: 0.4063 - val_mse: 0.4063 - val_mae: 0.4505\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1111 - mse: 0.1111 - mae: 0.2492 - val_loss: 0.4096 - val_mse: 0.4096 - val_mae: 0.4523\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1155 - mse: 0.1155 - mae: 0.2527 - val_loss: 0.4074 - val_mse: 0.4074 - val_mae: 0.4538\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1084 - mse: 0.1084 - mae: 0.2480 - val_loss: 0.4139 - val_mse: 0.4139 - val_mae: 0.4533\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1012 - mse: 0.1012 - mae: 0.2388 - val_loss: 0.3953 - val_mse: 0.3953 - val_mae: 0.4430\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0988 - mse: 0.0988 - mae: 0.2369 - val_loss: 0.4102 - val_mse: 0.4102 - val_mae: 0.4485\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0951 - mse: 0.0951 - mae: 0.2314 - val_loss: 0.3962 - val_mse: 0.3962 - val_mae: 0.4402\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0924 - mse: 0.0924 - mae: 0.2307 - val_loss: 0.3937 - val_mse: 0.3937 - val_mae: 0.4394\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0904 - mse: 0.0904 - mae: 0.2271 - val_loss: 0.4029 - val_mse: 0.4029 - val_mae: 0.4439\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.0934 - mse: 0.0934 - mae: 0.2307 - val_loss: 0.3843 - val_mse: 0.3843 - val_mae: 0.4364\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.0910 - mse: 0.0910 - mae: 0.2274 - val_loss: 0.4052 - val_mse: 0.4052 - val_mae: 0.4415\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0872 - mse: 0.0872 - mae: 0.2221 - val_loss: 0.3983 - val_mse: 0.3983 - val_mae: 0.4474\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.0891 - mse: 0.0891 - mae: 0.2253 - val_loss: 0.4033 - val_mse: 0.4033 - val_mae: 0.4483\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.0870 - mse: 0.0870 - mae: 0.2231 - val_loss: 0.3995 - val_mse: 0.3995 - val_mae: 0.4420\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.0842 - mse: 0.0842 - mae: 0.2192 - val_loss: 0.3961 - val_mse: 0.3961 - val_mae: 0.4389\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0834 - mse: 0.0834 - mae: 0.2178 - val_loss: 0.3965 - val_mse: 0.3965 - val_mae: 0.4431\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0796 - mse: 0.0796 - mae: 0.2129 - val_loss: 0.4127 - val_mse: 0.4127 - val_mae: 0.4392\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.0802 - mse: 0.0802 - mae: 0.2130 - val_loss: 0.4066 - val_mse: 0.4066 - val_mae: 0.4370\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.0760 - mse: 0.0760 - mae: 0.2075 - val_loss: 0.3917 - val_mse: 0.3917 - val_mae: 0.4430\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.0750 - mse: 0.0750 - mae: 0.2077 - val_loss: 0.3889 - val_mse: 0.3889 - val_mae: 0.4386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 174us/sample - loss: 0.9050 - mse: 0.9050 - mae: 0.7052 - val_loss: 1.0951 - val_mse: 1.0951 - val_mae: 0.8420\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.5209 - mse: 0.5209 - mae: 0.5347 - val_loss: 0.9313 - val_mse: 0.9313 - val_mae: 0.7362\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.4365 - mse: 0.4365 - mae: 0.4927 - val_loss: 0.7828 - val_mse: 0.7828 - val_mae: 0.7018\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.3779 - mse: 0.3779 - mae: 0.4592 - val_loss: 0.7387 - val_mse: 0.7387 - val_mae: 0.6752\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.3431 - mse: 0.3431 - mae: 0.4379 - val_loss: 0.6046 - val_mse: 0.6046 - val_mae: 0.6058\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.3190 - mse: 0.3190 - mae: 0.4208 - val_loss: 0.5487 - val_mse: 0.5487 - val_mae: 0.5701\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2925 - mse: 0.2925 - mae: 0.3998 - val_loss: 0.5007 - val_mse: 0.5007 - val_mae: 0.5418\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2702 - mse: 0.2702 - mae: 0.3882 - val_loss: 0.4965 - val_mse: 0.4965 - val_mae: 0.5317\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2599 - mse: 0.2599 - mae: 0.3807 - val_loss: 0.4393 - val_mse: 0.4393 - val_mae: 0.4964\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2393 - mse: 0.2393 - mae: 0.3649 - val_loss: 0.4504 - val_mse: 0.4504 - val_mae: 0.4866\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2215 - mse: 0.2215 - mae: 0.3509 - val_loss: 0.4105 - val_mse: 0.4105 - val_mae: 0.4687\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.2149 - mse: 0.2149 - mae: 0.3469 - val_loss: 0.4147 - val_mse: 0.4147 - val_mae: 0.4642\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.2008 - mse: 0.2008 - mae: 0.3349 - val_loss: 0.4077 - val_mse: 0.4077 - val_mae: 0.4567\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3299 - val_loss: 0.4099 - val_mse: 0.4099 - val_mae: 0.4608\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1755 - mse: 0.1755 - mae: 0.3121 - val_loss: 0.4167 - val_mse: 0.4167 - val_mae: 0.4706\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1739 - mse: 0.1739 - mae: 0.3085 - val_loss: 0.4017 - val_mse: 0.4017 - val_mae: 0.4537\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1740 - mse: 0.1740 - mae: 0.3095 - val_loss: 0.4057 - val_mse: 0.4057 - val_mae: 0.4588\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1639 - mse: 0.1639 - mae: 0.3046 - val_loss: 0.3856 - val_mse: 0.3856 - val_mae: 0.4441\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1532 - mse: 0.1532 - mae: 0.2921 - val_loss: 0.4081 - val_mse: 0.4081 - val_mae: 0.4569\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1542 - mse: 0.1542 - mae: 0.2927 - val_loss: 0.4259 - val_mse: 0.4259 - val_mae: 0.4696\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1469 - mse: 0.1469 - mae: 0.2882 - val_loss: 0.3995 - val_mse: 0.3995 - val_mae: 0.4476\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1471 - mse: 0.1471 - mae: 0.2866 - val_loss: 0.4127 - val_mse: 0.4127 - val_mae: 0.4593\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1313 - mse: 0.1313 - mae: 0.2719 - val_loss: 0.4152 - val_mse: 0.4152 - val_mae: 0.4531\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1315 - mse: 0.1315 - mae: 0.2708 - val_loss: 0.3985 - val_mse: 0.3985 - val_mae: 0.4438\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.1244 - mse: 0.1244 - mae: 0.2644 - val_loss: 0.3975 - val_mse: 0.3975 - val_mae: 0.4503\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1208 - mse: 0.1208 - mae: 0.2577 - val_loss: 0.3945 - val_mse: 0.3945 - val_mae: 0.4449\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1221 - mse: 0.1221 - mae: 0.2601 - val_loss: 0.4079 - val_mse: 0.4079 - val_mae: 0.4530\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 31us/sample - loss: 0.1146 - mse: 0.1146 - mae: 0.2544 - val_loss: 0.3936 - val_mse: 0.3936 - val_mae: 0.4432\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 201us/sample - loss: 0.8927 - mse: 0.8927 - mae: 0.7024 - val_loss: 1.0146 - val_mse: 1.0146 - val_mae: 0.8055\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 33us/sample - loss: 0.5110 - mse: 0.5110 - mae: 0.5338 - val_loss: 0.9752 - val_mse: 0.9752 - val_mae: 0.7587\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 32us/sample - loss: 0.4210 - mse: 0.4210 - mae: 0.4851 - val_loss: 0.9615 - val_mse: 0.9615 - val_mae: 0.7584\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 32us/sample - loss: 0.3665 - mse: 0.3665 - mae: 0.4490 - val_loss: 0.8964 - val_mse: 0.8964 - val_mae: 0.7574\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 32us/sample - loss: 0.3429 - mse: 0.3429 - mae: 0.4380 - val_loss: 0.5836 - val_mse: 0.5836 - val_mae: 0.5798\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 32us/sample - loss: 0.3163 - mse: 0.3163 - mae: 0.4193 - val_loss: 0.5862 - val_mse: 0.5862 - val_mae: 0.5848\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 31us/sample - loss: 0.2904 - mse: 0.2904 - mae: 0.4007 - val_loss: 0.4899 - val_mse: 0.4899 - val_mae: 0.5176\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 32us/sample - loss: 0.2702 - mse: 0.2702 - mae: 0.3873 - val_loss: 0.4641 - val_mse: 0.4641 - val_mae: 0.5128\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 32us/sample - loss: 0.2515 - mse: 0.2515 - mae: 0.3734 - val_loss: 0.4599 - val_mse: 0.4599 - val_mae: 0.5018\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 32us/sample - loss: 0.2411 - mse: 0.2411 - mae: 0.3677 - val_loss: 0.4737 - val_mse: 0.4737 - val_mae: 0.5019\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 31us/sample - loss: 0.2227 - mse: 0.2227 - mae: 0.3537 - val_loss: 0.4417 - val_mse: 0.4417 - val_mae: 0.4738\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 32us/sample - loss: 0.2116 - mse: 0.2116 - mae: 0.3422 - val_loss: 0.4521 - val_mse: 0.4521 - val_mae: 0.4808\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 31us/sample - loss: 0.2122 - mse: 0.2122 - mae: 0.3444 - val_loss: 0.4398 - val_mse: 0.4398 - val_mae: 0.4722\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 32us/sample - loss: 0.1961 - mse: 0.1961 - mae: 0.3337 - val_loss: 0.4191 - val_mse: 0.4191 - val_mae: 0.4587\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 32us/sample - loss: 0.1850 - mse: 0.1850 - mae: 0.3227 - val_loss: 0.3967 - val_mse: 0.3967 - val_mae: 0.4485\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 32us/sample - loss: 0.1717 - mse: 0.1717 - mae: 0.3098 - val_loss: 0.4044 - val_mse: 0.4044 - val_mae: 0.4465\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 31us/sample - loss: 0.1568 - mse: 0.1568 - mae: 0.2978 - val_loss: 0.4252 - val_mse: 0.4252 - val_mae: 0.4629\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 31us/sample - loss: 0.1598 - mse: 0.1598 - mae: 0.3003 - val_loss: 0.4088 - val_mse: 0.4088 - val_mae: 0.4500\n",
      "Epoch 19/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 31us/sample - loss: 0.1563 - mse: 0.1563 - mae: 0.2962 - val_loss: 0.4111 - val_mse: 0.4111 - val_mae: 0.4508\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 31us/sample - loss: 0.1439 - mse: 0.1439 - mae: 0.2886 - val_loss: 0.4100 - val_mse: 0.4100 - val_mae: 0.4516\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 31us/sample - loss: 0.1400 - mse: 0.1400 - mae: 0.2819 - val_loss: 0.3974 - val_mse: 0.3974 - val_mae: 0.4382\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 31us/sample - loss: 0.1386 - mse: 0.1386 - mae: 0.2782 - val_loss: 0.4211 - val_mse: 0.4211 - val_mae: 0.4485\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 31us/sample - loss: 0.1351 - mse: 0.1351 - mae: 0.2742 - val_loss: 0.4357 - val_mse: 0.4357 - val_mae: 0.4617\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 32us/sample - loss: 0.1367 - mse: 0.1367 - mae: 0.2742 - val_loss: 0.4188 - val_mse: 0.4188 - val_mae: 0.4535\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 31us/sample - loss: 0.1280 - mse: 0.1280 - mae: 0.2679 - val_loss: 0.4055 - val_mse: 0.4055 - val_mae: 0.4380\n",
      "Avg. MAE: 0.388534\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 147us/sample - loss: 1.1411 - mse: 1.1411 - mae: 0.7564 - val_loss: 2.2386 - val_mse: 2.2386 - val_mae: 1.2515\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.5412 - mse: 0.5412 - mae: 0.5455 - val_loss: 1.2412 - val_mse: 1.2412 - val_mae: 0.8621\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4726 - mse: 0.4726 - mae: 0.5092 - val_loss: 0.9699 - val_mse: 0.9699 - val_mae: 0.8063\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4448 - mse: 0.4448 - mae: 0.4986 - val_loss: 0.7834 - val_mse: 0.7834 - val_mae: 0.7070\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3882 - mse: 0.3882 - mae: 0.4629 - val_loss: 0.6328 - val_mse: 0.6328 - val_mae: 0.6201\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3590 - mse: 0.3590 - mae: 0.4468 - val_loss: 0.5446 - val_mse: 0.5446 - val_mae: 0.5810\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3328 - mse: 0.3328 - mae: 0.4301 - val_loss: 0.4729 - val_mse: 0.4729 - val_mae: 0.5144\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3086 - mse: 0.3086 - mae: 0.4116 - val_loss: 0.4786 - val_mse: 0.4786 - val_mae: 0.5075\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2969 - mse: 0.2969 - mae: 0.4058 - val_loss: 0.4006 - val_mse: 0.4006 - val_mae: 0.4709\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2756 - mse: 0.2756 - mae: 0.3930 - val_loss: 0.4425 - val_mse: 0.4425 - val_mae: 0.4834\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2673 - mse: 0.2673 - mae: 0.3835 - val_loss: 0.4152 - val_mse: 0.4152 - val_mae: 0.4681\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2419 - mse: 0.2419 - mae: 0.3675 - val_loss: 0.4003 - val_mse: 0.4003 - val_mae: 0.4672\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2337 - mse: 0.2337 - mae: 0.3638 - val_loss: 0.4206 - val_mse: 0.4206 - val_mae: 0.4715\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2244 - mse: 0.2244 - mae: 0.3528 - val_loss: 0.4477 - val_mse: 0.4477 - val_mae: 0.4847\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2223 - mse: 0.2223 - mae: 0.3549 - val_loss: 0.4114 - val_mse: 0.4114 - val_mae: 0.4657\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2157 - mse: 0.2157 - mae: 0.3486 - val_loss: 0.3889 - val_mse: 0.3889 - val_mae: 0.4522\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1929 - mse: 0.1929 - mae: 0.3292 - val_loss: 0.4040 - val_mse: 0.4040 - val_mae: 0.4618\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3265 - val_loss: 0.4044 - val_mse: 0.4044 - val_mae: 0.4543\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1879 - mse: 0.1879 - mae: 0.3267 - val_loss: 0.3878 - val_mse: 0.3878 - val_mae: 0.4462\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1779 - mse: 0.1779 - mae: 0.3172 - val_loss: 0.4237 - val_mse: 0.4237 - val_mae: 0.4728\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1630 - mse: 0.1630 - mae: 0.3037 - val_loss: 0.4280 - val_mse: 0.4280 - val_mae: 0.4643\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1628 - mse: 0.1628 - mae: 0.3028 - val_loss: 0.4159 - val_mse: 0.4159 - val_mae: 0.4637\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1628 - mse: 0.1628 - mae: 0.3009 - val_loss: 0.4163 - val_mse: 0.4163 - val_mae: 0.4595\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1557 - mse: 0.1557 - mae: 0.2950 - val_loss: 0.4266 - val_mse: 0.4266 - val_mae: 0.4652\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1482 - mse: 0.1482 - mae: 0.2897 - val_loss: 0.3962 - val_mse: 0.3962 - val_mae: 0.4560\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1371 - mse: 0.1371 - mae: 0.2790 - val_loss: 0.4271 - val_mse: 0.4271 - val_mae: 0.4629\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1350 - mse: 0.1350 - mae: 0.2759 - val_loss: 0.3804 - val_mse: 0.3804 - val_mae: 0.4378\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1303 - mse: 0.1303 - mae: 0.2703 - val_loss: 0.4160 - val_mse: 0.4160 - val_mae: 0.4500\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1296 - mse: 0.1296 - mae: 0.2698 - val_loss: 0.3893 - val_mse: 0.3893 - val_mae: 0.4413\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1310 - mse: 0.1310 - mae: 0.2715 - val_loss: 0.4345 - val_mse: 0.4345 - val_mae: 0.4704\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1301 - mse: 0.1301 - mae: 0.2670 - val_loss: 0.4112 - val_mse: 0.4112 - val_mae: 0.4556\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1287 - mse: 0.1287 - mae: 0.2692 - val_loss: 0.4028 - val_mse: 0.4028 - val_mae: 0.4456\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1207 - mse: 0.1207 - mae: 0.2603 - val_loss: 0.3862 - val_mse: 0.3862 - val_mae: 0.4397\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1127 - mse: 0.1127 - mae: 0.2495 - val_loss: 0.3915 - val_mse: 0.3915 - val_mae: 0.4439\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1089 - mse: 0.1089 - mae: 0.2469 - val_loss: 0.4013 - val_mse: 0.4013 - val_mae: 0.4466\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.1094 - mse: 0.1094 - mae: 0.2481 - val_loss: 0.3847 - val_mse: 0.3847 - val_mae: 0.4379\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1047 - mse: 0.1047 - mae: 0.2426 - val_loss: 0.3753 - val_mse: 0.3753 - val_mae: 0.4350\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1119 - mse: 0.1119 - mae: 0.2522 - val_loss: 0.3752 - val_mse: 0.3752 - val_mae: 0.4301\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1111 - mse: 0.1111 - mae: 0.2506 - val_loss: 0.3775 - val_mse: 0.3775 - val_mae: 0.4420\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1067 - mse: 0.1067 - mae: 0.2435 - val_loss: 0.4131 - val_mse: 0.4131 - val_mae: 0.4554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1082 - mse: 0.1082 - mae: 0.2478 - val_loss: 0.3868 - val_mse: 0.3868 - val_mae: 0.4441\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1034 - mse: 0.1034 - mae: 0.2400 - val_loss: 0.4001 - val_mse: 0.4001 - val_mae: 0.4510\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0994 - mse: 0.0994 - mae: 0.2356 - val_loss: 0.3965 - val_mse: 0.3965 - val_mae: 0.4439\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0955 - mse: 0.0955 - mae: 0.2313 - val_loss: 0.3986 - val_mse: 0.3986 - val_mae: 0.4455\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0931 - mse: 0.0931 - mae: 0.2305 - val_loss: 0.4013 - val_mse: 0.4013 - val_mae: 0.4515\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.0914 - mse: 0.0914 - mae: 0.2281 - val_loss: 0.3882 - val_mse: 0.3882 - val_mae: 0.4442\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.0915 - mse: 0.0915 - mae: 0.2271 - val_loss: 0.3910 - val_mse: 0.3910 - val_mae: 0.4408\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.0869 - mse: 0.0869 - mae: 0.2198 - val_loss: 0.3987 - val_mse: 0.3987 - val_mae: 0.4459\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 177us/sample - loss: 0.9810 - mse: 0.9810 - mae: 0.7110 - val_loss: 5.5841 - val_mse: 5.5841 - val_mae: 2.0958\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.5405 - mse: 0.5405 - mae: 0.5498 - val_loss: 2.1934 - val_mse: 2.1934 - val_mae: 1.1838\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4506 - mse: 0.4506 - mae: 0.4971 - val_loss: 1.3394 - val_mse: 1.3394 - val_mae: 0.9196\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4209 - mse: 0.4209 - mae: 0.4844 - val_loss: 0.8963 - val_mse: 0.8963 - val_mae: 0.7598\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3927 - mse: 0.3927 - mae: 0.4655 - val_loss: 0.7818 - val_mse: 0.7818 - val_mae: 0.6900\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3610 - mse: 0.3610 - mae: 0.4464 - val_loss: 0.6436 - val_mse: 0.6436 - val_mae: 0.5904\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3403 - mse: 0.3403 - mae: 0.4375 - val_loss: 0.5329 - val_mse: 0.5329 - val_mae: 0.5410\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3242 - mse: 0.3242 - mae: 0.4251 - val_loss: 0.5430 - val_mse: 0.5430 - val_mae: 0.5267\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2966 - mse: 0.2966 - mae: 0.4085 - val_loss: 0.5083 - val_mse: 0.5083 - val_mae: 0.5117\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2933 - mse: 0.2933 - mae: 0.4021 - val_loss: 0.4989 - val_mse: 0.4989 - val_mae: 0.4958\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2653 - mse: 0.2653 - mae: 0.3840 - val_loss: 0.4745 - val_mse: 0.4745 - val_mae: 0.4886\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2472 - mse: 0.2472 - mae: 0.3711 - val_loss: 0.4487 - val_mse: 0.4487 - val_mae: 0.4809\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2395 - mse: 0.2395 - mae: 0.3658 - val_loss: 0.5331 - val_mse: 0.5331 - val_mae: 0.4918\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2366 - mse: 0.2366 - mae: 0.3644 - val_loss: 0.4950 - val_mse: 0.4950 - val_mae: 0.4772\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2133 - mse: 0.2133 - mae: 0.3439 - val_loss: 0.4565 - val_mse: 0.4565 - val_mae: 0.4729\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2089 - mse: 0.2089 - mae: 0.3412 - val_loss: 0.4643 - val_mse: 0.4643 - val_mae: 0.4829\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2011 - mse: 0.2011 - mae: 0.3332 - val_loss: 0.4538 - val_mse: 0.4538 - val_mae: 0.4730\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2022 - mse: 0.2022 - mae: 0.3356 - val_loss: 0.4466 - val_mse: 0.4466 - val_mae: 0.4701\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1867 - mse: 0.1867 - mae: 0.3240 - val_loss: 0.4826 - val_mse: 0.4826 - val_mae: 0.4727\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1724 - mse: 0.1724 - mae: 0.3114 - val_loss: 0.4410 - val_mse: 0.4410 - val_mae: 0.4677\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1603 - mse: 0.1603 - mae: 0.2997 - val_loss: 0.4744 - val_mse: 0.4744 - val_mae: 0.4664\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1689 - mse: 0.1689 - mae: 0.3064 - val_loss: 0.4804 - val_mse: 0.4804 - val_mae: 0.4782\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1608 - mse: 0.1608 - mae: 0.2971 - val_loss: 0.4478 - val_mse: 0.4478 - val_mae: 0.4682\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1539 - mse: 0.1539 - mae: 0.2960 - val_loss: 0.4534 - val_mse: 0.4534 - val_mae: 0.4646\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1472 - mse: 0.1472 - mae: 0.2896 - val_loss: 0.4353 - val_mse: 0.4353 - val_mae: 0.4495\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1452 - mse: 0.1452 - mae: 0.2859 - val_loss: 0.4348 - val_mse: 0.4348 - val_mae: 0.4527\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1393 - mse: 0.1393 - mae: 0.2795 - val_loss: 0.4239 - val_mse: 0.4239 - val_mae: 0.4562\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1326 - mse: 0.1326 - mae: 0.2716 - val_loss: 0.4282 - val_mse: 0.4282 - val_mae: 0.4456\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1266 - mse: 0.1266 - mae: 0.2682 - val_loss: 0.4400 - val_mse: 0.4400 - val_mae: 0.4529\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1254 - mse: 0.1254 - mae: 0.2647 - val_loss: 0.4423 - val_mse: 0.4423 - val_mae: 0.4566\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1146 - mse: 0.1146 - mae: 0.2543 - val_loss: 0.4463 - val_mse: 0.4463 - val_mae: 0.4603\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1120 - mse: 0.1120 - mae: 0.2516 - val_loss: 0.4183 - val_mse: 0.4183 - val_mae: 0.4415\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1132 - mse: 0.1132 - mae: 0.2488 - val_loss: 0.4485 - val_mse: 0.4485 - val_mae: 0.4668\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1163 - mse: 0.1163 - mae: 0.2528 - val_loss: 0.4876 - val_mse: 0.4876 - val_mae: 0.4711\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1148 - mse: 0.1148 - mae: 0.2529 - val_loss: 0.4289 - val_mse: 0.4289 - val_mae: 0.4454\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1085 - mse: 0.1085 - mae: 0.2457 - val_loss: 0.4313 - val_mse: 0.4313 - val_mae: 0.4472\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1106 - mse: 0.1106 - mae: 0.2479 - val_loss: 0.4430 - val_mse: 0.4430 - val_mae: 0.4553\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1090 - mse: 0.1090 - mae: 0.2495 - val_loss: 0.4505 - val_mse: 0.4505 - val_mae: 0.4487\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1000 - mse: 0.1000 - mae: 0.2387 - val_loss: 0.4342 - val_mse: 0.4342 - val_mae: 0.4515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1011 - mse: 0.1011 - mae: 0.2365 - val_loss: 0.4355 - val_mse: 0.4355 - val_mae: 0.4456\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1073 - mse: 0.1073 - mae: 0.2436 - val_loss: 0.4384 - val_mse: 0.4384 - val_mae: 0.4517\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1011 - mse: 0.1011 - mae: 0.2385 - val_loss: 0.4266 - val_mse: 0.4266 - val_mae: 0.4438\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 148us/sample - loss: 1.0269 - mse: 1.0269 - mae: 0.7289 - val_loss: 19.1225 - val_mse: 19.1225 - val_mae: 4.0755\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.5454 - mse: 0.5454 - mae: 0.5473 - val_loss: 1.7307 - val_mse: 1.7307 - val_mae: 1.1275\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4697 - mse: 0.4697 - mae: 0.5094 - val_loss: 1.3146 - val_mse: 1.3146 - val_mae: 0.9344\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.4151 - mse: 0.4151 - mae: 0.4793 - val_loss: 0.7878 - val_mse: 0.7878 - val_mae: 0.7113\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3796 - mse: 0.3796 - mae: 0.4584 - val_loss: 0.5826 - val_mse: 0.5826 - val_mae: 0.5834\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3617 - mse: 0.3617 - mae: 0.4463 - val_loss: 0.5714 - val_mse: 0.5714 - val_mae: 0.5560\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.3260 - mse: 0.3260 - mae: 0.4260 - val_loss: 0.4763 - val_mse: 0.4763 - val_mae: 0.5227\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3083 - mse: 0.3083 - mae: 0.4143 - val_loss: 0.4703 - val_mse: 0.4703 - val_mae: 0.4983\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2984 - mse: 0.2984 - mae: 0.4098 - val_loss: 0.4506 - val_mse: 0.4506 - val_mae: 0.5055\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2697 - mse: 0.2697 - mae: 0.3865 - val_loss: 0.4194 - val_mse: 0.4194 - val_mae: 0.4631\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2612 - mse: 0.2612 - mae: 0.3829 - val_loss: 0.4294 - val_mse: 0.4294 - val_mae: 0.4705\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.2575 - mse: 0.2575 - mae: 0.3778 - val_loss: 0.4571 - val_mse: 0.4571 - val_mae: 0.4838\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2443 - mse: 0.2443 - mae: 0.3676 - val_loss: 0.4814 - val_mse: 0.4814 - val_mae: 0.4942\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2208 - mse: 0.2208 - mae: 0.3524 - val_loss: 0.4410 - val_mse: 0.4410 - val_mae: 0.4829\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2075 - mse: 0.2075 - mae: 0.3445 - val_loss: 0.4198 - val_mse: 0.4198 - val_mae: 0.4569\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2150 - mse: 0.2150 - mae: 0.3480 - val_loss: 0.4476 - val_mse: 0.4476 - val_mae: 0.4734\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1998 - mse: 0.1998 - mae: 0.3354 - val_loss: 0.4500 - val_mse: 0.4500 - val_mae: 0.4735\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1920 - mse: 0.1920 - mae: 0.3305 - val_loss: 0.4178 - val_mse: 0.4178 - val_mae: 0.4564\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1850 - mse: 0.1850 - mae: 0.3217 - val_loss: 0.4218 - val_mse: 0.4218 - val_mae: 0.4673\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1727 - mse: 0.1727 - mae: 0.3135 - val_loss: 0.4612 - val_mse: 0.4612 - val_mae: 0.4774\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1705 - mse: 0.1705 - mae: 0.3128 - val_loss: 0.4704 - val_mse: 0.4704 - val_mae: 0.4791\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1632 - mse: 0.1632 - mae: 0.3046 - val_loss: 0.4293 - val_mse: 0.4293 - val_mae: 0.4666\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1557 - mse: 0.1557 - mae: 0.2964 - val_loss: 0.4410 - val_mse: 0.4410 - val_mae: 0.4597\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1588 - mse: 0.1588 - mae: 0.2995 - val_loss: 0.4175 - val_mse: 0.4175 - val_mae: 0.4597\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1579 - mse: 0.1579 - mae: 0.3021 - val_loss: 0.4587 - val_mse: 0.4587 - val_mae: 0.4956\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1453 - mse: 0.1453 - mae: 0.2880 - val_loss: 0.4041 - val_mse: 0.4041 - val_mae: 0.4489\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1400 - mse: 0.1400 - mae: 0.2815 - val_loss: 0.4142 - val_mse: 0.4142 - val_mae: 0.4435\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.1404 - mse: 0.1404 - mae: 0.2814 - val_loss: 0.4195 - val_mse: 0.4195 - val_mae: 0.4473\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1245 - mse: 0.1245 - mae: 0.2651 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4569\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1346 - mse: 0.1346 - mae: 0.2747 - val_loss: 0.4229 - val_mse: 0.4229 - val_mae: 0.4608\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1239 - mse: 0.1239 - mae: 0.2648 - val_loss: 0.4079 - val_mse: 0.4079 - val_mae: 0.4525\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1209 - mse: 0.1209 - mae: 0.2628 - val_loss: 0.4105 - val_mse: 0.4105 - val_mae: 0.4478\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1160 - mse: 0.1160 - mae: 0.2566 - val_loss: 0.4302 - val_mse: 0.4302 - val_mae: 0.4549\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1096 - mse: 0.1096 - mae: 0.2498 - val_loss: 0.4228 - val_mse: 0.4228 - val_mae: 0.4529\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1093 - mse: 0.1093 - mae: 0.2503 - val_loss: 0.3956 - val_mse: 0.3956 - val_mae: 0.4418\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1057 - mse: 0.1057 - mae: 0.2433 - val_loss: 0.4081 - val_mse: 0.4081 - val_mae: 0.4456\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1146 - mse: 0.1146 - mae: 0.2523 - val_loss: 0.4212 - val_mse: 0.4212 - val_mae: 0.4522\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1131 - mse: 0.1131 - mae: 0.2516 - val_loss: 0.4256 - val_mse: 0.4256 - val_mae: 0.4481\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1056 - mse: 0.1056 - mae: 0.2464 - val_loss: 0.4085 - val_mse: 0.4085 - val_mae: 0.4439\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1074 - mse: 0.1074 - mae: 0.2454 - val_loss: 0.4062 - val_mse: 0.4062 - val_mae: 0.4448\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1034 - mse: 0.1034 - mae: 0.2419 - val_loss: 0.3990 - val_mse: 0.3990 - val_mae: 0.4396\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.0978 - mse: 0.0978 - mae: 0.2348 - val_loss: 0.4091 - val_mse: 0.4091 - val_mae: 0.4481\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1009 - mse: 0.1009 - mae: 0.2358 - val_loss: 0.4338 - val_mse: 0.4338 - val_mae: 0.4627\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0936 - mse: 0.0936 - mae: 0.2312 - val_loss: 0.4085 - val_mse: 0.4085 - val_mae: 0.4407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.0921 - mse: 0.0921 - mae: 0.2292 - val_loss: 0.4494 - val_mse: 0.4494 - val_mae: 0.4502\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 178us/sample - loss: 1.1384 - mse: 1.1384 - mae: 0.7554 - val_loss: 2.1034 - val_mse: 2.1034 - val_mae: 1.0439\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.5383 - mse: 0.5383 - mae: 0.5451 - val_loss: 0.9452 - val_mse: 0.9452 - val_mae: 0.7736\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.4687 - mse: 0.4687 - mae: 0.5101 - val_loss: 1.0177 - val_mse: 1.0177 - val_mae: 0.8237\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4227 - mse: 0.4227 - mae: 0.4826 - val_loss: 0.7409 - val_mse: 0.7409 - val_mae: 0.6897\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3862 - mse: 0.3862 - mae: 0.4622 - val_loss: 0.6372 - val_mse: 0.6372 - val_mae: 0.6258\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3553 - mse: 0.3553 - mae: 0.4442 - val_loss: 0.6066 - val_mse: 0.6066 - val_mae: 0.6004\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3361 - mse: 0.3361 - mae: 0.4308 - val_loss: 0.4959 - val_mse: 0.4959 - val_mae: 0.5347\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3085 - mse: 0.3085 - mae: 0.4154 - val_loss: 0.4723 - val_mse: 0.4723 - val_mae: 0.5054\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2966 - mse: 0.2966 - mae: 0.4096 - val_loss: 0.4418 - val_mse: 0.4418 - val_mae: 0.4838\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2786 - mse: 0.2786 - mae: 0.3924 - val_loss: 0.4570 - val_mse: 0.4570 - val_mae: 0.5012\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2614 - mse: 0.2614 - mae: 0.3810 - val_loss: 0.4266 - val_mse: 0.4266 - val_mae: 0.4743\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2637 - mse: 0.2637 - mae: 0.3822 - val_loss: 0.4251 - val_mse: 0.4251 - val_mae: 0.4705\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2473 - mse: 0.2473 - mae: 0.3736 - val_loss: 0.4275 - val_mse: 0.4275 - val_mae: 0.4655\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2335 - mse: 0.2335 - mae: 0.3612 - val_loss: 0.4221 - val_mse: 0.4221 - val_mae: 0.4731\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2177 - mse: 0.2177 - mae: 0.3495 - val_loss: 0.4249 - val_mse: 0.4249 - val_mae: 0.4723\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2083 - mse: 0.2083 - mae: 0.3399 - val_loss: 0.4189 - val_mse: 0.4189 - val_mae: 0.4611\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2004 - mse: 0.2004 - mae: 0.3336 - val_loss: 0.4064 - val_mse: 0.4064 - val_mae: 0.4585\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2018 - mse: 0.2018 - mae: 0.3374 - val_loss: 0.4119 - val_mse: 0.4119 - val_mae: 0.4641\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1858 - mse: 0.1858 - mae: 0.3236 - val_loss: 0.4052 - val_mse: 0.4052 - val_mae: 0.4586\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1811 - mse: 0.1811 - mae: 0.3201 - val_loss: 0.4030 - val_mse: 0.4030 - val_mae: 0.4562\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1771 - mse: 0.1771 - mae: 0.3142 - val_loss: 0.4172 - val_mse: 0.4172 - val_mae: 0.4634\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1750 - mse: 0.1750 - mae: 0.3117 - val_loss: 0.4221 - val_mse: 0.4221 - val_mae: 0.4686\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1617 - mse: 0.1617 - mae: 0.3032 - val_loss: 0.4065 - val_mse: 0.4065 - val_mae: 0.4622\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1578 - mse: 0.1578 - mae: 0.2978 - val_loss: 0.4096 - val_mse: 0.4096 - val_mae: 0.4567\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1518 - mse: 0.1518 - mae: 0.2939 - val_loss: 0.4171 - val_mse: 0.4171 - val_mae: 0.4636\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1449 - mse: 0.1449 - mae: 0.2844 - val_loss: 0.4156 - val_mse: 0.4156 - val_mae: 0.4587\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1470 - mse: 0.1470 - mae: 0.2882 - val_loss: 0.4105 - val_mse: 0.4105 - val_mae: 0.4641\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1441 - mse: 0.1441 - mae: 0.2840 - val_loss: 0.4351 - val_mse: 0.4351 - val_mae: 0.4743\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1495 - mse: 0.1495 - mae: 0.2905 - val_loss: 0.3865 - val_mse: 0.3865 - val_mae: 0.4415\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1326 - mse: 0.1326 - mae: 0.2719 - val_loss: 0.4162 - val_mse: 0.4162 - val_mae: 0.4593\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1253 - mse: 0.1253 - mae: 0.2672 - val_loss: 0.3990 - val_mse: 0.3990 - val_mae: 0.4441\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1245 - mse: 0.1245 - mae: 0.2648 - val_loss: 0.3871 - val_mse: 0.3871 - val_mae: 0.4428\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1268 - mse: 0.1268 - mae: 0.2676 - val_loss: 0.4031 - val_mse: 0.4031 - val_mae: 0.4496\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1173 - mse: 0.1173 - mae: 0.2589 - val_loss: 0.4203 - val_mse: 0.4203 - val_mae: 0.4532\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1116 - mse: 0.1116 - mae: 0.2521 - val_loss: 0.4061 - val_mse: 0.4061 - val_mae: 0.4510\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1091 - mse: 0.1091 - mae: 0.2501 - val_loss: 0.3867 - val_mse: 0.3867 - val_mae: 0.4361\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.1095 - mse: 0.1095 - mae: 0.2498 - val_loss: 0.4023 - val_mse: 0.4023 - val_mae: 0.4559\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1138 - mse: 0.1138 - mae: 0.2523 - val_loss: 0.3859 - val_mse: 0.3859 - val_mae: 0.4402\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1083 - mse: 0.1083 - mae: 0.2465 - val_loss: 0.3869 - val_mse: 0.3869 - val_mae: 0.4348\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1034 - mse: 0.1034 - mae: 0.2404 - val_loss: 0.3821 - val_mse: 0.3821 - val_mae: 0.4348\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1043 - mse: 0.1043 - mae: 0.2417 - val_loss: 0.3869 - val_mse: 0.3869 - val_mae: 0.4390\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1013 - mse: 0.1013 - mae: 0.2391 - val_loss: 0.3980 - val_mse: 0.3980 - val_mae: 0.4443\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1012 - mse: 0.1012 - mae: 0.2388 - val_loss: 0.3922 - val_mse: 0.3922 - val_mae: 0.4399\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0964 - mse: 0.0964 - mae: 0.2318 - val_loss: 0.3954 - val_mse: 0.3954 - val_mae: 0.4454\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.0904 - mse: 0.0904 - mae: 0.2254 - val_loss: 0.4047 - val_mse: 0.4047 - val_mae: 0.4472\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.0952 - mse: 0.0952 - mae: 0.2317 - val_loss: 0.3782 - val_mse: 0.3782 - val_mae: 0.4365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.0916 - mse: 0.0916 - mae: 0.2270 - val_loss: 0.3873 - val_mse: 0.3873 - val_mae: 0.4354\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0877 - mse: 0.0877 - mae: 0.2211 - val_loss: 0.4065 - val_mse: 0.4065 - val_mae: 0.4475\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0945 - mse: 0.0945 - mae: 0.2303 - val_loss: 0.3851 - val_mse: 0.3851 - val_mae: 0.4394\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0941 - mse: 0.0941 - mae: 0.2281 - val_loss: 0.3930 - val_mse: 0.3930 - val_mae: 0.4359\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0946 - mse: 0.0946 - mae: 0.2291 - val_loss: 0.3755 - val_mse: 0.3755 - val_mae: 0.4351\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0811 - mse: 0.0811 - mae: 0.2124 - val_loss: 0.3898 - val_mse: 0.3898 - val_mae: 0.4448\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0871 - mse: 0.0871 - mae: 0.2215 - val_loss: 0.3981 - val_mse: 0.3981 - val_mae: 0.4455\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0864 - mse: 0.0864 - mae: 0.2198 - val_loss: 0.3946 - val_mse: 0.3946 - val_mae: 0.4420\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0851 - mse: 0.0851 - mae: 0.2173 - val_loss: 0.3898 - val_mse: 0.3898 - val_mae: 0.4477\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0805 - mse: 0.0805 - mae: 0.2096 - val_loss: 0.3839 - val_mse: 0.3839 - val_mae: 0.4344\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0836 - mse: 0.0836 - mae: 0.2157 - val_loss: 0.3842 - val_mse: 0.3842 - val_mae: 0.4381\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0871 - mse: 0.0871 - mae: 0.2206 - val_loss: 0.3893 - val_mse: 0.3893 - val_mae: 0.4375\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.0810 - mse: 0.0810 - mae: 0.2101 - val_loss: 0.3859 - val_mse: 0.3859 - val_mae: 0.4369\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0861 - mse: 0.0861 - mae: 0.2160 - val_loss: 0.3951 - val_mse: 0.3951 - val_mae: 0.4438\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0807 - mse: 0.0807 - mae: 0.2105 - val_loss: 0.3983 - val_mse: 0.3983 - val_mae: 0.4429\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 148us/sample - loss: 1.2418 - mse: 1.2418 - mae: 0.7791 - val_loss: 4.0303 - val_mse: 4.0303 - val_mae: 1.7494\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 28us/sample - loss: 0.5824 - mse: 0.5824 - mae: 0.5688 - val_loss: 2.9993 - val_mse: 2.9993 - val_mae: 1.5158\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.4881 - mse: 0.4881 - mae: 0.5197 - val_loss: 1.1567 - val_mse: 1.1567 - val_mae: 0.8801\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.4357 - mse: 0.4357 - mae: 0.4912 - val_loss: 0.9314 - val_mse: 0.9314 - val_mae: 0.7757\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.4003 - mse: 0.4003 - mae: 0.4747 - val_loss: 0.6038 - val_mse: 0.6038 - val_mae: 0.5781\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.3825 - mse: 0.3825 - mae: 0.4630 - val_loss: 0.5370 - val_mse: 0.5370 - val_mae: 0.5485\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.3486 - mse: 0.3486 - mae: 0.4414 - val_loss: 0.5414 - val_mse: 0.5414 - val_mae: 0.5595\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.3254 - mse: 0.3254 - mae: 0.4268 - val_loss: 0.4761 - val_mse: 0.4761 - val_mae: 0.4954\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.3178 - mse: 0.3178 - mae: 0.4197 - val_loss: 0.4817 - val_mse: 0.4817 - val_mae: 0.5078\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2974 - mse: 0.2974 - mae: 0.4097 - val_loss: 0.4628 - val_mse: 0.4628 - val_mae: 0.4912\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2858 - mse: 0.2858 - mae: 0.3961 - val_loss: 0.4556 - val_mse: 0.4556 - val_mae: 0.4822\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.2649 - mse: 0.2649 - mae: 0.3832 - val_loss: 0.4361 - val_mse: 0.4361 - val_mae: 0.4691\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.2536 - mse: 0.2536 - mae: 0.3750 - val_loss: 0.4341 - val_mse: 0.4341 - val_mae: 0.4720\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2412 - mse: 0.2412 - mae: 0.3686 - val_loss: 0.4329 - val_mse: 0.4329 - val_mae: 0.4685\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2394 - mse: 0.2394 - mae: 0.3649 - val_loss: 0.4023 - val_mse: 0.4023 - val_mae: 0.4514\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.2127 - mse: 0.2127 - mae: 0.3456 - val_loss: 0.4448 - val_mse: 0.4448 - val_mae: 0.4577\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2111 - mse: 0.2111 - mae: 0.3445 - val_loss: 0.4303 - val_mse: 0.4303 - val_mae: 0.4639\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.2063 - mse: 0.2063 - mae: 0.3423 - val_loss: 0.4629 - val_mse: 0.4629 - val_mae: 0.4787\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.1915 - mse: 0.1915 - mae: 0.3280 - val_loss: 0.4308 - val_mse: 0.4308 - val_mae: 0.4541\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.1828 - mse: 0.1828 - mae: 0.3216 - val_loss: 0.4307 - val_mse: 0.4307 - val_mae: 0.4600\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1783 - mse: 0.1783 - mae: 0.3198 - val_loss: 0.4352 - val_mse: 0.4352 - val_mae: 0.4622\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.1692 - mse: 0.1692 - mae: 0.3073 - val_loss: 0.4306 - val_mse: 0.4306 - val_mae: 0.4621\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1703 - mse: 0.1703 - mae: 0.3087 - val_loss: 0.4748 - val_mse: 0.4748 - val_mae: 0.4954\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.1672 - mse: 0.1672 - mae: 0.3074 - val_loss: 0.4306 - val_mse: 0.4306 - val_mae: 0.4544\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1529 - mse: 0.1529 - mae: 0.2939 - val_loss: 0.4122 - val_mse: 0.4122 - val_mae: 0.4451\n",
      "Avg. MAE: 0.387825\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 313us/sample - loss: 39.8204 - mse: 39.8204 - mae: 2.9971 - val_loss: 12.7549 - val_mse: 12.7549 - val_mae: 3.1207\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 2s 223us/sample - loss: 0.9371 - mse: 0.9371 - mae: 0.7237 - val_loss: 1.6172 - val_mse: 1.6172 - val_mae: 1.0527\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 2s 223us/sample - loss: 0.6460 - mse: 0.6460 - mae: 0.5988 - val_loss: 1.0917 - val_mse: 1.0917 - val_mae: 0.8343\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 2s 222us/sample - loss: 0.5924 - mse: 0.5924 - mae: 0.5762 - val_loss: 0.9762 - val_mse: 0.9762 - val_mae: 0.7878\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.5267 - mse: 0.5267 - mae: 0.5432 - val_loss: 0.7027 - val_mse: 0.7027 - val_mae: 0.6662\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.5141 - mse: 0.5141 - mae: 0.5362 - val_loss: 0.7861 - val_mse: 0.7861 - val_mae: 0.7032\n",
      "Epoch 7/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 2s 223us/sample - loss: 0.4943 - mse: 0.4943 - mae: 0.5267 - val_loss: 0.5520 - val_mse: 0.5520 - val_mae: 0.5691\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.4864 - mse: 0.4864 - mae: 0.5198 - val_loss: 0.5476 - val_mse: 0.5476 - val_mae: 0.5672\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.4456 - mse: 0.4456 - mae: 0.4995 - val_loss: 0.5525 - val_mse: 0.5525 - val_mae: 0.5627\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 2s 231us/sample - loss: 0.4186 - mse: 0.4186 - mae: 0.4859 - val_loss: 0.5191 - val_mse: 0.5191 - val_mae: 0.5552\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 3s 237us/sample - loss: 0.4281 - mse: 0.4281 - mae: 0.4919 - val_loss: 0.5499 - val_mse: 0.5499 - val_mae: 0.5494\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.4351 - mse: 0.4351 - mae: 0.4932 - val_loss: 0.4786 - val_mse: 0.4786 - val_mae: 0.5244\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.3795 - mse: 0.3795 - mae: 0.4620 - val_loss: 0.5268 - val_mse: 0.5268 - val_mae: 0.5540\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.3700 - mse: 0.3700 - mae: 0.4517 - val_loss: 0.5443 - val_mse: 0.5443 - val_mae: 0.5642\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.4225 - mse: 0.4225 - mae: 0.4855 - val_loss: 0.5011 - val_mse: 0.5011 - val_mae: 0.5321\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.4267 - mse: 0.4267 - mae: 0.4858 - val_loss: 0.6172 - val_mse: 0.6172 - val_mae: 0.5838\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.4081 - mse: 0.4081 - mae: 0.4707 - val_loss: 0.5282 - val_mse: 0.5282 - val_mae: 0.5253\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.4207 - mse: 0.4207 - mae: 0.4811 - val_loss: 0.5422 - val_mse: 0.5422 - val_mae: 0.5655\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.4310 - mse: 0.4310 - mae: 0.4893 - val_loss: 0.5710 - val_mse: 0.5710 - val_mae: 0.5747\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.3487 - mse: 0.3487 - mae: 0.4432 - val_loss: 0.5119 - val_mse: 0.5119 - val_mae: 0.5322\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.3734 - mse: 0.3734 - mae: 0.4591 - val_loss: 0.4945 - val_mse: 0.4945 - val_mae: 0.5215\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.4660 - mse: 0.4660 - mae: 0.5053 - val_loss: 0.6425 - val_mse: 0.6425 - val_mae: 0.5871\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 291us/sample - loss: 58.0933 - mse: 58.0933 - mae: 3.6737 - val_loss: 4.6202 - val_mse: 4.6202 - val_mae: 1.3775\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 1.2326 - mse: 1.2326 - mae: 0.8128 - val_loss: 2.4212 - val_mse: 2.4212 - val_mae: 1.0351\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.6773 - mse: 0.6773 - mae: 0.6193 - val_loss: 1.1828 - val_mse: 1.1828 - val_mae: 0.8447\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.6060 - mse: 0.6060 - mae: 0.5867 - val_loss: 0.8466 - val_mse: 0.8466 - val_mae: 0.7219\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.6037 - mse: 0.6037 - mae: 0.5856 - val_loss: 0.7941 - val_mse: 0.7941 - val_mae: 0.6915\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.5267 - mse: 0.5267 - mae: 0.5517 - val_loss: 0.7700 - val_mse: 0.7700 - val_mae: 0.6500\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.4909 - mse: 0.4909 - mae: 0.5292 - val_loss: 0.6256 - val_mse: 0.6256 - val_mae: 0.5990\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.4771 - mse: 0.4771 - mae: 0.5215 - val_loss: 0.6529 - val_mse: 0.6529 - val_mae: 0.5766\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.4588 - mse: 0.4588 - mae: 0.5144 - val_loss: 0.6206 - val_mse: 0.6206 - val_mae: 0.5732\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 2s 224us/sample - loss: 0.4393 - mse: 0.4393 - mae: 0.4990 - val_loss: 0.5523 - val_mse: 0.5523 - val_mae: 0.5709\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.4251 - mse: 0.4251 - mae: 0.4898 - val_loss: 0.5539 - val_mse: 0.5539 - val_mae: 0.5695\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.4137 - mse: 0.4137 - mae: 0.4837 - val_loss: 0.5435 - val_mse: 0.5435 - val_mae: 0.5319\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.3875 - mse: 0.3875 - mae: 0.4666 - val_loss: 0.5290 - val_mse: 0.5290 - val_mae: 0.5207\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 2s 224us/sample - loss: 0.4048 - mse: 0.4048 - mae: 0.4817 - val_loss: 0.5121 - val_mse: 0.5121 - val_mae: 0.5326\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.4205 - mse: 0.4205 - mae: 0.4865 - val_loss: 1.0124 - val_mse: 1.0124 - val_mae: 0.6048\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 2s 224us/sample - loss: 0.4052 - mse: 0.4052 - mae: 0.4775 - val_loss: 0.5124 - val_mse: 0.5124 - val_mae: 0.5283\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.3635 - mse: 0.3635 - mae: 0.4519 - val_loss: 0.5671 - val_mse: 0.5671 - val_mae: 0.5664\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.3759 - mse: 0.3759 - mae: 0.4607 - val_loss: 0.5004 - val_mse: 0.5004 - val_mae: 0.5306\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.3237 - mse: 0.3237 - mae: 0.4274 - val_loss: 0.5688 - val_mse: 0.5688 - val_mae: 0.5550\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 2s 224us/sample - loss: 0.3235 - mse: 0.3235 - mae: 0.4300 - val_loss: 0.5239 - val_mse: 0.5239 - val_mae: 0.5254\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.3284 - mse: 0.3284 - mae: 0.4323 - val_loss: 0.6060 - val_mse: 0.6060 - val_mae: 0.5578\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.3383 - mse: 0.3383 - mae: 0.4392 - val_loss: 0.5979 - val_mse: 0.5979 - val_mae: 0.5667\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 2s 222us/sample - loss: 0.4329 - mse: 0.4329 - mae: 0.4892 - val_loss: 0.5166 - val_mse: 0.5166 - val_mae: 0.5106\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 2s 223us/sample - loss: 0.3271 - mse: 0.3271 - mae: 0.4301 - val_loss: 0.6695 - val_mse: 0.6695 - val_mae: 0.5117\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.3307 - mse: 0.3307 - mae: 0.4327 - val_loss: 0.4765 - val_mse: 0.4765 - val_mae: 0.4890\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.2964 - mse: 0.2964 - mae: 0.4119 - val_loss: 0.4673 - val_mse: 0.4673 - val_mae: 0.4908\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 2s 222us/sample - loss: 0.3133 - mse: 0.3133 - mae: 0.4253 - val_loss: 0.5561 - val_mse: 0.5561 - val_mae: 0.5367\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.2774 - mse: 0.2774 - mae: 0.3966 - val_loss: 0.5734 - val_mse: 0.5734 - val_mae: 0.5000\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 2s 224us/sample - loss: 0.2887 - mse: 0.2887 - mae: 0.4100 - val_loss: 0.4774 - val_mse: 0.4774 - val_mae: 0.4992\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 2s 224us/sample - loss: 0.3333 - mse: 0.3333 - mae: 0.4298 - val_loss: 0.5064 - val_mse: 0.5064 - val_mae: 0.5164\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 2s 224us/sample - loss: 0.3318 - mse: 0.3318 - mae: 0.4310 - val_loss: 0.4988 - val_mse: 0.4988 - val_mae: 0.5061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.3182 - mse: 0.3182 - mae: 0.4228 - val_loss: 0.7464 - val_mse: 0.7464 - val_mae: 0.5183\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.3063 - mse: 0.3063 - mae: 0.4142 - val_loss: 0.6252 - val_mse: 0.6252 - val_mae: 0.5875\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 2s 223us/sample - loss: 0.3425 - mse: 0.3425 - mae: 0.4448 - val_loss: 0.6017 - val_mse: 0.6017 - val_mae: 0.5132\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.4016 - mse: 0.4016 - mae: 0.4681 - val_loss: 0.5886 - val_mse: 0.5886 - val_mae: 0.5246\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 2s 223us/sample - loss: 0.3569 - mse: 0.3569 - mae: 0.4499 - val_loss: 0.5188 - val_mse: 0.5188 - val_mae: 0.5214\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 289us/sample - loss: 47.4791 - mse: 47.4791 - mae: 3.3510 - val_loss: 19.6475 - val_mse: 19.6475 - val_mae: 4.0770\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 1.0071 - mse: 1.0071 - mae: 0.7416 - val_loss: 2.9852 - val_mse: 2.9852 - val_mae: 1.5191\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.6792 - mse: 0.6792 - mae: 0.6205 - val_loss: 1.4611 - val_mse: 1.4611 - val_mae: 1.0093\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.6179 - mse: 0.6179 - mae: 0.5891 - val_loss: 0.8697 - val_mse: 0.8697 - val_mae: 0.7611\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 2s 224us/sample - loss: 0.5464 - mse: 0.5464 - mae: 0.5565 - val_loss: 0.7892 - val_mse: 0.7892 - val_mae: 0.7228\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 2s 224us/sample - loss: 0.5365 - mse: 0.5365 - mae: 0.5500 - val_loss: 0.5859 - val_mse: 0.5859 - val_mae: 0.6028\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.4859 - mse: 0.4859 - mae: 0.5249 - val_loss: 0.5372 - val_mse: 0.5372 - val_mae: 0.5601\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.4669 - mse: 0.4669 - mae: 0.5137 - val_loss: 0.5252 - val_mse: 0.5252 - val_mae: 0.5599\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.4706 - mse: 0.4706 - mae: 0.5184 - val_loss: 0.5139 - val_mse: 0.5139 - val_mae: 0.5453\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 2s 217us/sample - loss: 0.4383 - mse: 0.4383 - mae: 0.4924 - val_loss: 0.5543 - val_mse: 0.5543 - val_mae: 0.5696\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.4503 - mse: 0.4503 - mae: 0.4962 - val_loss: 0.5094 - val_mse: 0.5094 - val_mae: 0.5437\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 2s 218us/sample - loss: 0.4107 - mse: 0.4107 - mae: 0.4816 - val_loss: 0.4871 - val_mse: 0.4871 - val_mae: 0.5224\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 2s 218us/sample - loss: 0.4056 - mse: 0.4056 - mae: 0.4802 - val_loss: 0.5128 - val_mse: 0.5128 - val_mae: 0.5333\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.4127 - mse: 0.4127 - mae: 0.4749 - val_loss: 0.9761 - val_mse: 0.9761 - val_mae: 0.7007\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.4648 - mse: 0.4648 - mae: 0.5063 - val_loss: 0.4924 - val_mse: 0.4924 - val_mae: 0.5105\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 2s 218us/sample - loss: 0.3907 - mse: 0.3907 - mae: 0.4688 - val_loss: 0.6892 - val_mse: 0.6892 - val_mae: 0.6241\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.4101 - mse: 0.4101 - mae: 0.4735 - val_loss: 0.4643 - val_mse: 0.4643 - val_mae: 0.5072\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.3562 - mse: 0.3562 - mae: 0.4422 - val_loss: 0.4739 - val_mse: 0.4739 - val_mae: 0.5149\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 2s 217us/sample - loss: 0.3880 - mse: 0.3880 - mae: 0.4648 - val_loss: 0.5502 - val_mse: 0.5502 - val_mae: 0.5474\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.3937 - mse: 0.3937 - mae: 0.4705 - val_loss: 0.5214 - val_mse: 0.5214 - val_mae: 0.5255\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.3869 - mse: 0.3869 - mae: 0.4664 - val_loss: 0.5202 - val_mse: 0.5202 - val_mae: 0.5137\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 2s 218us/sample - loss: 0.3218 - mse: 0.3218 - mae: 0.4270 - val_loss: 0.4809 - val_mse: 0.4809 - val_mae: 0.5085\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 2s 217us/sample - loss: 0.3377 - mse: 0.3377 - mae: 0.4364 - val_loss: 0.5180 - val_mse: 0.5180 - val_mae: 0.5248\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.3530 - mse: 0.3530 - mae: 0.4480 - val_loss: 0.4798 - val_mse: 0.4798 - val_mae: 0.5101\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.3513 - mse: 0.3513 - mae: 0.4474 - val_loss: 0.5065 - val_mse: 0.5065 - val_mae: 0.5126\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.2995 - mse: 0.2995 - mae: 0.4111 - val_loss: 0.6153 - val_mse: 0.6153 - val_mae: 0.5922\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 2s 218us/sample - loss: 0.3131 - mse: 0.3131 - mae: 0.4168 - val_loss: 0.7491 - val_mse: 0.7491 - val_mae: 0.5973\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 284us/sample - loss: 41.0646 - mse: 41.0646 - mae: 3.1712 - val_loss: 4.8218 - val_mse: 4.8218 - val_mae: 1.8618\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.9790 - mse: 0.9790 - mae: 0.7291 - val_loss: 1.9626 - val_mse: 1.9626 - val_mae: 1.2250\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 2s 223us/sample - loss: 0.6159 - mse: 0.6159 - mae: 0.5854 - val_loss: 1.1481 - val_mse: 1.1481 - val_mae: 0.9102\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 2s 223us/sample - loss: 0.5711 - mse: 0.5711 - mae: 0.5689 - val_loss: 0.8416 - val_mse: 0.8416 - val_mae: 0.7607\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 2s 222us/sample - loss: 0.5187 - mse: 0.5187 - mae: 0.5418 - val_loss: 0.7192 - val_mse: 0.7192 - val_mae: 0.6579\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 2s 222us/sample - loss: 0.4920 - mse: 0.4920 - mae: 0.5276 - val_loss: 0.5565 - val_mse: 0.5565 - val_mae: 0.5637\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 2s 222us/sample - loss: 0.4654 - mse: 0.4654 - mae: 0.5144 - val_loss: 0.5829 - val_mse: 0.5829 - val_mae: 0.5948\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.4347 - mse: 0.4347 - mae: 0.4977 - val_loss: 0.6082 - val_mse: 0.6082 - val_mae: 0.6061\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.4639 - mse: 0.4639 - mae: 0.5119 - val_loss: 0.5638 - val_mse: 0.5638 - val_mae: 0.5467\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.4292 - mse: 0.4292 - mae: 0.4919 - val_loss: 0.5293 - val_mse: 0.5293 - val_mae: 0.5514\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.4144 - mse: 0.4144 - mae: 0.4836 - val_loss: 0.5370 - val_mse: 0.5370 - val_mae: 0.5491\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.3873 - mse: 0.3873 - mae: 0.4688 - val_loss: 0.5692 - val_mse: 0.5692 - val_mae: 0.5452\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.4033 - mse: 0.4033 - mae: 0.4753 - val_loss: 0.6359 - val_mse: 0.6359 - val_mae: 0.5985\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 2s 222us/sample - loss: 0.4689 - mse: 0.4689 - mae: 0.5133 - val_loss: 0.5009 - val_mse: 0.5009 - val_mae: 0.5247\n",
      "Epoch 15/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.4139 - mse: 0.4139 - mae: 0.4881 - val_loss: 0.5435 - val_mse: 0.5435 - val_mae: 0.5165\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.3828 - mse: 0.3828 - mae: 0.4674 - val_loss: 0.5385 - val_mse: 0.5385 - val_mae: 0.5298\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.3659 - mse: 0.3659 - mae: 0.4548 - val_loss: 0.5503 - val_mse: 0.5503 - val_mae: 0.5127\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.3766 - mse: 0.3766 - mae: 0.4573 - val_loss: 0.8621 - val_mse: 0.8621 - val_mae: 0.6624\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.4295 - mse: 0.4295 - mae: 0.4885 - val_loss: 0.6869 - val_mse: 0.6869 - val_mae: 0.5122\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.3639 - mse: 0.3639 - mae: 0.4571 - val_loss: 0.6566 - val_mse: 0.6566 - val_mae: 0.5055\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.3176 - mse: 0.3176 - mae: 0.4270 - val_loss: 0.6263 - val_mse: 0.6263 - val_mae: 0.5347\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 2s 223us/sample - loss: 0.3518 - mse: 0.3518 - mae: 0.4492 - val_loss: 0.6561 - val_mse: 0.6561 - val_mae: 0.5186\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.3208 - mse: 0.3208 - mae: 0.4227 - val_loss: 0.9277 - val_mse: 0.9277 - val_mae: 0.5444\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.5860 - mse: 0.5860 - mae: 0.5516 - val_loss: 0.5741 - val_mse: 0.5741 - val_mae: 0.5562\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 3s 312us/sample - loss: 50.8718 - mse: 50.8718 - mae: 3.4767 - val_loss: 25.1148 - val_mse: 25.1148 - val_mae: 4.8181\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 2s 223us/sample - loss: 1.1019 - mse: 1.1019 - mae: 0.7601 - val_loss: 5.1622 - val_mse: 5.1622 - val_mae: 2.1112\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 2s 219us/sample - loss: 0.6618 - mse: 0.6618 - mae: 0.6100 - val_loss: 1.5945 - val_mse: 1.5945 - val_mae: 1.0895\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 2s 221us/sample - loss: 0.5887 - mse: 0.5887 - mae: 0.5759 - val_loss: 0.9821 - val_mse: 0.9821 - val_mae: 0.8174\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 2s 221us/sample - loss: 0.5747 - mse: 0.5747 - mae: 0.5720 - val_loss: 0.7465 - val_mse: 0.7465 - val_mae: 0.7091\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 2s 220us/sample - loss: 0.4957 - mse: 0.4957 - mae: 0.5321 - val_loss: 0.6339 - val_mse: 0.6339 - val_mae: 0.6202\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 2s 220us/sample - loss: 0.4887 - mse: 0.4887 - mae: 0.5256 - val_loss: 0.5899 - val_mse: 0.5899 - val_mae: 0.5962\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 2s 225us/sample - loss: 0.4816 - mse: 0.4816 - mae: 0.5240 - val_loss: 0.5595 - val_mse: 0.5595 - val_mae: 0.5705\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 2s 220us/sample - loss: 0.4583 - mse: 0.4583 - mae: 0.5097 - val_loss: 0.4972 - val_mse: 0.4972 - val_mae: 0.5159\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 2s 219us/sample - loss: 0.4168 - mse: 0.4168 - mae: 0.4853 - val_loss: 0.5271 - val_mse: 0.5271 - val_mae: 0.5456\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 2s 222us/sample - loss: 0.4236 - mse: 0.4236 - mae: 0.4903 - val_loss: 0.6254 - val_mse: 0.6254 - val_mae: 0.5542\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 2s 219us/sample - loss: 0.4025 - mse: 0.4025 - mae: 0.4765 - val_loss: 0.5386 - val_mse: 0.5386 - val_mae: 0.5167\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 2s 219us/sample - loss: 0.3847 - mse: 0.3847 - mae: 0.4654 - val_loss: 0.4826 - val_mse: 0.4826 - val_mae: 0.5104\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 2s 222us/sample - loss: 0.3866 - mse: 0.3866 - mae: 0.4632 - val_loss: 0.5561 - val_mse: 0.5561 - val_mae: 0.5435\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 2s 220us/sample - loss: 0.3685 - mse: 0.3685 - mae: 0.4551 - val_loss: 0.4862 - val_mse: 0.4862 - val_mae: 0.5053\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 2s 219us/sample - loss: 0.3473 - mse: 0.3473 - mae: 0.4452 - val_loss: 0.4446 - val_mse: 0.4446 - val_mae: 0.4851\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 2s 219us/sample - loss: 0.3284 - mse: 0.3284 - mae: 0.4317 - val_loss: 0.5378 - val_mse: 0.5378 - val_mae: 0.5233\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 2s 219us/sample - loss: 0.3450 - mse: 0.3450 - mae: 0.4465 - val_loss: 0.5811 - val_mse: 0.5811 - val_mae: 0.5416\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 2s 220us/sample - loss: 0.3422 - mse: 0.3422 - mae: 0.4416 - val_loss: 0.5075 - val_mse: 0.5075 - val_mae: 0.4933\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 2s 218us/sample - loss: 0.3208 - mse: 0.3208 - mae: 0.4266 - val_loss: 0.5973 - val_mse: 0.5973 - val_mae: 0.5426\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 2s 222us/sample - loss: 0.3405 - mse: 0.3405 - mae: 0.4401 - val_loss: 0.7684 - val_mse: 0.7684 - val_mae: 0.6488\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 2s 218us/sample - loss: 0.3874 - mse: 0.3874 - mae: 0.4643 - val_loss: 0.5546 - val_mse: 0.5546 - val_mae: 0.5267\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 2s 219us/sample - loss: 0.4382 - mse: 0.4382 - mae: 0.4904 - val_loss: 1.4590 - val_mse: 1.4590 - val_mae: 0.8656\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 2s 219us/sample - loss: 0.5386 - mse: 0.5386 - mae: 0.5400 - val_loss: 0.4971 - val_mse: 0.4971 - val_mae: 0.5283\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 2s 228us/sample - loss: 0.4643 - mse: 0.4643 - mae: 0.4996 - val_loss: 0.6245 - val_mse: 0.6245 - val_mae: 0.5253\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 2s 220us/sample - loss: 0.3655 - mse: 0.3655 - mae: 0.4561 - val_loss: 0.5886 - val_mse: 0.5886 - val_mae: 0.5335\n",
      "Avg. MAE: 0.446431\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 145us/sample - loss: 0.7303 - mse: 0.7303 - mae: 0.6343 - val_loss: 0.6370 - val_mse: 0.6370 - val_mae: 0.6009\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 64us/sample - loss: 0.5729 - mse: 0.5729 - mae: 0.5651 - val_loss: 0.5609 - val_mse: 0.5609 - val_mae: 0.5517\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.5373 - mse: 0.5373 - mae: 0.5435 - val_loss: 0.5604 - val_mse: 0.5604 - val_mae: 0.5492\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.5200 - mse: 0.5200 - mae: 0.5377 - val_loss: 0.5623 - val_mse: 0.5623 - val_mae: 0.5527\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.5113 - mse: 0.5113 - mae: 0.5296 - val_loss: 0.5283 - val_mse: 0.5283 - val_mae: 0.5356\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4796 - mse: 0.4796 - mae: 0.5164 - val_loss: 0.5129 - val_mse: 0.5129 - val_mae: 0.5197\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4660 - mse: 0.4660 - mae: 0.5088 - val_loss: 0.5518 - val_mse: 0.5518 - val_mae: 0.5190\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4636 - mse: 0.4636 - mae: 0.5078 - val_loss: 0.5412 - val_mse: 0.5412 - val_mae: 0.5268\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.4485 - mse: 0.4485 - mae: 0.5003 - val_loss: 0.5064 - val_mse: 0.5064 - val_mae: 0.5252\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4350 - mse: 0.4350 - mae: 0.4947 - val_loss: 0.5457 - val_mse: 0.5457 - val_mae: 0.5250\n",
      "Epoch 11/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4270 - mse: 0.4270 - mae: 0.4836 - val_loss: 0.4871 - val_mse: 0.4871 - val_mae: 0.5171\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4298 - mse: 0.4298 - mae: 0.4883 - val_loss: 0.5293 - val_mse: 0.5293 - val_mae: 0.5099\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4174 - mse: 0.4174 - mae: 0.4840 - val_loss: 0.5237 - val_mse: 0.5237 - val_mae: 0.5331\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4111 - mse: 0.4111 - mae: 0.4760 - val_loss: 0.4800 - val_mse: 0.4800 - val_mae: 0.5041\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4023 - mse: 0.4023 - mae: 0.4740 - val_loss: 0.4973 - val_mse: 0.4973 - val_mae: 0.5114\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4111 - mse: 0.4111 - mae: 0.4779 - val_loss: 0.4804 - val_mse: 0.4804 - val_mae: 0.5060\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4074 - mse: 0.4074 - mae: 0.4787 - val_loss: 0.4688 - val_mse: 0.4688 - val_mae: 0.5024\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.3940 - mse: 0.3940 - mae: 0.4698 - val_loss: 0.4526 - val_mse: 0.4526 - val_mae: 0.4963\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3951 - mse: 0.3951 - mae: 0.4715 - val_loss: 0.4769 - val_mse: 0.4769 - val_mae: 0.4981\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3853 - mse: 0.3853 - mae: 0.4665 - val_loss: 0.4428 - val_mse: 0.4428 - val_mae: 0.4842\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.3782 - mse: 0.3782 - mae: 0.4606 - val_loss: 0.4899 - val_mse: 0.4899 - val_mae: 0.5005\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3784 - mse: 0.3784 - mae: 0.4595 - val_loss: 0.4559 - val_mse: 0.4559 - val_mae: 0.4940\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3770 - mse: 0.3770 - mae: 0.4611 - val_loss: 0.5167 - val_mse: 0.5167 - val_mae: 0.5018\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3717 - mse: 0.3717 - mae: 0.4575 - val_loss: 0.5280 - val_mse: 0.5280 - val_mae: 0.5224\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3763 - mse: 0.3763 - mae: 0.4582 - val_loss: 0.4849 - val_mse: 0.4849 - val_mae: 0.5021\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.3717 - mse: 0.3717 - mae: 0.4583 - val_loss: 0.5019 - val_mse: 0.5019 - val_mae: 0.5072\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3642 - mse: 0.3642 - mae: 0.4521 - val_loss: 0.4817 - val_mse: 0.4817 - val_mae: 0.4999\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3670 - mse: 0.3670 - mae: 0.4515 - val_loss: 0.5367 - val_mse: 0.5367 - val_mae: 0.5420\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3572 - mse: 0.3572 - mae: 0.4491 - val_loss: 0.4508 - val_mse: 0.4508 - val_mae: 0.4858\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3609 - mse: 0.3609 - mae: 0.4532 - val_loss: 0.4914 - val_mse: 0.4914 - val_mae: 0.5077\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 141us/sample - loss: 0.7375 - mse: 0.7375 - mae: 0.6435 - val_loss: 0.6744 - val_mse: 0.6744 - val_mae: 0.5959\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.5870 - mse: 0.5870 - mae: 0.5728 - val_loss: 0.6078 - val_mse: 0.6078 - val_mae: 0.5471\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.5363 - mse: 0.5363 - mae: 0.5503 - val_loss: 0.6961 - val_mse: 0.6961 - val_mae: 0.5678\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.5188 - mse: 0.5188 - mae: 0.5389 - val_loss: 0.5573 - val_mse: 0.5573 - val_mae: 0.5393\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.5083 - mse: 0.5083 - mae: 0.5313 - val_loss: 0.5458 - val_mse: 0.5458 - val_mae: 0.5478\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4932 - mse: 0.4932 - mae: 0.5258 - val_loss: 0.8297 - val_mse: 0.8297 - val_mae: 0.5355\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4694 - mse: 0.4694 - mae: 0.5120 - val_loss: 0.5458 - val_mse: 0.5458 - val_mae: 0.5143\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4666 - mse: 0.4666 - mae: 0.5101 - val_loss: 0.5985 - val_mse: 0.5985 - val_mae: 0.5180\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4475 - mse: 0.4475 - mae: 0.5031 - val_loss: 0.6037 - val_mse: 0.6037 - val_mae: 0.5284\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4445 - mse: 0.4445 - mae: 0.4990 - val_loss: 0.5203 - val_mse: 0.5203 - val_mae: 0.5174\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4251 - mse: 0.4251 - mae: 0.4880 - val_loss: 0.5941 - val_mse: 0.5941 - val_mae: 0.5320\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.4251 - mse: 0.4251 - mae: 0.4923 - val_loss: 0.5287 - val_mse: 0.5287 - val_mae: 0.5047\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4275 - mse: 0.4275 - mae: 0.4914 - val_loss: 0.6393 - val_mse: 0.6393 - val_mae: 0.5197\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4073 - mse: 0.4073 - mae: 0.4792 - val_loss: 0.5327 - val_mse: 0.5327 - val_mae: 0.5064\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4108 - mse: 0.4108 - mae: 0.4794 - val_loss: 0.5490 - val_mse: 0.5490 - val_mae: 0.5067\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4111 - mse: 0.4111 - mae: 0.4792 - val_loss: 0.5743 - val_mse: 0.5743 - val_mae: 0.5109\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4105 - mse: 0.4105 - mae: 0.4826 - val_loss: 0.5868 - val_mse: 0.5868 - val_mae: 0.5298\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4086 - mse: 0.4086 - mae: 0.4804 - val_loss: 0.5237 - val_mse: 0.5237 - val_mae: 0.4967\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3931 - mse: 0.3931 - mae: 0.4716 - val_loss: 0.5275 - val_mse: 0.5275 - val_mae: 0.5192\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.3857 - mse: 0.3857 - mae: 0.4671 - val_loss: 0.5683 - val_mse: 0.5683 - val_mae: 0.5091\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 138us/sample - loss: 0.7340 - mse: 0.7340 - mae: 0.6379 - val_loss: 0.6130 - val_mse: 0.6130 - val_mae: 0.6016\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.5920 - mse: 0.5920 - mae: 0.5719 - val_loss: 0.5499 - val_mse: 0.5499 - val_mae: 0.5507\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.5417 - mse: 0.5417 - mae: 0.5475 - val_loss: 0.5812 - val_mse: 0.5812 - val_mae: 0.5586\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.5223 - mse: 0.5223 - mae: 0.5406 - val_loss: 0.5176 - val_mse: 0.5176 - val_mae: 0.5184\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4964 - mse: 0.4964 - mae: 0.5248 - val_loss: 0.4975 - val_mse: 0.4975 - val_mae: 0.5170\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4849 - mse: 0.4849 - mae: 0.5193 - val_loss: 0.4815 - val_mse: 0.4815 - val_mae: 0.5133\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4675 - mse: 0.4675 - mae: 0.5124 - val_loss: 0.5223 - val_mse: 0.5223 - val_mae: 0.5105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4560 - mse: 0.4560 - mae: 0.5056 - val_loss: 0.5174 - val_mse: 0.5174 - val_mae: 0.5222\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4493 - mse: 0.4493 - mae: 0.5040 - val_loss: 0.5018 - val_mse: 0.5018 - val_mae: 0.5259\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4409 - mse: 0.4409 - mae: 0.4977 - val_loss: 0.5185 - val_mse: 0.5185 - val_mae: 0.5201\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4239 - mse: 0.4239 - mae: 0.4889 - val_loss: 0.4660 - val_mse: 0.4660 - val_mae: 0.5003\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4257 - mse: 0.4257 - mae: 0.4892 - val_loss: 0.4962 - val_mse: 0.4962 - val_mae: 0.5093\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4190 - mse: 0.4190 - mae: 0.4864 - val_loss: 0.4704 - val_mse: 0.4704 - val_mae: 0.5127\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - ETA: 0s - loss: 0.4121 - mse: 0.4121 - mae: 0.481 - 1s 58us/sample - loss: 0.4138 - mse: 0.4138 - mae: 0.4823 - val_loss: 0.5079 - val_mse: 0.5079 - val_mae: 0.5353\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4168 - mse: 0.4168 - mae: 0.4847 - val_loss: 0.4536 - val_mse: 0.4536 - val_mae: 0.4929\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.4066 - mse: 0.4066 - mae: 0.4796 - val_loss: 0.4829 - val_mse: 0.4829 - val_mae: 0.4980\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4030 - mse: 0.4030 - mae: 0.4751 - val_loss: 0.4639 - val_mse: 0.4639 - val_mae: 0.5072\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3943 - mse: 0.3943 - mae: 0.4729 - val_loss: 0.4923 - val_mse: 0.4923 - val_mae: 0.5123\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3994 - mse: 0.3994 - mae: 0.4735 - val_loss: 0.4976 - val_mse: 0.4976 - val_mae: 0.5209\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3910 - mse: 0.3910 - mae: 0.4714 - val_loss: 0.5018 - val_mse: 0.5018 - val_mae: 0.5258\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.3827 - mse: 0.3827 - mae: 0.4673 - val_loss: 0.4957 - val_mse: 0.4957 - val_mae: 0.5024\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.3829 - mse: 0.3829 - mae: 0.4667 - val_loss: 0.4769 - val_mse: 0.4769 - val_mae: 0.5043\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3820 - mse: 0.3820 - mae: 0.4626 - val_loss: 0.5389 - val_mse: 0.5389 - val_mae: 0.5183\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3694 - mse: 0.3694 - mae: 0.4590 - val_loss: 0.4718 - val_mse: 0.4718 - val_mae: 0.5062\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3676 - mse: 0.3676 - mae: 0.4582 - val_loss: 0.4762 - val_mse: 0.4762 - val_mae: 0.4938\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 141us/sample - loss: 0.7217 - mse: 0.7217 - mae: 0.6351 - val_loss: 0.6359 - val_mse: 0.6359 - val_mae: 0.5997\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.6018 - mse: 0.6018 - mae: 0.5759 - val_loss: 0.5541 - val_mse: 0.5541 - val_mae: 0.5556\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.5488 - mse: 0.5488 - mae: 0.5516 - val_loss: 0.5900 - val_mse: 0.5900 - val_mae: 0.5714\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.5161 - mse: 0.5161 - mae: 0.5339 - val_loss: 0.5207 - val_mse: 0.5207 - val_mae: 0.5351\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.5019 - mse: 0.5019 - mae: 0.5272 - val_loss: 0.5528 - val_mse: 0.5528 - val_mae: 0.5305\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4896 - mse: 0.4896 - mae: 0.5203 - val_loss: 0.5275 - val_mse: 0.5275 - val_mae: 0.5084\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.4740 - mse: 0.4740 - mae: 0.5131 - val_loss: 0.5508 - val_mse: 0.5508 - val_mae: 0.5281\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4605 - mse: 0.4605 - mae: 0.5058 - val_loss: 0.6259 - val_mse: 0.6259 - val_mae: 0.5286\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4549 - mse: 0.4549 - mae: 0.5006 - val_loss: 0.5408 - val_mse: 0.5408 - val_mae: 0.5099\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4409 - mse: 0.4409 - mae: 0.4968 - val_loss: 0.6300 - val_mse: 0.6300 - val_mae: 0.5103\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4344 - mse: 0.4344 - mae: 0.4925 - val_loss: 0.5356 - val_mse: 0.5356 - val_mae: 0.5246\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4273 - mse: 0.4273 - mae: 0.4918 - val_loss: 0.5826 - val_mse: 0.5826 - val_mae: 0.5241\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4200 - mse: 0.4200 - mae: 0.4832 - val_loss: 0.6444 - val_mse: 0.6444 - val_mae: 0.5118\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4172 - mse: 0.4172 - mae: 0.4797 - val_loss: 0.5503 - val_mse: 0.5503 - val_mae: 0.4975\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 142us/sample - loss: 0.7289 - mse: 0.7289 - mae: 0.6358 - val_loss: 0.5986 - val_mse: 0.5986 - val_mae: 0.5698\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.5871 - mse: 0.5871 - mae: 0.5738 - val_loss: 0.5910 - val_mse: 0.5910 - val_mae: 0.5508\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.5409 - mse: 0.5409 - mae: 0.5513 - val_loss: 0.5329 - val_mse: 0.5329 - val_mae: 0.5275\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.5198 - mse: 0.5198 - mae: 0.5383 - val_loss: 0.5402 - val_mse: 0.5402 - val_mae: 0.5336\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.4985 - mse: 0.4985 - mae: 0.5284 - val_loss: 0.5077 - val_mse: 0.5077 - val_mae: 0.5201\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.4920 - mse: 0.4920 - mae: 0.5242 - val_loss: 0.4900 - val_mse: 0.4900 - val_mae: 0.5016\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.4769 - mse: 0.4769 - mae: 0.5186 - val_loss: 0.5158 - val_mse: 0.5158 - val_mae: 0.5409\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.4621 - mse: 0.4621 - mae: 0.5078 - val_loss: 0.4946 - val_mse: 0.4946 - val_mae: 0.5075\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.4525 - mse: 0.4525 - mae: 0.5040 - val_loss: 0.4890 - val_mse: 0.4890 - val_mae: 0.5093\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.4451 - mse: 0.4451 - mae: 0.4983 - val_loss: 0.4905 - val_mse: 0.4905 - val_mae: 0.5068\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.4334 - mse: 0.4334 - mae: 0.4931 - val_loss: 0.5003 - val_mse: 0.5003 - val_mae: 0.5345\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.4358 - mse: 0.4358 - mae: 0.4935 - val_loss: 0.4790 - val_mse: 0.4790 - val_mae: 0.4963\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.4215 - mse: 0.4215 - mae: 0.4883 - val_loss: 0.4769 - val_mse: 0.4769 - val_mae: 0.4924\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.4136 - mse: 0.4136 - mae: 0.4838 - val_loss: 0.5111 - val_mse: 0.5111 - val_mae: 0.5114\n",
      "Epoch 15/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.4092 - mse: 0.4092 - mae: 0.4810 - val_loss: 0.4878 - val_mse: 0.4878 - val_mae: 0.4861\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.4033 - mse: 0.4033 - mae: 0.4779 - val_loss: 0.4866 - val_mse: 0.4866 - val_mae: 0.4967\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.4063 - mse: 0.4063 - mae: 0.4796 - val_loss: 0.4655 - val_mse: 0.4655 - val_mae: 0.4907\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.4038 - mse: 0.4038 - mae: 0.4790 - val_loss: 0.4643 - val_mse: 0.4643 - val_mae: 0.4974\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3863 - mse: 0.3863 - mae: 0.4664 - val_loss: 0.4518 - val_mse: 0.4518 - val_mae: 0.4826\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3809 - mse: 0.3809 - mae: 0.4660 - val_loss: 0.4886 - val_mse: 0.4886 - val_mae: 0.4874\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3841 - mse: 0.3841 - mae: 0.4651 - val_loss: 0.4489 - val_mse: 0.4489 - val_mae: 0.4852\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3858 - mse: 0.3858 - mae: 0.4663 - val_loss: 0.4588 - val_mse: 0.4588 - val_mae: 0.4877\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3842 - mse: 0.3842 - mae: 0.4642 - val_loss: 0.4686 - val_mse: 0.4686 - val_mae: 0.4901\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3806 - mse: 0.3806 - mae: 0.4669 - val_loss: 0.5409 - val_mse: 0.5409 - val_mae: 0.5041\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3709 - mse: 0.3709 - mae: 0.4557 - val_loss: 0.4910 - val_mse: 0.4910 - val_mae: 0.5016\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3767 - mse: 0.3767 - mae: 0.4621 - val_loss: 0.4689 - val_mse: 0.4689 - val_mae: 0.4912\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3766 - mse: 0.3766 - mae: 0.4624 - val_loss: 0.4805 - val_mse: 0.4805 - val_mae: 0.5087\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3652 - mse: 0.3652 - mae: 0.4563 - val_loss: 0.4545 - val_mse: 0.4545 - val_mae: 0.4900\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3689 - mse: 0.3689 - mae: 0.4579 - val_loss: 0.4498 - val_mse: 0.4498 - val_mae: 0.4729\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3637 - mse: 0.3637 - mae: 0.4550 - val_loss: 0.4568 - val_mse: 0.4568 - val_mae: 0.4804\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3551 - mse: 0.3551 - mae: 0.4496 - val_loss: 0.4696 - val_mse: 0.4696 - val_mae: 0.4919\n",
      "Avg. MAE: 0.443356\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 163us/sample - loss: 3.0380 - mse: 3.0380 - mae: 1.1811 - val_loss: 2.1585 - val_mse: 2.1585 - val_mae: 1.2738\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.9803 - mse: 0.9803 - mae: 0.7033 - val_loss: 1.6177 - val_mse: 1.6177 - val_mae: 1.0895\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.5877 - mse: 0.5877 - mae: 0.5635 - val_loss: 1.0613 - val_mse: 1.0613 - val_mae: 0.8621\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.4675 - mse: 0.4675 - mae: 0.5085 - val_loss: 0.9731 - val_mse: 0.9731 - val_mae: 0.8132\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.4077 - mse: 0.4077 - mae: 0.4779 - val_loss: 0.6758 - val_mse: 0.6758 - val_mae: 0.6622\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.3724 - mse: 0.3724 - mae: 0.4586 - val_loss: 0.6124 - val_mse: 0.6124 - val_mae: 0.6237\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.3467 - mse: 0.3467 - mae: 0.4412 - val_loss: 0.4949 - val_mse: 0.4949 - val_mae: 0.5443\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.3432 - mse: 0.3432 - mae: 0.4352 - val_loss: 0.4834 - val_mse: 0.4834 - val_mae: 0.5318\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.3521 - mse: 0.3521 - mae: 0.4419 - val_loss: 0.4846 - val_mse: 0.4846 - val_mae: 0.5302\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.3381 - mse: 0.3381 - mae: 0.4272 - val_loss: 0.4705 - val_mse: 0.4705 - val_mae: 0.5178\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.3355 - mse: 0.3355 - mae: 0.4302 - val_loss: 0.5206 - val_mse: 0.5206 - val_mae: 0.5317\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.3014 - mse: 0.3014 - mae: 0.4085 - val_loss: 0.4720 - val_mse: 0.4720 - val_mae: 0.5125\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2891 - mse: 0.2891 - mae: 0.4012 - val_loss: 0.4479 - val_mse: 0.4479 - val_mae: 0.5041\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2814 - mse: 0.2814 - mae: 0.3934 - val_loss: 0.4469 - val_mse: 0.4469 - val_mae: 0.5000\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2700 - mse: 0.2700 - mae: 0.3889 - val_loss: 0.4525 - val_mse: 0.4525 - val_mae: 0.4970\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.2857 - mse: 0.2857 - mae: 0.3931 - val_loss: 0.4824 - val_mse: 0.4824 - val_mae: 0.5062\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.3192 - mse: 0.3192 - mae: 0.4165 - val_loss: 0.4308 - val_mse: 0.4308 - val_mae: 0.4790\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2544 - mse: 0.2544 - mae: 0.3769 - val_loss: 0.4730 - val_mse: 0.4730 - val_mae: 0.4982\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2715 - mse: 0.2715 - mae: 0.3902 - val_loss: 0.4662 - val_mse: 0.4662 - val_mae: 0.4962\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2377 - mse: 0.2377 - mae: 0.3633 - val_loss: 0.4602 - val_mse: 0.4602 - val_mae: 0.4779\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2198 - mse: 0.2198 - mae: 0.3498 - val_loss: 0.4740 - val_mse: 0.4740 - val_mae: 0.4945\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2185 - mse: 0.2185 - mae: 0.3506 - val_loss: 0.4214 - val_mse: 0.4214 - val_mae: 0.4738\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2249 - mse: 0.2249 - mae: 0.3546 - val_loss: 0.4281 - val_mse: 0.4281 - val_mae: 0.4902\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2365 - mse: 0.2365 - mae: 0.3659 - val_loss: 0.4316 - val_mse: 0.4316 - val_mae: 0.4850\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2293 - mse: 0.2293 - mae: 0.3566 - val_loss: 0.4765 - val_mse: 0.4765 - val_mae: 0.5005\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 105us/sample - loss: 0.2416 - mse: 0.2416 - mae: 0.3651 - val_loss: 0.4393 - val_mse: 0.4393 - val_mae: 0.4936\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2239 - mse: 0.2239 - mae: 0.3503 - val_loss: 0.4772 - val_mse: 0.4772 - val_mae: 0.4990\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2161 - mse: 0.2161 - mae: 0.3437 - val_loss: 0.4354 - val_mse: 0.4354 - val_mae: 0.4817\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2152 - mse: 0.2152 - mae: 0.3454 - val_loss: 0.4372 - val_mse: 0.4372 - val_mae: 0.4830\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2081 - mse: 0.2081 - mae: 0.3416 - val_loss: 0.4528 - val_mse: 0.4528 - val_mae: 0.4920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2052 - mse: 0.2052 - mae: 0.3364 - val_loss: 0.4771 - val_mse: 0.4771 - val_mae: 0.5004\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 109us/sample - loss: 0.2146 - mse: 0.2146 - mae: 0.3459 - val_loss: 0.4430 - val_mse: 0.4430 - val_mae: 0.4851\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 191us/sample - loss: 3.2094 - mse: 3.2094 - mae: 1.2473 - val_loss: 1.6270 - val_mse: 1.6270 - val_mae: 1.0122\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.8970 - mse: 0.8970 - mae: 0.6831 - val_loss: 1.1337 - val_mse: 1.1337 - val_mae: 0.8573\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.5547 - mse: 0.5547 - mae: 0.5473 - val_loss: 1.1513 - val_mse: 1.1513 - val_mae: 0.8854\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.4815 - mse: 0.4815 - mae: 0.5195 - val_loss: 0.8164 - val_mse: 0.8164 - val_mae: 0.7316\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.4521 - mse: 0.4521 - mae: 0.5050 - val_loss: 0.7868 - val_mse: 0.7868 - val_mae: 0.6946\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.3694 - mse: 0.3694 - mae: 0.4579 - val_loss: 0.5722 - val_mse: 0.5722 - val_mae: 0.5724\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.3537 - mse: 0.3537 - mae: 0.4446 - val_loss: 0.6011 - val_mse: 0.6011 - val_mae: 0.5824\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.3684 - mse: 0.3684 - mae: 0.4543 - val_loss: 0.6511 - val_mse: 0.6511 - val_mae: 0.5570\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.3575 - mse: 0.3575 - mae: 0.4420 - val_loss: 0.5923 - val_mse: 0.5923 - val_mae: 0.5440\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.3405 - mse: 0.3405 - mae: 0.4303 - val_loss: 0.5549 - val_mse: 0.5549 - val_mae: 0.5574\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.4032 - mse: 0.4032 - mae: 0.4578 - val_loss: 0.5106 - val_mse: 0.5106 - val_mae: 0.5283\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.3930 - mse: 0.3930 - mae: 0.4531 - val_loss: 0.4873 - val_mse: 0.4873 - val_mae: 0.5075\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.3282 - mse: 0.3282 - mae: 0.4255 - val_loss: 0.5030 - val_mse: 0.5030 - val_mae: 0.5247\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2994 - mse: 0.2994 - mae: 0.4119 - val_loss: 0.4667 - val_mse: 0.4667 - val_mae: 0.4839\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2615 - mse: 0.2615 - mae: 0.3837 - val_loss: 0.4953 - val_mse: 0.4953 - val_mae: 0.5038\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2393 - mse: 0.2393 - mae: 0.3686 - val_loss: 0.4745 - val_mse: 0.4745 - val_mae: 0.4859\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2444 - mse: 0.2444 - mae: 0.3735 - val_loss: 0.4902 - val_mse: 0.4902 - val_mae: 0.5208\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2535 - mse: 0.2535 - mae: 0.3757 - val_loss: 0.4677 - val_mse: 0.4677 - val_mae: 0.4835\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2622 - mse: 0.2622 - mae: 0.3784 - val_loss: 0.4903 - val_mse: 0.4903 - val_mae: 0.5020\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2456 - mse: 0.2456 - mae: 0.3734 - val_loss: 0.4469 - val_mse: 0.4469 - val_mae: 0.4876\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2392 - mse: 0.2392 - mae: 0.3659 - val_loss: 0.4542 - val_mse: 0.4542 - val_mae: 0.4778\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2294 - mse: 0.2294 - mae: 0.3572 - val_loss: 0.4704 - val_mse: 0.4704 - val_mae: 0.4893\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2361 - mse: 0.2361 - mae: 0.3636 - val_loss: 0.4488 - val_mse: 0.4488 - val_mae: 0.4924\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2279 - mse: 0.2279 - mae: 0.3573 - val_loss: 0.4743 - val_mse: 0.4743 - val_mae: 0.4959\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2257 - mse: 0.2257 - mae: 0.3603 - val_loss: 0.4460 - val_mse: 0.4460 - val_mae: 0.4677\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2118 - mse: 0.2118 - mae: 0.3456 - val_loss: 0.4782 - val_mse: 0.4782 - val_mae: 0.4894\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2253 - mse: 0.2253 - mae: 0.3521 - val_loss: 0.4857 - val_mse: 0.4857 - val_mae: 0.5074\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2852 - mse: 0.2852 - mae: 0.3870 - val_loss: 0.5156 - val_mse: 0.5156 - val_mae: 0.5023\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2681 - mse: 0.2681 - mae: 0.3786 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.4768\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2527 - mse: 0.2527 - mae: 0.3695 - val_loss: 0.4747 - val_mse: 0.4747 - val_mae: 0.4873\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.1937 - mse: 0.1937 - mae: 0.3313 - val_loss: 0.4303 - val_mse: 0.4303 - val_mae: 0.4703\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.1798 - mse: 0.1798 - mae: 0.3191 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4629\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.1795 - mse: 0.1795 - mae: 0.3187 - val_loss: 0.4659 - val_mse: 0.4659 - val_mae: 0.4852\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.1774 - mse: 0.1774 - mae: 0.3156 - val_loss: 0.4423 - val_mse: 0.4423 - val_mae: 0.4559\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.1798 - mse: 0.1798 - mae: 0.3208 - val_loss: 0.4779 - val_mse: 0.4779 - val_mae: 0.4708\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.1802 - mse: 0.1802 - mae: 0.3170 - val_loss: 0.5633 - val_mse: 0.5633 - val_mae: 0.4782\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.1928 - mse: 0.1928 - mae: 0.3249 - val_loss: 0.4913 - val_mse: 0.4913 - val_mae: 0.4969\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2122 - mse: 0.2122 - mae: 0.3395 - val_loss: 0.5973 - val_mse: 0.5973 - val_mae: 0.5512\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2540 - mse: 0.2540 - mae: 0.3706 - val_loss: 0.4709 - val_mse: 0.4709 - val_mae: 0.5064\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2123 - mse: 0.2123 - mae: 0.3456 - val_loss: 0.4493 - val_mse: 0.4493 - val_mae: 0.4701\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.1963 - mse: 0.1963 - mae: 0.3310 - val_loss: 0.5111 - val_mse: 0.5111 - val_mae: 0.4859\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 166us/sample - loss: 2.7461 - mse: 2.7461 - mae: 1.1492 - val_loss: 2.4677 - val_mse: 2.4677 - val_mae: 1.3524\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 1.1930 - mse: 1.1930 - mae: 0.7356 - val_loss: 1.0965 - val_mse: 1.0965 - val_mae: 0.8243\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.7295 - mse: 0.7295 - mae: 0.5945 - val_loss: 1.1456 - val_mse: 1.1456 - val_mae: 0.8886\n",
      "Epoch 4/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.5831 - mse: 0.5831 - mae: 0.5684 - val_loss: 0.8404 - val_mse: 0.8404 - val_mae: 0.7382\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.4114 - mse: 0.4114 - mae: 0.4771 - val_loss: 0.7241 - val_mse: 0.7241 - val_mae: 0.6928\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.3854 - mse: 0.3854 - mae: 0.4636 - val_loss: 0.6239 - val_mse: 0.6239 - val_mae: 0.6337\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.3484 - mse: 0.3484 - mae: 0.4406 - val_loss: 0.5628 - val_mse: 0.5628 - val_mae: 0.5865\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.3397 - mse: 0.3397 - mae: 0.4309 - val_loss: 0.5425 - val_mse: 0.5425 - val_mae: 0.5483\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.3666 - mse: 0.3666 - mae: 0.4467 - val_loss: 0.5868 - val_mse: 0.5868 - val_mae: 0.5616\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.3872 - mse: 0.3872 - mae: 0.4515 - val_loss: 0.7405 - val_mse: 0.7405 - val_mae: 0.5778\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.3731 - mse: 0.3731 - mae: 0.4534 - val_loss: 0.4795 - val_mse: 0.4795 - val_mae: 0.5072\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2871 - mse: 0.2871 - mae: 0.4036 - val_loss: 0.4511 - val_mse: 0.4511 - val_mae: 0.4886\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2684 - mse: 0.2684 - mae: 0.3919 - val_loss: 0.4546 - val_mse: 0.4546 - val_mae: 0.4966\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 105us/sample - loss: 0.2520 - mse: 0.2520 - mae: 0.3777 - val_loss: 0.4359 - val_mse: 0.4359 - val_mae: 0.4685\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2498 - mse: 0.2498 - mae: 0.3772 - val_loss: 0.4603 - val_mse: 0.4603 - val_mae: 0.4952\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2520 - mse: 0.2520 - mae: 0.3780 - val_loss: 0.4401 - val_mse: 0.4401 - val_mae: 0.4719\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2744 - mse: 0.2744 - mae: 0.3870 - val_loss: 0.5045 - val_mse: 0.5045 - val_mae: 0.4969\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.3387 - mse: 0.3387 - mae: 0.4354 - val_loss: 0.4511 - val_mse: 0.4511 - val_mae: 0.4876\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2790 - mse: 0.2790 - mae: 0.3882 - val_loss: 0.5988 - val_mse: 0.5988 - val_mae: 0.5563\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.3134 - mse: 0.3134 - mae: 0.4180 - val_loss: 0.5279 - val_mse: 0.5279 - val_mae: 0.5063\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2751 - mse: 0.2751 - mae: 0.3912 - val_loss: 0.5043 - val_mse: 0.5043 - val_mae: 0.4943\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2272 - mse: 0.2272 - mae: 0.3568 - val_loss: 0.4310 - val_mse: 0.4310 - val_mae: 0.4716\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2443 - mse: 0.2443 - mae: 0.3763 - val_loss: 0.4670 - val_mse: 0.4670 - val_mae: 0.4876\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2217 - mse: 0.2217 - mae: 0.3523 - val_loss: 0.4974 - val_mse: 0.4974 - val_mae: 0.4844\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2347 - mse: 0.2347 - mae: 0.3627 - val_loss: 0.4891 - val_mse: 0.4891 - val_mae: 0.5182\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2411 - mse: 0.2411 - mae: 0.3640 - val_loss: 0.4965 - val_mse: 0.4965 - val_mae: 0.4933\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.2383 - mse: 0.2383 - mae: 0.3595 - val_loss: 0.4476 - val_mse: 0.4476 - val_mae: 0.4808\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2426 - mse: 0.2426 - mae: 0.3623 - val_loss: 0.4551 - val_mse: 0.4551 - val_mae: 0.4923\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2470 - mse: 0.2470 - mae: 0.3676 - val_loss: 0.4712 - val_mse: 0.4712 - val_mae: 0.5016\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2091 - mse: 0.2091 - mae: 0.3433 - val_loss: 0.4481 - val_mse: 0.4481 - val_mae: 0.4720\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.1987 - mse: 0.1987 - mae: 0.3326 - val_loss: 0.4441 - val_mse: 0.4441 - val_mae: 0.4757\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2098 - mse: 0.2098 - mae: 0.3466 - val_loss: 0.4341 - val_mse: 0.4341 - val_mae: 0.4752\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 162us/sample - loss: 2.9879 - mse: 2.9879 - mae: 1.1925 - val_loss: 1.2375 - val_mse: 1.2375 - val_mae: 0.8946\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.8558 - mse: 0.8558 - mae: 0.6655 - val_loss: 1.1853 - val_mse: 1.1853 - val_mae: 0.9094\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.7054 - mse: 0.7054 - mae: 0.6005 - val_loss: 1.0252 - val_mse: 1.0252 - val_mae: 0.8227\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.7975 - mse: 0.7975 - mae: 0.6283 - val_loss: 1.0018 - val_mse: 1.0018 - val_mae: 0.8264\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.5760 - mse: 0.5760 - mae: 0.5535 - val_loss: 0.7034 - val_mse: 0.7034 - val_mae: 0.6711\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.4076 - mse: 0.4076 - mae: 0.4709 - val_loss: 0.6054 - val_mse: 0.6054 - val_mae: 0.5961\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.3549 - mse: 0.3549 - mae: 0.4458 - val_loss: 0.5647 - val_mse: 0.5647 - val_mae: 0.5821\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.3183 - mse: 0.3183 - mae: 0.4244 - val_loss: 0.5152 - val_mse: 0.5152 - val_mae: 0.5568\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.3024 - mse: 0.3024 - mae: 0.4156 - val_loss: 0.5283 - val_mse: 0.5283 - val_mae: 0.5413\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2903 - mse: 0.2903 - mae: 0.4075 - val_loss: 0.5231 - val_mse: 0.5231 - val_mae: 0.5386\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2832 - mse: 0.2832 - mae: 0.4014 - val_loss: 0.5130 - val_mse: 0.5130 - val_mae: 0.5194\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2743 - mse: 0.2743 - mae: 0.3937 - val_loss: 0.4703 - val_mse: 0.4703 - val_mae: 0.5075\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2635 - mse: 0.2635 - mae: 0.3889 - val_loss: 0.5219 - val_mse: 0.5219 - val_mae: 0.5210\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.2682 - mse: 0.2682 - mae: 0.3881 - val_loss: 0.5122 - val_mse: 0.5122 - val_mae: 0.5134\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.3327 - mse: 0.3327 - mae: 0.4245 - val_loss: 0.5369 - val_mse: 0.5369 - val_mae: 0.5364\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2943 - mse: 0.2943 - mae: 0.4055 - val_loss: 0.5126 - val_mse: 0.5126 - val_mae: 0.5298\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2871 - mse: 0.2871 - mae: 0.3970 - val_loss: 0.4977 - val_mse: 0.4977 - val_mae: 0.4972\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2689 - mse: 0.2689 - mae: 0.3871 - val_loss: 0.5522 - val_mse: 0.5522 - val_mae: 0.5050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.3584 - mse: 0.3584 - mae: 0.4279 - val_loss: 0.6110 - val_mse: 0.6110 - val_mae: 0.5646\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.3660 - mse: 0.3660 - mae: 0.4397 - val_loss: 0.4656 - val_mse: 0.4656 - val_mae: 0.4989\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2361 - mse: 0.2361 - mae: 0.3612 - val_loss: 0.4535 - val_mse: 0.4535 - val_mae: 0.4854\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2447 - mse: 0.2447 - mae: 0.3733 - val_loss: 0.5090 - val_mse: 0.5090 - val_mae: 0.4963\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2296 - mse: 0.2296 - mae: 0.3581 - val_loss: 0.4954 - val_mse: 0.4954 - val_mae: 0.5184\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2333 - mse: 0.2333 - mae: 0.3654 - val_loss: 0.4672 - val_mse: 0.4672 - val_mae: 0.4988\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2074 - mse: 0.2074 - mae: 0.3437 - val_loss: 0.4100 - val_mse: 0.4100 - val_mae: 0.4591\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.1882 - mse: 0.1882 - mae: 0.3242 - val_loss: 0.4655 - val_mse: 0.4655 - val_mae: 0.4830\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.1920 - mse: 0.1920 - mae: 0.3242 - val_loss: 0.4150 - val_mse: 0.4150 - val_mae: 0.4752\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2139 - mse: 0.2139 - mae: 0.3431 - val_loss: 0.5912 - val_mse: 0.5912 - val_mae: 0.5316\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2933 - mse: 0.2933 - mae: 0.4052 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.4729\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2523 - mse: 0.2523 - mae: 0.3666 - val_loss: 0.5150 - val_mse: 0.5150 - val_mae: 0.5338\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2431 - mse: 0.2431 - mae: 0.3607 - val_loss: 0.6785 - val_mse: 0.6785 - val_mae: 0.5549\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.3205 - mse: 0.3205 - mae: 0.4108 - val_loss: 0.5435 - val_mse: 0.5435 - val_mae: 0.4896\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2307 - mse: 0.2307 - mae: 0.3546 - val_loss: 0.4568 - val_mse: 0.4568 - val_mae: 0.4828\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.1958 - mse: 0.1958 - mae: 0.3321 - val_loss: 0.4167 - val_mse: 0.4167 - val_mae: 0.4727\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.1796 - mse: 0.1796 - mae: 0.3208 - val_loss: 0.4505 - val_mse: 0.4505 - val_mae: 0.4690\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 167us/sample - loss: 2.5654 - mse: 2.5654 - mae: 1.1290 - val_loss: 1.1612 - val_mse: 1.1612 - val_mae: 0.8067\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 1s 100us/sample - loss: 1.0003 - mse: 1.0003 - mae: 0.7030 - val_loss: 1.0175 - val_mse: 1.0175 - val_mae: 0.7690\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.7933 - mse: 0.7933 - mae: 0.6275 - val_loss: 0.9387 - val_mse: 0.9387 - val_mae: 0.7805\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.5817 - mse: 0.5817 - mae: 0.5558 - val_loss: 0.8946 - val_mse: 0.8946 - val_mae: 0.7469\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 1s 99us/sample - loss: 0.4740 - mse: 0.4740 - mae: 0.5145 - val_loss: 0.6839 - val_mse: 0.6839 - val_mae: 0.6463\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 1s 99us/sample - loss: 0.4201 - mse: 0.4201 - mae: 0.4797 - val_loss: 0.7015 - val_mse: 0.7015 - val_mae: 0.6238\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.4258 - mse: 0.4258 - mae: 0.4843 - val_loss: 0.6466 - val_mse: 0.6466 - val_mae: 0.6118\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.3406 - mse: 0.3406 - mae: 0.4384 - val_loss: 0.6142 - val_mse: 0.6142 - val_mae: 0.5574\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.3149 - mse: 0.3149 - mae: 0.4242 - val_loss: 0.5305 - val_mse: 0.5305 - val_mae: 0.5506\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.3077 - mse: 0.3077 - mae: 0.4213 - val_loss: 0.4607 - val_mse: 0.4607 - val_mae: 0.5126\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 101us/sample - loss: 0.2979 - mse: 0.2979 - mae: 0.4151 - val_loss: 0.4957 - val_mse: 0.4957 - val_mae: 0.5216\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 99us/sample - loss: 0.2855 - mse: 0.2855 - mae: 0.4041 - val_loss: 0.4653 - val_mse: 0.4653 - val_mae: 0.4959\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 1s 97us/sample - loss: 0.2832 - mse: 0.2832 - mae: 0.4030 - val_loss: 0.4538 - val_mse: 0.4538 - val_mae: 0.4878\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 1s 99us/sample - loss: 0.2792 - mse: 0.2792 - mae: 0.3964 - val_loss: 0.4833 - val_mse: 0.4833 - val_mae: 0.4936\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.3014 - mse: 0.3014 - mae: 0.4094 - val_loss: 0.4911 - val_mse: 0.4911 - val_mae: 0.4977\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.2957 - mse: 0.2957 - mae: 0.4033 - val_loss: 0.4790 - val_mse: 0.4790 - val_mae: 0.4889\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 1s 99us/sample - loss: 0.3007 - mse: 0.3007 - mae: 0.4093 - val_loss: 0.6084 - val_mse: 0.6084 - val_mae: 0.5336\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.3494 - mse: 0.3494 - mae: 0.4398 - val_loss: 0.5057 - val_mse: 0.5057 - val_mae: 0.5016\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 1s 97us/sample - loss: 0.2717 - mse: 0.2717 - mae: 0.3896 - val_loss: 0.5207 - val_mse: 0.5207 - val_mae: 0.5235\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.2876 - mse: 0.2876 - mae: 0.3984 - val_loss: 0.4231 - val_mse: 0.4231 - val_mae: 0.4657\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 1s 100us/sample - loss: 0.2386 - mse: 0.2386 - mae: 0.3621 - val_loss: 0.5673 - val_mse: 0.5673 - val_mae: 0.4843\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 1s 99us/sample - loss: 0.2387 - mse: 0.2387 - mae: 0.3646 - val_loss: 0.4242 - val_mse: 0.4242 - val_mae: 0.4690\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 1s 97us/sample - loss: 0.2155 - mse: 0.2155 - mae: 0.3470 - val_loss: 0.4914 - val_mse: 0.4914 - val_mae: 0.4747\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 1s 99us/sample - loss: 0.2333 - mse: 0.2333 - mae: 0.3582 - val_loss: 0.4259 - val_mse: 0.4259 - val_mae: 0.4724\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 1s 100us/sample - loss: 0.2564 - mse: 0.2564 - mae: 0.3701 - val_loss: 0.4537 - val_mse: 0.4537 - val_mae: 0.4906\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.2515 - mse: 0.2515 - mae: 0.3746 - val_loss: 0.5073 - val_mse: 0.5073 - val_mae: 0.4853\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 1s 99us/sample - loss: 0.2359 - mse: 0.2359 - mae: 0.3576 - val_loss: 0.6513 - val_mse: 0.6513 - val_mae: 0.5105\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.2367 - mse: 0.2367 - mae: 0.3591 - val_loss: 0.5087 - val_mse: 0.5087 - val_mae: 0.4747\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.2348 - mse: 0.2348 - mae: 0.3580 - val_loss: 0.5118 - val_mse: 0.5118 - val_mae: 0.5064\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 1s 100us/sample - loss: 0.2543 - mse: 0.2543 - mae: 0.3699 - val_loss: 0.4938 - val_mse: 0.4938 - val_mae: 0.5131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. MAE: 0.412624\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 21s 2ms/sample - loss: 67.9188 - mse: 67.9188 - mae: 3.3051 - val_loss: 18769.4384 - val_mse: 18769.4395 - val_mae: 106.5516\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 1.0340 - mse: 1.0340 - mae: 0.7548 - val_loss: 45.5841 - val_mse: 45.5841 - val_mae: 6.4065\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.8351 - mse: 0.8351 - mae: 0.6731 - val_loss: 11.2101 - val_mse: 11.2101 - val_mae: 3.0514\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.7453 - mse: 0.7453 - mae: 0.6433 - val_loss: 4.3054 - val_mse: 4.3054 - val_mae: 1.8452\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6885 - mse: 0.6885 - mae: 0.6154 - val_loss: 2.6107 - val_mse: 2.6107 - val_mae: 1.4534\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6730 - mse: 0.6730 - mae: 0.6104 - val_loss: 1.3746 - val_mse: 1.3746 - val_mae: 0.9743\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6286 - mse: 0.6286 - mae: 0.5872 - val_loss: 0.7483 - val_mse: 0.7483 - val_mae: 0.6852\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5932 - mse: 0.5932 - mae: 0.5761 - val_loss: 0.7812 - val_mse: 0.7812 - val_mae: 0.7112\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5855 - mse: 0.5855 - mae: 0.5714 - val_loss: 0.7887 - val_mse: 0.7887 - val_mae: 0.6823\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5635 - mse: 0.5635 - mae: 0.5562 - val_loss: 0.7782 - val_mse: 0.7782 - val_mae: 0.6946\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5095 - mse: 0.5095 - mae: 0.5300 - val_loss: 0.6280 - val_mse: 0.6280 - val_mae: 0.5924\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5165 - mse: 0.5165 - mae: 0.5367 - val_loss: 0.5665 - val_mse: 0.5665 - val_mae: 0.5750\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4769 - mse: 0.4769 - mae: 0.5124 - val_loss: 0.5624 - val_mse: 0.5624 - val_mae: 0.5569\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4200 - mse: 0.4200 - mae: 0.4827 - val_loss: 0.4981 - val_mse: 0.4981 - val_mae: 0.5191\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4035 - mse: 0.4035 - mae: 0.4747 - val_loss: 0.5158 - val_mse: 0.5158 - val_mae: 0.5293\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4165 - mse: 0.4165 - mae: 0.4781 - val_loss: 0.4878 - val_mse: 0.4878 - val_mae: 0.5175\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3956 - mse: 0.3956 - mae: 0.4631 - val_loss: 0.4727 - val_mse: 0.4727 - val_mae: 0.5036\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3618 - mse: 0.3618 - mae: 0.4506 - val_loss: 0.5651 - val_mse: 0.5651 - val_mae: 0.5454\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3286 - mse: 0.3286 - mae: 0.4277 - val_loss: 0.5203 - val_mse: 0.5203 - val_mae: 0.5380\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3227 - mse: 0.3227 - mae: 0.4189 - val_loss: 0.4777 - val_mse: 0.4777 - val_mae: 0.5136\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3424 - mse: 0.3424 - mae: 0.4343 - val_loss: 0.4847 - val_mse: 0.4847 - val_mae: 0.5091\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3412 - mse: 0.3412 - mae: 0.4371 - val_loss: 0.5505 - val_mse: 0.5505 - val_mae: 0.5622\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3001 - mse: 0.3001 - mae: 0.4140 - val_loss: 0.5519 - val_mse: 0.5519 - val_mae: 0.5560\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3209 - mse: 0.3209 - mae: 0.4199 - val_loss: 0.8550 - val_mse: 0.8550 - val_mae: 0.6368\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3535 - mse: 0.3535 - mae: 0.4273 - val_loss: 0.4448 - val_mse: 0.4448 - val_mae: 0.4973\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2882 - mse: 0.2882 - mae: 0.4030 - val_loss: 0.5099 - val_mse: 0.5099 - val_mae: 0.5275\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3037 - mse: 0.3037 - mae: 0.4146 - val_loss: 0.5110 - val_mse: 0.5110 - val_mae: 0.4974\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2384 - mse: 0.2384 - mae: 0.3637 - val_loss: 0.4949 - val_mse: 0.4949 - val_mae: 0.5246\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3161 - mse: 0.3161 - mae: 0.4188 - val_loss: 0.4749 - val_mse: 0.4749 - val_mae: 0.4923\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2226 - mse: 0.2226 - mae: 0.3568 - val_loss: 0.4261 - val_mse: 0.4261 - val_mae: 0.4703\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2721 - mse: 0.2721 - mae: 0.3830 - val_loss: 0.4311 - val_mse: 0.4311 - val_mae: 0.4740\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2332 - mse: 0.2332 - mae: 0.3550 - val_loss: 0.4354 - val_mse: 0.4354 - val_mae: 0.4721\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2075 - mse: 0.2075 - mae: 0.3463 - val_loss: 0.4392 - val_mse: 0.4392 - val_mae: 0.4853\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2481 - mse: 0.2481 - mae: 0.3651 - val_loss: 0.5101 - val_mse: 0.5101 - val_mae: 0.5101\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2888 - mse: 0.2888 - mae: 0.3959 - val_loss: 0.4061 - val_mse: 0.4061 - val_mae: 0.4641\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2548 - mse: 0.2548 - mae: 0.3829 - val_loss: 0.6269 - val_mse: 0.6269 - val_mae: 0.5831\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.1930 - mse: 0.1930 - mae: 0.3316 - val_loss: 0.4414 - val_mse: 0.4414 - val_mae: 0.4909\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2502 - mse: 0.2502 - mae: 0.3723 - val_loss: 0.5608 - val_mse: 0.5608 - val_mae: 0.5404\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2298 - mse: 0.2298 - mae: 0.3614 - val_loss: 0.4216 - val_mse: 0.4216 - val_mae: 0.4856\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2402 - mse: 0.2402 - mae: 0.3460 - val_loss: 1.1383 - val_mse: 1.1383 - val_mae: 0.6661\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3847 - mse: 0.3847 - mae: 0.4037 - val_loss: 0.5607 - val_mse: 0.5607 - val_mae: 0.5425\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.1895 - mse: 0.1895 - mae: 0.3244 - val_loss: 0.5395 - val_mse: 0.5395 - val_mae: 0.5489\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2012 - mse: 0.2012 - mae: 0.3257 - val_loss: 0.5492 - val_mse: 0.5492 - val_mae: 0.5157\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.1917 - mse: 0.1917 - mae: 0.3308 - val_loss: 0.4899 - val_mse: 0.4899 - val_mae: 0.4859\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3196 - mse: 0.3196 - mae: 0.4043 - val_loss: 0.4231 - val_mse: 0.4231 - val_mae: 0.4704\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 20s 2ms/sample - loss: 54.5754 - mse: 54.5754 - mae: 2.8975 - val_loss: 15457.7551 - val_mse: 15457.7539 - val_mae: 100.5120\n",
      "Epoch 2/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.9508 - mse: 0.9508 - mae: 0.7370 - val_loss: 60.7646 - val_mse: 60.7646 - val_mae: 5.7835\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.7581 - mse: 0.7581 - mae: 0.6564 - val_loss: 11.4168 - val_mse: 11.4168 - val_mae: 2.9229\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.7264 - mse: 0.7264 - mae: 0.6404 - val_loss: 3.1531 - val_mse: 3.1531 - val_mae: 1.5689\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.7037 - mse: 0.7037 - mae: 0.6253 - val_loss: 2.9436 - val_mse: 2.9436 - val_mae: 1.4764\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6894 - mse: 0.6894 - mae: 0.6294 - val_loss: 1.2105 - val_mse: 1.2105 - val_mae: 0.9272\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6301 - mse: 0.6301 - mae: 0.5919 - val_loss: 0.8815 - val_mse: 0.8815 - val_mae: 0.7139\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6296 - mse: 0.6296 - mae: 0.5920 - val_loss: 0.8523 - val_mse: 0.8523 - val_mae: 0.6553\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5671 - mse: 0.5671 - mae: 0.5619 - val_loss: 1.0249 - val_mse: 1.0249 - val_mae: 0.7200\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5762 - mse: 0.5762 - mae: 0.5690 - val_loss: 0.6008 - val_mse: 0.6008 - val_mae: 0.5591\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5643 - mse: 0.5643 - mae: 0.5611 - val_loss: 0.6812 - val_mse: 0.6812 - val_mae: 0.5800\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5024 - mse: 0.5024 - mae: 0.5316 - val_loss: 0.6725 - val_mse: 0.6725 - val_mae: 0.5673\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5015 - mse: 0.5015 - mae: 0.5305 - val_loss: 0.6427 - val_mse: 0.6427 - val_mae: 0.5709\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5161 - mse: 0.5161 - mae: 0.5408 - val_loss: 0.7660 - val_mse: 0.7660 - val_mae: 0.6020\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4461 - mse: 0.4461 - mae: 0.4952 - val_loss: 0.5267 - val_mse: 0.5267 - val_mae: 0.5182\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4220 - mse: 0.4220 - mae: 0.4907 - val_loss: 0.6847 - val_mse: 0.6847 - val_mae: 0.5660\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4309 - mse: 0.4309 - mae: 0.4889 - val_loss: 0.6661 - val_mse: 0.6661 - val_mae: 0.5989\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3849 - mse: 0.3849 - mae: 0.4706 - val_loss: 0.5250 - val_mse: 0.5250 - val_mae: 0.5183\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3885 - mse: 0.3885 - mae: 0.4693 - val_loss: 0.8150 - val_mse: 0.8150 - val_mae: 0.6181\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4046 - mse: 0.4046 - mae: 0.4656 - val_loss: 0.5908 - val_mse: 0.5908 - val_mae: 0.5282\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3274 - mse: 0.3274 - mae: 0.4312 - val_loss: 0.7513 - val_mse: 0.7513 - val_mae: 0.6122\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3524 - mse: 0.3524 - mae: 0.4383 - val_loss: 0.5681 - val_mse: 0.5681 - val_mae: 0.5265\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3425 - mse: 0.3425 - mae: 0.4376 - val_loss: 0.8539 - val_mse: 0.8539 - val_mae: 0.6582\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3286 - mse: 0.3286 - mae: 0.4266 - val_loss: 0.6600 - val_mse: 0.6600 - val_mae: 0.5466\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3080 - mse: 0.3080 - mae: 0.4144 - val_loss: 0.5686 - val_mse: 0.5686 - val_mae: 0.5561\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3236 - mse: 0.3236 - mae: 0.4208 - val_loss: 0.5146 - val_mse: 0.5146 - val_mae: 0.5132\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3202 - mse: 0.3202 - mae: 0.4241 - val_loss: 0.5943 - val_mse: 0.5943 - val_mae: 0.5557\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3587 - mse: 0.3587 - mae: 0.4197 - val_loss: 0.5995 - val_mse: 0.5995 - val_mae: 0.5369\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3129 - mse: 0.3129 - mae: 0.4145 - val_loss: 0.6703 - val_mse: 0.6703 - val_mae: 0.5400\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4108 - mse: 0.4108 - mae: 0.4614 - val_loss: 0.5824 - val_mse: 0.5824 - val_mae: 0.5407\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3084 - mse: 0.3084 - mae: 0.3999 - val_loss: 0.5252 - val_mse: 0.5252 - val_mae: 0.5133\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2699 - mse: 0.2699 - mae: 0.3932 - val_loss: 0.5052 - val_mse: 0.5052 - val_mae: 0.5058\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2802 - mse: 0.2802 - mae: 0.3908 - val_loss: 0.5156 - val_mse: 0.5156 - val_mae: 0.5233\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2614 - mse: 0.2614 - mae: 0.3770 - val_loss: 0.5525 - val_mse: 0.5525 - val_mae: 0.5064\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2638 - mse: 0.2638 - mae: 0.3868 - val_loss: 0.6651 - val_mse: 0.6651 - val_mae: 0.5526\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3892 - mse: 0.3892 - mae: 0.4216 - val_loss: 0.6374 - val_mse: 0.6374 - val_mae: 0.5773\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4156 - mse: 0.4156 - mae: 0.4310 - val_loss: 0.5270 - val_mse: 0.5270 - val_mae: 0.5131\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2816 - mse: 0.2816 - mae: 0.3740 - val_loss: 0.7946 - val_mse: 0.7946 - val_mae: 0.6395\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2865 - mse: 0.2865 - mae: 0.3968 - val_loss: 0.5095 - val_mse: 0.5095 - val_mae: 0.4900\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2013 - mse: 0.2013 - mae: 0.3421 - val_loss: 0.5431 - val_mse: 0.5431 - val_mae: 0.4918\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2582 - mse: 0.2582 - mae: 0.3671 - val_loss: 0.8977 - val_mse: 0.8977 - val_mae: 0.5960\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2793 - mse: 0.2793 - mae: 0.3772 - val_loss: 0.4897 - val_mse: 0.4897 - val_mae: 0.5005\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2421 - mse: 0.2421 - mae: 0.3511 - val_loss: 0.4754 - val_mse: 0.4754 - val_mae: 0.5022\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2262 - mse: 0.2262 - mae: 0.3536 - val_loss: 0.8340 - val_mse: 0.8340 - val_mae: 0.6817\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3405 - mse: 0.3405 - mae: 0.4402 - val_loss: 0.8442 - val_mse: 0.8442 - val_mae: 0.5685\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2585 - mse: 0.2585 - mae: 0.3778 - val_loss: 0.4838 - val_mse: 0.4838 - val_mae: 0.4734\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2377 - mse: 0.2377 - mae: 0.3541 - val_loss: 0.7584 - val_mse: 0.7584 - val_mae: 0.6297\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.1948 - mse: 0.1948 - mae: 0.3335 - val_loss: 0.5161 - val_mse: 0.5161 - val_mae: 0.4901\n",
      "Epoch 49/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2679 - mse: 0.2679 - mae: 0.3627 - val_loss: 0.4262 - val_mse: 0.4262 - val_mae: 0.4529\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2015 - mse: 0.2015 - mae: 0.3317 - val_loss: 0.7014 - val_mse: 0.7014 - val_mae: 0.5939\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2133 - mse: 0.2133 - mae: 0.3419 - val_loss: 0.4657 - val_mse: 0.4657 - val_mae: 0.4712\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2106 - mse: 0.2106 - mae: 0.3376 - val_loss: 0.4691 - val_mse: 0.4691 - val_mae: 0.4858\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.1749 - mse: 0.1749 - mae: 0.3086 - val_loss: 0.5461 - val_mse: 0.5461 - val_mae: 0.4924\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2040 - mse: 0.2040 - mae: 0.3297 - val_loss: 0.7777 - val_mse: 0.7777 - val_mae: 0.5484\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3006 - mse: 0.3006 - mae: 0.3675 - val_loss: 0.5452 - val_mse: 0.5452 - val_mae: 0.5358\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.1774 - mse: 0.1774 - mae: 0.3176 - val_loss: 0.5921 - val_mse: 0.5921 - val_mae: 0.5569\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.1981 - mse: 0.1981 - mae: 0.3271 - val_loss: 0.4847 - val_mse: 0.4847 - val_mae: 0.4972\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2491 - mse: 0.2491 - mae: 0.3585 - val_loss: 0.8774 - val_mse: 0.8774 - val_mae: 0.6320\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3181 - mse: 0.3181 - mae: 0.3827 - val_loss: 0.6859 - val_mse: 0.6859 - val_mae: 0.6204\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 21s 2ms/sample - loss: 76.8681 - mse: 76.8681 - mae: 3.5553 - val_loss: 18827.8850 - val_mse: 18827.8848 - val_mae: 115.7728\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 20s 2ms/sample - loss: 1.0277 - mse: 1.0277 - mae: 0.7561 - val_loss: 42.9191 - val_mse: 42.9191 - val_mae: 5.4719\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.8309 - mse: 0.8309 - mae: 0.6870 - val_loss: 8.5535 - val_mse: 8.5535 - val_mae: 2.5449\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.8083 - mse: 0.8083 - mae: 0.6703 - val_loss: 3.0638 - val_mse: 3.0638 - val_mae: 1.5723\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.7719 - mse: 0.7719 - mae: 0.6574 - val_loss: 1.8567 - val_mse: 1.8567 - val_mae: 1.1505\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.7843 - mse: 0.7843 - mae: 0.6671 - val_loss: 1.4167 - val_mse: 1.4167 - val_mae: 0.9796\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.7468 - mse: 0.7468 - mae: 0.6341 - val_loss: 0.7614 - val_mse: 0.7614 - val_mae: 0.6913\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.7075 - mse: 0.7075 - mae: 0.6235 - val_loss: 0.8279 - val_mse: 0.8279 - val_mae: 0.6634\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6792 - mse: 0.6792 - mae: 0.6093 - val_loss: 0.7798 - val_mse: 0.7798 - val_mae: 0.6615\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6767 - mse: 0.6767 - mae: 0.6101 - val_loss: 0.6605 - val_mse: 0.6605 - val_mae: 0.6091\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6196 - mse: 0.6196 - mae: 0.5832 - val_loss: 0.6395 - val_mse: 0.6395 - val_mae: 0.5946\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6201 - mse: 0.6201 - mae: 0.5832 - val_loss: 0.7301 - val_mse: 0.7301 - val_mae: 0.5931\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6012 - mse: 0.6012 - mae: 0.5737 - val_loss: 0.7238 - val_mse: 0.7238 - val_mae: 0.5943\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5560 - mse: 0.5560 - mae: 0.5538 - val_loss: 0.5918 - val_mse: 0.5918 - val_mae: 0.5817\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5517 - mse: 0.5517 - mae: 0.5543 - val_loss: 0.6984 - val_mse: 0.6984 - val_mae: 0.6092\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5093 - mse: 0.5093 - mae: 0.5315 - val_loss: 0.6606 - val_mse: 0.6606 - val_mae: 0.5780\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4944 - mse: 0.4944 - mae: 0.5185 - val_loss: 0.6379 - val_mse: 0.6379 - val_mae: 0.5852\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5033 - mse: 0.5033 - mae: 0.5233 - val_loss: 0.5284 - val_mse: 0.5284 - val_mae: 0.5279\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4545 - mse: 0.4545 - mae: 0.4956 - val_loss: 0.6062 - val_mse: 0.6062 - val_mae: 0.5816\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4117 - mse: 0.4117 - mae: 0.4776 - val_loss: 0.5323 - val_mse: 0.5323 - val_mae: 0.5370\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4248 - mse: 0.4248 - mae: 0.4950 - val_loss: 0.7585 - val_mse: 0.7585 - val_mae: 0.5717\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4825 - mse: 0.4825 - mae: 0.4993 - val_loss: 0.5458 - val_mse: 0.5458 - val_mae: 0.5149\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3771 - mse: 0.3771 - mae: 0.4580 - val_loss: 0.5586 - val_mse: 0.5586 - val_mae: 0.5331\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4172 - mse: 0.4172 - mae: 0.4772 - val_loss: 0.4983 - val_mse: 0.4983 - val_mae: 0.5091\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3693 - mse: 0.3693 - mae: 0.4577 - val_loss: 0.5165 - val_mse: 0.5165 - val_mae: 0.5004\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3583 - mse: 0.3583 - mae: 0.4431 - val_loss: 0.6894 - val_mse: 0.6894 - val_mae: 0.5559\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3450 - mse: 0.3450 - mae: 0.4353 - val_loss: 0.4650 - val_mse: 0.4650 - val_mae: 0.4889\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3480 - mse: 0.3480 - mae: 0.4401 - val_loss: 0.5118 - val_mse: 0.5118 - val_mae: 0.5169\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3629 - mse: 0.3629 - mae: 0.4327 - val_loss: 0.4591 - val_mse: 0.4591 - val_mae: 0.4975\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3795 - mse: 0.3795 - mae: 0.4405 - val_loss: 0.6073 - val_mse: 0.6073 - val_mae: 0.5370\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3508 - mse: 0.3508 - mae: 0.4322 - val_loss: 0.6472 - val_mse: 0.6472 - val_mae: 0.5996\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3159 - mse: 0.3159 - mae: 0.4144 - val_loss: 0.5284 - val_mse: 0.5284 - val_mae: 0.4925\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3257 - mse: 0.3257 - mae: 0.4015 - val_loss: 0.4376 - val_mse: 0.4376 - val_mae: 0.4817\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2673 - mse: 0.2673 - mae: 0.3780 - val_loss: 0.4732 - val_mse: 0.4732 - val_mae: 0.5045\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2758 - mse: 0.2758 - mae: 0.3892 - val_loss: 0.6110 - val_mse: 0.6110 - val_mae: 0.5229\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2868 - mse: 0.2868 - mae: 0.3934 - val_loss: 0.6536 - val_mse: 0.6536 - val_mae: 0.5888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2638 - mse: 0.2638 - mae: 0.3766 - val_loss: 0.4387 - val_mse: 0.4387 - val_mae: 0.4709\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2372 - mse: 0.2372 - mae: 0.3603 - val_loss: 0.4549 - val_mse: 0.4549 - val_mae: 0.4826\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3126 - mse: 0.3126 - mae: 0.3880 - val_loss: 0.7094 - val_mse: 0.7094 - val_mae: 0.5301\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3324 - mse: 0.3324 - mae: 0.3906 - val_loss: 0.5696 - val_mse: 0.5696 - val_mae: 0.5236\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2188 - mse: 0.2188 - mae: 0.3481 - val_loss: 0.7498 - val_mse: 0.7498 - val_mae: 0.5482\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2346 - mse: 0.2346 - mae: 0.3609 - val_loss: 0.4378 - val_mse: 0.4378 - val_mae: 0.4686\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.1920 - mse: 0.1920 - mae: 0.3317 - val_loss: 0.4764 - val_mse: 0.4764 - val_mae: 0.5177\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 20s 2ms/sample - loss: 84.4291 - mse: 84.4291 - mae: 3.3280 - val_loss: 5005.0765 - val_mse: 5005.0767 - val_mae: 54.0698\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.9326 - mse: 0.9326 - mae: 0.7328 - val_loss: 5.5868 - val_mse: 5.5868 - val_mae: 2.0906\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.8279 - mse: 0.8279 - mae: 0.6896 - val_loss: 2.4883 - val_mse: 2.4883 - val_mae: 1.3732\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.7771 - mse: 0.7771 - mae: 0.6625 - val_loss: 1.5204 - val_mse: 1.5204 - val_mae: 1.0590\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.7396 - mse: 0.7396 - mae: 0.6453 - val_loss: 1.0667 - val_mse: 1.0667 - val_mae: 0.8667\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.7022 - mse: 0.7022 - mae: 0.6289 - val_loss: 0.7046 - val_mse: 0.7046 - val_mae: 0.6412\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6735 - mse: 0.6735 - mae: 0.6154 - val_loss: 0.7861 - val_mse: 0.7861 - val_mae: 0.7206\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6270 - mse: 0.6270 - mae: 0.5906 - val_loss: 0.6622 - val_mse: 0.6622 - val_mae: 0.6361\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.6228 - mse: 0.6228 - mae: 0.5904 - val_loss: 0.5910 - val_mse: 0.5910 - val_mae: 0.5745\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5846 - mse: 0.5846 - mae: 0.5703 - val_loss: 0.6420 - val_mse: 0.6420 - val_mae: 0.6149\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5554 - mse: 0.5554 - mae: 0.5581 - val_loss: 0.5854 - val_mse: 0.5854 - val_mae: 0.5543\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5293 - mse: 0.5293 - mae: 0.5463 - val_loss: 0.5659 - val_mse: 0.5659 - val_mae: 0.5522\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.5306 - mse: 0.5306 - mae: 0.5478 - val_loss: 0.7557 - val_mse: 0.7557 - val_mae: 0.6176\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4981 - mse: 0.4981 - mae: 0.5299 - val_loss: 0.6047 - val_mse: 0.6047 - val_mae: 0.5661\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4322 - mse: 0.4322 - mae: 0.4921 - val_loss: 0.5484 - val_mse: 0.5484 - val_mae: 0.5405\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.4376 - mse: 0.4376 - mae: 0.4936 - val_loss: 0.4950 - val_mse: 0.4950 - val_mae: 0.5082\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3999 - mse: 0.3999 - mae: 0.4707 - val_loss: 0.5854 - val_mse: 0.5854 - val_mae: 0.5540\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3765 - mse: 0.3765 - mae: 0.4605 - val_loss: 0.4751 - val_mse: 0.4751 - val_mae: 0.4950\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3515 - mse: 0.3515 - mae: 0.4441 - val_loss: 0.5904 - val_mse: 0.5904 - val_mae: 0.5646\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3521 - mse: 0.3521 - mae: 0.4469 - val_loss: 0.5381 - val_mse: 0.5381 - val_mae: 0.5315\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3452 - mse: 0.3452 - mae: 0.4394 - val_loss: 0.4886 - val_mse: 0.4886 - val_mae: 0.5185\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3717 - mse: 0.3717 - mae: 0.4574 - val_loss: 0.5659 - val_mse: 0.5659 - val_mae: 0.5416\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3132 - mse: 0.3132 - mae: 0.4251 - val_loss: 0.4608 - val_mse: 0.4608 - val_mae: 0.4895\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3129 - mse: 0.3129 - mae: 0.4185 - val_loss: 0.4776 - val_mse: 0.4776 - val_mae: 0.5032\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3430 - mse: 0.3430 - mae: 0.4421 - val_loss: 0.4314 - val_mse: 0.4314 - val_mae: 0.4815\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2853 - mse: 0.2853 - mae: 0.4023 - val_loss: 0.4245 - val_mse: 0.4245 - val_mae: 0.4744\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2800 - mse: 0.2800 - mae: 0.3984 - val_loss: 0.6499 - val_mse: 0.6499 - val_mae: 0.6033\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2704 - mse: 0.2704 - mae: 0.3954 - val_loss: 0.5188 - val_mse: 0.5188 - val_mae: 0.5168\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2739 - mse: 0.2739 - mae: 0.3975 - val_loss: 0.4610 - val_mse: 0.4610 - val_mae: 0.5125\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2719 - mse: 0.2719 - mae: 0.3967 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.4674\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2696 - mse: 0.2696 - mae: 0.3884 - val_loss: 0.4926 - val_mse: 0.4926 - val_mae: 0.5023\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2395 - mse: 0.2395 - mae: 0.3697 - val_loss: 0.4505 - val_mse: 0.4505 - val_mae: 0.4881\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3183 - mse: 0.3183 - mae: 0.4291 - val_loss: 0.4500 - val_mse: 0.4500 - val_mae: 0.4913\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.3341 - mse: 0.3341 - mae: 0.4330 - val_loss: 0.4994 - val_mse: 0.4994 - val_mae: 0.5033\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2632 - mse: 0.2632 - mae: 0.3799 - val_loss: 0.4390 - val_mse: 0.4390 - val_mae: 0.4930\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2750 - mse: 0.2750 - mae: 0.3952 - val_loss: 0.4870 - val_mse: 0.4870 - val_mae: 0.5240\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2631 - mse: 0.2631 - mae: 0.3833 - val_loss: 0.6437 - val_mse: 0.6437 - val_mae: 0.5685\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2055 - mse: 0.2055 - mae: 0.3432 - val_loss: 0.4342 - val_mse: 0.4342 - val_mae: 0.4766\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2254 - mse: 0.2254 - mae: 0.3584 - val_loss: 0.4548 - val_mse: 0.4548 - val_mae: 0.4799\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.2135 - mse: 0.2135 - mae: 0.3454 - val_loss: 0.4614 - val_mse: 0.4614 - val_mae: 0.4879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 21s 2ms/sample - loss: 64.4194 - mse: 64.4194 - mae: 2.7243 - val_loss: 5051.0326 - val_mse: 5051.0327 - val_mae: 47.6563\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.9505 - mse: 0.9505 - mae: 0.7401 - val_loss: 28.5437 - val_mse: 28.5437 - val_mae: 3.7990\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.8697 - mse: 0.8697 - mae: 0.7007 - val_loss: 5.3024 - val_mse: 5.3024 - val_mae: 1.8564\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.8329 - mse: 0.8329 - mae: 0.6842 - val_loss: 1.7441 - val_mse: 1.7441 - val_mae: 1.1295\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.7581 - mse: 0.7581 - mae: 0.6545 - val_loss: 1.2162 - val_mse: 1.2162 - val_mae: 0.9479\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.7115 - mse: 0.7115 - mae: 0.6338 - val_loss: 0.8398 - val_mse: 0.8398 - val_mae: 0.7097\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.6893 - mse: 0.6893 - mae: 0.6214 - val_loss: 0.6905 - val_mse: 0.6905 - val_mae: 0.6553\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.6541 - mse: 0.6541 - mae: 0.6052 - val_loss: 0.6989 - val_mse: 0.6989 - val_mae: 0.6508\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.6356 - mse: 0.6356 - mae: 0.5963 - val_loss: 0.6664 - val_mse: 0.6664 - val_mae: 0.6213\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.6058 - mse: 0.6058 - mae: 0.5814 - val_loss: 0.6313 - val_mse: 0.6313 - val_mae: 0.5889\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.5654 - mse: 0.5654 - mae: 0.5689 - val_loss: 0.6887 - val_mse: 0.6887 - val_mae: 0.6038\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.5486 - mse: 0.5486 - mae: 0.5583 - val_loss: 0.8839 - val_mse: 0.8839 - val_mae: 0.6511\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.5395 - mse: 0.5395 - mae: 0.5421 - val_loss: 0.7184 - val_mse: 0.7184 - val_mae: 0.6200\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.4588 - mse: 0.4588 - mae: 0.5127 - val_loss: 0.6241 - val_mse: 0.6241 - val_mae: 0.5850\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.4557 - mse: 0.4557 - mae: 0.5094 - val_loss: 0.6230 - val_mse: 0.6230 - val_mae: 0.5527\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.4088 - mse: 0.4088 - mae: 0.4852 - val_loss: 0.4769 - val_mse: 0.4769 - val_mae: 0.4978\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.4217 - mse: 0.4217 - mae: 0.4943 - val_loss: 0.8476 - val_mse: 0.8476 - val_mae: 0.6691\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.4397 - mse: 0.4397 - mae: 0.5018 - val_loss: 0.6097 - val_mse: 0.6097 - val_mae: 0.5301\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.3941 - mse: 0.3941 - mae: 0.4776 - val_loss: 0.5472 - val_mse: 0.5472 - val_mae: 0.5487\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.4584 - mse: 0.4584 - mae: 0.5010 - val_loss: 0.4614 - val_mse: 0.4614 - val_mae: 0.4853\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.3539 - mse: 0.3539 - mae: 0.4443 - val_loss: 0.5605 - val_mse: 0.5605 - val_mae: 0.5580\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.3485 - mse: 0.3485 - mae: 0.4444 - val_loss: 0.4526 - val_mse: 0.4526 - val_mae: 0.4876\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.3604 - mse: 0.3604 - mae: 0.4498 - val_loss: 0.5712 - val_mse: 0.5712 - val_mae: 0.5672\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.3349 - mse: 0.3349 - mae: 0.4405 - val_loss: 0.5007 - val_mse: 0.5007 - val_mae: 0.5401\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.3246 - mse: 0.3246 - mae: 0.4299 - val_loss: 0.8992 - val_mse: 0.8992 - val_mae: 0.6289\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.2943 - mse: 0.2943 - mae: 0.4093 - val_loss: 0.4535 - val_mse: 0.4535 - val_mae: 0.4685\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.3265 - mse: 0.3265 - mae: 0.4183 - val_loss: 0.5481 - val_mse: 0.5481 - val_mae: 0.5480\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.2840 - mse: 0.2840 - mae: 0.3958 - val_loss: 0.5601 - val_mse: 0.5601 - val_mae: 0.5552\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.2698 - mse: 0.2698 - mae: 0.3952 - val_loss: 0.6645 - val_mse: 0.6645 - val_mae: 0.5294\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.2451 - mse: 0.2451 - mae: 0.3726 - val_loss: 0.5630 - val_mse: 0.5630 - val_mae: 0.5569\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.2686 - mse: 0.2686 - mae: 0.3889 - val_loss: 0.4998 - val_mse: 0.4998 - val_mae: 0.4998\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 0.2646 - mse: 0.2646 - mae: 0.3933 - val_loss: 0.4893 - val_mse: 0.4893 - val_mae: 0.4987\n",
      "Avg. MAE: 0.414944\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 112us/sample - loss: 1.5043 - mse: 1.5043 - mae: 0.8378 - val_loss: 3.4137 - val_mse: 3.4137 - val_mae: 1.6171\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.5313 - mse: 0.5313 - mae: 0.5429 - val_loss: 1.1222 - val_mse: 1.1222 - val_mae: 0.8912\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4531 - mse: 0.4531 - mae: 0.4993 - val_loss: 0.8860 - val_mse: 0.8860 - val_mae: 0.7731\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.4379 - mse: 0.4379 - mae: 0.4934 - val_loss: 0.7627 - val_mse: 0.7627 - val_mae: 0.7074\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3920 - mse: 0.3920 - mae: 0.4663 - val_loss: 0.5931 - val_mse: 0.5931 - val_mae: 0.6075\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3501 - mse: 0.3501 - mae: 0.4439 - val_loss: 0.5190 - val_mse: 0.5190 - val_mae: 0.5661\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3329 - mse: 0.3329 - mae: 0.4315 - val_loss: 0.4831 - val_mse: 0.4831 - val_mae: 0.5359\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3072 - mse: 0.3072 - mae: 0.4116 - val_loss: 0.4618 - val_mse: 0.4618 - val_mae: 0.5244\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3008 - mse: 0.3008 - mae: 0.4107 - val_loss: 0.4276 - val_mse: 0.4276 - val_mae: 0.4956\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - ETA: 0s - loss: 0.2847 - mse: 0.2847 - mae: 0.399 - 0s 28us/sample - loss: 0.2810 - mse: 0.2810 - mae: 0.3970 - val_loss: 0.4107 - val_mse: 0.4107 - val_mae: 0.4777\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2641 - mse: 0.2641 - mae: 0.3850 - val_loss: 0.4462 - val_mse: 0.4462 - val_mae: 0.4939\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2461 - mse: 0.2461 - mae: 0.3727 - val_loss: 0.4106 - val_mse: 0.4106 - val_mae: 0.4798\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2395 - mse: 0.2395 - mae: 0.3706 - val_loss: 0.4360 - val_mse: 0.4360 - val_mae: 0.4772\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2219 - mse: 0.2219 - mae: 0.3545 - val_loss: 0.4147 - val_mse: 0.4147 - val_mae: 0.4697\n",
      "Epoch 15/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2258 - mse: 0.2258 - mae: 0.3602 - val_loss: 0.4171 - val_mse: 0.4171 - val_mae: 0.4708\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2200 - mse: 0.2200 - mae: 0.3524 - val_loss: 0.3921 - val_mse: 0.3921 - val_mae: 0.4551\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2044 - mse: 0.2044 - mae: 0.3397 - val_loss: 0.3886 - val_mse: 0.3886 - val_mae: 0.4547\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1925 - mse: 0.1925 - mae: 0.3285 - val_loss: 0.4199 - val_mse: 0.4199 - val_mae: 0.4727\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1831 - mse: 0.1831 - mae: 0.3241 - val_loss: 0.4010 - val_mse: 0.4010 - val_mae: 0.4581\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1753 - mse: 0.1753 - mae: 0.3151 - val_loss: 0.4156 - val_mse: 0.4156 - val_mae: 0.4723\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1671 - mse: 0.1671 - mae: 0.3096 - val_loss: 0.3977 - val_mse: 0.3977 - val_mae: 0.4612\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1716 - mse: 0.1716 - mae: 0.3121 - val_loss: 0.4134 - val_mse: 0.4134 - val_mae: 0.4705\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1563 - mse: 0.1563 - mae: 0.2988 - val_loss: 0.3833 - val_mse: 0.3833 - val_mae: 0.4540\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1634 - mse: 0.1634 - mae: 0.3054 - val_loss: 0.4385 - val_mse: 0.4385 - val_mae: 0.4880\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1627 - mse: 0.1627 - mae: 0.3046 - val_loss: 0.4006 - val_mse: 0.4006 - val_mae: 0.4588\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1475 - mse: 0.1475 - mae: 0.2904 - val_loss: 0.4117 - val_mse: 0.4117 - val_mae: 0.4669\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1337 - mse: 0.1337 - mae: 0.2766 - val_loss: 0.3714 - val_mse: 0.3714 - val_mae: 0.4399\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1280 - mse: 0.1280 - mae: 0.2687 - val_loss: 0.4061 - val_mse: 0.4061 - val_mae: 0.4696\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1289 - mse: 0.1289 - mae: 0.2719 - val_loss: 0.3895 - val_mse: 0.3895 - val_mae: 0.4531\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1273 - mse: 0.1273 - mae: 0.2697 - val_loss: 0.3918 - val_mse: 0.3918 - val_mae: 0.4566\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1229 - mse: 0.1229 - mae: 0.2626 - val_loss: 0.3934 - val_mse: 0.3934 - val_mae: 0.4510\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1259 - mse: 0.1259 - mae: 0.2681 - val_loss: 0.3937 - val_mse: 0.3937 - val_mae: 0.4564\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1204 - mse: 0.1204 - mae: 0.2621 - val_loss: 0.3912 - val_mse: 0.3912 - val_mae: 0.4514\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1122 - mse: 0.1122 - mae: 0.2525 - val_loss: 0.3829 - val_mse: 0.3829 - val_mae: 0.4479\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1101 - mse: 0.1101 - mae: 0.2493 - val_loss: 0.3838 - val_mse: 0.3838 - val_mae: 0.4440\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1056 - mse: 0.1056 - mae: 0.2455 - val_loss: 0.3780 - val_mse: 0.3780 - val_mae: 0.4401\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1086 - mse: 0.1086 - mae: 0.2497 - val_loss: 0.3785 - val_mse: 0.3785 - val_mae: 0.4458\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 110us/sample - loss: 1.6103 - mse: 1.6103 - mae: 0.8482 - val_loss: 1.8782 - val_mse: 1.8782 - val_mae: 1.0382\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.5363 - mse: 0.5363 - mae: 0.5497 - val_loss: 1.0383 - val_mse: 1.0383 - val_mae: 0.7358\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4604 - mse: 0.4604 - mae: 0.5080 - val_loss: 0.8798 - val_mse: 0.8798 - val_mae: 0.7260\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4226 - mse: 0.4226 - mae: 0.4872 - val_loss: 0.6714 - val_mse: 0.6714 - val_mae: 0.6485\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.3967 - mse: 0.3967 - mae: 0.4726 - val_loss: 0.5895 - val_mse: 0.5895 - val_mae: 0.6080\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.3553 - mse: 0.3553 - mae: 0.4486 - val_loss: 0.5201 - val_mse: 0.5201 - val_mae: 0.5448\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3394 - mse: 0.3394 - mae: 0.4375 - val_loss: 0.4977 - val_mse: 0.4977 - val_mae: 0.5207\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3195 - mse: 0.3195 - mae: 0.4277 - val_loss: 0.5453 - val_mse: 0.5453 - val_mae: 0.5226\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3082 - mse: 0.3082 - mae: 0.4183 - val_loss: 0.5549 - val_mse: 0.5549 - val_mae: 0.5353\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2971 - mse: 0.2971 - mae: 0.4106 - val_loss: 0.4974 - val_mse: 0.4974 - val_mae: 0.5316\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2690 - mse: 0.2690 - mae: 0.3910 - val_loss: 0.4680 - val_mse: 0.4680 - val_mae: 0.4987\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2537 - mse: 0.2537 - mae: 0.3792 - val_loss: 0.4420 - val_mse: 0.4420 - val_mae: 0.4912\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2575 - mse: 0.2575 - mae: 0.3832 - val_loss: 0.4594 - val_mse: 0.4594 - val_mae: 0.4750\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2448 - mse: 0.2448 - mae: 0.3755 - val_loss: 0.4398 - val_mse: 0.4398 - val_mae: 0.4806\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2420 - mse: 0.2420 - mae: 0.3703 - val_loss: 0.4728 - val_mse: 0.4728 - val_mae: 0.4965\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2312 - mse: 0.2312 - mae: 0.3609 - val_loss: 0.4633 - val_mse: 0.4633 - val_mae: 0.4884\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2158 - mse: 0.2158 - mae: 0.3489 - val_loss: 0.4427 - val_mse: 0.4427 - val_mae: 0.4873\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1987 - mse: 0.1987 - mae: 0.3354 - val_loss: 0.4297 - val_mse: 0.4297 - val_mae: 0.4680\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1865 - mse: 0.1865 - mae: 0.3233 - val_loss: 0.4488 - val_mse: 0.4488 - val_mae: 0.4741\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1829 - mse: 0.1829 - mae: 0.3216 - val_loss: 0.4143 - val_mse: 0.4143 - val_mae: 0.4594\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1767 - mse: 0.1767 - mae: 0.3158 - val_loss: 0.4190 - val_mse: 0.4190 - val_mae: 0.4658\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1723 - mse: 0.1723 - mae: 0.3113 - val_loss: 0.4579 - val_mse: 0.4579 - val_mae: 0.4936\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1854 - mse: 0.1854 - mae: 0.3253 - val_loss: 0.4651 - val_mse: 0.4651 - val_mae: 0.4935\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1616 - mse: 0.1616 - mae: 0.3046 - val_loss: 0.4127 - val_mse: 0.4127 - val_mae: 0.4590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1465 - mse: 0.1465 - mae: 0.2901 - val_loss: 0.4067 - val_mse: 0.4067 - val_mae: 0.4548\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1416 - mse: 0.1416 - mae: 0.2828 - val_loss: 0.4320 - val_mse: 0.4320 - val_mae: 0.4685\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1566 - mse: 0.1566 - mae: 0.2957 - val_loss: 0.4229 - val_mse: 0.4229 - val_mae: 0.4564\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1391 - mse: 0.1391 - mae: 0.2809 - val_loss: 0.4214 - val_mse: 0.4214 - val_mae: 0.4542\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1350 - mse: 0.1350 - mae: 0.2780 - val_loss: 0.4320 - val_mse: 0.4320 - val_mae: 0.4670\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1312 - mse: 0.1312 - mae: 0.2753 - val_loss: 0.3904 - val_mse: 0.3904 - val_mae: 0.4397\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1228 - mse: 0.1228 - mae: 0.2648 - val_loss: 0.4007 - val_mse: 0.4007 - val_mae: 0.4513\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1264 - mse: 0.1264 - mae: 0.2683 - val_loss: 0.3924 - val_mse: 0.3924 - val_mae: 0.4483\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1300 - mse: 0.1300 - mae: 0.2733 - val_loss: 0.4143 - val_mse: 0.4143 - val_mae: 0.4561\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1216 - mse: 0.1216 - mae: 0.2630 - val_loss: 0.4181 - val_mse: 0.4181 - val_mae: 0.4496\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1148 - mse: 0.1148 - mae: 0.2560 - val_loss: 0.4012 - val_mse: 0.4012 - val_mae: 0.4444\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1097 - mse: 0.1097 - mae: 0.2514 - val_loss: 0.4342 - val_mse: 0.4342 - val_mae: 0.4621\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1139 - mse: 0.1139 - mae: 0.2557 - val_loss: 0.4595 - val_mse: 0.4595 - val_mae: 0.4788\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1097 - mse: 0.1097 - mae: 0.2507 - val_loss: 0.4254 - val_mse: 0.4254 - val_mae: 0.4583\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1007 - mse: 0.1007 - mae: 0.2424 - val_loss: 0.3996 - val_mse: 0.3996 - val_mae: 0.4422\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1031 - mse: 0.1031 - mae: 0.2409 - val_loss: 0.4088 - val_mse: 0.4088 - val_mae: 0.4506\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 109us/sample - loss: 1.4913 - mse: 1.4913 - mae: 0.8203 - val_loss: 4.7699 - val_mse: 4.7699 - val_mae: 1.9743\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.5305 - mse: 0.5305 - mae: 0.5421 - val_loss: 2.0557 - val_mse: 2.0557 - val_mae: 1.2627\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4600 - mse: 0.4600 - mae: 0.5067 - val_loss: 1.2052 - val_mse: 1.2052 - val_mae: 0.9373\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4159 - mse: 0.4159 - mae: 0.4808 - val_loss: 0.8607 - val_mse: 0.8607 - val_mae: 0.7731\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3892 - mse: 0.3892 - mae: 0.4664 - val_loss: 0.6052 - val_mse: 0.6052 - val_mae: 0.6161\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.3879 - mse: 0.3879 - mae: 0.4621 - val_loss: 0.5077 - val_mse: 0.5077 - val_mae: 0.5522\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3259 - mse: 0.3259 - mae: 0.4256 - val_loss: 0.4540 - val_mse: 0.4540 - val_mae: 0.5050\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3175 - mse: 0.3175 - mae: 0.4196 - val_loss: 0.4580 - val_mse: 0.4580 - val_mae: 0.5050\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2890 - mse: 0.2890 - mae: 0.4025 - val_loss: 0.4645 - val_mse: 0.4645 - val_mae: 0.5147\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2743 - mse: 0.2743 - mae: 0.3910 - val_loss: 0.4845 - val_mse: 0.4845 - val_mae: 0.5013\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2677 - mse: 0.2677 - mae: 0.3880 - val_loss: 0.3967 - val_mse: 0.3967 - val_mae: 0.4583\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2573 - mse: 0.2573 - mae: 0.3813 - val_loss: 0.4255 - val_mse: 0.4255 - val_mae: 0.4738\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2566 - mse: 0.2566 - mae: 0.3793 - val_loss: 0.4187 - val_mse: 0.4187 - val_mae: 0.4704\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2270 - mse: 0.2270 - mae: 0.3576 - val_loss: 0.3933 - val_mse: 0.3933 - val_mae: 0.4510\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2131 - mse: 0.2131 - mae: 0.3485 - val_loss: 0.4122 - val_mse: 0.4122 - val_mae: 0.4651\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2228 - mse: 0.2228 - mae: 0.3565 - val_loss: 0.4082 - val_mse: 0.4082 - val_mae: 0.4547\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.2071 - mse: 0.2071 - mae: 0.3418 - val_loss: 0.4167 - val_mse: 0.4167 - val_mae: 0.4618\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1950 - mse: 0.1950 - mae: 0.3322 - val_loss: 0.3939 - val_mse: 0.3939 - val_mae: 0.4518\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1794 - mse: 0.1794 - mae: 0.3197 - val_loss: 0.4138 - val_mse: 0.4138 - val_mae: 0.4521\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1767 - mse: 0.1767 - mae: 0.3174 - val_loss: 0.4329 - val_mse: 0.4329 - val_mae: 0.4500\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1762 - mse: 0.1762 - mae: 0.3182 - val_loss: 0.4073 - val_mse: 0.4073 - val_mae: 0.4499\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1612 - mse: 0.1612 - mae: 0.3018 - val_loss: 0.4139 - val_mse: 0.4139 - val_mae: 0.4705\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1609 - mse: 0.1609 - mae: 0.3035 - val_loss: 0.4038 - val_mse: 0.4038 - val_mae: 0.4602\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1584 - mse: 0.1584 - mae: 0.3003 - val_loss: 0.3847 - val_mse: 0.3847 - val_mae: 0.4449\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1504 - mse: 0.1504 - mae: 0.2928 - val_loss: 0.4001 - val_mse: 0.4001 - val_mae: 0.4550\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1444 - mse: 0.1444 - mae: 0.2904 - val_loss: 0.4089 - val_mse: 0.4089 - val_mae: 0.4483\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1398 - mse: 0.1398 - mae: 0.2838 - val_loss: 0.3854 - val_mse: 0.3854 - val_mae: 0.4431\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1424 - mse: 0.1424 - mae: 0.2853 - val_loss: 0.3810 - val_mse: 0.3810 - val_mae: 0.4382\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1332 - mse: 0.1332 - mae: 0.2771 - val_loss: 0.4168 - val_mse: 0.4168 - val_mae: 0.4480\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1323 - mse: 0.1323 - mae: 0.2745 - val_loss: 0.3973 - val_mse: 0.3973 - val_mae: 0.4431\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1276 - mse: 0.1276 - mae: 0.2698 - val_loss: 0.4027 - val_mse: 0.4027 - val_mae: 0.4526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1226 - mse: 0.1226 - mae: 0.2631 - val_loss: 0.4059 - val_mse: 0.4059 - val_mae: 0.4539\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1244 - mse: 0.1244 - mae: 0.2682 - val_loss: 0.3943 - val_mse: 0.3943 - val_mae: 0.4456\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1107 - mse: 0.1107 - mae: 0.2520 - val_loss: 0.3805 - val_mse: 0.3805 - val_mae: 0.4337\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1114 - mse: 0.1114 - mae: 0.2522 - val_loss: 0.3879 - val_mse: 0.3879 - val_mae: 0.4428\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1088 - mse: 0.1088 - mae: 0.2507 - val_loss: 0.3894 - val_mse: 0.3894 - val_mae: 0.4362\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1076 - mse: 0.1076 - mae: 0.2501 - val_loss: 0.3893 - val_mse: 0.3893 - val_mae: 0.4347\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0991 - mse: 0.0991 - mae: 0.2388 - val_loss: 0.3878 - val_mse: 0.3878 - val_mae: 0.4395\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1045 - mse: 0.1045 - mae: 0.2452 - val_loss: 0.3799 - val_mse: 0.3799 - val_mae: 0.4368\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1003 - mse: 0.1003 - mae: 0.2391 - val_loss: 0.4273 - val_mse: 0.4273 - val_mae: 0.4526\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1011 - mse: 0.1011 - mae: 0.2420 - val_loss: 0.3990 - val_mse: 0.3990 - val_mae: 0.4477\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0957 - mse: 0.0957 - mae: 0.2360 - val_loss: 0.3902 - val_mse: 0.3902 - val_mae: 0.4440\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.0914 - mse: 0.0914 - mae: 0.2305 - val_loss: 0.3822 - val_mse: 0.3822 - val_mae: 0.4395\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0873 - mse: 0.0873 - mae: 0.2254 - val_loss: 0.3963 - val_mse: 0.3963 - val_mae: 0.4315\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0857 - mse: 0.0857 - mae: 0.2237 - val_loss: 0.3961 - val_mse: 0.3961 - val_mae: 0.4410\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0864 - mse: 0.0864 - mae: 0.2245 - val_loss: 0.4149 - val_mse: 0.4149 - val_mae: 0.4578\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0923 - mse: 0.0923 - mae: 0.2320 - val_loss: 0.3809 - val_mse: 0.3809 - val_mae: 0.4449\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0874 - mse: 0.0874 - mae: 0.2251 - val_loss: 0.3995 - val_mse: 0.3995 - val_mae: 0.4433\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.0920 - mse: 0.0920 - mae: 0.2313 - val_loss: 0.3945 - val_mse: 0.3945 - val_mae: 0.4486\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 149us/sample - loss: 1.6931 - mse: 1.6931 - mae: 0.8621 - val_loss: 6.3689 - val_mse: 6.3689 - val_mae: 2.1794\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.5483 - mse: 0.5483 - mae: 0.5506 - val_loss: 1.2160 - val_mse: 1.2160 - val_mae: 0.9240\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.4757 - mse: 0.4757 - mae: 0.5149 - val_loss: 0.7642 - val_mse: 0.7642 - val_mae: 0.7121\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4368 - mse: 0.4368 - mae: 0.4934 - val_loss: 0.6681 - val_mse: 0.6681 - val_mae: 0.6530\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3959 - mse: 0.3959 - mae: 0.4709 - val_loss: 0.6067 - val_mse: 0.6067 - val_mae: 0.6025\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3668 - mse: 0.3668 - mae: 0.4551 - val_loss: 0.5697 - val_mse: 0.5697 - val_mae: 0.5716\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3415 - mse: 0.3415 - mae: 0.4373 - val_loss: 0.4981 - val_mse: 0.4981 - val_mae: 0.5353\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.3111 - mse: 0.3111 - mae: 0.4199 - val_loss: 0.4793 - val_mse: 0.4793 - val_mae: 0.5328\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2941 - mse: 0.2941 - mae: 0.4067 - val_loss: 0.4462 - val_mse: 0.4462 - val_mae: 0.4953\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2830 - mse: 0.2830 - mae: 0.4005 - val_loss: 0.4644 - val_mse: 0.4644 - val_mae: 0.5159\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2599 - mse: 0.2599 - mae: 0.3837 - val_loss: 0.4645 - val_mse: 0.4645 - val_mae: 0.5028\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2642 - mse: 0.2642 - mae: 0.3865 - val_loss: 0.4363 - val_mse: 0.4363 - val_mae: 0.4752\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2512 - mse: 0.2512 - mae: 0.3756 - val_loss: 0.4432 - val_mse: 0.4432 - val_mae: 0.4889\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2369 - mse: 0.2369 - mae: 0.3647 - val_loss: 0.4419 - val_mse: 0.4419 - val_mae: 0.4846\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2245 - mse: 0.2245 - mae: 0.3573 - val_loss: 0.4305 - val_mse: 0.4305 - val_mae: 0.4802\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2159 - mse: 0.2159 - mae: 0.3478 - val_loss: 0.4120 - val_mse: 0.4120 - val_mae: 0.4682\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2195 - mse: 0.2195 - mae: 0.3544 - val_loss: 0.4207 - val_mse: 0.4207 - val_mae: 0.4738\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2083 - mse: 0.2083 - mae: 0.3451 - val_loss: 0.4141 - val_mse: 0.4141 - val_mae: 0.4655\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1880 - mse: 0.1880 - mae: 0.3279 - val_loss: 0.4604 - val_mse: 0.4604 - val_mae: 0.4962\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1975 - mse: 0.1975 - mae: 0.3340 - val_loss: 0.4183 - val_mse: 0.4183 - val_mae: 0.4714\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1680 - mse: 0.1680 - mae: 0.3083 - val_loss: 0.4134 - val_mse: 0.4134 - val_mae: 0.4637\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1662 - mse: 0.1662 - mae: 0.3077 - val_loss: 0.4167 - val_mse: 0.4167 - val_mae: 0.4728\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1562 - mse: 0.1562 - mae: 0.2994 - val_loss: 0.4050 - val_mse: 0.4050 - val_mae: 0.4558\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1569 - mse: 0.1569 - mae: 0.2971 - val_loss: 0.4240 - val_mse: 0.4240 - val_mae: 0.4682\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1576 - mse: 0.1576 - mae: 0.2997 - val_loss: 0.3948 - val_mse: 0.3948 - val_mae: 0.4506\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1458 - mse: 0.1458 - mae: 0.2867 - val_loss: 0.4002 - val_mse: 0.4002 - val_mae: 0.4584\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1484 - mse: 0.1484 - mae: 0.2898 - val_loss: 0.3975 - val_mse: 0.3975 - val_mae: 0.4528\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1426 - mse: 0.1426 - mae: 0.2857 - val_loss: 0.4090 - val_mse: 0.4090 - val_mae: 0.4598\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1511 - mse: 0.1511 - mae: 0.2959 - val_loss: 0.4125 - val_mse: 0.4125 - val_mae: 0.4735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1370 - mse: 0.1370 - mae: 0.2810 - val_loss: 0.3962 - val_mse: 0.3962 - val_mae: 0.4514\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1273 - mse: 0.1273 - mae: 0.2706 - val_loss: 0.3898 - val_mse: 0.3898 - val_mae: 0.4476\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1247 - mse: 0.1247 - mae: 0.2646 - val_loss: 0.3974 - val_mse: 0.3974 - val_mae: 0.4508\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1266 - mse: 0.1266 - mae: 0.2723 - val_loss: 0.4042 - val_mse: 0.4042 - val_mae: 0.4496\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1186 - mse: 0.1186 - mae: 0.2603 - val_loss: 0.3901 - val_mse: 0.3901 - val_mae: 0.4489\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1160 - mse: 0.1160 - mae: 0.2581 - val_loss: 0.3905 - val_mse: 0.3905 - val_mae: 0.4436\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1159 - mse: 0.1159 - mae: 0.2578 - val_loss: 0.4023 - val_mse: 0.4023 - val_mae: 0.4623\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1151 - mse: 0.1151 - mae: 0.2549 - val_loss: 0.3898 - val_mse: 0.3898 - val_mae: 0.4443\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1053 - mse: 0.1053 - mae: 0.2452 - val_loss: 0.3979 - val_mse: 0.3979 - val_mae: 0.4561\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1062 - mse: 0.1062 - mae: 0.2454 - val_loss: 0.3950 - val_mse: 0.3950 - val_mae: 0.4434\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.0949 - mse: 0.0949 - mae: 0.2339 - val_loss: 0.3991 - val_mse: 0.3991 - val_mae: 0.4476\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.0997 - mse: 0.0997 - mae: 0.2378 - val_loss: 0.3934 - val_mse: 0.3934 - val_mae: 0.4515\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 112us/sample - loss: 2.1146 - mse: 2.1146 - mae: 0.9298 - val_loss: 4.4836 - val_mse: 4.4836 - val_mae: 1.8710\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 28us/sample - loss: 0.5580 - mse: 0.5580 - mae: 0.5569 - val_loss: 0.9991 - val_mse: 0.9991 - val_mae: 0.7883\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 33us/sample - loss: 0.4717 - mse: 0.4717 - mae: 0.5138 - val_loss: 1.0373 - val_mse: 1.0373 - val_mae: 0.8172\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.4277 - mse: 0.4277 - mae: 0.4891 - val_loss: 0.7931 - val_mse: 0.7931 - val_mae: 0.7221\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.3872 - mse: 0.3872 - mae: 0.4670 - val_loss: 0.6618 - val_mse: 0.6618 - val_mae: 0.6451\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.3633 - mse: 0.3633 - mae: 0.4532 - val_loss: 0.5238 - val_mse: 0.5238 - val_mae: 0.5563\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.3584 - mse: 0.3584 - mae: 0.4472 - val_loss: 0.5513 - val_mse: 0.5513 - val_mae: 0.5692\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.3210 - mse: 0.3210 - mae: 0.4256 - val_loss: 0.4704 - val_mse: 0.4704 - val_mae: 0.5042\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.3051 - mse: 0.3051 - mae: 0.4150 - val_loss: 0.4282 - val_mse: 0.4282 - val_mae: 0.4905\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.3104 - mse: 0.3104 - mae: 0.4185 - val_loss: 0.4664 - val_mse: 0.4664 - val_mae: 0.5147\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2888 - mse: 0.2888 - mae: 0.4051 - val_loss: 0.4749 - val_mse: 0.4749 - val_mae: 0.5001\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2710 - mse: 0.2710 - mae: 0.3925 - val_loss: 0.4372 - val_mse: 0.4372 - val_mae: 0.4807\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2636 - mse: 0.2636 - mae: 0.3843 - val_loss: 0.4317 - val_mse: 0.4317 - val_mae: 0.4713\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 28us/sample - loss: 0.2410 - mse: 0.2410 - mae: 0.3697 - val_loss: 0.4131 - val_mse: 0.4131 - val_mae: 0.4630\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.2363 - mse: 0.2363 - mae: 0.3650 - val_loss: 0.4184 - val_mse: 0.4184 - val_mae: 0.4589\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 28us/sample - loss: 0.2168 - mse: 0.2168 - mae: 0.3512 - val_loss: 0.4317 - val_mse: 0.4317 - val_mae: 0.4710\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2075 - mse: 0.2075 - mae: 0.3427 - val_loss: 0.4416 - val_mse: 0.4416 - val_mae: 0.4752\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2065 - mse: 0.2065 - mae: 0.3437 - val_loss: 0.4363 - val_mse: 0.4363 - val_mae: 0.4761\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.1962 - mse: 0.1962 - mae: 0.3347 - val_loss: 0.4186 - val_mse: 0.4186 - val_mae: 0.4596\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 28us/sample - loss: 0.1943 - mse: 0.1943 - mae: 0.3338 - val_loss: 0.4224 - val_mse: 0.4224 - val_mae: 0.4741\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1887 - mse: 0.1887 - mae: 0.3272 - val_loss: 0.4103 - val_mse: 0.4103 - val_mae: 0.4526\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1829 - mse: 0.1829 - mae: 0.3204 - val_loss: 0.3887 - val_mse: 0.3887 - val_mae: 0.4424\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1744 - mse: 0.1744 - mae: 0.3161 - val_loss: 0.4496 - val_mse: 0.4496 - val_mae: 0.4806\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1744 - mse: 0.1744 - mae: 0.3132 - val_loss: 0.4085 - val_mse: 0.4085 - val_mae: 0.4590\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.1669 - mse: 0.1669 - mae: 0.3082 - val_loss: 0.4268 - val_mse: 0.4268 - val_mae: 0.4602\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1578 - mse: 0.1578 - mae: 0.2984 - val_loss: 0.3912 - val_mse: 0.3912 - val_mae: 0.4410\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.1527 - mse: 0.1527 - mae: 0.2929 - val_loss: 0.4099 - val_mse: 0.4099 - val_mae: 0.4601\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1504 - mse: 0.1504 - mae: 0.2916 - val_loss: 0.3810 - val_mse: 0.3810 - val_mae: 0.4354\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1438 - mse: 0.1438 - mae: 0.2858 - val_loss: 0.4007 - val_mse: 0.4007 - val_mae: 0.4486\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1399 - mse: 0.1399 - mae: 0.2796 - val_loss: 0.3986 - val_mse: 0.3986 - val_mae: 0.4444\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.1433 - mse: 0.1433 - mae: 0.2838 - val_loss: 0.3972 - val_mse: 0.3972 - val_mae: 0.4529\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1320 - mse: 0.1320 - mae: 0.2741 - val_loss: 0.4118 - val_mse: 0.4118 - val_mae: 0.4536\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 28us/sample - loss: 0.1282 - mse: 0.1282 - mae: 0.2709 - val_loss: 0.4660 - val_mse: 0.4660 - val_mae: 0.4655\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.1227 - mse: 0.1227 - mae: 0.2648 - val_loss: 0.3945 - val_mse: 0.3945 - val_mae: 0.4439\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1245 - mse: 0.1245 - mae: 0.2650 - val_loss: 0.4384 - val_mse: 0.4384 - val_mae: 0.4653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1201 - mse: 0.1201 - mae: 0.2613 - val_loss: 0.3850 - val_mse: 0.3850 - val_mae: 0.4287\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1158 - mse: 0.1158 - mae: 0.2573 - val_loss: 0.3995 - val_mse: 0.3995 - val_mae: 0.4390\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.1125 - mse: 0.1125 - mae: 0.2538 - val_loss: 0.3904 - val_mse: 0.3904 - val_mae: 0.4341\n",
      "Avg. MAE: 0.387737\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 169us/sample - loss: 1.6726 - mse: 1.6726 - mae: 0.8666 - val_loss: 2.5162 - val_mse: 2.5162 - val_mae: 1.2154\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.5427 - mse: 0.5427 - mae: 0.5483 - val_loss: 1.1890 - val_mse: 1.1890 - val_mae: 0.8269\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.4469 - mse: 0.4469 - mae: 0.4924 - val_loss: 0.9249 - val_mse: 0.9249 - val_mae: 0.7905\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.4197 - mse: 0.4197 - mae: 0.4813 - val_loss: 0.7710 - val_mse: 0.7710 - val_mae: 0.7011\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.3844 - mse: 0.3844 - mae: 0.4609 - val_loss: 0.5701 - val_mse: 0.5701 - val_mae: 0.5837\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.3275 - mse: 0.3275 - mae: 0.4290 - val_loss: 0.5197 - val_mse: 0.5197 - val_mae: 0.5582\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.3083 - mse: 0.3083 - mae: 0.4129 - val_loss: 0.4539 - val_mse: 0.4539 - val_mae: 0.5075\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.2822 - mse: 0.2822 - mae: 0.3940 - val_loss: 0.4407 - val_mse: 0.4407 - val_mae: 0.4957\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.2774 - mse: 0.2774 - mae: 0.3931 - val_loss: 0.4206 - val_mse: 0.4206 - val_mae: 0.4739\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.2559 - mse: 0.2559 - mae: 0.3799 - val_loss: 0.4706 - val_mse: 0.4706 - val_mae: 0.5001\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.2257 - mse: 0.2257 - mae: 0.3544 - val_loss: 0.4228 - val_mse: 0.4228 - val_mae: 0.4767\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.2163 - mse: 0.2163 - mae: 0.3486 - val_loss: 0.4172 - val_mse: 0.4172 - val_mae: 0.4737\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.2060 - mse: 0.2060 - mae: 0.3421 - val_loss: 0.4450 - val_mse: 0.4450 - val_mae: 0.4762\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1788 - mse: 0.1788 - mae: 0.3148 - val_loss: 0.3976 - val_mse: 0.3976 - val_mae: 0.4556\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1730 - mse: 0.1730 - mae: 0.3111 - val_loss: 0.4079 - val_mse: 0.4079 - val_mae: 0.4629\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1863 - mse: 0.1863 - mae: 0.3236 - val_loss: 0.4204 - val_mse: 0.4204 - val_mae: 0.4641\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1642 - mse: 0.1642 - mae: 0.3030 - val_loss: 0.3960 - val_mse: 0.3960 - val_mae: 0.4576\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1569 - mse: 0.1569 - mae: 0.2944 - val_loss: 0.4111 - val_mse: 0.4111 - val_mae: 0.4625\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1473 - mse: 0.1473 - mae: 0.2911 - val_loss: 0.3864 - val_mse: 0.3864 - val_mae: 0.4500\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1349 - mse: 0.1349 - mae: 0.2758 - val_loss: 0.4192 - val_mse: 0.4192 - val_mae: 0.4701\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1310 - mse: 0.1310 - mae: 0.2723 - val_loss: 0.4003 - val_mse: 0.4003 - val_mae: 0.4578\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1359 - mse: 0.1359 - mae: 0.2748 - val_loss: 0.4072 - val_mse: 0.4072 - val_mae: 0.4557\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1312 - mse: 0.1312 - mae: 0.2660 - val_loss: 0.3976 - val_mse: 0.3976 - val_mae: 0.4523\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.1219 - mse: 0.1219 - mae: 0.2596 - val_loss: 0.4173 - val_mse: 0.4173 - val_mae: 0.4643\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1182 - mse: 0.1182 - mae: 0.2563 - val_loss: 0.4192 - val_mse: 0.4192 - val_mae: 0.4635\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1101 - mse: 0.1101 - mae: 0.2480 - val_loss: 0.3997 - val_mse: 0.3997 - val_mae: 0.4494\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1117 - mse: 0.1117 - mae: 0.2490 - val_loss: 0.3829 - val_mse: 0.3829 - val_mae: 0.4419\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1132 - mse: 0.1132 - mae: 0.2498 - val_loss: 0.4177 - val_mse: 0.4177 - val_mae: 0.4615\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1073 - mse: 0.1073 - mae: 0.2438 - val_loss: 0.3878 - val_mse: 0.3878 - val_mae: 0.4491\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1052 - mse: 0.1052 - mae: 0.2423 - val_loss: 0.4513 - val_mse: 0.4513 - val_mae: 0.4784\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0989 - mse: 0.0989 - mae: 0.2354 - val_loss: 0.4083 - val_mse: 0.4083 - val_mae: 0.4533\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1017 - mse: 0.1017 - mae: 0.2377 - val_loss: 0.3999 - val_mse: 0.3999 - val_mae: 0.4612\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 47us/sample - loss: 0.1003 - mse: 0.1003 - mae: 0.2351 - val_loss: 0.3892 - val_mse: 0.3892 - val_mae: 0.4403\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0952 - mse: 0.0952 - mae: 0.2304 - val_loss: 0.3854 - val_mse: 0.3854 - val_mae: 0.4423\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.0908 - mse: 0.0908 - mae: 0.2210 - val_loss: 0.3911 - val_mse: 0.3911 - val_mae: 0.4442\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0854 - mse: 0.0854 - mae: 0.2186 - val_loss: 0.3851 - val_mse: 0.3851 - val_mae: 0.4357\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.0772 - mse: 0.0772 - mae: 0.2082 - val_loss: 0.3708 - val_mse: 0.3708 - val_mae: 0.4289\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0824 - mse: 0.0824 - mae: 0.2132 - val_loss: 0.4121 - val_mse: 0.4121 - val_mae: 0.4526\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0823 - mse: 0.0823 - mae: 0.2139 - val_loss: 0.3858 - val_mse: 0.3858 - val_mae: 0.4437\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0781 - mse: 0.0781 - mae: 0.2052 - val_loss: 0.4323 - val_mse: 0.4323 - val_mae: 0.4628\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0791 - mse: 0.0791 - mae: 0.2131 - val_loss: 0.3761 - val_mse: 0.3761 - val_mae: 0.4362\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.0774 - mse: 0.0774 - mae: 0.2062 - val_loss: 0.3823 - val_mse: 0.3823 - val_mae: 0.4376\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0791 - mse: 0.0791 - mae: 0.2106 - val_loss: 0.3841 - val_mse: 0.3841 - val_mae: 0.4393\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.0760 - mse: 0.0760 - mae: 0.2037 - val_loss: 0.3672 - val_mse: 0.3672 - val_mae: 0.4266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0750 - mse: 0.0750 - mae: 0.2057 - val_loss: 0.3640 - val_mse: 0.3640 - val_mae: 0.4314\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0677 - mse: 0.0677 - mae: 0.1948 - val_loss: 0.3741 - val_mse: 0.3741 - val_mae: 0.4312\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0674 - mse: 0.0674 - mae: 0.1930 - val_loss: 0.3677 - val_mse: 0.3677 - val_mae: 0.4264\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0676 - mse: 0.0676 - mae: 0.1922 - val_loss: 0.3734 - val_mse: 0.3734 - val_mae: 0.4287\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0695 - mse: 0.0695 - mae: 0.1942 - val_loss: 0.3702 - val_mse: 0.3702 - val_mae: 0.4298\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0722 - mse: 0.0722 - mae: 0.1996 - val_loss: 0.3718 - val_mse: 0.3718 - val_mae: 0.4338\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0687 - mse: 0.0687 - mae: 0.1927 - val_loss: 0.3647 - val_mse: 0.3647 - val_mae: 0.4251\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.0657 - mse: 0.0657 - mae: 0.1876 - val_loss: 0.3898 - val_mse: 0.3898 - val_mae: 0.4366\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0725 - mse: 0.0725 - mae: 0.1987 - val_loss: 0.3635 - val_mse: 0.3635 - val_mae: 0.4214\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0694 - mse: 0.0694 - mae: 0.1942 - val_loss: 0.3828 - val_mse: 0.3828 - val_mae: 0.4356\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0617 - mse: 0.0617 - mae: 0.1845 - val_loss: 0.3935 - val_mse: 0.3935 - val_mae: 0.4412\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0631 - mse: 0.0631 - mae: 0.1859 - val_loss: 0.3714 - val_mse: 0.3714 - val_mae: 0.4255\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 47us/sample - loss: 0.0610 - mse: 0.0610 - mae: 0.1838 - val_loss: 0.3614 - val_mse: 0.3614 - val_mae: 0.4208\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0612 - mse: 0.0612 - mae: 0.1836 - val_loss: 0.3556 - val_mse: 0.3556 - val_mae: 0.4186\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0600 - mse: 0.0600 - mae: 0.1811 - val_loss: 0.3545 - val_mse: 0.3545 - val_mae: 0.4211\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.0659 - mse: 0.0659 - mae: 0.1885 - val_loss: 0.3793 - val_mse: 0.3793 - val_mae: 0.4338\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0593 - mse: 0.0593 - mae: 0.1809 - val_loss: 0.3809 - val_mse: 0.3809 - val_mae: 0.4352\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0576 - mse: 0.0576 - mae: 0.1760 - val_loss: 0.3738 - val_mse: 0.3738 - val_mae: 0.4297\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0602 - mse: 0.0602 - mae: 0.1803 - val_loss: 0.3705 - val_mse: 0.3705 - val_mae: 0.4289\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0591 - mse: 0.0591 - mae: 0.1786 - val_loss: 0.3628 - val_mse: 0.3628 - val_mae: 0.4258\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0590 - mse: 0.0590 - mae: 0.1783 - val_loss: 0.3675 - val_mse: 0.3675 - val_mae: 0.4285\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0575 - mse: 0.0575 - mae: 0.1770 - val_loss: 0.3747 - val_mse: 0.3747 - val_mae: 0.4401\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0540 - mse: 0.0540 - mae: 0.1707 - val_loss: 0.3763 - val_mse: 0.3763 - val_mae: 0.4290\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0535 - mse: 0.0535 - mae: 0.1708 - val_loss: 0.3607 - val_mse: 0.3607 - val_mae: 0.4232\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0575 - mse: 0.0575 - mae: 0.1728 - val_loss: 0.3721 - val_mse: 0.3721 - val_mae: 0.4298\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 202us/sample - loss: 1.5934 - mse: 1.5934 - mae: 0.8478 - val_loss: 1.8984 - val_mse: 1.8984 - val_mae: 1.0187\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.5296 - mse: 0.5296 - mae: 0.5469 - val_loss: 1.2749 - val_mse: 1.2749 - val_mae: 0.8282\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.4285 - mse: 0.4285 - mae: 0.4888 - val_loss: 1.2503 - val_mse: 1.2503 - val_mae: 0.8648\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.3897 - mse: 0.3897 - mae: 0.4675 - val_loss: 0.8706 - val_mse: 0.8706 - val_mae: 0.7376\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 47us/sample - loss: 0.3669 - mse: 0.3669 - mae: 0.4537 - val_loss: 0.6579 - val_mse: 0.6579 - val_mae: 0.6181\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.3273 - mse: 0.3273 - mae: 0.4274 - val_loss: 0.5373 - val_mse: 0.5373 - val_mae: 0.5555\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.3068 - mse: 0.3068 - mae: 0.4148 - val_loss: 0.5015 - val_mse: 0.5015 - val_mae: 0.5140\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.2875 - mse: 0.2875 - mae: 0.4017 - val_loss: 0.5549 - val_mse: 0.5549 - val_mae: 0.5338\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.2599 - mse: 0.2599 - mae: 0.3834 - val_loss: 0.5216 - val_mse: 0.5216 - val_mae: 0.4980\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 47us/sample - loss: 0.2588 - mse: 0.2588 - mae: 0.3808 - val_loss: 0.4429 - val_mse: 0.4429 - val_mae: 0.4891\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.2313 - mse: 0.2313 - mae: 0.3598 - val_loss: 0.4817 - val_mse: 0.4817 - val_mae: 0.4793\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.2050 - mse: 0.2050 - mae: 0.3386 - val_loss: 0.4261 - val_mse: 0.4261 - val_mae: 0.4724\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.1928 - mse: 0.1928 - mae: 0.3302 - val_loss: 0.5036 - val_mse: 0.5036 - val_mae: 0.4800\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.1889 - mse: 0.1889 - mae: 0.3257 - val_loss: 0.4401 - val_mse: 0.4401 - val_mae: 0.4621\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1871 - mse: 0.1871 - mae: 0.3228 - val_loss: 0.4443 - val_mse: 0.4443 - val_mae: 0.4685\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1773 - mse: 0.1773 - mae: 0.3151 - val_loss: 0.5095 - val_mse: 0.5095 - val_mae: 0.4886\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1777 - mse: 0.1777 - mae: 0.3174 - val_loss: 0.4683 - val_mse: 0.4683 - val_mae: 0.4842\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1697 - mse: 0.1697 - mae: 0.3094 - val_loss: 0.4332 - val_mse: 0.4332 - val_mae: 0.4626\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1488 - mse: 0.1488 - mae: 0.2884 - val_loss: 0.4915 - val_mse: 0.4915 - val_mae: 0.4687\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 47us/sample - loss: 0.1428 - mse: 0.1428 - mae: 0.2832 - val_loss: 0.4356 - val_mse: 0.4356 - val_mae: 0.4521\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 47us/sample - loss: 0.1385 - mse: 0.1385 - mae: 0.2798 - val_loss: 0.4365 - val_mse: 0.4365 - val_mae: 0.4666\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1357 - mse: 0.1357 - mae: 0.2760 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 171us/sample - loss: 1.6591 - mse: 1.6591 - mae: 0.8538 - val_loss: 1.6303 - val_mse: 1.6303 - val_mae: 0.9483\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.5085 - mse: 0.5085 - mae: 0.5322 - val_loss: 0.9858 - val_mse: 0.9858 - val_mae: 0.7881\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.4235 - mse: 0.4235 - mae: 0.4870 - val_loss: 1.2119 - val_mse: 1.2119 - val_mae: 0.8863\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.3865 - mse: 0.3865 - mae: 0.4664 - val_loss: 0.8758 - val_mse: 0.8758 - val_mae: 0.7454\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.3527 - mse: 0.3527 - mae: 0.4423 - val_loss: 0.6778 - val_mse: 0.6778 - val_mae: 0.6482\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.3218 - mse: 0.3218 - mae: 0.4225 - val_loss: 0.5675 - val_mse: 0.5675 - val_mae: 0.5861\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.2844 - mse: 0.2844 - mae: 0.3975 - val_loss: 0.4746 - val_mse: 0.4746 - val_mae: 0.5175\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.2822 - mse: 0.2822 - mae: 0.3972 - val_loss: 0.4426 - val_mse: 0.4426 - val_mae: 0.5016\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.2586 - mse: 0.2586 - mae: 0.3798 - val_loss: 0.5003 - val_mse: 0.5003 - val_mae: 0.5433\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.2304 - mse: 0.2304 - mae: 0.3595 - val_loss: 0.4441 - val_mse: 0.4441 - val_mae: 0.4757\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.2215 - mse: 0.2215 - mae: 0.3511 - val_loss: 0.3973 - val_mse: 0.3973 - val_mae: 0.4559\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.2091 - mse: 0.2091 - mae: 0.3472 - val_loss: 0.4132 - val_mse: 0.4132 - val_mae: 0.4614\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.1988 - mse: 0.1988 - mae: 0.3339 - val_loss: 0.4399 - val_mse: 0.4399 - val_mae: 0.4628\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1831 - mse: 0.1831 - mae: 0.3253 - val_loss: 0.3941 - val_mse: 0.3941 - val_mae: 0.4540\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1657 - mse: 0.1657 - mae: 0.3073 - val_loss: 0.4261 - val_mse: 0.4261 - val_mae: 0.4654\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1745 - mse: 0.1745 - mae: 0.3155 - val_loss: 0.4028 - val_mse: 0.4028 - val_mae: 0.4575\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1604 - mse: 0.1604 - mae: 0.3007 - val_loss: 0.3956 - val_mse: 0.3956 - val_mae: 0.4512\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1438 - mse: 0.1438 - mae: 0.2876 - val_loss: 0.3921 - val_mse: 0.3921 - val_mae: 0.4463\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1370 - mse: 0.1370 - mae: 0.2773 - val_loss: 0.4032 - val_mse: 0.4032 - val_mae: 0.4451\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1304 - mse: 0.1304 - mae: 0.2702 - val_loss: 0.4256 - val_mse: 0.4256 - val_mae: 0.4637\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1342 - mse: 0.1342 - mae: 0.2769 - val_loss: 0.4087 - val_mse: 0.4087 - val_mae: 0.4500\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1259 - mse: 0.1259 - mae: 0.2670 - val_loss: 0.3988 - val_mse: 0.3988 - val_mae: 0.4572\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.1202 - mse: 0.1202 - mae: 0.2600 - val_loss: 0.4201 - val_mse: 0.4201 - val_mae: 0.4481\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1133 - mse: 0.1133 - mae: 0.2540 - val_loss: 0.3833 - val_mse: 0.3833 - val_mae: 0.4404\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1114 - mse: 0.1114 - mae: 0.2516 - val_loss: 0.4318 - val_mse: 0.4318 - val_mae: 0.4660\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1067 - mse: 0.1067 - mae: 0.2476 - val_loss: 0.4052 - val_mse: 0.4052 - val_mae: 0.4518\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1041 - mse: 0.1041 - mae: 0.2422 - val_loss: 0.3773 - val_mse: 0.3773 - val_mae: 0.4321\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1002 - mse: 0.1002 - mae: 0.2390 - val_loss: 0.3985 - val_mse: 0.3985 - val_mae: 0.4500\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0976 - mse: 0.0976 - mae: 0.2347 - val_loss: 0.4116 - val_mse: 0.4116 - val_mae: 0.4423\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1004 - mse: 0.1004 - mae: 0.2369 - val_loss: 0.4311 - val_mse: 0.4311 - val_mae: 0.4571\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0982 - mse: 0.0982 - mae: 0.2340 - val_loss: 0.4059 - val_mse: 0.4059 - val_mae: 0.4488\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0887 - mse: 0.0887 - mae: 0.2236 - val_loss: 0.4102 - val_mse: 0.4102 - val_mae: 0.4556\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.0921 - mse: 0.0921 - mae: 0.2296 - val_loss: 0.3928 - val_mse: 0.3928 - val_mae: 0.4391\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0850 - mse: 0.0850 - mae: 0.2194 - val_loss: 0.3813 - val_mse: 0.3813 - val_mae: 0.4330\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0892 - mse: 0.0892 - mae: 0.2245 - val_loss: 0.3982 - val_mse: 0.3982 - val_mae: 0.4528\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0865 - mse: 0.0865 - mae: 0.2207 - val_loss: 0.3767 - val_mse: 0.3767 - val_mae: 0.4332\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 47us/sample - loss: 0.0847 - mse: 0.0847 - mae: 0.2181 - val_loss: 0.3825 - val_mse: 0.3825 - val_mae: 0.4384\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.0803 - mse: 0.0803 - mae: 0.2134 - val_loss: 0.3991 - val_mse: 0.3991 - val_mae: 0.4374\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0796 - mse: 0.0796 - mae: 0.2139 - val_loss: 0.3871 - val_mse: 0.3871 - val_mae: 0.4352\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0746 - mse: 0.0746 - mae: 0.2065 - val_loss: 0.3846 - val_mse: 0.3846 - val_mae: 0.4366\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0719 - mse: 0.0719 - mae: 0.2039 - val_loss: 0.4079 - val_mse: 0.4079 - val_mae: 0.4511\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0710 - mse: 0.0710 - mae: 0.2020 - val_loss: 0.3997 - val_mse: 0.3997 - val_mae: 0.4447\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0713 - mse: 0.0713 - mae: 0.1994 - val_loss: 0.3869 - val_mse: 0.3869 - val_mae: 0.4349\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0697 - mse: 0.0697 - mae: 0.1984 - val_loss: 0.3823 - val_mse: 0.3823 - val_mae: 0.4236\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.0673 - mse: 0.0673 - mae: 0.1964 - val_loss: 0.3796 - val_mse: 0.3796 - val_mae: 0.4288\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0663 - mse: 0.0663 - mae: 0.1953 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.4526\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 2s 165us/sample - loss: 1.8257 - mse: 1.8257 - mae: 0.9114 - val_loss: 6.4517 - val_mse: 6.4517 - val_mae: 2.1082\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.5197 - mse: 0.5197 - mae: 0.5351 - val_loss: 0.9188 - val_mse: 0.9188 - val_mae: 0.7730\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.4361 - mse: 0.4361 - mae: 0.4907 - val_loss: 0.8104 - val_mse: 0.8104 - val_mae: 0.7291\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.3855 - mse: 0.3855 - mae: 0.4627 - val_loss: 0.8415 - val_mse: 0.8415 - val_mae: 0.7271\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.3626 - mse: 0.3626 - mae: 0.4492 - val_loss: 0.6013 - val_mse: 0.6013 - val_mae: 0.6178\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.3200 - mse: 0.3200 - mae: 0.4231 - val_loss: 0.5148 - val_mse: 0.5148 - val_mae: 0.5497\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.2883 - mse: 0.2883 - mae: 0.4024 - val_loss: 0.5060 - val_mse: 0.5060 - val_mae: 0.5503\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.2685 - mse: 0.2685 - mae: 0.3900 - val_loss: 0.4440 - val_mse: 0.4440 - val_mae: 0.5049\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.2603 - mse: 0.2603 - mae: 0.3831 - val_loss: 0.4307 - val_mse: 0.4307 - val_mae: 0.4960\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.2410 - mse: 0.2410 - mae: 0.3683 - val_loss: 0.4172 - val_mse: 0.4172 - val_mae: 0.4808\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.2135 - mse: 0.2135 - mae: 0.3457 - val_loss: 0.4270 - val_mse: 0.4270 - val_mae: 0.4835\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.2118 - mse: 0.2118 - mae: 0.3443 - val_loss: 0.4481 - val_mse: 0.4481 - val_mae: 0.4888\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.2000 - mse: 0.2000 - mae: 0.3388 - val_loss: 0.4229 - val_mse: 0.4229 - val_mae: 0.4734\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.2000 - mse: 0.2000 - mae: 0.3362 - val_loss: 0.4017 - val_mse: 0.4017 - val_mae: 0.4606\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1750 - mse: 0.1750 - mae: 0.3141 - val_loss: 0.4267 - val_mse: 0.4267 - val_mae: 0.4806\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.1752 - mse: 0.1752 - mae: 0.3106 - val_loss: 0.3837 - val_mse: 0.3837 - val_mae: 0.4451\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1633 - mse: 0.1633 - mae: 0.3014 - val_loss: 0.3981 - val_mse: 0.3981 - val_mae: 0.4500\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1561 - mse: 0.1561 - mae: 0.2987 - val_loss: 0.4176 - val_mse: 0.4176 - val_mae: 0.4635\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1480 - mse: 0.1480 - mae: 0.2898 - val_loss: 0.3999 - val_mse: 0.3999 - val_mae: 0.4522\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1463 - mse: 0.1463 - mae: 0.2872 - val_loss: 0.3975 - val_mse: 0.3975 - val_mae: 0.4587\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.1287 - mse: 0.1287 - mae: 0.2674 - val_loss: 0.3982 - val_mse: 0.3982 - val_mae: 0.4489\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1306 - mse: 0.1306 - mae: 0.2706 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4613\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1221 - mse: 0.1221 - mae: 0.2610 - val_loss: 0.3856 - val_mse: 0.3856 - val_mae: 0.4515\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1200 - mse: 0.1200 - mae: 0.2607 - val_loss: 0.4154 - val_mse: 0.4154 - val_mae: 0.4627\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1084 - mse: 0.1084 - mae: 0.2466 - val_loss: 0.3928 - val_mse: 0.3928 - val_mae: 0.4471\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1072 - mse: 0.1072 - mae: 0.2447 - val_loss: 0.3813 - val_mse: 0.3813 - val_mae: 0.4409\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1096 - mse: 0.1096 - mae: 0.2479 - val_loss: 0.3854 - val_mse: 0.3854 - val_mae: 0.4557\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1055 - mse: 0.1055 - mae: 0.2453 - val_loss: 0.3995 - val_mse: 0.3995 - val_mae: 0.4493\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1109 - mse: 0.1109 - mae: 0.2479 - val_loss: 0.3897 - val_mse: 0.3897 - val_mae: 0.4427\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1066 - mse: 0.1066 - mae: 0.2450 - val_loss: 0.3730 - val_mse: 0.3730 - val_mae: 0.4365\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0936 - mse: 0.0936 - mae: 0.2291 - val_loss: 0.3598 - val_mse: 0.3598 - val_mae: 0.4309\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0978 - mse: 0.0978 - mae: 0.2329 - val_loss: 0.3872 - val_mse: 0.3872 - val_mae: 0.4392\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0949 - mse: 0.0949 - mae: 0.2302 - val_loss: 0.3751 - val_mse: 0.3751 - val_mae: 0.4328\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0884 - mse: 0.0884 - mae: 0.2226 - val_loss: 0.3810 - val_mse: 0.3810 - val_mae: 0.4357\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.0847 - mse: 0.0847 - mae: 0.2190 - val_loss: 0.3693 - val_mse: 0.3693 - val_mae: 0.4335\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.0841 - mse: 0.0841 - mae: 0.2169 - val_loss: 0.3707 - val_mse: 0.3707 - val_mae: 0.4312\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0865 - mse: 0.0865 - mae: 0.2185 - val_loss: 0.3803 - val_mse: 0.3803 - val_mae: 0.4386\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.0843 - mse: 0.0843 - mae: 0.2167 - val_loss: 0.3718 - val_mse: 0.3718 - val_mae: 0.4312\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0823 - mse: 0.0823 - mae: 0.2149 - val_loss: 0.3649 - val_mse: 0.3649 - val_mae: 0.4187\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0764 - mse: 0.0764 - mae: 0.2042 - val_loss: 0.3716 - val_mse: 0.3716 - val_mae: 0.4253\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.0764 - mse: 0.0764 - mae: 0.2055 - val_loss: 0.3690 - val_mse: 0.3690 - val_mae: 0.4268\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 205us/sample - loss: 1.7370 - mse: 1.7370 - mae: 0.8706 - val_loss: 2.0935 - val_mse: 2.0935 - val_mae: 1.2424\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 47us/sample - loss: 0.5306 - mse: 0.5306 - mae: 0.5473 - val_loss: 1.1760 - val_mse: 1.1760 - val_mae: 0.8220\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.4447 - mse: 0.4447 - mae: 0.4961 - val_loss: 1.0718 - val_mse: 1.0718 - val_mae: 0.8052\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.4123 - mse: 0.4123 - mae: 0.4806 - val_loss: 0.9236 - val_mse: 0.9236 - val_mae: 0.7658\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.3825 - mse: 0.3825 - mae: 0.4615 - val_loss: 0.6390 - val_mse: 0.6390 - val_mae: 0.6233\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.3303 - mse: 0.3303 - mae: 0.4260 - val_loss: 0.5169 - val_mse: 0.5169 - val_mae: 0.5346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.2962 - mse: 0.2962 - mae: 0.4077 - val_loss: 0.5297 - val_mse: 0.5297 - val_mae: 0.5443\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.2906 - mse: 0.2906 - mae: 0.4006 - val_loss: 0.4624 - val_mse: 0.4624 - val_mae: 0.5052\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.2708 - mse: 0.2708 - mae: 0.3873 - val_loss: 0.5080 - val_mse: 0.5080 - val_mae: 0.5283\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.2679 - mse: 0.2679 - mae: 0.3862 - val_loss: 0.5195 - val_mse: 0.5195 - val_mae: 0.5136\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.2435 - mse: 0.2435 - mae: 0.3699 - val_loss: 0.4480 - val_mse: 0.4480 - val_mae: 0.4760\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2218 - mse: 0.2218 - mae: 0.3514 - val_loss: 0.4741 - val_mse: 0.4741 - val_mae: 0.4748\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.2063 - mse: 0.2063 - mae: 0.3369 - val_loss: 0.4410 - val_mse: 0.4410 - val_mae: 0.4738\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.1972 - mse: 0.1972 - mae: 0.3324 - val_loss: 0.4476 - val_mse: 0.4476 - val_mae: 0.4773\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.1853 - mse: 0.1853 - mae: 0.3225 - val_loss: 0.4268 - val_mse: 0.4268 - val_mae: 0.4598\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.1736 - mse: 0.1736 - mae: 0.3119 - val_loss: 0.4387 - val_mse: 0.4387 - val_mae: 0.4720\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.1741 - mse: 0.1741 - mae: 0.3113 - val_loss: 0.4177 - val_mse: 0.4177 - val_mae: 0.4563\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.1695 - mse: 0.1695 - mae: 0.3079 - val_loss: 0.4207 - val_mse: 0.4207 - val_mae: 0.4561\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.1597 - mse: 0.1597 - mae: 0.2983 - val_loss: 0.3953 - val_mse: 0.3953 - val_mae: 0.4419\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.1523 - mse: 0.1523 - mae: 0.2922 - val_loss: 0.4173 - val_mse: 0.4173 - val_mae: 0.4538\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.1378 - mse: 0.1378 - mae: 0.2778 - val_loss: 0.4052 - val_mse: 0.4052 - val_mae: 0.4396\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.1327 - mse: 0.1327 - mae: 0.2725 - val_loss: 0.4009 - val_mse: 0.4009 - val_mae: 0.4488\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.1317 - mse: 0.1317 - mae: 0.2701 - val_loss: 0.4475 - val_mse: 0.4475 - val_mae: 0.4784\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.1308 - mse: 0.1308 - mae: 0.2690 - val_loss: 0.4204 - val_mse: 0.4204 - val_mae: 0.4547\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 47us/sample - loss: 0.1308 - mse: 0.1308 - mae: 0.2695 - val_loss: 0.5122 - val_mse: 0.5122 - val_mae: 0.4949\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.1271 - mse: 0.1271 - mae: 0.2621 - val_loss: 0.3997 - val_mse: 0.3997 - val_mae: 0.4430\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.1148 - mse: 0.1148 - mae: 0.2546 - val_loss: 0.4009 - val_mse: 0.4009 - val_mae: 0.4399\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.1068 - mse: 0.1068 - mae: 0.2444 - val_loss: 0.3860 - val_mse: 0.3860 - val_mae: 0.4337\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 47us/sample - loss: 0.1099 - mse: 0.1099 - mae: 0.2472 - val_loss: 0.3836 - val_mse: 0.3836 - val_mae: 0.4323\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0968 - mse: 0.0968 - mae: 0.2323 - val_loss: 0.3908 - val_mse: 0.3908 - val_mae: 0.4360\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0953 - mse: 0.0953 - mae: 0.2305 - val_loss: 0.3923 - val_mse: 0.3923 - val_mae: 0.4389\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.1053 - mse: 0.1053 - mae: 0.2423 - val_loss: 0.3913 - val_mse: 0.3913 - val_mae: 0.4329\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.0954 - mse: 0.0954 - mae: 0.2330 - val_loss: 0.4171 - val_mse: 0.4171 - val_mae: 0.4398\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0896 - mse: 0.0896 - mae: 0.2253 - val_loss: 0.3897 - val_mse: 0.3897 - val_mae: 0.4375\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.0891 - mse: 0.0891 - mae: 0.2230 - val_loss: 0.4007 - val_mse: 0.4007 - val_mae: 0.4335\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.0893 - mse: 0.0893 - mae: 0.2239 - val_loss: 0.4033 - val_mse: 0.4033 - val_mae: 0.4416\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0840 - mse: 0.0840 - mae: 0.2161 - val_loss: 0.3824 - val_mse: 0.3824 - val_mae: 0.4281\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.0879 - mse: 0.0879 - mae: 0.2211 - val_loss: 0.3836 - val_mse: 0.3836 - val_mae: 0.4286\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.0882 - mse: 0.0882 - mae: 0.2195 - val_loss: 0.3945 - val_mse: 0.3945 - val_mae: 0.4423\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0837 - mse: 0.0837 - mae: 0.2149 - val_loss: 0.3803 - val_mse: 0.3803 - val_mae: 0.4223\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.0837 - mse: 0.0837 - mae: 0.2172 - val_loss: 0.3915 - val_mse: 0.3915 - val_mae: 0.4392\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0842 - mse: 0.0842 - mae: 0.2190 - val_loss: 0.4016 - val_mse: 0.4016 - val_mae: 0.4445\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.0821 - mse: 0.0821 - mae: 0.2148 - val_loss: 0.3759 - val_mse: 0.3759 - val_mae: 0.4269\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0848 - mse: 0.0848 - mae: 0.2165 - val_loss: 0.3692 - val_mse: 0.3692 - val_mae: 0.4157\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.0705 - mse: 0.0705 - mae: 0.1980 - val_loss: 0.3848 - val_mse: 0.3848 - val_mae: 0.4275\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0738 - mse: 0.0738 - mae: 0.2033 - val_loss: 0.3608 - val_mse: 0.3608 - val_mae: 0.4073\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0733 - mse: 0.0733 - mae: 0.2008 - val_loss: 0.3918 - val_mse: 0.3918 - val_mae: 0.4258\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.0747 - mse: 0.0747 - mae: 0.2019 - val_loss: 0.3772 - val_mse: 0.3772 - val_mae: 0.4154\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0707 - mse: 0.0707 - mae: 0.1983 - val_loss: 0.3868 - val_mse: 0.3868 - val_mae: 0.4257\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0701 - mse: 0.0701 - mae: 0.1975 - val_loss: 0.3612 - val_mse: 0.3612 - val_mae: 0.4153\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.0775 - mse: 0.0775 - mae: 0.2104 - val_loss: 0.3780 - val_mse: 0.3780 - val_mae: 0.4287\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0750 - mse: 0.0750 - mae: 0.2031 - val_loss: 0.4038 - val_mse: 0.4038 - val_mae: 0.4338\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.0715 - mse: 0.0715 - mae: 0.2008 - val_loss: 0.3818 - val_mse: 0.3818 - val_mae: 0.4234\n",
      "Epoch 54/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 45us/sample - loss: 0.0797 - mse: 0.0797 - mae: 0.2113 - val_loss: 0.3719 - val_mse: 0.3719 - val_mae: 0.4209\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0728 - mse: 0.0728 - mae: 0.2024 - val_loss: 0.3840 - val_mse: 0.3840 - val_mae: 0.4251\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 0s 46us/sample - loss: 0.0677 - mse: 0.0677 - mae: 0.1950 - val_loss: 0.3909 - val_mse: 0.3909 - val_mae: 0.4322\n",
      "Avg. MAE: 0.381631\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 198us/sample - loss: 1.6289 - mse: 1.6289 - mae: 0.9629 - val_loss: 0.9880 - val_mse: 0.9880 - val_mae: 0.7825\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.8844 - mse: 0.8844 - mae: 0.7230 - val_loss: 0.9357 - val_mse: 0.9357 - val_mae: 0.7159\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.7047 - mse: 0.7047 - mae: 0.6457 - val_loss: 0.9161 - val_mse: 0.9161 - val_mae: 0.7090\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.5932 - mse: 0.5932 - mae: 0.5966 - val_loss: 0.8677 - val_mse: 0.8677 - val_mae: 0.6987\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.5092 - mse: 0.5092 - mae: 0.5505 - val_loss: 0.8078 - val_mse: 0.8078 - val_mae: 0.6783\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.4636 - mse: 0.4636 - mae: 0.5255 - val_loss: 0.7390 - val_mse: 0.7390 - val_mae: 0.6526\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.4194 - mse: 0.4194 - mae: 0.4978 - val_loss: 0.6699 - val_mse: 0.6699 - val_mae: 0.6248\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.3922 - mse: 0.3922 - mae: 0.4844 - val_loss: 0.6389 - val_mse: 0.6389 - val_mae: 0.6073\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3674 - mse: 0.3674 - mae: 0.4675 - val_loss: 0.6291 - val_mse: 0.6291 - val_mae: 0.5989\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3463 - mse: 0.3463 - mae: 0.4533 - val_loss: 0.6287 - val_mse: 0.6287 - val_mae: 0.5907\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3270 - mse: 0.3270 - mae: 0.4397 - val_loss: 0.6115 - val_mse: 0.6115 - val_mae: 0.5840\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3060 - mse: 0.3060 - mae: 0.4253 - val_loss: 0.6199 - val_mse: 0.6199 - val_mae: 0.5786\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.2848 - mse: 0.2848 - mae: 0.4097 - val_loss: 0.6344 - val_mse: 0.6344 - val_mae: 0.5770\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2739 - mse: 0.2739 - mae: 0.4012 - val_loss: 0.6154 - val_mse: 0.6154 - val_mae: 0.5713\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2583 - mse: 0.2583 - mae: 0.3904 - val_loss: 0.5779 - val_mse: 0.5779 - val_mae: 0.5602\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2503 - mse: 0.2503 - mae: 0.3826 - val_loss: 0.5945 - val_mse: 0.5945 - val_mae: 0.5620\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2399 - mse: 0.2399 - mae: 0.3764 - val_loss: 0.6041 - val_mse: 0.6041 - val_mae: 0.5582\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2307 - mse: 0.2307 - mae: 0.3688 - val_loss: 0.5743 - val_mse: 0.5743 - val_mae: 0.5533\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2238 - mse: 0.2238 - mae: 0.3637 - val_loss: 0.5650 - val_mse: 0.5650 - val_mae: 0.5475\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2129 - mse: 0.2129 - mae: 0.3553 - val_loss: 0.5734 - val_mse: 0.5734 - val_mae: 0.5480\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2072 - mse: 0.2072 - mae: 0.3490 - val_loss: 0.5709 - val_mse: 0.5709 - val_mae: 0.5462\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2016 - mse: 0.2016 - mae: 0.3443 - val_loss: 0.5730 - val_mse: 0.5730 - val_mae: 0.5424\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1854 - mse: 0.1854 - mae: 0.3327 - val_loss: 0.5696 - val_mse: 0.5696 - val_mae: 0.5416\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1879 - mse: 0.1879 - mae: 0.3342 - val_loss: 0.5462 - val_mse: 0.5462 - val_mae: 0.5333\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1889 - mse: 0.1889 - mae: 0.3342 - val_loss: 0.5738 - val_mse: 0.5738 - val_mae: 0.5412\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1757 - mse: 0.1757 - mae: 0.3215 - val_loss: 0.5555 - val_mse: 0.5555 - val_mae: 0.5359\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1670 - mse: 0.1670 - mae: 0.3144 - val_loss: 0.5366 - val_mse: 0.5366 - val_mae: 0.5317\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1650 - mse: 0.1650 - mae: 0.3139 - val_loss: 0.5400 - val_mse: 0.5400 - val_mae: 0.5321\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1632 - mse: 0.1632 - mae: 0.3100 - val_loss: 0.5378 - val_mse: 0.5378 - val_mae: 0.5275\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1624 - mse: 0.1624 - mae: 0.3105 - val_loss: 0.5501 - val_mse: 0.5501 - val_mae: 0.5279\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1511 - mse: 0.1511 - mae: 0.3014 - val_loss: 0.5324 - val_mse: 0.5324 - val_mae: 0.5252\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1521 - mse: 0.1521 - mae: 0.2995 - val_loss: 0.5150 - val_mse: 0.5150 - val_mae: 0.5200\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1499 - mse: 0.1499 - mae: 0.2995 - val_loss: 0.5322 - val_mse: 0.5322 - val_mae: 0.5232\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1454 - mse: 0.1454 - mae: 0.2930 - val_loss: 0.5221 - val_mse: 0.5221 - val_mae: 0.5219\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1421 - mse: 0.1421 - mae: 0.2889 - val_loss: 0.5132 - val_mse: 0.5132 - val_mae: 0.5176\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1372 - mse: 0.1372 - mae: 0.2842 - val_loss: 0.5038 - val_mse: 0.5038 - val_mae: 0.5141\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1401 - mse: 0.1401 - mae: 0.2878 - val_loss: 0.5122 - val_mse: 0.5122 - val_mae: 0.5177\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1368 - mse: 0.1368 - mae: 0.2842 - val_loss: 0.4989 - val_mse: 0.4989 - val_mae: 0.5140\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1312 - mse: 0.1312 - mae: 0.2786 - val_loss: 0.4936 - val_mse: 0.4936 - val_mae: 0.5103\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1262 - mse: 0.1262 - mae: 0.2726 - val_loss: 0.5178 - val_mse: 0.5178 - val_mae: 0.5161\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1289 - mse: 0.1289 - mae: 0.2748 - val_loss: 0.5053 - val_mse: 0.5053 - val_mae: 0.5113\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1223 - mse: 0.1223 - mae: 0.2706 - val_loss: 0.5072 - val_mse: 0.5072 - val_mae: 0.5107\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - ETA: 0s - loss: 0.1222 - mse: 0.1222 - mae: 0.268 - 1s 55us/sample - loss: 0.1228 - mse: 0.1228 - mae: 0.2686 - val_loss: 0.5100 - val_mse: 0.5100 - val_mae: 0.5131\n",
      "Epoch 44/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - ETA: 0s - loss: 0.1185 - mse: 0.1185 - mae: 0.264 - 1s 54us/sample - loss: 0.1219 - mse: 0.1219 - mae: 0.2676 - val_loss: 0.5134 - val_mse: 0.5134 - val_mae: 0.5118\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1159 - mse: 0.1159 - mae: 0.2635 - val_loss: 0.5094 - val_mse: 0.5094 - val_mae: 0.5108\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1141 - mse: 0.1141 - mae: 0.2584 - val_loss: 0.4887 - val_mse: 0.4887 - val_mae: 0.5033\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1169 - mse: 0.1169 - mae: 0.2628 - val_loss: 0.4946 - val_mse: 0.4946 - val_mae: 0.5046\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1127 - mse: 0.1127 - mae: 0.2579 - val_loss: 0.4981 - val_mse: 0.4981 - val_mae: 0.5068\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1125 - mse: 0.1125 - mae: 0.2568 - val_loss: 0.4816 - val_mse: 0.4816 - val_mae: 0.5011\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1106 - mse: 0.1106 - mae: 0.2546 - val_loss: 0.4866 - val_mse: 0.4866 - val_mae: 0.5007\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1056 - mse: 0.1056 - mae: 0.2509 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.4969\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1044 - mse: 0.1044 - mae: 0.2490 - val_loss: 0.4745 - val_mse: 0.4745 - val_mae: 0.4959\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1094 - mse: 0.1094 - mae: 0.2532 - val_loss: 0.4839 - val_mse: 0.4839 - val_mae: 0.4968\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1018 - mse: 0.1018 - mae: 0.2441 - val_loss: 0.4815 - val_mse: 0.4815 - val_mae: 0.4965\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1051 - mse: 0.1051 - mae: 0.2462 - val_loss: 0.4773 - val_mse: 0.4773 - val_mae: 0.4977\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1025 - mse: 0.1025 - mae: 0.2449 - val_loss: 0.4741 - val_mse: 0.4741 - val_mae: 0.4930\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1005 - mse: 0.1005 - mae: 0.2432 - val_loss: 0.4624 - val_mse: 0.4624 - val_mae: 0.4872\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0992 - mse: 0.0992 - mae: 0.2397 - val_loss: 0.4707 - val_mse: 0.4707 - val_mae: 0.4907\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0983 - mse: 0.0983 - mae: 0.2410 - val_loss: 0.4690 - val_mse: 0.4690 - val_mae: 0.4889\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0975 - mse: 0.0975 - mae: 0.2381 - val_loss: 0.4664 - val_mse: 0.4664 - val_mae: 0.4913\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0959 - mse: 0.0959 - mae: 0.2357 - val_loss: 0.4699 - val_mse: 0.4699 - val_mae: 0.4914\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0930 - mse: 0.0930 - mae: 0.2337 - val_loss: 0.4542 - val_mse: 0.4542 - val_mae: 0.4850\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0957 - mse: 0.0957 - mae: 0.2363 - val_loss: 0.4534 - val_mse: 0.4534 - val_mae: 0.4805\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0942 - mse: 0.0942 - mae: 0.2366 - val_loss: 0.4541 - val_mse: 0.4541 - val_mae: 0.4820\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2275 - val_loss: 0.4463 - val_mse: 0.4463 - val_mae: 0.4811\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0896 - mse: 0.0896 - mae: 0.2273 - val_loss: 0.4577 - val_mse: 0.4577 - val_mae: 0.4827\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0896 - mse: 0.0896 - mae: 0.2286 - val_loss: 0.4663 - val_mse: 0.4663 - val_mae: 0.4842\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0902 - mse: 0.0902 - mae: 0.2300 - val_loss: 0.4582 - val_mse: 0.4582 - val_mae: 0.4811\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0889 - mse: 0.0889 - mae: 0.2280 - val_loss: 0.4449 - val_mse: 0.4449 - val_mae: 0.4765\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0842 - mse: 0.0842 - mae: 0.2228 - val_loss: 0.4501 - val_mse: 0.4501 - val_mae: 0.4774\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0884 - mse: 0.0884 - mae: 0.2272 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.4755\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0874 - mse: 0.0874 - mae: 0.2244 - val_loss: 0.4387 - val_mse: 0.4387 - val_mae: 0.4756\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0855 - mse: 0.0855 - mae: 0.2246 - val_loss: 0.4628 - val_mse: 0.4628 - val_mae: 0.4839\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0847 - mse: 0.0847 - mae: 0.2231 - val_loss: 0.4482 - val_mse: 0.4482 - val_mae: 0.4774\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0836 - mse: 0.0836 - mae: 0.2200 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4747\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0851 - mse: 0.0851 - mae: 0.2226 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4745\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0837 - mse: 0.0837 - mae: 0.2214 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4741\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0776 - mse: 0.0776 - mae: 0.2111 - val_loss: 0.4387 - val_mse: 0.4387 - val_mae: 0.4724\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0807 - mse: 0.0807 - mae: 0.2153 - val_loss: 0.4449 - val_mse: 0.4449 - val_mae: 0.4752\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0822 - mse: 0.0822 - mae: 0.2201 - val_loss: 0.4447 - val_mse: 0.4447 - val_mae: 0.4746\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0801 - mse: 0.0801 - mae: 0.2165 - val_loss: 0.4461 - val_mse: 0.4461 - val_mae: 0.4745\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0792 - mse: 0.0792 - mae: 0.2150 - val_loss: 0.4423 - val_mse: 0.4423 - val_mae: 0.4707\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 1.6230 - mse: 1.6230 - mae: 0.9657 - val_loss: 1.0260 - val_mse: 1.0260 - val_mae: 0.7938\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.9047 - mse: 0.9047 - mae: 0.7316 - val_loss: 0.9561 - val_mse: 0.9561 - val_mae: 0.7215\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.7156 - mse: 0.7156 - mae: 0.6488 - val_loss: 0.9485 - val_mse: 0.9485 - val_mae: 0.7139\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.6006 - mse: 0.6006 - mae: 0.5991 - val_loss: 0.8971 - val_mse: 0.8971 - val_mae: 0.7016\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.5386 - mse: 0.5386 - mae: 0.5661 - val_loss: 0.8302 - val_mse: 0.8302 - val_mae: 0.6838\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.4759 - mse: 0.4759 - mae: 0.5308 - val_loss: 0.7633 - val_mse: 0.7633 - val_mae: 0.6596\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.4316 - mse: 0.4316 - mae: 0.5011 - val_loss: 0.7249 - val_mse: 0.7249 - val_mae: 0.6410\n",
      "Epoch 8/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.4134 - mse: 0.4134 - mae: 0.4923 - val_loss: 0.6742 - val_mse: 0.6742 - val_mae: 0.6180\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.3680 - mse: 0.3680 - mae: 0.4664 - val_loss: 0.6531 - val_mse: 0.6531 - val_mae: 0.6016\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.3469 - mse: 0.3469 - mae: 0.4541 - val_loss: 0.6310 - val_mse: 0.6310 - val_mae: 0.5868\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.3267 - mse: 0.3267 - mae: 0.4410 - val_loss: 0.6166 - val_mse: 0.6166 - val_mae: 0.5765\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3031 - mse: 0.3031 - mae: 0.4251 - val_loss: 0.6031 - val_mse: 0.6031 - val_mae: 0.5676\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2853 - mse: 0.2853 - mae: 0.4119 - val_loss: 0.5894 - val_mse: 0.5894 - val_mae: 0.5578\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2703 - mse: 0.2703 - mae: 0.4033 - val_loss: 0.5830 - val_mse: 0.5830 - val_mae: 0.5526\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2618 - mse: 0.2618 - mae: 0.3960 - val_loss: 0.5802 - val_mse: 0.5802 - val_mae: 0.5501\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2532 - mse: 0.2532 - mae: 0.3860 - val_loss: 0.5729 - val_mse: 0.5729 - val_mae: 0.5450\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2376 - mse: 0.2376 - mae: 0.3749 - val_loss: 0.5593 - val_mse: 0.5593 - val_mae: 0.5367\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2352 - mse: 0.2352 - mae: 0.3724 - val_loss: 0.5539 - val_mse: 0.5539 - val_mae: 0.5330\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2260 - mse: 0.2260 - mae: 0.3669 - val_loss: 0.5537 - val_mse: 0.5537 - val_mae: 0.5313\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2145 - mse: 0.2145 - mae: 0.3587 - val_loss: 0.5434 - val_mse: 0.5434 - val_mae: 0.5264\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2060 - mse: 0.2060 - mae: 0.3503 - val_loss: 0.5778 - val_mse: 0.5778 - val_mae: 0.5282\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2017 - mse: 0.2017 - mae: 0.3457 - val_loss: 0.5493 - val_mse: 0.5493 - val_mae: 0.5208\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1996 - mse: 0.1996 - mae: 0.3436 - val_loss: 0.5634 - val_mse: 0.5634 - val_mae: 0.5219\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1953 - mse: 0.1953 - mae: 0.3393 - val_loss: 0.5342 - val_mse: 0.5342 - val_mae: 0.5180\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1884 - mse: 0.1884 - mae: 0.3370 - val_loss: 0.5312 - val_mse: 0.5312 - val_mae: 0.5173\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1784 - mse: 0.1784 - mae: 0.3259 - val_loss: 0.5365 - val_mse: 0.5365 - val_mae: 0.5181\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.1774 - mse: 0.1774 - mae: 0.3251 - val_loss: 0.5234 - val_mse: 0.5234 - val_mae: 0.5125\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1680 - mse: 0.1680 - mae: 0.3150 - val_loss: 0.5272 - val_mse: 0.5272 - val_mae: 0.5154\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1727 - mse: 0.1727 - mae: 0.3204 - val_loss: 0.5183 - val_mse: 0.5183 - val_mae: 0.5103\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1668 - mse: 0.1668 - mae: 0.3126 - val_loss: 0.5211 - val_mse: 0.5211 - val_mae: 0.5129\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1528 - mse: 0.1528 - mae: 0.3017 - val_loss: 0.5311 - val_mse: 0.5311 - val_mae: 0.5120\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1478 - mse: 0.1478 - mae: 0.2985 - val_loss: 0.5188 - val_mse: 0.5188 - val_mae: 0.5085\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1524 - mse: 0.1524 - mae: 0.3003 - val_loss: 0.5180 - val_mse: 0.5180 - val_mae: 0.5077\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1421 - mse: 0.1421 - mae: 0.2919 - val_loss: 0.5065 - val_mse: 0.5065 - val_mae: 0.5050\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.1478 - mse: 0.1478 - mae: 0.2956 - val_loss: 0.5119 - val_mse: 0.5119 - val_mae: 0.5037\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1432 - mse: 0.1432 - mae: 0.2912 - val_loss: 0.5115 - val_mse: 0.5115 - val_mae: 0.5039\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1438 - mse: 0.1438 - mae: 0.2920 - val_loss: 0.5062 - val_mse: 0.5062 - val_mae: 0.5027\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1373 - mse: 0.1373 - mae: 0.2865 - val_loss: 0.5066 - val_mse: 0.5066 - val_mae: 0.5017\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1349 - mse: 0.1349 - mae: 0.2818 - val_loss: 0.5004 - val_mse: 0.5004 - val_mae: 0.4966\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1289 - mse: 0.1289 - mae: 0.2771 - val_loss: 0.4925 - val_mse: 0.4925 - val_mae: 0.4959\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1343 - mse: 0.1343 - mae: 0.2812 - val_loss: 0.5010 - val_mse: 0.5010 - val_mae: 0.4968\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1307 - mse: 0.1307 - mae: 0.2767 - val_loss: 0.4974 - val_mse: 0.4974 - val_mae: 0.4931\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1187 - mse: 0.1187 - mae: 0.2651 - val_loss: 0.4961 - val_mse: 0.4961 - val_mae: 0.4949\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1219 - mse: 0.1219 - mae: 0.2686 - val_loss: 0.4967 - val_mse: 0.4967 - val_mae: 0.4958\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1205 - mse: 0.1205 - mae: 0.2667 - val_loss: 0.4957 - val_mse: 0.4957 - val_mae: 0.4925\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1220 - mse: 0.1220 - mae: 0.2677 - val_loss: 0.4916 - val_mse: 0.4916 - val_mae: 0.4925\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1194 - mse: 0.1194 - mae: 0.2648 - val_loss: 0.4935 - val_mse: 0.4935 - val_mae: 0.4906\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1123 - mse: 0.1123 - mae: 0.2575 - val_loss: 0.4906 - val_mse: 0.4906 - val_mae: 0.4858\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1111 - mse: 0.1111 - mae: 0.2558 - val_loss: 0.4889 - val_mse: 0.4889 - val_mae: 0.4873\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1113 - mse: 0.1113 - mae: 0.2575 - val_loss: 0.4827 - val_mse: 0.4827 - val_mae: 0.4862\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1099 - mse: 0.1099 - mae: 0.2537 - val_loss: 0.4844 - val_mse: 0.4844 - val_mae: 0.4868\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1130 - mse: 0.1130 - mae: 0.2567 - val_loss: 0.4817 - val_mse: 0.4817 - val_mae: 0.4842\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1086 - mse: 0.1086 - mae: 0.2536 - val_loss: 0.4806 - val_mse: 0.4806 - val_mae: 0.4845\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1098 - mse: 0.1098 - mae: 0.2541 - val_loss: 0.4795 - val_mse: 0.4795 - val_mae: 0.4828\n",
      "Epoch 55/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1043 - mse: 0.1043 - mae: 0.2469 - val_loss: 0.4771 - val_mse: 0.4771 - val_mae: 0.4825\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1071 - mse: 0.1071 - mae: 0.2502 - val_loss: 0.4712 - val_mse: 0.4712 - val_mae: 0.4797\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1030 - mse: 0.1030 - mae: 0.2467 - val_loss: 0.4734 - val_mse: 0.4734 - val_mae: 0.4787\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1002 - mse: 0.1002 - mae: 0.2421 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.4776\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0969 - mse: 0.0969 - mae: 0.2375 - val_loss: 0.4685 - val_mse: 0.4685 - val_mae: 0.4764\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1003 - mse: 0.1003 - mae: 0.2420 - val_loss: 0.4699 - val_mse: 0.4699 - val_mae: 0.4775\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0944 - mse: 0.0944 - mae: 0.2365 - val_loss: 0.4705 - val_mse: 0.4705 - val_mae: 0.4777\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0976 - mse: 0.0976 - mae: 0.2397 - val_loss: 0.4729 - val_mse: 0.4729 - val_mae: 0.4774\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0944 - mse: 0.0944 - mae: 0.2351 - val_loss: 0.4660 - val_mse: 0.4660 - val_mae: 0.4737\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0961 - mse: 0.0961 - mae: 0.2376 - val_loss: 0.4603 - val_mse: 0.4603 - val_mae: 0.4728\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0927 - mse: 0.0927 - mae: 0.2343 - val_loss: 0.4751 - val_mse: 0.4751 - val_mae: 0.4768\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0933 - mse: 0.0933 - mae: 0.2327 - val_loss: 0.4745 - val_mse: 0.4745 - val_mae: 0.4774\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0930 - mse: 0.0930 - mae: 0.2331 - val_loss: 0.4594 - val_mse: 0.4594 - val_mae: 0.4732\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0901 - mse: 0.0901 - mae: 0.2299 - val_loss: 0.4643 - val_mse: 0.4643 - val_mae: 0.4745\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0871 - mse: 0.0871 - mae: 0.2269 - val_loss: 0.4637 - val_mse: 0.4637 - val_mae: 0.4735\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0876 - mse: 0.0876 - mae: 0.2285 - val_loss: 0.4634 - val_mse: 0.4634 - val_mae: 0.4737\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0880 - mse: 0.0880 - mae: 0.2273 - val_loss: 0.4552 - val_mse: 0.4552 - val_mae: 0.4681\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0869 - mse: 0.0869 - mae: 0.2259 - val_loss: 0.4745 - val_mse: 0.4745 - val_mae: 0.4772\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0835 - mse: 0.0835 - mae: 0.2215 - val_loss: 0.4561 - val_mse: 0.4561 - val_mae: 0.4684\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0806 - mse: 0.0806 - mae: 0.2182 - val_loss: 0.4586 - val_mse: 0.4586 - val_mae: 0.4706\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0824 - mse: 0.0824 - mae: 0.2210 - val_loss: 0.4523 - val_mse: 0.4523 - val_mae: 0.4683\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0823 - mse: 0.0823 - mae: 0.2185 - val_loss: 0.4519 - val_mse: 0.4519 - val_mae: 0.4672\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0838 - mse: 0.0838 - mae: 0.2208 - val_loss: 0.4528 - val_mse: 0.4528 - val_mae: 0.4675\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0833 - mse: 0.0833 - mae: 0.2227 - val_loss: 0.4533 - val_mse: 0.4533 - val_mae: 0.4678\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0787 - mse: 0.0787 - mae: 0.2166 - val_loss: 0.4514 - val_mse: 0.4514 - val_mae: 0.4675\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0798 - mse: 0.0798 - mae: 0.2162 - val_loss: 0.4570 - val_mse: 0.4570 - val_mae: 0.4673\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0789 - mse: 0.0789 - mae: 0.2151 - val_loss: 0.4495 - val_mse: 0.4495 - val_mae: 0.4654\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0798 - mse: 0.0798 - mae: 0.2158 - val_loss: 0.4518 - val_mse: 0.4518 - val_mae: 0.4655\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0789 - mse: 0.0789 - mae: 0.2155 - val_loss: 0.4519 - val_mse: 0.4519 - val_mae: 0.4669\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0789 - mse: 0.0789 - mae: 0.2147 - val_loss: 0.4524 - val_mse: 0.4524 - val_mae: 0.4674\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0786 - mse: 0.0786 - mae: 0.2144 - val_loss: 0.4496 - val_mse: 0.4496 - val_mae: 0.4647\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.0779 - mse: 0.0779 - mae: 0.2137 - val_loss: 0.4446 - val_mse: 0.4446 - val_mae: 0.4616\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.0752 - mse: 0.0752 - mae: 0.2092 - val_loss: 0.4460 - val_mse: 0.4460 - val_mae: 0.4636\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.0737 - mse: 0.0737 - mae: 0.2081 - val_loss: 0.4473 - val_mse: 0.4473 - val_mae: 0.4638\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0726 - mse: 0.0726 - mae: 0.2068 - val_loss: 0.4414 - val_mse: 0.4414 - val_mae: 0.4600\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0747 - mse: 0.0747 - mae: 0.2096 - val_loss: 0.4453 - val_mse: 0.4453 - val_mae: 0.4605\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0736 - mse: 0.0736 - mae: 0.2074 - val_loss: 0.4469 - val_mse: 0.4469 - val_mae: 0.4635\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.0758 - mse: 0.0758 - mae: 0.2098 - val_loss: 0.4471 - val_mse: 0.4471 - val_mae: 0.4624\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0733 - mse: 0.0733 - mae: 0.2076 - val_loss: 0.4432 - val_mse: 0.4432 - val_mae: 0.4620\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0704 - mse: 0.0704 - mae: 0.2015 - val_loss: 0.4435 - val_mse: 0.4435 - val_mae: 0.4608\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0711 - mse: 0.0711 - mae: 0.2039 - val_loss: 0.4430 - val_mse: 0.4430 - val_mae: 0.4599\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0693 - mse: 0.0693 - mae: 0.2029 - val_loss: 0.4448 - val_mse: 0.4448 - val_mae: 0.4608\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0718 - mse: 0.0718 - mae: 0.2061 - val_loss: 0.4462 - val_mse: 0.4462 - val_mae: 0.4612\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0688 - mse: 0.0688 - mae: 0.1999 - val_loss: 0.4366 - val_mse: 0.4366 - val_mae: 0.4573\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0687 - mse: 0.0687 - mae: 0.1998 - val_loss: 0.4442 - val_mse: 0.4442 - val_mae: 0.4587\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0694 - mse: 0.0694 - mae: 0.2002 - val_loss: 0.4379 - val_mse: 0.4379 - val_mae: 0.4557\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0684 - mse: 0.0684 - mae: 0.2009 - val_loss: 0.4422 - val_mse: 0.4422 - val_mae: 0.4578\n",
      "Epoch 102/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0706 - mse: 0.0706 - mae: 0.2014 - val_loss: 0.4343 - val_mse: 0.4343 - val_mae: 0.4561\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.0687 - mse: 0.0687 - mae: 0.2001 - val_loss: 0.4322 - val_mse: 0.4322 - val_mae: 0.4567\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0663 - mse: 0.0663 - mae: 0.1976 - val_loss: 0.4314 - val_mse: 0.4314 - val_mae: 0.4583\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0676 - mse: 0.0676 - mae: 0.2006 - val_loss: 0.4331 - val_mse: 0.4331 - val_mae: 0.4566\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0653 - mse: 0.0653 - mae: 0.1937 - val_loss: 0.4347 - val_mse: 0.4347 - val_mae: 0.4572\n",
      "Epoch 107/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0662 - mse: 0.0662 - mae: 0.1964 - val_loss: 0.4279 - val_mse: 0.4279 - val_mae: 0.4544\n",
      "Epoch 108/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0651 - mse: 0.0651 - mae: 0.1947 - val_loss: 0.4364 - val_mse: 0.4364 - val_mae: 0.4591\n",
      "Epoch 109/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0639 - mse: 0.0639 - mae: 0.1942 - val_loss: 0.4310 - val_mse: 0.4310 - val_mae: 0.4553\n",
      "Epoch 110/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0628 - mse: 0.0628 - mae: 0.1922 - val_loss: 0.4331 - val_mse: 0.4331 - val_mae: 0.4593\n",
      "Epoch 111/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0646 - mse: 0.0646 - mae: 0.1944 - val_loss: 0.4334 - val_mse: 0.4334 - val_mae: 0.4605\n",
      "Epoch 112/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0637 - mse: 0.0637 - mae: 0.1924 - val_loss: 0.4315 - val_mse: 0.4315 - val_mae: 0.4570\n",
      "Epoch 113/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0635 - mse: 0.0635 - mae: 0.1935 - val_loss: 0.4311 - val_mse: 0.4311 - val_mae: 0.4549\n",
      "Epoch 114/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0610 - mse: 0.0610 - mae: 0.1895 - val_loss: 0.4281 - val_mse: 0.4281 - val_mae: 0.4561\n",
      "Epoch 115/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0627 - mse: 0.0627 - mae: 0.1907 - val_loss: 0.4319 - val_mse: 0.4319 - val_mae: 0.4554\n",
      "Epoch 116/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0630 - mse: 0.0630 - mae: 0.1915 - val_loss: 0.4313 - val_mse: 0.4313 - val_mae: 0.4550\n",
      "Epoch 117/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0622 - mse: 0.0622 - mae: 0.1884 - val_loss: 0.4321 - val_mse: 0.4321 - val_mae: 0.4531\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 200us/sample - loss: 1.6273 - mse: 1.6273 - mae: 0.9702 - val_loss: 0.9994 - val_mse: 0.9994 - val_mae: 0.7774\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.9042 - mse: 0.9042 - mae: 0.7309 - val_loss: 0.9509 - val_mse: 0.9509 - val_mae: 0.7368\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.7076 - mse: 0.7076 - mae: 0.6475 - val_loss: 0.9137 - val_mse: 0.9137 - val_mae: 0.7184\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.6180 - mse: 0.6180 - mae: 0.6067 - val_loss: 0.8745 - val_mse: 0.8745 - val_mae: 0.7031\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.5258 - mse: 0.5258 - mae: 0.5582 - val_loss: 0.8118 - val_mse: 0.8118 - val_mae: 0.6775\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.4771 - mse: 0.4771 - mae: 0.5321 - val_loss: 0.7596 - val_mse: 0.7596 - val_mae: 0.6549\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.4243 - mse: 0.4243 - mae: 0.5017 - val_loss: 0.7942 - val_mse: 0.7942 - val_mae: 0.6303\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.3977 - mse: 0.3977 - mae: 0.4831 - val_loss: 0.7080 - val_mse: 0.7080 - val_mae: 0.6048\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.3736 - mse: 0.3736 - mae: 0.4729 - val_loss: 0.6858 - val_mse: 0.6858 - val_mae: 0.5894\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.3460 - mse: 0.3460 - mae: 0.4539 - val_loss: 0.6434 - val_mse: 0.6434 - val_mae: 0.5739\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3319 - mse: 0.3319 - mae: 0.4423 - val_loss: 0.6142 - val_mse: 0.6142 - val_mae: 0.5666\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.3058 - mse: 0.3058 - mae: 0.4257 - val_loss: 0.6672 - val_mse: 0.6672 - val_mae: 0.5588\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2880 - mse: 0.2880 - mae: 0.4138 - val_loss: 0.6038 - val_mse: 0.6038 - val_mae: 0.5470\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.2750 - mse: 0.2750 - mae: 0.4043 - val_loss: 0.6505 - val_mse: 0.6505 - val_mae: 0.5468\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2642 - mse: 0.2642 - mae: 0.3986 - val_loss: 0.6189 - val_mse: 0.6189 - val_mae: 0.5415\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2592 - mse: 0.2592 - mae: 0.3925 - val_loss: 0.6417 - val_mse: 0.6417 - val_mae: 0.5412\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2455 - mse: 0.2455 - mae: 0.3810 - val_loss: 0.6088 - val_mse: 0.6088 - val_mae: 0.5382\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2342 - mse: 0.2342 - mae: 0.3732 - val_loss: 0.6247 - val_mse: 0.6247 - val_mae: 0.5300\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2232 - mse: 0.2232 - mae: 0.3649 - val_loss: 0.5920 - val_mse: 0.5920 - val_mae: 0.5295\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2105 - mse: 0.2105 - mae: 0.3549 - val_loss: 0.5657 - val_mse: 0.5657 - val_mae: 0.5245\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2077 - mse: 0.2077 - mae: 0.3506 - val_loss: 0.5979 - val_mse: 0.5979 - val_mae: 0.5247\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1968 - mse: 0.1968 - mae: 0.3444 - val_loss: 0.5916 - val_mse: 0.5916 - val_mae: 0.5282\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.1956 - mse: 0.1956 - mae: 0.3401 - val_loss: 0.5887 - val_mse: 0.5887 - val_mae: 0.5218\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1848 - mse: 0.1848 - mae: 0.3321 - val_loss: 0.5702 - val_mse: 0.5702 - val_mae: 0.5208\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1850 - mse: 0.1850 - mae: 0.3306 - val_loss: 0.5595 - val_mse: 0.5595 - val_mae: 0.5144\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1800 - mse: 0.1800 - mae: 0.3287 - val_loss: 0.5493 - val_mse: 0.5493 - val_mae: 0.5114\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1763 - mse: 0.1763 - mae: 0.3260 - val_loss: 0.5365 - val_mse: 0.5365 - val_mae: 0.5099\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1706 - mse: 0.1706 - mae: 0.3174 - val_loss: 0.5363 - val_mse: 0.5363 - val_mae: 0.5096\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1619 - mse: 0.1619 - mae: 0.3119 - val_loss: 0.5188 - val_mse: 0.5188 - val_mae: 0.5062\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1607 - mse: 0.1607 - mae: 0.3090 - val_loss: 0.5144 - val_mse: 0.5144 - val_mae: 0.5028\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.1610 - mse: 0.1610 - mae: 0.3090 - val_loss: 0.5295 - val_mse: 0.5295 - val_mae: 0.5053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1495 - mse: 0.1495 - mae: 0.3007 - val_loss: 0.5357 - val_mse: 0.5357 - val_mae: 0.5017\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1510 - mse: 0.1510 - mae: 0.3014 - val_loss: 0.5283 - val_mse: 0.5283 - val_mae: 0.5024\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1433 - mse: 0.1433 - mae: 0.2920 - val_loss: 0.5192 - val_mse: 0.5192 - val_mae: 0.5012\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1441 - mse: 0.1441 - mae: 0.2942 - val_loss: 0.5097 - val_mse: 0.5097 - val_mae: 0.4977\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1459 - mse: 0.1459 - mae: 0.2928 - val_loss: 0.5491 - val_mse: 0.5491 - val_mae: 0.4986\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1347 - mse: 0.1347 - mae: 0.2842 - val_loss: 0.5140 - val_mse: 0.5140 - val_mae: 0.4975\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1355 - mse: 0.1355 - mae: 0.2852 - val_loss: 0.5135 - val_mse: 0.5135 - val_mae: 0.4956\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1397 - mse: 0.1397 - mae: 0.2900 - val_loss: 0.5014 - val_mse: 0.5014 - val_mae: 0.4897\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1348 - mse: 0.1348 - mae: 0.2822 - val_loss: 0.5279 - val_mse: 0.5279 - val_mae: 0.4958\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1287 - mse: 0.1287 - mae: 0.2776 - val_loss: 0.5184 - val_mse: 0.5184 - val_mae: 0.4952\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1260 - mse: 0.1260 - mae: 0.2769 - val_loss: 0.5083 - val_mse: 0.5083 - val_mae: 0.4902\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1239 - mse: 0.1239 - mae: 0.2716 - val_loss: 0.4921 - val_mse: 0.4921 - val_mae: 0.4914\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1198 - mse: 0.1198 - mae: 0.2690 - val_loss: 0.4934 - val_mse: 0.4934 - val_mae: 0.4878\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1168 - mse: 0.1168 - mae: 0.2635 - val_loss: 0.4938 - val_mse: 0.4938 - val_mae: 0.4860\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1167 - mse: 0.1167 - mae: 0.2654 - val_loss: 0.4959 - val_mse: 0.4959 - val_mae: 0.4906\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1173 - mse: 0.1173 - mae: 0.2654 - val_loss: 0.4953 - val_mse: 0.4953 - val_mae: 0.4884\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1170 - mse: 0.1170 - mae: 0.2651 - val_loss: 0.4851 - val_mse: 0.4851 - val_mae: 0.4869\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1118 - mse: 0.1118 - mae: 0.2593 - val_loss: 0.4885 - val_mse: 0.4885 - val_mae: 0.4857\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1129 - mse: 0.1129 - mae: 0.2593 - val_loss: 0.4971 - val_mse: 0.4971 - val_mae: 0.4870\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1103 - mse: 0.1103 - mae: 0.2574 - val_loss: 0.4917 - val_mse: 0.4917 - val_mae: 0.4882\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1044 - mse: 0.1044 - mae: 0.2499 - val_loss: 0.5017 - val_mse: 0.5017 - val_mae: 0.4850\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.1045 - mse: 0.1045 - mae: 0.2490 - val_loss: 0.4853 - val_mse: 0.4853 - val_mae: 0.4881\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1054 - mse: 0.1054 - mae: 0.2517 - val_loss: 0.5035 - val_mse: 0.5035 - val_mae: 0.4836\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1037 - mse: 0.1037 - mae: 0.2490 - val_loss: 0.4836 - val_mse: 0.4836 - val_mae: 0.4812\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1066 - mse: 0.1066 - mae: 0.2531 - val_loss: 0.4799 - val_mse: 0.4799 - val_mae: 0.4796\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1001 - mse: 0.1001 - mae: 0.2442 - val_loss: 0.4837 - val_mse: 0.4837 - val_mae: 0.4804\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0982 - mse: 0.0982 - mae: 0.2436 - val_loss: 0.4708 - val_mse: 0.4708 - val_mae: 0.4743\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0979 - mse: 0.0979 - mae: 0.2425 - val_loss: 0.4744 - val_mse: 0.4744 - val_mae: 0.4744\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0978 - mse: 0.0978 - mae: 0.2422 - val_loss: 0.4811 - val_mse: 0.4811 - val_mae: 0.4793\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0968 - mse: 0.0968 - mae: 0.2405 - val_loss: 0.4706 - val_mse: 0.4706 - val_mae: 0.4745\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0970 - mse: 0.0970 - mae: 0.2403 - val_loss: 0.4998 - val_mse: 0.4998 - val_mae: 0.4730\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0933 - mse: 0.0933 - mae: 0.2356 - val_loss: 0.4586 - val_mse: 0.4586 - val_mae: 0.4682\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0925 - mse: 0.0925 - mae: 0.2349 - val_loss: 0.4929 - val_mse: 0.4929 - val_mae: 0.4777\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0869 - mse: 0.0869 - mae: 0.2293 - val_loss: 0.4662 - val_mse: 0.4662 - val_mae: 0.4723\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0945 - mse: 0.0945 - mae: 0.2388 - val_loss: 0.4612 - val_mse: 0.4612 - val_mae: 0.4691\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0885 - mse: 0.0885 - mae: 0.2302 - val_loss: 0.4718 - val_mse: 0.4718 - val_mae: 0.4718\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0881 - mse: 0.0881 - mae: 0.2292 - val_loss: 0.4659 - val_mse: 0.4659 - val_mae: 0.4691\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0858 - mse: 0.0858 - mae: 0.2262 - val_loss: 0.4447 - val_mse: 0.4447 - val_mae: 0.4669\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0847 - mse: 0.0847 - mae: 0.2243 - val_loss: 0.4540 - val_mse: 0.4540 - val_mae: 0.4671\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0856 - mse: 0.0856 - mae: 0.2260 - val_loss: 0.4462 - val_mse: 0.4462 - val_mae: 0.4673\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0837 - mse: 0.0837 - mae: 0.2237 - val_loss: 0.4611 - val_mse: 0.4611 - val_mae: 0.4693\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0842 - mse: 0.0842 - mae: 0.2246 - val_loss: 0.4626 - val_mse: 0.4626 - val_mae: 0.4732\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0829 - mse: 0.0829 - mae: 0.2238 - val_loss: 0.4587 - val_mse: 0.4587 - val_mae: 0.4713\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0837 - mse: 0.0837 - mae: 0.2242 - val_loss: 0.4450 - val_mse: 0.4450 - val_mae: 0.4679\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0773 - mse: 0.0773 - mae: 0.2147 - val_loss: 0.4523 - val_mse: 0.4523 - val_mae: 0.4682\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.0854 - mse: 0.0854 - mae: 0.2237 - val_loss: 0.4477 - val_mse: 0.4477 - val_mae: 0.4688\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0791 - mse: 0.0791 - mae: 0.2174 - val_loss: 0.4472 - val_mse: 0.4472 - val_mae: 0.4674\n",
      "Epoch 79/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0813 - mse: 0.0813 - mae: 0.2204 - val_loss: 0.4427 - val_mse: 0.4427 - val_mae: 0.4669\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.0780 - mse: 0.0780 - mae: 0.2172 - val_loss: 0.4387 - val_mse: 0.4387 - val_mae: 0.4659\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.0788 - mse: 0.0788 - mae: 0.2190 - val_loss: 0.4414 - val_mse: 0.4414 - val_mae: 0.4676\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0765 - mse: 0.0765 - mae: 0.2141 - val_loss: 0.4514 - val_mse: 0.4514 - val_mae: 0.4676\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0744 - mse: 0.0744 - mae: 0.2116 - val_loss: 0.4457 - val_mse: 0.4457 - val_mae: 0.4666\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0746 - mse: 0.0746 - mae: 0.2118 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.4656\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.0738 - mse: 0.0738 - mae: 0.2096 - val_loss: 0.4444 - val_mse: 0.4444 - val_mae: 0.4627\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0764 - mse: 0.0764 - mae: 0.2136 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4683\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0742 - mse: 0.0742 - mae: 0.2097 - val_loss: 0.4463 - val_mse: 0.4463 - val_mae: 0.4665\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0734 - mse: 0.0734 - mae: 0.2093 - val_loss: 0.4389 - val_mse: 0.4389 - val_mae: 0.4633\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0711 - mse: 0.0711 - mae: 0.2073 - val_loss: 0.4396 - val_mse: 0.4396 - val_mae: 0.4629\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0731 - mse: 0.0731 - mae: 0.2095 - val_loss: 0.4412 - val_mse: 0.4412 - val_mae: 0.4618\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 198us/sample - loss: 1.6145 - mse: 1.6145 - mae: 0.9719 - val_loss: 1.0193 - val_mse: 1.0193 - val_mae: 0.8119\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.8904 - mse: 0.8904 - mae: 0.7272 - val_loss: 0.9470 - val_mse: 0.9470 - val_mae: 0.7307\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.6934 - mse: 0.6934 - mae: 0.6440 - val_loss: 0.8997 - val_mse: 0.8997 - val_mae: 0.7118\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.6050 - mse: 0.6050 - mae: 0.5979 - val_loss: 0.8552 - val_mse: 0.8552 - val_mae: 0.6968\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.5231 - mse: 0.5231 - mae: 0.5552 - val_loss: 0.7971 - val_mse: 0.7971 - val_mae: 0.6716\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.4768 - mse: 0.4768 - mae: 0.5305 - val_loss: 0.7275 - val_mse: 0.7275 - val_mae: 0.6506\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.4322 - mse: 0.4322 - mae: 0.5057 - val_loss: 0.6707 - val_mse: 0.6707 - val_mae: 0.6219\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.3973 - mse: 0.3973 - mae: 0.4844 - val_loss: 0.6328 - val_mse: 0.6328 - val_mae: 0.6026\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.3716 - mse: 0.3716 - mae: 0.4698 - val_loss: 0.6017 - val_mse: 0.6017 - val_mae: 0.5866\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3490 - mse: 0.3490 - mae: 0.4566 - val_loss: 0.6078 - val_mse: 0.6078 - val_mae: 0.5800\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3192 - mse: 0.3192 - mae: 0.4368 - val_loss: 0.5714 - val_mse: 0.5714 - val_mae: 0.5642\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.3110 - mse: 0.3110 - mae: 0.4291 - val_loss: 0.5718 - val_mse: 0.5718 - val_mae: 0.5633\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2935 - mse: 0.2935 - mae: 0.4184 - val_loss: 0.5502 - val_mse: 0.5502 - val_mae: 0.5547\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2757 - mse: 0.2757 - mae: 0.4040 - val_loss: 0.5276 - val_mse: 0.5276 - val_mae: 0.5435\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - ETA: 0s - loss: 0.2590 - mse: 0.2590 - mae: 0.391 - 1s 56us/sample - loss: 0.2582 - mse: 0.2582 - mae: 0.3910 - val_loss: 0.5316 - val_mse: 0.5316 - val_mae: 0.5378\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2530 - mse: 0.2530 - mae: 0.3849 - val_loss: 0.5269 - val_mse: 0.5269 - val_mae: 0.5361\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2435 - mse: 0.2435 - mae: 0.3798 - val_loss: 0.5115 - val_mse: 0.5115 - val_mae: 0.5283\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2311 - mse: 0.2311 - mae: 0.3693 - val_loss: 0.5107 - val_mse: 0.5107 - val_mae: 0.5241\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2227 - mse: 0.2227 - mae: 0.3637 - val_loss: 0.5195 - val_mse: 0.5195 - val_mae: 0.5275\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2170 - mse: 0.2170 - mae: 0.3572 - val_loss: 0.5214 - val_mse: 0.5214 - val_mae: 0.5262\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2046 - mse: 0.2046 - mae: 0.3493 - val_loss: 0.5040 - val_mse: 0.5040 - val_mae: 0.5197\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2057 - mse: 0.2057 - mae: 0.3495 - val_loss: 0.5046 - val_mse: 0.5046 - val_mae: 0.5206\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1956 - mse: 0.1956 - mae: 0.3398 - val_loss: 0.5014 - val_mse: 0.5014 - val_mae: 0.5135\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1947 - mse: 0.1947 - mae: 0.3391 - val_loss: 0.4967 - val_mse: 0.4967 - val_mae: 0.5120\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1874 - mse: 0.1874 - mae: 0.3323 - val_loss: 0.4958 - val_mse: 0.4958 - val_mae: 0.5099\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1801 - mse: 0.1801 - mae: 0.3250 - val_loss: 0.4851 - val_mse: 0.4851 - val_mae: 0.5077\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1742 - mse: 0.1742 - mae: 0.3217 - val_loss: 0.4817 - val_mse: 0.4817 - val_mae: 0.5028\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1712 - mse: 0.1712 - mae: 0.3187 - val_loss: 0.4931 - val_mse: 0.4931 - val_mae: 0.5060\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1716 - mse: 0.1716 - mae: 0.3196 - val_loss: 0.4860 - val_mse: 0.4860 - val_mae: 0.5015\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1637 - mse: 0.1637 - mae: 0.3116 - val_loss: 0.4837 - val_mse: 0.4837 - val_mae: 0.5031\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1562 - mse: 0.1562 - mae: 0.3061 - val_loss: 0.4741 - val_mse: 0.4741 - val_mae: 0.4971\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.1517 - mse: 0.1517 - mae: 0.2999 - val_loss: 0.4725 - val_mse: 0.4725 - val_mae: 0.4964\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1536 - mse: 0.1536 - mae: 0.3035 - val_loss: 0.4752 - val_mse: 0.4752 - val_mae: 0.4951\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1447 - mse: 0.1447 - mae: 0.2931 - val_loss: 0.4677 - val_mse: 0.4677 - val_mae: 0.4931\n",
      "Epoch 35/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1462 - mse: 0.1462 - mae: 0.2959 - val_loss: 0.4605 - val_mse: 0.4605 - val_mae: 0.4887\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1361 - mse: 0.1361 - mae: 0.2844 - val_loss: 0.4632 - val_mse: 0.4632 - val_mae: 0.4912\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1412 - mse: 0.1412 - mae: 0.2891 - val_loss: 0.4597 - val_mse: 0.4597 - val_mae: 0.4887\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1366 - mse: 0.1366 - mae: 0.2838 - val_loss: 0.4560 - val_mse: 0.4560 - val_mae: 0.4861\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1334 - mse: 0.1334 - mae: 0.2798 - val_loss: 0.4515 - val_mse: 0.4515 - val_mae: 0.4836\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1296 - mse: 0.1296 - mae: 0.2762 - val_loss: 0.4594 - val_mse: 0.4594 - val_mae: 0.4865\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1288 - mse: 0.1288 - mae: 0.2753 - val_loss: 0.4518 - val_mse: 0.4518 - val_mae: 0.4847\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1292 - mse: 0.1292 - mae: 0.2759 - val_loss: 0.4593 - val_mse: 0.4593 - val_mae: 0.4852\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1292 - mse: 0.1292 - mae: 0.2757 - val_loss: 0.4403 - val_mse: 0.4403 - val_mae: 0.4788\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1226 - mse: 0.1226 - mae: 0.2683 - val_loss: 0.4429 - val_mse: 0.4429 - val_mae: 0.4803\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1212 - mse: 0.1212 - mae: 0.2670 - val_loss: 0.4375 - val_mse: 0.4375 - val_mae: 0.4798\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1207 - mse: 0.1207 - mae: 0.2655 - val_loss: 0.4418 - val_mse: 0.4418 - val_mae: 0.4781\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1173 - mse: 0.1173 - mae: 0.2629 - val_loss: 0.4377 - val_mse: 0.4377 - val_mae: 0.4762\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1144 - mse: 0.1144 - mae: 0.2594 - val_loss: 0.4331 - val_mse: 0.4331 - val_mae: 0.4744\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1141 - mse: 0.1141 - mae: 0.2598 - val_loss: 0.4395 - val_mse: 0.4395 - val_mae: 0.4755\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1122 - mse: 0.1122 - mae: 0.2542 - val_loss: 0.4283 - val_mse: 0.4283 - val_mae: 0.4737\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1138 - mse: 0.1138 - mae: 0.2576 - val_loss: 0.4340 - val_mse: 0.4340 - val_mae: 0.4732\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1046 - mse: 0.1046 - mae: 0.2484 - val_loss: 0.4354 - val_mse: 0.4354 - val_mae: 0.4752\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1082 - mse: 0.1082 - mae: 0.2513 - val_loss: 0.4357 - val_mse: 0.4357 - val_mae: 0.4742\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.1079 - mse: 0.1079 - mae: 0.2497 - val_loss: 0.4300 - val_mse: 0.4300 - val_mae: 0.4714\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1042 - mse: 0.1042 - mae: 0.2456 - val_loss: 0.4305 - val_mse: 0.4305 - val_mae: 0.4710\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1001 - mse: 0.1001 - mae: 0.2412 - val_loss: 0.4425 - val_mse: 0.4425 - val_mae: 0.4755\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1026 - mse: 0.1026 - mae: 0.2457 - val_loss: 0.4289 - val_mse: 0.4289 - val_mae: 0.4686\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1012 - mse: 0.1012 - mae: 0.2429 - val_loss: 0.4269 - val_mse: 0.4269 - val_mae: 0.4654\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.1047 - mse: 0.1047 - mae: 0.2473 - val_loss: 0.4262 - val_mse: 0.4262 - val_mae: 0.4648\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.1032 - mse: 0.1032 - mae: 0.2456 - val_loss: 0.4300 - val_mse: 0.4300 - val_mae: 0.4680\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0951 - mse: 0.0951 - mae: 0.2355 - val_loss: 0.4226 - val_mse: 0.4226 - val_mae: 0.4638\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0970 - mse: 0.0970 - mae: 0.2383 - val_loss: 0.4250 - val_mse: 0.4250 - val_mae: 0.4644\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0926 - mse: 0.0926 - mae: 0.2323 - val_loss: 0.4225 - val_mse: 0.4225 - val_mae: 0.4641\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0917 - mse: 0.0917 - mae: 0.2329 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4633\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0891 - mse: 0.0891 - mae: 0.2290 - val_loss: 0.4190 - val_mse: 0.4190 - val_mae: 0.4645\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0965 - mse: 0.0965 - mae: 0.2363 - val_loss: 0.4145 - val_mse: 0.4145 - val_mae: 0.4608\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0930 - mse: 0.0930 - mae: 0.2332 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.4655\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0940 - mse: 0.0940 - mae: 0.2333 - val_loss: 0.4203 - val_mse: 0.4203 - val_mae: 0.4611\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0916 - mse: 0.0916 - mae: 0.2307 - val_loss: 0.4201 - val_mse: 0.4201 - val_mae: 0.4626\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0886 - mse: 0.0886 - mae: 0.2276 - val_loss: 0.4202 - val_mse: 0.4202 - val_mae: 0.4628\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0873 - mse: 0.0873 - mae: 0.2271 - val_loss: 0.4240 - val_mse: 0.4240 - val_mae: 0.4626\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0847 - mse: 0.0847 - mae: 0.2221 - val_loss: 0.4268 - val_mse: 0.4268 - val_mae: 0.4645\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.0858 - mse: 0.0858 - mae: 0.2229 - val_loss: 0.4225 - val_mse: 0.4225 - val_mae: 0.4613\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.0858 - mse: 0.0858 - mae: 0.2231 - val_loss: 0.4159 - val_mse: 0.4159 - val_mae: 0.4572\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.0841 - mse: 0.0841 - mae: 0.2209 - val_loss: 0.4232 - val_mse: 0.4232 - val_mae: 0.4588\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.0879 - mse: 0.0879 - mae: 0.2249 - val_loss: 0.4311 - val_mse: 0.4311 - val_mae: 0.4624\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 3s 239us/sample - loss: 1.6863 - mse: 1.6863 - mae: 0.9877 - val_loss: 0.9751 - val_mse: 0.9751 - val_mae: 0.7605\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.9351 - mse: 0.9351 - mae: 0.7417 - val_loss: 1.0046 - val_mse: 1.0046 - val_mae: 0.7495\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.7250 - mse: 0.7250 - mae: 0.6557 - val_loss: 0.9863 - val_mse: 0.9863 - val_mae: 0.7375\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.6234 - mse: 0.6234 - mae: 0.6037 - val_loss: 0.9057 - val_mse: 0.9057 - val_mae: 0.7115\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.5310 - mse: 0.5310 - mae: 0.5623 - val_loss: 0.7946 - val_mse: 0.7946 - val_mae: 0.6678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.4953 - mse: 0.4953 - mae: 0.5398 - val_loss: 0.7043 - val_mse: 0.7043 - val_mae: 0.6259\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.4448 - mse: 0.4448 - mae: 0.5138 - val_loss: 0.6604 - val_mse: 0.6604 - val_mae: 0.6033\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.4099 - mse: 0.4099 - mae: 0.4925 - val_loss: 0.6290 - val_mse: 0.6290 - val_mae: 0.5809\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3756 - mse: 0.3756 - mae: 0.4726 - val_loss: 0.6229 - val_mse: 0.6229 - val_mae: 0.5768\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3566 - mse: 0.3566 - mae: 0.4588 - val_loss: 0.5969 - val_mse: 0.5969 - val_mae: 0.5658\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.3291 - mse: 0.3291 - mae: 0.4420 - val_loss: 0.6091 - val_mse: 0.6091 - val_mae: 0.5591\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3108 - mse: 0.3108 - mae: 0.4278 - val_loss: 0.6052 - val_mse: 0.6052 - val_mae: 0.5614\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.2929 - mse: 0.2929 - mae: 0.4170 - val_loss: 0.5890 - val_mse: 0.5890 - val_mae: 0.5511\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.2814 - mse: 0.2814 - mae: 0.4099 - val_loss: 0.5893 - val_mse: 0.5893 - val_mae: 0.5458\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.2700 - mse: 0.2700 - mae: 0.3989 - val_loss: 0.5884 - val_mse: 0.5884 - val_mae: 0.5412\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.2514 - mse: 0.2514 - mae: 0.3852 - val_loss: 0.5875 - val_mse: 0.5875 - val_mae: 0.5373\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.2468 - mse: 0.2468 - mae: 0.3846 - val_loss: 0.5771 - val_mse: 0.5771 - val_mae: 0.5358\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.2341 - mse: 0.2341 - mae: 0.3710 - val_loss: 0.5637 - val_mse: 0.5637 - val_mae: 0.5286\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.2258 - mse: 0.2258 - mae: 0.3651 - val_loss: 0.5554 - val_mse: 0.5554 - val_mae: 0.5227\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.2202 - mse: 0.2202 - mae: 0.3611 - val_loss: 0.5409 - val_mse: 0.5409 - val_mae: 0.5182\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.2118 - mse: 0.2118 - mae: 0.3554 - val_loss: 0.5550 - val_mse: 0.5550 - val_mae: 0.5191\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.2024 - mse: 0.2024 - mae: 0.3470 - val_loss: 0.5668 - val_mse: 0.5668 - val_mae: 0.5181\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.1961 - mse: 0.1961 - mae: 0.3389 - val_loss: 0.5458 - val_mse: 0.5458 - val_mae: 0.5133\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.1949 - mse: 0.1949 - mae: 0.3402 - val_loss: 0.5346 - val_mse: 0.5346 - val_mae: 0.5105\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1892 - mse: 0.1892 - mae: 0.3354 - val_loss: 0.5261 - val_mse: 0.5261 - val_mae: 0.5090\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1777 - mse: 0.1777 - mae: 0.3238 - val_loss: 0.5237 - val_mse: 0.5237 - val_mae: 0.5079\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1778 - mse: 0.1778 - mae: 0.3262 - val_loss: 0.5191 - val_mse: 0.5191 - val_mae: 0.5065\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1685 - mse: 0.1685 - mae: 0.3168 - val_loss: 0.5054 - val_mse: 0.5054 - val_mae: 0.4992\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1651 - mse: 0.1651 - mae: 0.3129 - val_loss: 0.5116 - val_mse: 0.5116 - val_mae: 0.5032\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1598 - mse: 0.1598 - mae: 0.3065 - val_loss: 0.5116 - val_mse: 0.5116 - val_mae: 0.5028\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1632 - mse: 0.1632 - mae: 0.3104 - val_loss: 0.5087 - val_mse: 0.5087 - val_mae: 0.5010\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1551 - mse: 0.1551 - mae: 0.3047 - val_loss: 0.5004 - val_mse: 0.5004 - val_mae: 0.4979\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1520 - mse: 0.1520 - mae: 0.3002 - val_loss: 0.5056 - val_mse: 0.5056 - val_mae: 0.4976\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1458 - mse: 0.1458 - mae: 0.2954 - val_loss: 0.4906 - val_mse: 0.4906 - val_mae: 0.4932\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1469 - mse: 0.1469 - mae: 0.2937 - val_loss: 0.4928 - val_mse: 0.4928 - val_mae: 0.4930\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.1418 - mse: 0.1418 - mae: 0.2892 - val_loss: 0.4897 - val_mse: 0.4897 - val_mae: 0.4913\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1434 - mse: 0.1434 - mae: 0.2902 - val_loss: 0.4893 - val_mse: 0.4893 - val_mae: 0.4895\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.1380 - mse: 0.1380 - mae: 0.2851 - val_loss: 0.4868 - val_mse: 0.4868 - val_mae: 0.4894\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1373 - mse: 0.1373 - mae: 0.2834 - val_loss: 0.4995 - val_mse: 0.4995 - val_mae: 0.4898\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1343 - mse: 0.1343 - mae: 0.2825 - val_loss: 0.4833 - val_mse: 0.4833 - val_mae: 0.4879\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1298 - mse: 0.1298 - mae: 0.2762 - val_loss: 0.4768 - val_mse: 0.4768 - val_mae: 0.4862\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1266 - mse: 0.1266 - mae: 0.2744 - val_loss: 0.4740 - val_mse: 0.4740 - val_mae: 0.4835\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1223 - mse: 0.1223 - mae: 0.2698 - val_loss: 0.4731 - val_mse: 0.4731 - val_mae: 0.4816\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.1277 - mse: 0.1277 - mae: 0.2746 - val_loss: 0.4644 - val_mse: 0.4644 - val_mae: 0.4804\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.1194 - mse: 0.1194 - mae: 0.2669 - val_loss: 0.4676 - val_mse: 0.4676 - val_mae: 0.4807\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.1205 - mse: 0.1205 - mae: 0.2657 - val_loss: 0.4666 - val_mse: 0.4666 - val_mae: 0.4783\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1189 - mse: 0.1189 - mae: 0.2655 - val_loss: 0.4617 - val_mse: 0.4617 - val_mae: 0.4790\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1181 - mse: 0.1181 - mae: 0.2642 - val_loss: 0.4731 - val_mse: 0.4731 - val_mae: 0.4818\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1179 - mse: 0.1179 - mae: 0.2631 - val_loss: 0.4697 - val_mse: 0.4697 - val_mae: 0.4779\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1140 - mse: 0.1140 - mae: 0.2603 - val_loss: 0.4589 - val_mse: 0.4589 - val_mae: 0.4754\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1123 - mse: 0.1123 - mae: 0.2580 - val_loss: 0.4582 - val_mse: 0.4582 - val_mae: 0.4739\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1080 - mse: 0.1080 - mae: 0.2533 - val_loss: 0.4519 - val_mse: 0.4519 - val_mae: 0.4734\n",
      "Epoch 53/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1077 - mse: 0.1077 - mae: 0.2506 - val_loss: 0.4503 - val_mse: 0.4503 - val_mae: 0.4724\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.1097 - mse: 0.1097 - mae: 0.2526 - val_loss: 0.4592 - val_mse: 0.4592 - val_mae: 0.4786\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1079 - mse: 0.1079 - mae: 0.2537 - val_loss: 0.4540 - val_mse: 0.4540 - val_mae: 0.4728\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1059 - mse: 0.1059 - mae: 0.2508 - val_loss: 0.4548 - val_mse: 0.4548 - val_mae: 0.4734\n",
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.1032 - mse: 0.1032 - mae: 0.2467 - val_loss: 0.4471 - val_mse: 0.4471 - val_mae: 0.4707\n",
      "Epoch 58/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.1009 - mse: 0.1009 - mae: 0.2437 - val_loss: 0.4481 - val_mse: 0.4481 - val_mae: 0.4728\n",
      "Epoch 59/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.0982 - mse: 0.0982 - mae: 0.2405 - val_loss: 0.4441 - val_mse: 0.4441 - val_mae: 0.4701\n",
      "Epoch 60/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0981 - mse: 0.0981 - mae: 0.2394 - val_loss: 0.4496 - val_mse: 0.4496 - val_mae: 0.4699\n",
      "Epoch 61/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0951 - mse: 0.0951 - mae: 0.2372 - val_loss: 0.4449 - val_mse: 0.4449 - val_mae: 0.4670\n",
      "Epoch 62/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0947 - mse: 0.0947 - mae: 0.2360 - val_loss: 0.4456 - val_mse: 0.4456 - val_mae: 0.4682\n",
      "Epoch 63/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.0957 - mse: 0.0957 - mae: 0.2392 - val_loss: 0.4388 - val_mse: 0.4388 - val_mae: 0.4660\n",
      "Epoch 64/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.0934 - mse: 0.0934 - mae: 0.2348 - val_loss: 0.4409 - val_mse: 0.4409 - val_mae: 0.4658\n",
      "Epoch 65/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0947 - mse: 0.0947 - mae: 0.2361 - val_loss: 0.4363 - val_mse: 0.4363 - val_mae: 0.4604\n",
      "Epoch 66/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0911 - mse: 0.0911 - mae: 0.2299 - val_loss: 0.4391 - val_mse: 0.4391 - val_mae: 0.4619\n",
      "Epoch 67/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.0949 - mse: 0.0949 - mae: 0.2363 - val_loss: 0.4394 - val_mse: 0.4394 - val_mae: 0.4630\n",
      "Epoch 68/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0923 - mse: 0.0923 - mae: 0.2328 - val_loss: 0.4375 - val_mse: 0.4375 - val_mae: 0.4643\n",
      "Epoch 69/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0915 - mse: 0.0915 - mae: 0.2329 - val_loss: 0.4371 - val_mse: 0.4371 - val_mae: 0.4625\n",
      "Epoch 70/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.0919 - mse: 0.0919 - mae: 0.2332 - val_loss: 0.4358 - val_mse: 0.4358 - val_mae: 0.4603\n",
      "Epoch 71/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.0870 - mse: 0.0870 - mae: 0.2263 - val_loss: 0.4300 - val_mse: 0.4300 - val_mae: 0.4591\n",
      "Epoch 72/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0900 - mse: 0.0900 - mae: 0.2300 - val_loss: 0.4351 - val_mse: 0.4351 - val_mae: 0.4616\n",
      "Epoch 73/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0868 - mse: 0.0868 - mae: 0.2258 - val_loss: 0.4314 - val_mse: 0.4314 - val_mae: 0.4602\n",
      "Epoch 74/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0835 - mse: 0.0835 - mae: 0.2206 - val_loss: 0.4280 - val_mse: 0.4280 - val_mae: 0.4576\n",
      "Epoch 75/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0904 - mse: 0.0904 - mae: 0.2295 - val_loss: 0.4279 - val_mse: 0.4279 - val_mae: 0.4572\n",
      "Epoch 76/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.0827 - mse: 0.0827 - mae: 0.2198 - val_loss: 0.4273 - val_mse: 0.4273 - val_mae: 0.4596\n",
      "Epoch 77/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0837 - mse: 0.0837 - mae: 0.2211 - val_loss: 0.4376 - val_mse: 0.4376 - val_mae: 0.4614\n",
      "Epoch 78/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0816 - mse: 0.0816 - mae: 0.2183 - val_loss: 0.4295 - val_mse: 0.4295 - val_mae: 0.4569\n",
      "Epoch 79/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0826 - mse: 0.0826 - mae: 0.2199 - val_loss: 0.4249 - val_mse: 0.4249 - val_mae: 0.4569\n",
      "Epoch 80/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0836 - mse: 0.0836 - mae: 0.2223 - val_loss: 0.4211 - val_mse: 0.4211 - val_mae: 0.4574\n",
      "Epoch 81/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0803 - mse: 0.0803 - mae: 0.2178 - val_loss: 0.4226 - val_mse: 0.4226 - val_mae: 0.4546\n",
      "Epoch 82/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0776 - mse: 0.0776 - mae: 0.2143 - val_loss: 0.4267 - val_mse: 0.4267 - val_mae: 0.4584\n",
      "Epoch 83/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0804 - mse: 0.0804 - mae: 0.2173 - val_loss: 0.4284 - val_mse: 0.4284 - val_mae: 0.4583\n",
      "Epoch 84/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.0783 - mse: 0.0783 - mae: 0.2140 - val_loss: 0.4251 - val_mse: 0.4251 - val_mae: 0.4541\n",
      "Epoch 85/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0768 - mse: 0.0768 - mae: 0.2122 - val_loss: 0.4233 - val_mse: 0.4233 - val_mae: 0.4550\n",
      "Epoch 86/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0771 - mse: 0.0771 - mae: 0.2140 - val_loss: 0.4233 - val_mse: 0.4233 - val_mae: 0.4564\n",
      "Epoch 87/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0752 - mse: 0.0752 - mae: 0.2096 - val_loss: 0.4229 - val_mse: 0.4229 - val_mae: 0.4541\n",
      "Epoch 88/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0749 - mse: 0.0749 - mae: 0.2108 - val_loss: 0.4198 - val_mse: 0.4198 - val_mae: 0.4533\n",
      "Epoch 89/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.0783 - mse: 0.0783 - mae: 0.2148 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.4533\n",
      "Epoch 90/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0747 - mse: 0.0747 - mae: 0.2085 - val_loss: 0.4204 - val_mse: 0.4204 - val_mae: 0.4528\n",
      "Epoch 91/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0738 - mse: 0.0738 - mae: 0.2078 - val_loss: 0.4200 - val_mse: 0.4200 - val_mae: 0.4525\n",
      "Epoch 92/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0764 - mse: 0.0764 - mae: 0.2114 - val_loss: 0.4192 - val_mse: 0.4192 - val_mae: 0.4515\n",
      "Epoch 93/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0720 - mse: 0.0720 - mae: 0.2052 - val_loss: 0.4148 - val_mse: 0.4148 - val_mae: 0.4502\n",
      "Epoch 94/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0699 - mse: 0.0699 - mae: 0.2025 - val_loss: 0.4150 - val_mse: 0.4150 - val_mae: 0.4508\n",
      "Epoch 95/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.0724 - mse: 0.0724 - mae: 0.2058 - val_loss: 0.4175 - val_mse: 0.4175 - val_mae: 0.4508\n",
      "Epoch 96/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.0702 - mse: 0.0702 - mae: 0.2022 - val_loss: 0.4128 - val_mse: 0.4128 - val_mae: 0.4493\n",
      "Epoch 97/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0684 - mse: 0.0684 - mae: 0.2011 - val_loss: 0.4135 - val_mse: 0.4135 - val_mae: 0.4482\n",
      "Epoch 98/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0682 - mse: 0.0682 - mae: 0.1993 - val_loss: 0.4158 - val_mse: 0.4158 - val_mae: 0.4516\n",
      "Epoch 99/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0685 - mse: 0.0685 - mae: 0.2009 - val_loss: 0.4133 - val_mse: 0.4133 - val_mae: 0.4486\n",
      "Epoch 100/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0729 - mse: 0.0729 - mae: 0.2052 - val_loss: 0.4156 - val_mse: 0.4156 - val_mae: 0.4473\n",
      "Epoch 101/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.0683 - mse: 0.0683 - mae: 0.1989 - val_loss: 0.4113 - val_mse: 0.4113 - val_mae: 0.4468\n",
      "Epoch 102/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0702 - mse: 0.0702 - mae: 0.2023 - val_loss: 0.4144 - val_mse: 0.4144 - val_mae: 0.4479\n",
      "Epoch 103/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.0665 - mse: 0.0665 - mae: 0.1979 - val_loss: 0.4063 - val_mse: 0.4063 - val_mae: 0.4433\n",
      "Epoch 104/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0657 - mse: 0.0657 - mae: 0.1957 - val_loss: 0.4116 - val_mse: 0.4116 - val_mae: 0.4449\n",
      "Epoch 105/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0667 - mse: 0.0667 - mae: 0.1979 - val_loss: 0.4114 - val_mse: 0.4114 - val_mae: 0.4466\n",
      "Epoch 106/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0692 - mse: 0.0692 - mae: 0.2005 - val_loss: 0.4081 - val_mse: 0.4081 - val_mae: 0.4452\n",
      "Epoch 107/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0648 - mse: 0.0648 - mae: 0.1933 - val_loss: 0.4075 - val_mse: 0.4075 - val_mae: 0.4424\n",
      "Epoch 108/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0644 - mse: 0.0644 - mae: 0.1938 - val_loss: 0.4033 - val_mse: 0.4033 - val_mae: 0.4417\n",
      "Epoch 109/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0630 - mse: 0.0630 - mae: 0.1910 - val_loss: 0.4028 - val_mse: 0.4028 - val_mae: 0.4410\n",
      "Epoch 110/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0639 - mse: 0.0639 - mae: 0.1929 - val_loss: 0.4001 - val_mse: 0.4001 - val_mae: 0.4421\n",
      "Epoch 111/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0665 - mse: 0.0665 - mae: 0.1960 - val_loss: 0.4041 - val_mse: 0.4041 - val_mae: 0.4413\n",
      "Epoch 112/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.0678 - mse: 0.0678 - mae: 0.1981 - val_loss: 0.3971 - val_mse: 0.3971 - val_mae: 0.4395\n",
      "Epoch 113/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0670 - mse: 0.0670 - mae: 0.1975 - val_loss: 0.4004 - val_mse: 0.4004 - val_mae: 0.4395\n",
      "Epoch 114/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0648 - mse: 0.0648 - mae: 0.1952 - val_loss: 0.3990 - val_mse: 0.3990 - val_mae: 0.4404\n",
      "Epoch 115/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0627 - mse: 0.0627 - mae: 0.1939 - val_loss: 0.4010 - val_mse: 0.4010 - val_mae: 0.4393\n",
      "Epoch 116/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0628 - mse: 0.0628 - mae: 0.1919 - val_loss: 0.3931 - val_mse: 0.3931 - val_mae: 0.4377\n",
      "Epoch 117/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0619 - mse: 0.0619 - mae: 0.1902 - val_loss: 0.3972 - val_mse: 0.3972 - val_mae: 0.4386\n",
      "Epoch 118/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0608 - mse: 0.0608 - mae: 0.1894 - val_loss: 0.4044 - val_mse: 0.4044 - val_mae: 0.4426\n",
      "Epoch 119/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0613 - mse: 0.0613 - mae: 0.1898 - val_loss: 0.3991 - val_mse: 0.3991 - val_mae: 0.4378\n",
      "Epoch 120/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0595 - mse: 0.0595 - mae: 0.1868 - val_loss: 0.3982 - val_mse: 0.3982 - val_mae: 0.4407\n",
      "Epoch 121/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0591 - mse: 0.0591 - mae: 0.1868 - val_loss: 0.4010 - val_mse: 0.4010 - val_mae: 0.4389\n",
      "Epoch 122/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0606 - mse: 0.0606 - mae: 0.1887 - val_loss: 0.3989 - val_mse: 0.3989 - val_mae: 0.4386\n",
      "Epoch 123/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0604 - mse: 0.0604 - mae: 0.1873 - val_loss: 0.3949 - val_mse: 0.3949 - val_mae: 0.4381\n",
      "Epoch 124/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0625 - mse: 0.0625 - mae: 0.1929 - val_loss: 0.4001 - val_mse: 0.4001 - val_mae: 0.4394\n",
      "Epoch 125/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0588 - mse: 0.0588 - mae: 0.1840 - val_loss: 0.3938 - val_mse: 0.3938 - val_mae: 0.4344\n",
      "Epoch 126/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0591 - mse: 0.0591 - mae: 0.1842 - val_loss: 0.3928 - val_mse: 0.3928 - val_mae: 0.4334\n",
      "Epoch 127/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0589 - mse: 0.0589 - mae: 0.1860 - val_loss: 0.3946 - val_mse: 0.3946 - val_mae: 0.4349\n",
      "Epoch 128/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0561 - mse: 0.0561 - mae: 0.1819 - val_loss: 0.3905 - val_mse: 0.3905 - val_mae: 0.4326\n",
      "Epoch 129/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0586 - mse: 0.0586 - mae: 0.1862 - val_loss: 0.3936 - val_mse: 0.3936 - val_mae: 0.4366\n",
      "Epoch 130/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0587 - mse: 0.0587 - mae: 0.1848 - val_loss: 0.3910 - val_mse: 0.3910 - val_mae: 0.4335\n",
      "Epoch 131/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0562 - mse: 0.0562 - mae: 0.1815 - val_loss: 0.3933 - val_mse: 0.3933 - val_mae: 0.4342\n",
      "Epoch 132/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0573 - mse: 0.0573 - mae: 0.1812 - val_loss: 0.3970 - val_mse: 0.3970 - val_mae: 0.4347\n",
      "Epoch 133/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0563 - mse: 0.0563 - mae: 0.1798 - val_loss: 0.3913 - val_mse: 0.3913 - val_mae: 0.4333\n",
      "Epoch 134/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.0587 - mse: 0.0587 - mae: 0.1855 - val_loss: 0.3905 - val_mse: 0.3905 - val_mae: 0.4346\n",
      "Epoch 135/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0580 - mse: 0.0580 - mae: 0.1832 - val_loss: 0.3883 - val_mse: 0.3883 - val_mae: 0.4307\n",
      "Epoch 136/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0575 - mse: 0.0575 - mae: 0.1825 - val_loss: 0.3905 - val_mse: 0.3905 - val_mae: 0.4304\n",
      "Epoch 137/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0547 - mse: 0.0547 - mae: 0.1798 - val_loss: 0.3862 - val_mse: 0.3862 - val_mae: 0.4301\n",
      "Epoch 138/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0540 - mse: 0.0540 - mae: 0.1769 - val_loss: 0.3941 - val_mse: 0.3941 - val_mae: 0.4340\n",
      "Epoch 139/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0527 - mse: 0.0527 - mae: 0.1753 - val_loss: 0.3887 - val_mse: 0.3887 - val_mae: 0.4314\n",
      "Epoch 140/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0575 - mse: 0.0575 - mae: 0.1822 - val_loss: 0.3885 - val_mse: 0.3885 - val_mae: 0.4305\n",
      "Epoch 141/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0547 - mse: 0.0547 - mae: 0.1782 - val_loss: 0.3931 - val_mse: 0.3931 - val_mae: 0.4340\n",
      "Epoch 142/3000\n",
      "10664/10664 [==============================] - 1s 54us/sample - loss: 0.0549 - mse: 0.0549 - mae: 0.1785 - val_loss: 0.3940 - val_mse: 0.3940 - val_mae: 0.4347\n",
      "Epoch 143/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0548 - mse: 0.0548 - mae: 0.1795 - val_loss: 0.3935 - val_mse: 0.3935 - val_mae: 0.4329\n",
      "Epoch 144/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0541 - mse: 0.0541 - mae: 0.1771 - val_loss: 0.3968 - val_mse: 0.3968 - val_mae: 0.4334\n",
      "Epoch 145/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.0560 - mse: 0.0560 - mae: 0.1797 - val_loss: 0.3913 - val_mse: 0.3913 - val_mae: 0.4311\n",
      "Epoch 146/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0516 - mse: 0.0516 - mae: 0.1726 - val_loss: 0.3874 - val_mse: 0.3874 - val_mae: 0.4285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.0545 - mse: 0.0545 - mae: 0.1774 - val_loss: 0.3931 - val_mse: 0.3931 - val_mae: 0.4305\n",
      "Avg. MAE: 0.403136\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 18s 2ms/sample - loss: 13.5164 - mse: 13.5164 - mae: 2.2363 - val_loss: 0.9970 - val_mse: 0.9970 - val_mae: 0.7723\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 1.4163 - mse: 1.4163 - mae: 0.8511 - val_loss: 0.9522 - val_mse: 0.9522 - val_mae: 0.7354\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.5210 - mse: 0.5210 - mae: 0.5366 - val_loss: 1.0080 - val_mse: 1.0080 - val_mae: 0.7886\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.3216 - mse: 0.3216 - mae: 0.4247 - val_loss: 0.9625 - val_mse: 0.9625 - val_mae: 0.7616\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.2418 - mse: 0.2418 - mae: 0.3647 - val_loss: 0.8444 - val_mse: 0.8444 - val_mae: 0.7310\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.2016 - mse: 0.2016 - mae: 0.3267 - val_loss: 0.7915 - val_mse: 0.7915 - val_mae: 0.6969\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1881 - mse: 0.1881 - mae: 0.3113 - val_loss: 0.8034 - val_mse: 0.8034 - val_mae: 0.6835\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1731 - mse: 0.1731 - mae: 0.2980 - val_loss: 0.7895 - val_mse: 0.7895 - val_mae: 0.6774\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1480 - mse: 0.1480 - mae: 0.2786 - val_loss: 0.7345 - val_mse: 0.7345 - val_mae: 0.6544\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1348 - mse: 0.1348 - mae: 0.2673 - val_loss: 0.6843 - val_mse: 0.6843 - val_mae: 0.6249\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1255 - mse: 0.1255 - mae: 0.2561 - val_loss: 0.6495 - val_mse: 0.6495 - val_mae: 0.6104\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1337 - mse: 0.1337 - mae: 0.2614 - val_loss: 0.5618 - val_mse: 0.5618 - val_mae: 0.5746\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1283 - mse: 0.1283 - mae: 0.2585 - val_loss: 0.5379 - val_mse: 0.5379 - val_mae: 0.5541\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1133 - mse: 0.1133 - mae: 0.2470 - val_loss: 0.5453 - val_mse: 0.5453 - val_mae: 0.5607\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1198 - mse: 0.1198 - mae: 0.2527 - val_loss: 0.4774 - val_mse: 0.4774 - val_mae: 0.5231\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1174 - mse: 0.1174 - mae: 0.2521 - val_loss: 0.4533 - val_mse: 0.4533 - val_mae: 0.5248\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1051 - mse: 0.1051 - mae: 0.2392 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.4910\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0940 - mse: 0.0940 - mae: 0.2228 - val_loss: 0.4016 - val_mse: 0.4016 - val_mae: 0.4792\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0884 - mse: 0.0884 - mae: 0.2205 - val_loss: 0.4896 - val_mse: 0.4896 - val_mae: 0.5288\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1106 - mse: 0.1106 - mae: 0.2345 - val_loss: 0.3806 - val_mse: 0.3806 - val_mae: 0.4541\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0953 - mse: 0.0953 - mae: 0.2273 - val_loss: 0.4025 - val_mse: 0.4025 - val_mae: 0.4720\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0963 - mse: 0.0963 - mae: 0.2282 - val_loss: 0.4515 - val_mse: 0.4515 - val_mae: 0.5061\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0989 - mse: 0.0989 - mae: 0.2336 - val_loss: 0.3833 - val_mse: 0.3833 - val_mae: 0.4501\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0910 - mse: 0.0910 - mae: 0.2146 - val_loss: 0.3928 - val_mse: 0.3928 - val_mae: 0.4549\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0795 - mse: 0.0795 - mae: 0.2019 - val_loss: 0.4637 - val_mse: 0.4637 - val_mae: 0.5001\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0805 - mse: 0.0805 - mae: 0.2078 - val_loss: 0.4178 - val_mse: 0.4178 - val_mae: 0.4597\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0746 - mse: 0.0746 - mae: 0.1969 - val_loss: 0.3843 - val_mse: 0.3843 - val_mae: 0.4455\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0685 - mse: 0.0685 - mae: 0.1876 - val_loss: 0.3700 - val_mse: 0.3700 - val_mae: 0.4379\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0641 - mse: 0.0641 - mae: 0.1850 - val_loss: 0.3923 - val_mse: 0.3923 - val_mae: 0.4542\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0661 - mse: 0.0661 - mae: 0.1889 - val_loss: 0.3928 - val_mse: 0.3928 - val_mae: 0.4466\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0618 - mse: 0.0618 - mae: 0.1813 - val_loss: 0.3899 - val_mse: 0.3899 - val_mae: 0.4414\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0555 - mse: 0.0555 - mae: 0.1710 - val_loss: 0.4169 - val_mse: 0.4169 - val_mae: 0.4535\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0683 - mse: 0.0683 - mae: 0.1896 - val_loss: 0.3998 - val_mse: 0.3998 - val_mae: 0.4512\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0700 - mse: 0.0700 - mae: 0.1866 - val_loss: 0.3552 - val_mse: 0.3552 - val_mae: 0.4251\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0641 - mse: 0.0641 - mae: 0.1813 - val_loss: 0.3864 - val_mse: 0.3864 - val_mae: 0.4483\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0658 - mse: 0.0658 - mae: 0.1864 - val_loss: 0.3747 - val_mse: 0.3747 - val_mae: 0.4420\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0682 - mse: 0.0682 - mae: 0.1889 - val_loss: 0.3610 - val_mse: 0.3610 - val_mae: 0.4272\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0671 - mse: 0.0671 - mae: 0.1891 - val_loss: 0.4380 - val_mse: 0.4380 - val_mae: 0.4761\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0730 - mse: 0.0730 - mae: 0.1950 - val_loss: 0.3650 - val_mse: 0.3650 - val_mae: 0.4339\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0670 - mse: 0.0670 - mae: 0.1886 - val_loss: 0.3778 - val_mse: 0.3778 - val_mae: 0.4379\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0698 - mse: 0.0698 - mae: 0.1927 - val_loss: 0.3772 - val_mse: 0.3772 - val_mae: 0.4382\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0705 - mse: 0.0705 - mae: 0.1895 - val_loss: 0.3828 - val_mse: 0.3828 - val_mae: 0.4425\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0729 - mse: 0.0729 - mae: 0.1995 - val_loss: 0.3875 - val_mse: 0.3875 - val_mae: 0.4453\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0746 - mse: 0.0746 - mae: 0.1978 - val_loss: 0.3728 - val_mse: 0.3728 - val_mae: 0.4382\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 18s 2ms/sample - loss: 13.0149 - mse: 13.0149 - mae: 2.0871 - val_loss: 1.4256 - val_mse: 1.4256 - val_mae: 1.0084\n",
      "Epoch 2/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 1.2587 - mse: 1.2587 - mae: 0.8088 - val_loss: 2.3857 - val_mse: 2.3857 - val_mae: 1.2270\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.5961 - mse: 0.5961 - mae: 0.5599 - val_loss: 1.8337 - val_mse: 1.8337 - val_mae: 0.8085\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.3321 - mse: 0.3321 - mae: 0.4300 - val_loss: 1.0714 - val_mse: 1.0714 - val_mae: 0.7523\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.2551 - mse: 0.2551 - mae: 0.3759 - val_loss: 0.9743 - val_mse: 0.9743 - val_mae: 0.7023\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1987 - mse: 0.1987 - mae: 0.3308 - val_loss: 0.9759 - val_mse: 0.9759 - val_mae: 0.6850\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1753 - mse: 0.1753 - mae: 0.3074 - val_loss: 0.8808 - val_mse: 0.8808 - val_mae: 0.6633\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1509 - mse: 0.1509 - mae: 0.2902 - val_loss: 0.8227 - val_mse: 0.8227 - val_mae: 0.6439\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1505 - mse: 0.1505 - mae: 0.2838 - val_loss: 0.7303 - val_mse: 0.7303 - val_mae: 0.6198\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1332 - mse: 0.1332 - mae: 0.2690 - val_loss: 0.6561 - val_mse: 0.6561 - val_mae: 0.6061\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1195 - mse: 0.1195 - mae: 0.2491 - val_loss: 0.6178 - val_mse: 0.6178 - val_mae: 0.5769\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1196 - mse: 0.1196 - mae: 0.2521 - val_loss: 0.5780 - val_mse: 0.5780 - val_mae: 0.5515\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1282 - mse: 0.1282 - mae: 0.2555 - val_loss: 0.7433 - val_mse: 0.7433 - val_mae: 0.5938\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1515 - mse: 0.1515 - mae: 0.2774 - val_loss: 0.5313 - val_mse: 0.5313 - val_mae: 0.5589\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1473 - mse: 0.1473 - mae: 0.2729 - val_loss: 0.5314 - val_mse: 0.5314 - val_mae: 0.5307\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1408 - mse: 0.1408 - mae: 0.2649 - val_loss: 0.5963 - val_mse: 0.5963 - val_mae: 0.5346\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1621 - mse: 0.1621 - mae: 0.2773 - val_loss: 0.5420 - val_mse: 0.5420 - val_mae: 0.5570\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1554 - mse: 0.1554 - mae: 0.2847 - val_loss: 0.4327 - val_mse: 0.4327 - val_mae: 0.4736\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1063 - mse: 0.1063 - mae: 0.2399 - val_loss: 0.4595 - val_mse: 0.4595 - val_mae: 0.4906\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0877 - mse: 0.0877 - mae: 0.2224 - val_loss: 0.4318 - val_mse: 0.4318 - val_mae: 0.4620\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0817 - mse: 0.0817 - mae: 0.2097 - val_loss: 0.4690 - val_mse: 0.4690 - val_mae: 0.4568\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0774 - mse: 0.0774 - mae: 0.2035 - val_loss: 0.4375 - val_mse: 0.4375 - val_mae: 0.4690\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0916 - mse: 0.0916 - mae: 0.2179 - val_loss: 0.4332 - val_mse: 0.4332 - val_mae: 0.4639\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0775 - mse: 0.0775 - mae: 0.2068 - val_loss: 0.4144 - val_mse: 0.4144 - val_mae: 0.4448\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0690 - mse: 0.0690 - mae: 0.1916 - val_loss: 0.4839 - val_mse: 0.4839 - val_mae: 0.4773\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0728 - mse: 0.0728 - mae: 0.1939 - val_loss: 0.4259 - val_mse: 0.4259 - val_mae: 0.4529\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0684 - mse: 0.0684 - mae: 0.1928 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.4623\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0618 - mse: 0.0618 - mae: 0.1839 - val_loss: 0.4421 - val_mse: 0.4421 - val_mae: 0.4416\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0679 - mse: 0.0679 - mae: 0.1926 - val_loss: 0.4133 - val_mse: 0.4133 - val_mae: 0.4351\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0713 - mse: 0.0713 - mae: 0.1904 - val_loss: 0.4296 - val_mse: 0.4296 - val_mae: 0.4550\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0814 - mse: 0.0814 - mae: 0.2024 - val_loss: 0.4020 - val_mse: 0.4020 - val_mae: 0.4394\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0634 - mse: 0.0634 - mae: 0.1862 - val_loss: 0.4238 - val_mse: 0.4238 - val_mae: 0.4595\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0560 - mse: 0.0560 - mae: 0.1739 - val_loss: 0.3985 - val_mse: 0.3985 - val_mae: 0.4334\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0599 - mse: 0.0599 - mae: 0.1762 - val_loss: 0.3989 - val_mse: 0.3989 - val_mae: 0.4348\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0731 - mse: 0.0731 - mae: 0.1941 - val_loss: 0.4534 - val_mse: 0.4534 - val_mae: 0.4607\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0944 - mse: 0.0944 - mae: 0.2209 - val_loss: 0.4320 - val_mse: 0.4320 - val_mae: 0.4648\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0850 - mse: 0.0850 - mae: 0.2150 - val_loss: 0.4004 - val_mse: 0.4004 - val_mae: 0.4404\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1059 - mse: 0.1059 - mae: 0.2281 - val_loss: 0.4963 - val_mse: 0.4963 - val_mae: 0.4671\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0892 - mse: 0.0892 - mae: 0.2108 - val_loss: 0.4236 - val_mse: 0.4236 - val_mae: 0.4483\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0806 - mse: 0.0806 - mae: 0.2065 - val_loss: 0.4382 - val_mse: 0.4382 - val_mae: 0.4629\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0696 - mse: 0.0696 - mae: 0.1963 - val_loss: 0.4092 - val_mse: 0.4092 - val_mae: 0.4452\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.0707 - mse: 0.0707 - mae: 0.1925 - val_loss: 0.4348 - val_mse: 0.4348 - val_mae: 0.4537\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0613 - mse: 0.0613 - mae: 0.1814 - val_loss: 0.4153 - val_mse: 0.4153 - val_mae: 0.4405\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 18s 2ms/sample - loss: 10.6013 - mse: 10.6013 - mae: 2.0109 - val_loss: 3.2210 - val_mse: 3.2210 - val_mae: 1.5780\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 1.1189 - mse: 1.1189 - mae: 0.7715 - val_loss: 1.0265 - val_mse: 1.0265 - val_mae: 0.7738\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.5378 - mse: 0.5378 - mae: 0.5339 - val_loss: 1.0411 - val_mse: 1.0411 - val_mae: 0.8251\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.3424 - mse: 0.3424 - mae: 0.4328 - val_loss: 0.9566 - val_mse: 0.9566 - val_mae: 0.7789\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.2578 - mse: 0.2578 - mae: 0.3797 - val_loss: 0.8965 - val_mse: 0.8965 - val_mae: 0.7289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.2007 - mse: 0.2007 - mae: 0.3322 - val_loss: 0.8976 - val_mse: 0.8976 - val_mae: 0.7265\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1874 - mse: 0.1874 - mae: 0.3260 - val_loss: 0.8267 - val_mse: 0.8267 - val_mae: 0.6788\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1516 - mse: 0.1516 - mae: 0.2902 - val_loss: 0.7473 - val_mse: 0.7473 - val_mae: 0.6574\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1419 - mse: 0.1419 - mae: 0.2810 - val_loss: 0.8221 - val_mse: 0.8221 - val_mae: 0.6917\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.1305 - mse: 0.1305 - mae: 0.2713 - val_loss: 0.7211 - val_mse: 0.7211 - val_mae: 0.6359\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1219 - mse: 0.1219 - mae: 0.2589 - val_loss: 0.6772 - val_mse: 0.6772 - val_mae: 0.6201\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1128 - mse: 0.1128 - mae: 0.2483 - val_loss: 0.6593 - val_mse: 0.6593 - val_mae: 0.5820\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1061 - mse: 0.1061 - mae: 0.2378 - val_loss: 0.5095 - val_mse: 0.5095 - val_mae: 0.5376\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1052 - mse: 0.1052 - mae: 0.2412 - val_loss: 0.5376 - val_mse: 0.5376 - val_mae: 0.5382\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1063 - mse: 0.1063 - mae: 0.2462 - val_loss: 0.4513 - val_mse: 0.4513 - val_mae: 0.5090\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1066 - mse: 0.1066 - mae: 0.2444 - val_loss: 0.4560 - val_mse: 0.4560 - val_mae: 0.5072\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0852 - mse: 0.0852 - mae: 0.2189 - val_loss: 0.4724 - val_mse: 0.4724 - val_mae: 0.5224\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.1076 - mse: 0.1076 - mae: 0.2435 - val_loss: 0.4545 - val_mse: 0.4545 - val_mae: 0.4918\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.0963 - mse: 0.0963 - mae: 0.2292 - val_loss: 0.4246 - val_mse: 0.4246 - val_mae: 0.4771\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0909 - mse: 0.0909 - mae: 0.2238 - val_loss: 0.4176 - val_mse: 0.4176 - val_mae: 0.4712\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0875 - mse: 0.0875 - mae: 0.2212 - val_loss: 0.4350 - val_mse: 0.4350 - val_mae: 0.4690\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1265 - mse: 0.1265 - mae: 0.2698 - val_loss: 0.4341 - val_mse: 0.4341 - val_mae: 0.4748\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1027 - mse: 0.1027 - mae: 0.2455 - val_loss: 0.4250 - val_mse: 0.4250 - val_mae: 0.4593\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0946 - mse: 0.0946 - mae: 0.2246 - val_loss: 0.4160 - val_mse: 0.4160 - val_mae: 0.4554\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0892 - mse: 0.0892 - mae: 0.2202 - val_loss: 0.4192 - val_mse: 0.4192 - val_mae: 0.4731\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0876 - mse: 0.0876 - mae: 0.2199 - val_loss: 0.4563 - val_mse: 0.4563 - val_mae: 0.4833\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0901 - mse: 0.0901 - mae: 0.2255 - val_loss: 0.3953 - val_mse: 0.3953 - val_mae: 0.4513\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0781 - mse: 0.0781 - mae: 0.2116 - val_loss: 0.4287 - val_mse: 0.4287 - val_mae: 0.4572\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0640 - mse: 0.0640 - mae: 0.1880 - val_loss: 0.3940 - val_mse: 0.3940 - val_mae: 0.4399\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0623 - mse: 0.0623 - mae: 0.1841 - val_loss: 0.3829 - val_mse: 0.3829 - val_mae: 0.4343\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0592 - mse: 0.0592 - mae: 0.1804 - val_loss: 0.3732 - val_mse: 0.3732 - val_mae: 0.4349\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0661 - mse: 0.0661 - mae: 0.1869 - val_loss: 0.3889 - val_mse: 0.3889 - val_mae: 0.4397\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0731 - mse: 0.0731 - mae: 0.1930 - val_loss: 0.4096 - val_mse: 0.4096 - val_mae: 0.4497\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0652 - mse: 0.0652 - mae: 0.1920 - val_loss: 0.4008 - val_mse: 0.4008 - val_mae: 0.4491\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0615 - mse: 0.0615 - mae: 0.1875 - val_loss: 0.3534 - val_mse: 0.3534 - val_mae: 0.4178\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0564 - mse: 0.0564 - mae: 0.1776 - val_loss: 0.3869 - val_mse: 0.3869 - val_mae: 0.4477\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0601 - mse: 0.0601 - mae: 0.1867 - val_loss: 0.3733 - val_mse: 0.3733 - val_mae: 0.4366\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0575 - mse: 0.0575 - mae: 0.1806 - val_loss: 0.3768 - val_mse: 0.3768 - val_mae: 0.4291\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0658 - mse: 0.0658 - mae: 0.1945 - val_loss: 0.4027 - val_mse: 0.4027 - val_mae: 0.4608\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0609 - mse: 0.0609 - mae: 0.1832 - val_loss: 0.4042 - val_mse: 0.4042 - val_mae: 0.4474\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0575 - mse: 0.0575 - mae: 0.1760 - val_loss: 0.4254 - val_mse: 0.4254 - val_mae: 0.4672\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0670 - mse: 0.0670 - mae: 0.1943 - val_loss: 0.3791 - val_mse: 0.3791 - val_mae: 0.4433\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0582 - mse: 0.0582 - mae: 0.1816 - val_loss: 0.3805 - val_mse: 0.3805 - val_mae: 0.4412\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0558 - mse: 0.0558 - mae: 0.1760 - val_loss: 0.3685 - val_mse: 0.3685 - val_mae: 0.4265\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0554 - mse: 0.0554 - mae: 0.1745 - val_loss: 0.3675 - val_mse: 0.3675 - val_mae: 0.4269\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 18s 2ms/sample - loss: 14.6173 - mse: 14.6173 - mae: 2.2990 - val_loss: 1.7986 - val_mse: 1.7986 - val_mae: 1.1398\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 1.2882 - mse: 1.2882 - mae: 0.8131 - val_loss: 1.4081 - val_mse: 1.4081 - val_mae: 0.9859\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.6042 - mse: 0.6042 - mae: 0.5579 - val_loss: 1.0152 - val_mse: 1.0152 - val_mae: 0.7875\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.3459 - mse: 0.3459 - mae: 0.4353 - val_loss: 0.9330 - val_mse: 0.9330 - val_mae: 0.7489\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.2649 - mse: 0.2649 - mae: 0.3805 - val_loss: 0.8187 - val_mse: 0.8187 - val_mae: 0.6956\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1932 - mse: 0.1932 - mae: 0.3218 - val_loss: 0.8667 - val_mse: 0.8667 - val_mae: 0.6975\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1661 - mse: 0.1661 - mae: 0.3034 - val_loss: 0.8359 - val_mse: 0.8359 - val_mae: 0.6784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1473 - mse: 0.1473 - mae: 0.2852 - val_loss: 0.7934 - val_mse: 0.7934 - val_mae: 0.6696\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1382 - mse: 0.1382 - mae: 0.2761 - val_loss: 0.7762 - val_mse: 0.7762 - val_mae: 0.6631\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.1236 - mse: 0.1236 - mae: 0.2594 - val_loss: 0.7445 - val_mse: 0.7445 - val_mae: 0.6545\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1454 - mse: 0.1454 - mae: 0.2760 - val_loss: 0.6820 - val_mse: 0.6820 - val_mae: 0.6181\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1462 - mse: 0.1462 - mae: 0.2795 - val_loss: 0.6282 - val_mse: 0.6282 - val_mae: 0.6121\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1173 - mse: 0.1173 - mae: 0.2520 - val_loss: 0.5978 - val_mse: 0.5978 - val_mae: 0.5974\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1201 - mse: 0.1201 - mae: 0.2533 - val_loss: 0.6011 - val_mse: 0.6011 - val_mae: 0.6022\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1446 - mse: 0.1446 - mae: 0.2722 - val_loss: 0.5707 - val_mse: 0.5707 - val_mae: 0.5932\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1067 - mse: 0.1067 - mae: 0.2366 - val_loss: 0.4565 - val_mse: 0.4565 - val_mae: 0.5089\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1082 - mse: 0.1082 - mae: 0.2421 - val_loss: 0.4241 - val_mse: 0.4241 - val_mae: 0.4842\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1065 - mse: 0.1065 - mae: 0.2378 - val_loss: 0.3959 - val_mse: 0.3959 - val_mae: 0.4677\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2216 - val_loss: 0.4013 - val_mse: 0.4013 - val_mae: 0.4712\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0875 - mse: 0.0875 - mae: 0.2093 - val_loss: 0.3805 - val_mse: 0.3805 - val_mae: 0.4479\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0804 - mse: 0.0804 - mae: 0.2054 - val_loss: 0.4289 - val_mse: 0.4289 - val_mae: 0.4795\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0908 - mse: 0.0908 - mae: 0.2177 - val_loss: 0.3797 - val_mse: 0.3797 - val_mae: 0.4465\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0898 - mse: 0.0898 - mae: 0.2200 - val_loss: 0.4177 - val_mse: 0.4177 - val_mae: 0.4683\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1002 - mse: 0.1002 - mae: 0.2267 - val_loss: 0.3959 - val_mse: 0.3959 - val_mae: 0.4544\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1010 - mse: 0.1010 - mae: 0.2333 - val_loss: 0.3909 - val_mse: 0.3909 - val_mae: 0.4504\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1161 - mse: 0.1161 - mae: 0.2354 - val_loss: 0.3888 - val_mse: 0.3888 - val_mae: 0.4516\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0936 - mse: 0.0936 - mae: 0.2232 - val_loss: 0.3777 - val_mse: 0.3777 - val_mae: 0.4469\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0783 - mse: 0.0783 - mae: 0.2048 - val_loss: 0.3635 - val_mse: 0.3635 - val_mae: 0.4336\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0873 - mse: 0.0873 - mae: 0.2197 - val_loss: 0.3841 - val_mse: 0.3841 - val_mae: 0.4478\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0753 - mse: 0.0753 - mae: 0.2015 - val_loss: 0.4251 - val_mse: 0.4251 - val_mae: 0.4759\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0818 - mse: 0.0818 - mae: 0.2091 - val_loss: 0.4727 - val_mse: 0.4727 - val_mae: 0.4707\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0771 - mse: 0.0771 - mae: 0.2010 - val_loss: 0.3711 - val_mse: 0.3711 - val_mae: 0.4399\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0784 - mse: 0.0784 - mae: 0.2042 - val_loss: 0.3909 - val_mse: 0.3909 - val_mae: 0.4486\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0691 - mse: 0.0691 - mae: 0.1914 - val_loss: 0.3647 - val_mse: 0.3647 - val_mae: 0.4318\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0631 - mse: 0.0631 - mae: 0.1842 - val_loss: 0.3616 - val_mse: 0.3616 - val_mae: 0.4238\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0633 - mse: 0.0633 - mae: 0.1851 - val_loss: 0.3650 - val_mse: 0.3650 - val_mae: 0.4341\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0644 - mse: 0.0644 - mae: 0.1882 - val_loss: 0.3744 - val_mse: 0.3744 - val_mae: 0.4389\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0566 - mse: 0.0566 - mae: 0.1747 - val_loss: 0.3522 - val_mse: 0.3522 - val_mae: 0.4211\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0557 - mse: 0.0557 - mae: 0.1747 - val_loss: 0.3568 - val_mse: 0.3568 - val_mae: 0.4263\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0563 - mse: 0.0563 - mae: 0.1743 - val_loss: 0.3723 - val_mse: 0.3723 - val_mae: 0.4338\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0641 - mse: 0.0641 - mae: 0.1820 - val_loss: 0.4218 - val_mse: 0.4218 - val_mae: 0.4517\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0639 - mse: 0.0639 - mae: 0.1879 - val_loss: 0.3566 - val_mse: 0.3566 - val_mae: 0.4262\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0605 - mse: 0.0605 - mae: 0.1807 - val_loss: 0.3676 - val_mse: 0.3676 - val_mae: 0.4412\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0583 - mse: 0.0583 - mae: 0.1752 - val_loss: 0.3716 - val_mse: 0.3716 - val_mae: 0.4341\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0598 - mse: 0.0598 - mae: 0.1822 - val_loss: 0.3911 - val_mse: 0.3911 - val_mae: 0.4428\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0556 - mse: 0.0556 - mae: 0.1721 - val_loss: 0.3813 - val_mse: 0.3813 - val_mae: 0.4338\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0541 - mse: 0.0541 - mae: 0.1672 - val_loss: 0.3744 - val_mse: 0.3744 - val_mae: 0.4261\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0484 - mse: 0.0484 - mae: 0.1562 - val_loss: 0.3508 - val_mse: 0.3508 - val_mae: 0.4238\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0697 - mse: 0.0697 - mae: 0.1964 - val_loss: 0.3613 - val_mse: 0.3613 - val_mae: 0.4250\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0675 - mse: 0.0675 - mae: 0.1853 - val_loss: 0.4135 - val_mse: 0.4135 - val_mae: 0.4372\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0569 - mse: 0.0569 - mae: 0.1704 - val_loss: 0.3386 - val_mse: 0.3386 - val_mae: 0.4156\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0605 - mse: 0.0605 - mae: 0.1726 - val_loss: 0.3756 - val_mse: 0.3756 - val_mae: 0.4410\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0815 - mse: 0.0815 - mae: 0.2037 - val_loss: 0.4136 - val_mse: 0.4136 - val_mae: 0.4581\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0651 - mse: 0.0651 - mae: 0.1864 - val_loss: 0.3525 - val_mse: 0.3525 - val_mae: 0.4237\n",
      "Epoch 55/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0785 - mse: 0.0785 - mae: 0.1935 - val_loss: 0.3597 - val_mse: 0.3597 - val_mae: 0.4308\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0737 - mse: 0.0737 - mae: 0.1894 - val_loss: 0.3499 - val_mse: 0.3499 - val_mae: 0.4223\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.0530 - mse: 0.0530 - mae: 0.1686 - val_loss: 0.3774 - val_mse: 0.3774 - val_mae: 0.4378\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 18s 2ms/sample - loss: 0.0545 - mse: 0.0545 - mae: 0.1717 - val_loss: 0.3479 - val_mse: 0.3479 - val_mae: 0.4190\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.0555 - mse: 0.0555 - mae: 0.1674 - val_loss: 0.3671 - val_mse: 0.3671 - val_mae: 0.4278\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 18s 2ms/sample - loss: 0.0550 - mse: 0.0550 - mae: 0.1719 - val_loss: 0.3608 - val_mse: 0.3608 - val_mae: 0.4310\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.0516 - mse: 0.0516 - mae: 0.1656 - val_loss: 0.3506 - val_mse: 0.3506 - val_mae: 0.4226\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 13.9806 - mse: 13.9806 - mae: 2.1931 - val_loss: 1.7012 - val_mse: 1.7012 - val_mae: 0.9218\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 19s 2ms/sample - loss: 1.2309 - mse: 1.2309 - mae: 0.8245 - val_loss: 1.1003 - val_mse: 1.1003 - val_mae: 0.8600\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 18s 2ms/sample - loss: 0.5176 - mse: 0.5176 - mae: 0.5397 - val_loss: 0.9767 - val_mse: 0.9767 - val_mae: 0.7717\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 18s 2ms/sample - loss: 0.3189 - mse: 0.3189 - mae: 0.4252 - val_loss: 0.9224 - val_mse: 0.9224 - val_mae: 0.7617\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.2447 - mse: 0.2447 - mae: 0.3737 - val_loss: 0.8455 - val_mse: 0.8455 - val_mae: 0.7181\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.1973 - mse: 0.1973 - mae: 0.3302 - val_loss: 0.7776 - val_mse: 0.7776 - val_mae: 0.6776\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.1785 - mse: 0.1785 - mae: 0.3128 - val_loss: 0.7713 - val_mse: 0.7713 - val_mae: 0.6786\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.1487 - mse: 0.1487 - mae: 0.2860 - val_loss: 0.7850 - val_mse: 0.7850 - val_mae: 0.6755\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.1587 - mse: 0.1587 - mae: 0.2939 - val_loss: 0.8187 - val_mse: 0.8187 - val_mae: 0.7026\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 18s 2ms/sample - loss: 0.1429 - mse: 0.1429 - mae: 0.2771 - val_loss: 0.6696 - val_mse: 0.6696 - val_mae: 0.6302\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.1244 - mse: 0.1244 - mae: 0.2571 - val_loss: 0.6492 - val_mse: 0.6492 - val_mae: 0.6158\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.1311 - mse: 0.1311 - mae: 0.2666 - val_loss: 0.6344 - val_mse: 0.6344 - val_mae: 0.6131\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.1244 - mse: 0.1244 - mae: 0.2567 - val_loss: 0.6130 - val_mse: 0.6130 - val_mae: 0.6048\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.1261 - mse: 0.1261 - mae: 0.2602 - val_loss: 0.6586 - val_mse: 0.6586 - val_mae: 0.6348\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.1159 - mse: 0.1159 - mae: 0.2558 - val_loss: 0.5299 - val_mse: 0.5299 - val_mae: 0.5484\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 18s 2ms/sample - loss: 0.1165 - mse: 0.1165 - mae: 0.2529 - val_loss: 0.4568 - val_mse: 0.4568 - val_mae: 0.4954\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.1127 - mse: 0.1127 - mae: 0.2519 - val_loss: 0.4635 - val_mse: 0.4635 - val_mae: 0.5043\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 18s 2ms/sample - loss: 0.0994 - mse: 0.0994 - mae: 0.2357 - val_loss: 0.4363 - val_mse: 0.4363 - val_mae: 0.4867\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.0870 - mse: 0.0870 - mae: 0.2183 - val_loss: 0.4112 - val_mse: 0.4112 - val_mae: 0.4659\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.0811 - mse: 0.0811 - mae: 0.2128 - val_loss: 0.4498 - val_mse: 0.4498 - val_mae: 0.4883\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 18s 2ms/sample - loss: 0.0715 - mse: 0.0715 - mae: 0.1986 - val_loss: 0.4060 - val_mse: 0.4060 - val_mae: 0.4596\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.0863 - mse: 0.0863 - mae: 0.2200 - val_loss: 0.4551 - val_mse: 0.4551 - val_mae: 0.4885\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.0919 - mse: 0.0919 - mae: 0.2287 - val_loss: 0.4607 - val_mse: 0.4607 - val_mae: 0.4806\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.0864 - mse: 0.0864 - mae: 0.2199 - val_loss: 0.4005 - val_mse: 0.4005 - val_mae: 0.4489\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.0798 - mse: 0.0798 - mae: 0.2099 - val_loss: 0.3928 - val_mse: 0.3928 - val_mae: 0.4380\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.0832 - mse: 0.0832 - mae: 0.2120 - val_loss: 0.3943 - val_mse: 0.3943 - val_mae: 0.4465\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.0746 - mse: 0.0746 - mae: 0.2036 - val_loss: 0.4006 - val_mse: 0.4006 - val_mae: 0.4579\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 18s 2ms/sample - loss: 0.0714 - mse: 0.0714 - mae: 0.2012 - val_loss: 0.3896 - val_mse: 0.3896 - val_mae: 0.4435\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.0626 - mse: 0.0626 - mae: 0.1860 - val_loss: 0.4063 - val_mse: 0.4063 - val_mae: 0.4458\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0704 - mse: 0.0704 - mae: 0.1937 - val_loss: 0.4137 - val_mse: 0.4137 - val_mae: 0.4492\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.0765 - mse: 0.0765 - mae: 0.2036 - val_loss: 0.3751 - val_mse: 0.3751 - val_mae: 0.4260\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0631 - mse: 0.0631 - mae: 0.1855 - val_loss: 0.3823 - val_mse: 0.3823 - val_mae: 0.4260\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0636 - mse: 0.0636 - mae: 0.1911 - val_loss: 0.3826 - val_mse: 0.3826 - val_mae: 0.4354\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0605 - mse: 0.0605 - mae: 0.1839 - val_loss: 0.3806 - val_mse: 0.3806 - val_mae: 0.4288\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.0687 - mse: 0.0687 - mae: 0.1961 - val_loss: 0.4080 - val_mse: 0.4080 - val_mae: 0.4470\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 17s 2ms/sample - loss: 0.0614 - mse: 0.0614 - mae: 0.1873 - val_loss: 0.3686 - val_mse: 0.3686 - val_mae: 0.4216\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0630 - mse: 0.0630 - mae: 0.1874 - val_loss: 0.4349 - val_mse: 0.4349 - val_mae: 0.4338\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0673 - mse: 0.0673 - mae: 0.1905 - val_loss: 0.3980 - val_mse: 0.3980 - val_mae: 0.4453\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0693 - mse: 0.0693 - mae: 0.1948 - val_loss: 0.3871 - val_mse: 0.3871 - val_mae: 0.4339\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0613 - mse: 0.0613 - mae: 0.1860 - val_loss: 0.3868 - val_mse: 0.3868 - val_mae: 0.4361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0826 - mse: 0.0826 - mae: 0.2134 - val_loss: 0.4155 - val_mse: 0.4155 - val_mae: 0.4624\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0686 - mse: 0.0686 - mae: 0.1946 - val_loss: 0.3793 - val_mse: 0.3793 - val_mae: 0.4255\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0660 - mse: 0.0660 - mae: 0.1935 - val_loss: 0.3929 - val_mse: 0.3929 - val_mae: 0.4397\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0610 - mse: 0.0610 - mae: 0.1812 - val_loss: 0.4059 - val_mse: 0.4059 - val_mae: 0.4394\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0602 - mse: 0.0602 - mae: 0.1800 - val_loss: 0.3857 - val_mse: 0.3857 - val_mae: 0.4314\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 16s 2ms/sample - loss: 0.0660 - mse: 0.0660 - mae: 0.1885 - val_loss: 0.3945 - val_mse: 0.3945 - val_mae: 0.4317\n",
      "Avg. MAE: 0.372585\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 10s 921us/sample - loss: 81.1801 - mse: 81.1801 - mae: 4.1005 - val_loss: 72.6824 - val_mse: 72.6824 - val_mae: 7.8699\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 1.0027 - mse: 1.0027 - mae: 0.7610 - val_loss: 4.6150 - val_mse: 4.6150 - val_mae: 1.6107\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.7629 - mse: 0.7629 - mae: 0.6611 - val_loss: 1.0066 - val_mse: 1.0066 - val_mae: 0.8032\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.7085 - mse: 0.7085 - mae: 0.6357 - val_loss: 1.0002 - val_mse: 1.0002 - val_mae: 0.8015\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 9s 814us/sample - loss: 0.6834 - mse: 0.6834 - mae: 0.6195 - val_loss: 0.8305 - val_mse: 0.8305 - val_mae: 0.7209\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 9s 828us/sample - loss: 0.6614 - mse: 0.6614 - mae: 0.6095 - val_loss: 0.8029 - val_mse: 0.8029 - val_mae: 0.7117\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 9s 832us/sample - loss: 0.6505 - mse: 0.6505 - mae: 0.6033 - val_loss: 0.7445 - val_mse: 0.7445 - val_mae: 0.6738\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 9s 824us/sample - loss: 0.6287 - mse: 0.6287 - mae: 0.5899 - val_loss: 0.7117 - val_mse: 0.7117 - val_mae: 0.6501\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.6214 - mse: 0.6214 - mae: 0.5850 - val_loss: 0.7007 - val_mse: 0.7007 - val_mae: 0.6533\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.6061 - mse: 0.6061 - mae: 0.5804 - val_loss: 0.6818 - val_mse: 0.6818 - val_mae: 0.6401\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 9s 820us/sample - loss: 0.5876 - mse: 0.5876 - mae: 0.5688 - val_loss: 0.6734 - val_mse: 0.6734 - val_mae: 0.6420\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.5884 - mse: 0.5884 - mae: 0.5661 - val_loss: 0.6834 - val_mse: 0.6834 - val_mae: 0.6325\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.5694 - mse: 0.5694 - mae: 0.5612 - val_loss: 0.6445 - val_mse: 0.6445 - val_mae: 0.6197\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 9s 825us/sample - loss: 0.5541 - mse: 0.5541 - mae: 0.5508 - val_loss: 0.6321 - val_mse: 0.6321 - val_mae: 0.5959\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 9s 820us/sample - loss: 0.5348 - mse: 0.5348 - mae: 0.5419 - val_loss: 0.6000 - val_mse: 0.6000 - val_mae: 0.5821\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.5103 - mse: 0.5103 - mae: 0.5293 - val_loss: 0.5850 - val_mse: 0.5850 - val_mae: 0.5731\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 9s 828us/sample - loss: 0.4961 - mse: 0.4961 - mae: 0.5232 - val_loss: 0.5675 - val_mse: 0.5675 - val_mae: 0.5623\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.4835 - mse: 0.4835 - mae: 0.5133 - val_loss: 0.5655 - val_mse: 0.5655 - val_mae: 0.5505\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.4670 - mse: 0.4670 - mae: 0.5034 - val_loss: 0.5686 - val_mse: 0.5686 - val_mae: 0.5532\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 9s 818us/sample - loss: 0.4463 - mse: 0.4463 - mae: 0.4949 - val_loss: 0.5465 - val_mse: 0.5465 - val_mae: 0.5395\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 9s 838us/sample - loss: 0.4119 - mse: 0.4119 - mae: 0.4753 - val_loss: 0.5348 - val_mse: 0.5348 - val_mae: 0.5398\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 9s 841us/sample - loss: 0.4014 - mse: 0.4014 - mae: 0.4682 - val_loss: 0.5561 - val_mse: 0.5561 - val_mae: 0.5461\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.3795 - mse: 0.3795 - mae: 0.4558 - val_loss: 0.5243 - val_mse: 0.5243 - val_mae: 0.5237\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 9s 818us/sample - loss: 0.3592 - mse: 0.3592 - mae: 0.4428 - val_loss: 0.4960 - val_mse: 0.4960 - val_mae: 0.5178\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.3388 - mse: 0.3388 - mae: 0.4312 - val_loss: 0.5273 - val_mse: 0.5273 - val_mae: 0.5384\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.3184 - mse: 0.3184 - mae: 0.4203 - val_loss: 0.4975 - val_mse: 0.4975 - val_mae: 0.5120\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 9s 818us/sample - loss: 0.3114 - mse: 0.3114 - mae: 0.4137 - val_loss: 0.4579 - val_mse: 0.4579 - val_mae: 0.5024\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 9s 825us/sample - loss: 0.3135 - mse: 0.3135 - mae: 0.4144 - val_loss: 0.4622 - val_mse: 0.4622 - val_mae: 0.5048\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.2804 - mse: 0.2804 - mae: 0.3972 - val_loss: 0.4777 - val_mse: 0.4777 - val_mae: 0.5135\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 9s 814us/sample - loss: 0.2917 - mse: 0.2917 - mae: 0.4003 - val_loss: 0.5304 - val_mse: 0.5304 - val_mae: 0.5290\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 9s 838us/sample - loss: 0.2806 - mse: 0.2806 - mae: 0.4000 - val_loss: 0.4836 - val_mse: 0.4836 - val_mae: 0.5044\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.2654 - mse: 0.2654 - mae: 0.3865 - val_loss: 0.5033 - val_mse: 0.5033 - val_mae: 0.5296\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 9s 822us/sample - loss: 0.2488 - mse: 0.2488 - mae: 0.3738 - val_loss: 0.4201 - val_mse: 0.4201 - val_mae: 0.4778\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.2397 - mse: 0.2397 - mae: 0.3647 - val_loss: 0.4899 - val_mse: 0.4899 - val_mae: 0.5178\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 9s 825us/sample - loss: 0.2315 - mse: 0.2315 - mae: 0.3638 - val_loss: 0.4258 - val_mse: 0.4258 - val_mae: 0.4814\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.2273 - mse: 0.2273 - mae: 0.3585 - val_loss: 0.4116 - val_mse: 0.4116 - val_mae: 0.4745\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.2157 - mse: 0.2157 - mae: 0.3469 - val_loss: 0.4029 - val_mse: 0.4029 - val_mae: 0.4677\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.2149 - mse: 0.2149 - mae: 0.3492 - val_loss: 0.4998 - val_mse: 0.4998 - val_mae: 0.5140\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.2252 - mse: 0.2252 - mae: 0.3560 - val_loss: 0.3996 - val_mse: 0.3996 - val_mae: 0.4614\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.1921 - mse: 0.1921 - mae: 0.3297 - val_loss: 0.5034 - val_mse: 0.5034 - val_mae: 0.5150\n",
      "Epoch 41/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.2125 - mse: 0.2125 - mae: 0.3443 - val_loss: 0.4174 - val_mse: 0.4174 - val_mae: 0.4744\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 9s 824us/sample - loss: 0.1773 - mse: 0.1773 - mae: 0.3158 - val_loss: 0.3866 - val_mse: 0.3866 - val_mae: 0.4530\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 9s 814us/sample - loss: 0.1763 - mse: 0.1763 - mae: 0.3139 - val_loss: 0.4316 - val_mse: 0.4316 - val_mae: 0.4778\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.1697 - mse: 0.1697 - mae: 0.3090 - val_loss: 0.4625 - val_mse: 0.4625 - val_mae: 0.4969\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.1680 - mse: 0.1680 - mae: 0.3094 - val_loss: 0.4140 - val_mse: 0.4140 - val_mae: 0.4720\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.1903 - mse: 0.1903 - mae: 0.3284 - val_loss: 0.3875 - val_mse: 0.3875 - val_mae: 0.4494\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.1655 - mse: 0.1655 - mae: 0.3069 - val_loss: 0.4239 - val_mse: 0.4239 - val_mae: 0.4779\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.1878 - mse: 0.1878 - mae: 0.3250 - val_loss: 0.4156 - val_mse: 0.4156 - val_mae: 0.4715\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 9s 823us/sample - loss: 0.1601 - mse: 0.1601 - mae: 0.3036 - val_loss: 0.4125 - val_mse: 0.4125 - val_mae: 0.4641\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 9s 820us/sample - loss: 0.1511 - mse: 0.1511 - mae: 0.2901 - val_loss: 0.4147 - val_mse: 0.4147 - val_mae: 0.4726\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.1630 - mse: 0.1630 - mae: 0.3014 - val_loss: 0.4185 - val_mse: 0.4185 - val_mae: 0.4902\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.1469 - mse: 0.1469 - mae: 0.2894 - val_loss: 0.4298 - val_mse: 0.4298 - val_mae: 0.4723\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 10s 919us/sample - loss: 81.9807 - mse: 81.9808 - mae: 4.0684 - val_loss: 38.1229 - val_mse: 38.1229 - val_mae: 4.6573\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 9s 819us/sample - loss: 0.9566 - mse: 0.9566 - mae: 0.7453 - val_loss: 13.7279 - val_mse: 13.7279 - val_mae: 2.9691\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.7617 - mse: 0.7617 - mae: 0.6612 - val_loss: 2.7729 - val_mse: 2.7729 - val_mae: 1.2334\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 9s 825us/sample - loss: 0.7225 - mse: 0.7225 - mae: 0.6441 - val_loss: 1.3048 - val_mse: 1.3048 - val_mae: 0.8893\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 9s 818us/sample - loss: 0.6996 - mse: 0.6996 - mae: 0.6299 - val_loss: 1.1522 - val_mse: 1.1522 - val_mae: 0.8363\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.6755 - mse: 0.6755 - mae: 0.6181 - val_loss: 1.0178 - val_mse: 1.0178 - val_mae: 0.7641\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.6591 - mse: 0.6591 - mae: 0.6067 - val_loss: 0.8194 - val_mse: 0.8194 - val_mae: 0.7080\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.6498 - mse: 0.6498 - mae: 0.6036 - val_loss: 0.7574 - val_mse: 0.7574 - val_mae: 0.6663\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 9s 810us/sample - loss: 0.6326 - mse: 0.6326 - mae: 0.5927 - val_loss: 0.7599 - val_mse: 0.7599 - val_mae: 0.6593\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 9s 822us/sample - loss: 0.6139 - mse: 0.6139 - mae: 0.5829 - val_loss: 0.7190 - val_mse: 0.7190 - val_mae: 0.6391\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 9s 829us/sample - loss: 0.6058 - mse: 0.6058 - mae: 0.5776 - val_loss: 0.7089 - val_mse: 0.7089 - val_mae: 0.6489\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.6009 - mse: 0.6009 - mae: 0.5739 - val_loss: 0.7195 - val_mse: 0.7195 - val_mae: 0.6475\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 9s 823us/sample - loss: 0.5720 - mse: 0.5720 - mae: 0.5607 - val_loss: 0.6444 - val_mse: 0.6444 - val_mae: 0.6040\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.5571 - mse: 0.5571 - mae: 0.5530 - val_loss: 0.6473 - val_mse: 0.6473 - val_mae: 0.6000\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.5458 - mse: 0.5458 - mae: 0.5474 - val_loss: 0.6191 - val_mse: 0.6191 - val_mae: 0.5771\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.5241 - mse: 0.5241 - mae: 0.5353 - val_loss: 0.6208 - val_mse: 0.6208 - val_mae: 0.5774\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.5183 - mse: 0.5183 - mae: 0.5331 - val_loss: 0.6250 - val_mse: 0.6250 - val_mae: 0.5881\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 9s 824us/sample - loss: 0.4981 - mse: 0.4981 - mae: 0.5231 - val_loss: 0.6022 - val_mse: 0.6022 - val_mae: 0.5683\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 9s 828us/sample - loss: 0.4734 - mse: 0.4734 - mae: 0.5108 - val_loss: 0.6010 - val_mse: 0.6010 - val_mae: 0.5705\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.4581 - mse: 0.4581 - mae: 0.5031 - val_loss: 0.5660 - val_mse: 0.5660 - val_mae: 0.5387\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.4480 - mse: 0.4480 - mae: 0.4978 - val_loss: 0.5853 - val_mse: 0.5853 - val_mae: 0.5474\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 9s 810us/sample - loss: 0.4221 - mse: 0.4221 - mae: 0.4807 - val_loss: 0.5821 - val_mse: 0.5821 - val_mae: 0.5588\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 9s 809us/sample - loss: 0.3949 - mse: 0.3949 - mae: 0.4682 - val_loss: 0.6227 - val_mse: 0.6227 - val_mae: 0.5646\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 9s 830us/sample - loss: 0.3847 - mse: 0.3847 - mae: 0.4625 - val_loss: 0.5448 - val_mse: 0.5448 - val_mae: 0.5294\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 9s 818us/sample - loss: 0.3532 - mse: 0.3532 - mae: 0.4454 - val_loss: 0.5449 - val_mse: 0.5449 - val_mae: 0.5284\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.3459 - mse: 0.3459 - mae: 0.4386 - val_loss: 0.5092 - val_mse: 0.5092 - val_mae: 0.5029\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.3265 - mse: 0.3265 - mae: 0.4263 - val_loss: 0.4989 - val_mse: 0.4989 - val_mae: 0.5205\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.3181 - mse: 0.3181 - mae: 0.4228 - val_loss: 0.4851 - val_mse: 0.4851 - val_mae: 0.4934\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.3007 - mse: 0.3007 - mae: 0.4099 - val_loss: 0.4594 - val_mse: 0.4594 - val_mae: 0.4875\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.2809 - mse: 0.2809 - mae: 0.3954 - val_loss: 0.4897 - val_mse: 0.4897 - val_mae: 0.5068\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.2751 - mse: 0.2751 - mae: 0.3928 - val_loss: 0.4410 - val_mse: 0.4410 - val_mae: 0.4795\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 9s 818us/sample - loss: 0.2617 - mse: 0.2617 - mae: 0.3848 - val_loss: 0.4746 - val_mse: 0.4746 - val_mae: 0.4996\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 9s 817us/sample - loss: 0.2611 - mse: 0.2611 - mae: 0.3802 - val_loss: 0.4357 - val_mse: 0.4357 - val_mae: 0.4780\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 9s 811us/sample - loss: 0.2407 - mse: 0.2407 - mae: 0.3711 - val_loss: 0.4562 - val_mse: 0.4562 - val_mae: 0.4796\n",
      "Epoch 35/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.2357 - mse: 0.2357 - mae: 0.3650 - val_loss: 0.5079 - val_mse: 0.5079 - val_mae: 0.5130\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.2485 - mse: 0.2485 - mae: 0.3766 - val_loss: 0.4253 - val_mse: 0.4253 - val_mae: 0.4654\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.2144 - mse: 0.2144 - mae: 0.3480 - val_loss: 0.5079 - val_mse: 0.5079 - val_mae: 0.4937\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.2259 - mse: 0.2259 - mae: 0.3582 - val_loss: 0.5012 - val_mse: 0.5012 - val_mae: 0.4991\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 9s 850us/sample - loss: 0.2121 - mse: 0.2121 - mae: 0.3430 - val_loss: 0.4448 - val_mse: 0.4448 - val_mae: 0.4896\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 9s 811us/sample - loss: 0.2031 - mse: 0.2031 - mae: 0.3387 - val_loss: 0.4371 - val_mse: 0.4371 - val_mae: 0.4684\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 9s 808us/sample - loss: 0.2215 - mse: 0.2215 - mae: 0.3550 - val_loss: 0.5862 - val_mse: 0.5862 - val_mae: 0.4839\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 9s 809us/sample - loss: 0.2016 - mse: 0.2016 - mae: 0.3356 - val_loss: 0.4522 - val_mse: 0.4522 - val_mae: 0.4820\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 9s 820us/sample - loss: 0.1908 - mse: 0.1908 - mae: 0.3308 - val_loss: 0.4370 - val_mse: 0.4370 - val_mae: 0.4803\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 9s 814us/sample - loss: 0.2052 - mse: 0.2052 - mae: 0.3383 - val_loss: 0.5636 - val_mse: 0.5636 - val_mae: 0.4982\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 9s 810us/sample - loss: 0.1796 - mse: 0.1796 - mae: 0.3174 - val_loss: 0.4472 - val_mse: 0.4472 - val_mae: 0.4741\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 9s 817us/sample - loss: 0.1753 - mse: 0.1753 - mae: 0.3150 - val_loss: 0.4881 - val_mse: 0.4881 - val_mae: 0.4838\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 10s 955us/sample - loss: 88.1730 - mse: 88.1730 - mae: 4.1964 - val_loss: 23.7995 - val_mse: 23.7995 - val_mae: 3.6069\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 9s 811us/sample - loss: 1.0395 - mse: 1.0395 - mae: 0.7821 - val_loss: 1.8904 - val_mse: 1.8904 - val_mae: 0.9497\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.7878 - mse: 0.7878 - mae: 0.6762 - val_loss: 1.0307 - val_mse: 1.0307 - val_mae: 0.7857\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.7300 - mse: 0.7300 - mae: 0.6461 - val_loss: 0.9377 - val_mse: 0.9377 - val_mae: 0.7319\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.7009 - mse: 0.7009 - mae: 0.6285 - val_loss: 0.8880 - val_mse: 0.8880 - val_mae: 0.7433\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 9s 817us/sample - loss: 0.6728 - mse: 0.6728 - mae: 0.6139 - val_loss: 0.8358 - val_mse: 0.8358 - val_mae: 0.7247\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 9s 838us/sample - loss: 0.6553 - mse: 0.6553 - mae: 0.6021 - val_loss: 0.8119 - val_mse: 0.8119 - val_mae: 0.7188\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 9s 876us/sample - loss: 0.6361 - mse: 0.6361 - mae: 0.5924 - val_loss: 0.7264 - val_mse: 0.7264 - val_mae: 0.6676\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 9s 818us/sample - loss: 0.6177 - mse: 0.6177 - mae: 0.5824 - val_loss: 0.7222 - val_mse: 0.7222 - val_mae: 0.6775\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 9s 811us/sample - loss: 0.6062 - mse: 0.6062 - mae: 0.5780 - val_loss: 0.7234 - val_mse: 0.7234 - val_mae: 0.6677\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.5846 - mse: 0.5846 - mae: 0.5673 - val_loss: 0.6728 - val_mse: 0.6728 - val_mae: 0.6382\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.5632 - mse: 0.5632 - mae: 0.5559 - val_loss: 0.6508 - val_mse: 0.6508 - val_mae: 0.6343\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 9s 821us/sample - loss: 0.5441 - mse: 0.5441 - mae: 0.5466 - val_loss: 0.6203 - val_mse: 0.6203 - val_mae: 0.6134\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.5241 - mse: 0.5241 - mae: 0.5351 - val_loss: 0.6090 - val_mse: 0.6090 - val_mae: 0.5954\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 9s 814us/sample - loss: 0.5044 - mse: 0.5044 - mae: 0.5277 - val_loss: 0.5879 - val_mse: 0.5879 - val_mae: 0.5879\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.4913 - mse: 0.4913 - mae: 0.5216 - val_loss: 0.6520 - val_mse: 0.6520 - val_mae: 0.6051\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.4716 - mse: 0.4716 - mae: 0.5095 - val_loss: 0.5808 - val_mse: 0.5808 - val_mae: 0.5718\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.4558 - mse: 0.4558 - mae: 0.5013 - val_loss: 0.5661 - val_mse: 0.5661 - val_mae: 0.5673\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 9s 823us/sample - loss: 0.4238 - mse: 0.4238 - mae: 0.4816 - val_loss: 0.5606 - val_mse: 0.5606 - val_mae: 0.5647\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 9s 825us/sample - loss: 0.3891 - mse: 0.3891 - mae: 0.4641 - val_loss: 0.5477 - val_mse: 0.5477 - val_mae: 0.5451\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 9s 831us/sample - loss: 0.3939 - mse: 0.3939 - mae: 0.4673 - val_loss: 0.5015 - val_mse: 0.5015 - val_mae: 0.5207\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 9s 818us/sample - loss: 0.3699 - mse: 0.3699 - mae: 0.4530 - val_loss: 0.5318 - val_mse: 0.5318 - val_mae: 0.5400\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.3577 - mse: 0.3577 - mae: 0.4440 - val_loss: 0.5167 - val_mse: 0.5167 - val_mae: 0.5264\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.3565 - mse: 0.3565 - mae: 0.4456 - val_loss: 0.5025 - val_mse: 0.5025 - val_mae: 0.5268\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 9s 821us/sample - loss: 0.3250 - mse: 0.3250 - mae: 0.4245 - val_loss: 0.4802 - val_mse: 0.4802 - val_mae: 0.5145\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.3116 - mse: 0.3116 - mae: 0.4165 - val_loss: 0.4773 - val_mse: 0.4773 - val_mae: 0.5017\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 9s 822us/sample - loss: 0.2955 - mse: 0.2955 - mae: 0.4043 - val_loss: 0.4984 - val_mse: 0.4984 - val_mae: 0.5137\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.2911 - mse: 0.2911 - mae: 0.4024 - val_loss: 0.4799 - val_mse: 0.4799 - val_mae: 0.4983\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 9s 827us/sample - loss: 0.2790 - mse: 0.2790 - mae: 0.3971 - val_loss: 0.4486 - val_mse: 0.4486 - val_mae: 0.4902\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 9s 814us/sample - loss: 0.2725 - mse: 0.2725 - mae: 0.3925 - val_loss: 0.4927 - val_mse: 0.4927 - val_mae: 0.5039\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.2553 - mse: 0.2553 - mae: 0.3798 - val_loss: 0.4647 - val_mse: 0.4647 - val_mae: 0.5034\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 9s 821us/sample - loss: 0.2489 - mse: 0.2489 - mae: 0.3727 - val_loss: 0.4736 - val_mse: 0.4736 - val_mae: 0.4910\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 9s 818us/sample - loss: 0.2404 - mse: 0.2404 - mae: 0.3670 - val_loss: 0.4851 - val_mse: 0.4851 - val_mae: 0.4976\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 9s 819us/sample - loss: 0.2350 - mse: 0.2350 - mae: 0.3636 - val_loss: 0.4843 - val_mse: 0.4843 - val_mae: 0.5003\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 9s 821us/sample - loss: 0.2227 - mse: 0.2227 - mae: 0.3557 - val_loss: 0.4285 - val_mse: 0.4285 - val_mae: 0.4760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 9s 822us/sample - loss: 0.2187 - mse: 0.2187 - mae: 0.3523 - val_loss: 0.4239 - val_mse: 0.4239 - val_mae: 0.4638\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.2001 - mse: 0.2001 - mae: 0.3362 - val_loss: 0.4446 - val_mse: 0.4446 - val_mae: 0.4776\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 9s 822us/sample - loss: 0.1876 - mse: 0.1876 - mae: 0.3251 - val_loss: 0.4328 - val_mse: 0.4328 - val_mae: 0.4639\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.2005 - mse: 0.2005 - mae: 0.3383 - val_loss: 0.4315 - val_mse: 0.4315 - val_mae: 0.4691\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.1862 - mse: 0.1862 - mae: 0.3223 - val_loss: 0.4707 - val_mse: 0.4707 - val_mae: 0.5056\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 9s 819us/sample - loss: 0.1923 - mse: 0.1923 - mae: 0.3317 - val_loss: 0.4815 - val_mse: 0.4815 - val_mae: 0.4980\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.1845 - mse: 0.1845 - mae: 0.3233 - val_loss: 0.4289 - val_mse: 0.4289 - val_mae: 0.4701\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.1974 - mse: 0.1974 - mae: 0.3354 - val_loss: 0.6136 - val_mse: 0.6136 - val_mae: 0.5780\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.1778 - mse: 0.1778 - mae: 0.3173 - val_loss: 0.4022 - val_mse: 0.4022 - val_mae: 0.4497\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.1635 - mse: 0.1635 - mae: 0.3039 - val_loss: 0.4866 - val_mse: 0.4866 - val_mae: 0.4876\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 9s 818us/sample - loss: 0.1752 - mse: 0.1752 - mae: 0.3139 - val_loss: 0.4636 - val_mse: 0.4636 - val_mae: 0.4915\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.1652 - mse: 0.1652 - mae: 0.3081 - val_loss: 0.4485 - val_mse: 0.4485 - val_mae: 0.4810\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 9s 817us/sample - loss: 0.1630 - mse: 0.1630 - mae: 0.3031 - val_loss: 0.4772 - val_mse: 0.4772 - val_mae: 0.4931\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.1987 - mse: 0.1987 - mae: 0.3296 - val_loss: 0.4349 - val_mse: 0.4349 - val_mae: 0.4705\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 9s 823us/sample - loss: 0.1600 - mse: 0.1600 - mae: 0.3020 - val_loss: 0.4428 - val_mse: 0.4428 - val_mae: 0.4760\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 9s 823us/sample - loss: 0.1445 - mse: 0.1445 - mae: 0.2859 - val_loss: 0.3996 - val_mse: 0.3996 - val_mae: 0.4493\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 9s 818us/sample - loss: 0.1415 - mse: 0.1415 - mae: 0.2847 - val_loss: 0.4112 - val_mse: 0.4112 - val_mae: 0.4455\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 9s 840us/sample - loss: 0.1272 - mse: 0.1272 - mae: 0.2695 - val_loss: 0.4102 - val_mse: 0.4102 - val_mae: 0.4531\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.1328 - mse: 0.1328 - mae: 0.2749 - val_loss: 0.4709 - val_mse: 0.4709 - val_mae: 0.4777\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.1349 - mse: 0.1349 - mae: 0.2759 - val_loss: 0.4166 - val_mse: 0.4166 - val_mae: 0.4583\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.1328 - mse: 0.1328 - mae: 0.2744 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4622\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 9s 810us/sample - loss: 0.1353 - mse: 0.1353 - mae: 0.2749 - val_loss: 0.4168 - val_mse: 0.4168 - val_mae: 0.4442\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.1142 - mse: 0.1142 - mae: 0.2540 - val_loss: 0.3976 - val_mse: 0.3976 - val_mae: 0.4459\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.1282 - mse: 0.1282 - mae: 0.2673 - val_loss: 0.5000 - val_mse: 0.5000 - val_mae: 0.4558\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.1255 - mse: 0.1255 - mae: 0.2625 - val_loss: 0.4049 - val_mse: 0.4049 - val_mae: 0.4359\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 9s 811us/sample - loss: 0.1079 - mse: 0.1079 - mae: 0.2478 - val_loss: 0.4080 - val_mse: 0.4080 - val_mae: 0.4497\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 9s 841us/sample - loss: 0.1066 - mse: 0.1066 - mae: 0.2447 - val_loss: 0.4053 - val_mse: 0.4053 - val_mae: 0.4450\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 9s 829us/sample - loss: 0.1057 - mse: 0.1057 - mae: 0.2449 - val_loss: 0.4330 - val_mse: 0.4330 - val_mae: 0.4785\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 9s 809us/sample - loss: 0.1243 - mse: 0.1243 - mae: 0.2647 - val_loss: 0.4678 - val_mse: 0.4678 - val_mae: 0.4996\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.1301 - mse: 0.1301 - mae: 0.2712 - val_loss: 0.5056 - val_mse: 0.5056 - val_mae: 0.4817\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.1279 - mse: 0.1279 - mae: 0.2653 - val_loss: 0.4651 - val_mse: 0.4651 - val_mae: 0.4810\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 9s 809us/sample - loss: 0.1083 - mse: 0.1083 - mae: 0.2478 - val_loss: 0.4114 - val_mse: 0.4114 - val_mae: 0.4551\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 9s 823us/sample - loss: 0.1046 - mse: 0.1046 - mae: 0.2458 - val_loss: 0.4175 - val_mse: 0.4175 - val_mae: 0.4599\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 10s 927us/sample - loss: 63.7560 - mse: 63.7560 - mae: 3.6393 - val_loss: 16.4345 - val_mse: 16.4345 - val_mae: 3.0323\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 9s 809us/sample - loss: 0.9628 - mse: 0.9628 - mae: 0.7376 - val_loss: 20.8563 - val_mse: 20.8563 - val_mae: 4.1240\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.7353 - mse: 0.7353 - mae: 0.6470 - val_loss: 3.0765 - val_mse: 3.0765 - val_mae: 1.5140\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 9s 817us/sample - loss: 0.6926 - mse: 0.6926 - mae: 0.6228 - val_loss: 1.4267 - val_mse: 1.4267 - val_mae: 1.0038\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.6656 - mse: 0.6656 - mae: 0.6074 - val_loss: 1.0812 - val_mse: 1.0812 - val_mae: 0.8601\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 9s 817us/sample - loss: 0.6524 - mse: 0.6524 - mae: 0.6011 - val_loss: 0.8575 - val_mse: 0.8575 - val_mae: 0.7500\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.6314 - mse: 0.6314 - mae: 0.5884 - val_loss: 0.8122 - val_mse: 0.8122 - val_mae: 0.7297\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 9s 822us/sample - loss: 0.6189 - mse: 0.6189 - mae: 0.5842 - val_loss: 0.7559 - val_mse: 0.7559 - val_mae: 0.6932\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.6055 - mse: 0.6055 - mae: 0.5770 - val_loss: 0.7227 - val_mse: 0.7227 - val_mae: 0.6791\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 9s 814us/sample - loss: 0.5915 - mse: 0.5915 - mae: 0.5707 - val_loss: 0.6964 - val_mse: 0.6964 - val_mae: 0.6553\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 9s 814us/sample - loss: 0.5833 - mse: 0.5833 - mae: 0.5662 - val_loss: 0.6513 - val_mse: 0.6513 - val_mae: 0.6213\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.5610 - mse: 0.5610 - mae: 0.5567 - val_loss: 0.6288 - val_mse: 0.6288 - val_mae: 0.6009\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 9s 814us/sample - loss: 0.5497 - mse: 0.5497 - mae: 0.5492 - val_loss: 0.6009 - val_mse: 0.6009 - val_mae: 0.5821\n",
      "Epoch 14/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.5299 - mse: 0.5299 - mae: 0.5411 - val_loss: 0.6154 - val_mse: 0.6154 - val_mae: 0.5868\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 9s 819us/sample - loss: 0.5135 - mse: 0.5135 - mae: 0.5313 - val_loss: 0.6134 - val_mse: 0.6134 - val_mae: 0.5845\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 9s 814us/sample - loss: 0.4955 - mse: 0.4955 - mae: 0.5242 - val_loss: 0.6161 - val_mse: 0.6161 - val_mae: 0.5750\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 9s 811us/sample - loss: 0.4681 - mse: 0.4681 - mae: 0.5058 - val_loss: 0.5303 - val_mse: 0.5303 - val_mae: 0.5339\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 9s 809us/sample - loss: 0.4293 - mse: 0.4293 - mae: 0.4871 - val_loss: 0.6012 - val_mse: 0.6012 - val_mae: 0.5637\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.4122 - mse: 0.4122 - mae: 0.4772 - val_loss: 0.5659 - val_mse: 0.5659 - val_mae: 0.5512\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.3895 - mse: 0.3895 - mae: 0.4629 - val_loss: 0.5857 - val_mse: 0.5857 - val_mae: 0.5535\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 9s 810us/sample - loss: 0.3973 - mse: 0.3973 - mae: 0.4674 - val_loss: 0.6117 - val_mse: 0.6117 - val_mae: 0.5716\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 9s 818us/sample - loss: 0.3865 - mse: 0.3865 - mae: 0.4598 - val_loss: 0.5454 - val_mse: 0.5454 - val_mae: 0.5319\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.3587 - mse: 0.3587 - mae: 0.4474 - val_loss: 0.4925 - val_mse: 0.4925 - val_mae: 0.5160\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 9s 814us/sample - loss: 0.3526 - mse: 0.3526 - mae: 0.4385 - val_loss: 0.5610 - val_mse: 0.5610 - val_mae: 0.5418\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.3396 - mse: 0.3396 - mae: 0.4322 - val_loss: 0.5397 - val_mse: 0.5397 - val_mae: 0.5365\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.3116 - mse: 0.3116 - mae: 0.4154 - val_loss: 0.4874 - val_mse: 0.4874 - val_mae: 0.5022\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.3039 - mse: 0.3039 - mae: 0.4136 - val_loss: 0.4757 - val_mse: 0.4757 - val_mae: 0.4965\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 9s 840us/sample - loss: 0.2796 - mse: 0.2796 - mae: 0.3946 - val_loss: 0.4748 - val_mse: 0.4748 - val_mae: 0.4980\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 9s 841us/sample - loss: 0.2731 - mse: 0.2731 - mae: 0.3914 - val_loss: 0.4433 - val_mse: 0.4433 - val_mae: 0.4809\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.2494 - mse: 0.2494 - mae: 0.3727 - val_loss: 0.4240 - val_mse: 0.4240 - val_mae: 0.4718\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 9s 811us/sample - loss: 0.2502 - mse: 0.2502 - mae: 0.3749 - val_loss: 0.4297 - val_mse: 0.4297 - val_mae: 0.4760\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.2458 - mse: 0.2458 - mae: 0.3709 - val_loss: 0.4519 - val_mse: 0.4519 - val_mae: 0.4813\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.2533 - mse: 0.2533 - mae: 0.3784 - val_loss: 0.4414 - val_mse: 0.4414 - val_mae: 0.4824\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 9s 809us/sample - loss: 0.2426 - mse: 0.2426 - mae: 0.3651 - val_loss: 0.4478 - val_mse: 0.4478 - val_mae: 0.4803\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 9s 811us/sample - loss: 0.2289 - mse: 0.2289 - mae: 0.3596 - val_loss: 0.4502 - val_mse: 0.4502 - val_mae: 0.4815\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 9s 821us/sample - loss: 0.2162 - mse: 0.2162 - mae: 0.3508 - val_loss: 0.4459 - val_mse: 0.4459 - val_mae: 0.4848\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.1971 - mse: 0.1971 - mae: 0.3319 - val_loss: 0.4486 - val_mse: 0.4486 - val_mae: 0.4906\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 9s 811us/sample - loss: 0.2259 - mse: 0.2259 - mae: 0.3573 - val_loss: 0.4326 - val_mse: 0.4326 - val_mae: 0.4797\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 9s 817us/sample - loss: 0.2038 - mse: 0.2038 - mae: 0.3389 - val_loss: 0.4067 - val_mse: 0.4067 - val_mae: 0.4600\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.1969 - mse: 0.1969 - mae: 0.3326 - val_loss: 0.4352 - val_mse: 0.4352 - val_mae: 0.4722\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.1792 - mse: 0.1792 - mae: 0.3187 - val_loss: 0.3952 - val_mse: 0.3952 - val_mae: 0.4444\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 9s 810us/sample - loss: 0.1752 - mse: 0.1752 - mae: 0.3105 - val_loss: 0.3988 - val_mse: 0.3988 - val_mae: 0.4502\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 9s 821us/sample - loss: 0.1786 - mse: 0.1786 - mae: 0.3164 - val_loss: 0.3766 - val_mse: 0.3766 - val_mae: 0.4402\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.1745 - mse: 0.1745 - mae: 0.3139 - val_loss: 0.3890 - val_mse: 0.3890 - val_mae: 0.4486\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 9s 810us/sample - loss: 0.1648 - mse: 0.1648 - mae: 0.3014 - val_loss: 0.4438 - val_mse: 0.4438 - val_mae: 0.4757\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 9s 812us/sample - loss: 0.1748 - mse: 0.1748 - mae: 0.3147 - val_loss: 0.4356 - val_mse: 0.4356 - val_mae: 0.4786\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 9s 817us/sample - loss: 0.1763 - mse: 0.1763 - mae: 0.3161 - val_loss: 0.4373 - val_mse: 0.4373 - val_mae: 0.4701\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 9s 810us/sample - loss: 0.1630 - mse: 0.1630 - mae: 0.3019 - val_loss: 0.4296 - val_mse: 0.4296 - val_mae: 0.4673\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 9s 815us/sample - loss: 0.1759 - mse: 0.1759 - mae: 0.3154 - val_loss: 0.4854 - val_mse: 0.4854 - val_mae: 0.5034\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 9s 813us/sample - loss: 0.1579 - mse: 0.1579 - mae: 0.2960 - val_loss: 0.4222 - val_mse: 0.4222 - val_mae: 0.4672\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 9s 817us/sample - loss: 0.1540 - mse: 0.1540 - mae: 0.2912 - val_loss: 0.3895 - val_mse: 0.3895 - val_mae: 0.4484\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 9s 816us/sample - loss: 0.1376 - mse: 0.1376 - mae: 0.2790 - val_loss: 0.4029 - val_mse: 0.4029 - val_mae: 0.4510\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 9s 811us/sample - loss: 0.1378 - mse: 0.1378 - mae: 0.2763 - val_loss: 0.4043 - val_mse: 0.4043 - val_mae: 0.4518\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 10s 915us/sample - loss: 91.7768 - mse: 91.7768 - mae: 4.4576 - val_loss: 109.3785 - val_mse: 109.3785 - val_mae: 9.0876\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 9s 810us/sample - loss: 1.2392 - mse: 1.2392 - mae: 0.8544 - val_loss: 31.3855 - val_mse: 31.3855 - val_mae: 4.8329\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 9s 813us/sample - loss: 0.8176 - mse: 0.8176 - mae: 0.6908 - val_loss: 5.1456 - val_mse: 5.1456 - val_mae: 1.8352\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 9s 818us/sample - loss: 0.7572 - mse: 0.7572 - mae: 0.6597 - val_loss: 1.3435 - val_mse: 1.3435 - val_mae: 0.9803\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 9s 811us/sample - loss: 0.7234 - mse: 0.7234 - mae: 0.6443 - val_loss: 1.0395 - val_mse: 1.0395 - val_mae: 0.8238\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 9s 813us/sample - loss: 0.7010 - mse: 0.7010 - mae: 0.6300 - val_loss: 0.8474 - val_mse: 0.8474 - val_mae: 0.7417\n",
      "Epoch 7/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 9s 814us/sample - loss: 0.6854 - mse: 0.6854 - mae: 0.6231 - val_loss: 0.7871 - val_mse: 0.7871 - val_mae: 0.7109\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 9s 816us/sample - loss: 0.6668 - mse: 0.6668 - mae: 0.6132 - val_loss: 0.7463 - val_mse: 0.7463 - val_mae: 0.6749\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 9s 822us/sample - loss: 0.6494 - mse: 0.6494 - mae: 0.6050 - val_loss: 0.7133 - val_mse: 0.7133 - val_mae: 0.6563\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 9s 814us/sample - loss: 0.6362 - mse: 0.6362 - mae: 0.5965 - val_loss: 0.6963 - val_mse: 0.6963 - val_mae: 0.6530\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 9s 818us/sample - loss: 0.6217 - mse: 0.6217 - mae: 0.5888 - val_loss: 0.6859 - val_mse: 0.6859 - val_mae: 0.6444\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 9s 810us/sample - loss: 0.6138 - mse: 0.6138 - mae: 0.5861 - val_loss: 0.6729 - val_mse: 0.6729 - val_mae: 0.6325\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 9s 813us/sample - loss: 0.5932 - mse: 0.5932 - mae: 0.5737 - val_loss: 0.6903 - val_mse: 0.6903 - val_mae: 0.6138\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 9s 836us/sample - loss: 0.5785 - mse: 0.5785 - mae: 0.5647 - val_loss: 0.6256 - val_mse: 0.6256 - val_mae: 0.5842\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 9s 809us/sample - loss: 0.5653 - mse: 0.5653 - mae: 0.5589 - val_loss: 0.6405 - val_mse: 0.6405 - val_mae: 0.6004\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 9s 816us/sample - loss: 0.5469 - mse: 0.5469 - mae: 0.5476 - val_loss: 0.5885 - val_mse: 0.5885 - val_mae: 0.5789\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 9s 856us/sample - loss: 0.5282 - mse: 0.5282 - mae: 0.5383 - val_loss: 0.5755 - val_mse: 0.5755 - val_mae: 0.5544\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 9s 820us/sample - loss: 0.5052 - mse: 0.5052 - mae: 0.5250 - val_loss: 0.5775 - val_mse: 0.5775 - val_mae: 0.5590\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 9s 811us/sample - loss: 0.4874 - mse: 0.4874 - mae: 0.5171 - val_loss: 0.5493 - val_mse: 0.5493 - val_mae: 0.5603\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 9s 815us/sample - loss: 0.4622 - mse: 0.4622 - mae: 0.5053 - val_loss: 0.5424 - val_mse: 0.5424 - val_mae: 0.5527\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 9s 814us/sample - loss: 0.4410 - mse: 0.4410 - mae: 0.4922 - val_loss: 0.5045 - val_mse: 0.5045 - val_mae: 0.5285\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 9s 808us/sample - loss: 0.4071 - mse: 0.4071 - mae: 0.4705 - val_loss: 0.5092 - val_mse: 0.5092 - val_mae: 0.5236\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 9s 810us/sample - loss: 0.3882 - mse: 0.3882 - mae: 0.4617 - val_loss: 0.5070 - val_mse: 0.5070 - val_mae: 0.5302\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 9s 808us/sample - loss: 0.3851 - mse: 0.3851 - mae: 0.4616 - val_loss: 0.4859 - val_mse: 0.4859 - val_mae: 0.5121\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 9s 822us/sample - loss: 0.3592 - mse: 0.3592 - mae: 0.4478 - val_loss: 0.4806 - val_mse: 0.4806 - val_mae: 0.5080\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 9s 810us/sample - loss: 0.3259 - mse: 0.3259 - mae: 0.4258 - val_loss: 0.4898 - val_mse: 0.4898 - val_mae: 0.4984\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 9s 809us/sample - loss: 0.3311 - mse: 0.3311 - mae: 0.4293 - val_loss: 0.5004 - val_mse: 0.5004 - val_mae: 0.5053\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 9s 815us/sample - loss: 0.3141 - mse: 0.3141 - mae: 0.4169 - val_loss: 0.4540 - val_mse: 0.4540 - val_mae: 0.4829\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 9s 809us/sample - loss: 0.2885 - mse: 0.2885 - mae: 0.4010 - val_loss: 0.4550 - val_mse: 0.4550 - val_mae: 0.4956\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 9s 814us/sample - loss: 0.2670 - mse: 0.2670 - mae: 0.3869 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4810\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 9s 808us/sample - loss: 0.2820 - mse: 0.2820 - mae: 0.3965 - val_loss: 0.4457 - val_mse: 0.4457 - val_mae: 0.4977\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 9s 820us/sample - loss: 0.2592 - mse: 0.2592 - mae: 0.3826 - val_loss: 0.4149 - val_mse: 0.4149 - val_mae: 0.4588\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 9s 815us/sample - loss: 0.2459 - mse: 0.2459 - mae: 0.3704 - val_loss: 0.4191 - val_mse: 0.4191 - val_mae: 0.4741\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 9s 842us/sample - loss: 0.2422 - mse: 0.2422 - mae: 0.3700 - val_loss: 0.4290 - val_mse: 0.4290 - val_mae: 0.4747\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 9s 817us/sample - loss: 0.2359 - mse: 0.2359 - mae: 0.3616 - val_loss: 0.4102 - val_mse: 0.4102 - val_mae: 0.4651\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 9s 809us/sample - loss: 0.2329 - mse: 0.2329 - mae: 0.3647 - val_loss: 0.4252 - val_mse: 0.4252 - val_mae: 0.4704\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 9s 811us/sample - loss: 0.2335 - mse: 0.2335 - mae: 0.3628 - val_loss: 0.3977 - val_mse: 0.3977 - val_mae: 0.4474\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 9s 809us/sample - loss: 0.2204 - mse: 0.2204 - mae: 0.3542 - val_loss: 0.4106 - val_mse: 0.4106 - val_mae: 0.4550\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 9s 821us/sample - loss: 0.2113 - mse: 0.2113 - mae: 0.3450 - val_loss: 0.4280 - val_mse: 0.4280 - val_mae: 0.4716\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 9s 814us/sample - loss: 0.2089 - mse: 0.2089 - mae: 0.3449 - val_loss: 0.4239 - val_mse: 0.4239 - val_mae: 0.4658\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 9s 812us/sample - loss: 0.1990 - mse: 0.1990 - mae: 0.3363 - val_loss: 0.4133 - val_mse: 0.4133 - val_mae: 0.4613\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 9s 809us/sample - loss: 0.1904 - mse: 0.1904 - mae: 0.3297 - val_loss: 0.4127 - val_mse: 0.4127 - val_mae: 0.4527\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 9s 813us/sample - loss: 0.1876 - mse: 0.1876 - mae: 0.3263 - val_loss: 0.4394 - val_mse: 0.4394 - val_mae: 0.4868\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 9s 823us/sample - loss: 0.1781 - mse: 0.1781 - mae: 0.3194 - val_loss: 0.4061 - val_mse: 0.4061 - val_mae: 0.4498\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 9s 828us/sample - loss: 0.1651 - mse: 0.1651 - mae: 0.3060 - val_loss: 0.3837 - val_mse: 0.3837 - val_mae: 0.4367\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 9s 814us/sample - loss: 0.1838 - mse: 0.1838 - mae: 0.3209 - val_loss: 0.3983 - val_mse: 0.3983 - val_mae: 0.4506\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 9s 812us/sample - loss: 0.1719 - mse: 0.1719 - mae: 0.3109 - val_loss: 0.4047 - val_mse: 0.4047 - val_mae: 0.4524\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 9s 820us/sample - loss: 0.1586 - mse: 0.1586 - mae: 0.3008 - val_loss: 0.3984 - val_mse: 0.3984 - val_mae: 0.4514\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 9s 821us/sample - loss: 0.1681 - mse: 0.1681 - mae: 0.3112 - val_loss: 0.4041 - val_mse: 0.4041 - val_mae: 0.4570\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 9s 857us/sample - loss: 0.1540 - mse: 0.1540 - mae: 0.2944 - val_loss: 0.3851 - val_mse: 0.3851 - val_mae: 0.4373\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 9s 844us/sample - loss: 0.1437 - mse: 0.1437 - mae: 0.2854 - val_loss: 0.4070 - val_mse: 0.4070 - val_mae: 0.4551\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 9s 814us/sample - loss: 0.1547 - mse: 0.1547 - mae: 0.2973 - val_loss: 0.3743 - val_mse: 0.3743 - val_mae: 0.4308\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 9s 818us/sample - loss: 0.1492 - mse: 0.1492 - mae: 0.2918 - val_loss: 0.4568 - val_mse: 0.4568 - val_mae: 0.4741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 9s 814us/sample - loss: 0.1417 - mse: 0.1417 - mae: 0.2818 - val_loss: 0.4049 - val_mse: 0.4049 - val_mae: 0.4507\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 9s 811us/sample - loss: 0.1530 - mse: 0.1530 - mae: 0.2946 - val_loss: 0.3996 - val_mse: 0.3996 - val_mae: 0.4471\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 9s 810us/sample - loss: 0.1405 - mse: 0.1405 - mae: 0.2804 - val_loss: 0.3942 - val_mse: 0.3942 - val_mae: 0.4361\n",
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 9s 818us/sample - loss: 0.1403 - mse: 0.1403 - mae: 0.2791 - val_loss: 0.4106 - val_mse: 0.4106 - val_mae: 0.4630\n",
      "Epoch 58/3000\n",
      "10664/10664 [==============================] - 9s 815us/sample - loss: 0.1392 - mse: 0.1392 - mae: 0.2788 - val_loss: 0.4965 - val_mse: 0.4965 - val_mae: 0.4844\n",
      "Epoch 59/3000\n",
      "10664/10664 [==============================] - 9s 818us/sample - loss: 0.1663 - mse: 0.1663 - mae: 0.2989 - val_loss: 0.5136 - val_mse: 0.5136 - val_mae: 0.5093\n",
      "Epoch 60/3000\n",
      "10664/10664 [==============================] - 9s 820us/sample - loss: 0.1321 - mse: 0.1321 - mae: 0.2750 - val_loss: 0.5176 - val_mse: 0.5176 - val_mae: 0.5164\n",
      "Epoch 61/3000\n",
      "10664/10664 [==============================] - 9s 819us/sample - loss: 0.1399 - mse: 0.1399 - mae: 0.2792 - val_loss: 0.3718 - val_mse: 0.3718 - val_mae: 0.4252\n",
      "Epoch 62/3000\n",
      "10664/10664 [==============================] - 9s 814us/sample - loss: 0.1331 - mse: 0.1331 - mae: 0.2716 - val_loss: 0.4733 - val_mse: 0.4733 - val_mae: 0.4805\n",
      "Epoch 63/3000\n",
      "10664/10664 [==============================] - 9s 813us/sample - loss: 0.1111 - mse: 0.1111 - mae: 0.2503 - val_loss: 0.3771 - val_mse: 0.3771 - val_mae: 0.4352\n",
      "Epoch 64/3000\n",
      "10664/10664 [==============================] - 9s 809us/sample - loss: 0.1186 - mse: 0.1186 - mae: 0.2586 - val_loss: 0.3983 - val_mse: 0.3983 - val_mae: 0.4335\n",
      "Epoch 65/3000\n",
      "10664/10664 [==============================] - 9s 808us/sample - loss: 0.1182 - mse: 0.1182 - mae: 0.2596 - val_loss: 0.3836 - val_mse: 0.3836 - val_mae: 0.4328\n",
      "Epoch 66/3000\n",
      "10664/10664 [==============================] - 9s 812us/sample - loss: 0.1149 - mse: 0.1149 - mae: 0.2568 - val_loss: 0.4215 - val_mse: 0.4215 - val_mae: 0.4540\n",
      "Epoch 67/3000\n",
      "10664/10664 [==============================] - 9s 815us/sample - loss: 0.1137 - mse: 0.1137 - mae: 0.2550 - val_loss: 0.4333 - val_mse: 0.4333 - val_mae: 0.4664\n",
      "Epoch 68/3000\n",
      "10664/10664 [==============================] - 9s 817us/sample - loss: 0.1082 - mse: 0.1082 - mae: 0.2468 - val_loss: 0.4070 - val_mse: 0.4070 - val_mae: 0.4397\n",
      "Epoch 69/3000\n",
      "10664/10664 [==============================] - 9s 811us/sample - loss: 0.1171 - mse: 0.1171 - mae: 0.2561 - val_loss: 0.4411 - val_mse: 0.4411 - val_mae: 0.4608\n",
      "Epoch 70/3000\n",
      "10664/10664 [==============================] - 9s 809us/sample - loss: 0.1104 - mse: 0.1104 - mae: 0.2492 - val_loss: 0.4005 - val_mse: 0.4005 - val_mae: 0.4563\n",
      "Epoch 71/3000\n",
      "10664/10664 [==============================] - 9s 812us/sample - loss: 0.1023 - mse: 0.1023 - mae: 0.2404 - val_loss: 0.4653 - val_mse: 0.4653 - val_mae: 0.4861\n",
      "Avg. MAE: 0.393091\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 189us/sample - loss: 3.7447 - mse: 3.7447 - mae: 1.3178 - val_loss: 3.3119 - val_mse: 3.3119 - val_mae: 1.4096\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.7465 - mse: 0.7465 - mae: 0.6524 - val_loss: 7.8723 - val_mse: 7.8723 - val_mae: 2.3587\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.5591 - mse: 0.5591 - mae: 0.5592 - val_loss: 4.9228 - val_mse: 4.9228 - val_mae: 1.7616\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.4804 - mse: 0.4804 - mae: 0.5168 - val_loss: 1.4092 - val_mse: 1.4092 - val_mae: 0.9187\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4148 - mse: 0.4148 - mae: 0.4754 - val_loss: 1.2041 - val_mse: 1.2041 - val_mae: 0.8345\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3694 - mse: 0.3694 - mae: 0.4531 - val_loss: 1.1413 - val_mse: 1.1413 - val_mae: 0.8182\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3315 - mse: 0.3315 - mae: 0.4287 - val_loss: 1.2816 - val_mse: 1.2816 - val_mae: 0.8452\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3034 - mse: 0.3034 - mae: 0.4075 - val_loss: 1.3710 - val_mse: 1.3710 - val_mae: 0.8685\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2772 - mse: 0.2772 - mae: 0.3947 - val_loss: 0.9499 - val_mse: 0.9499 - val_mae: 0.7683\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2584 - mse: 0.2584 - mae: 0.3790 - val_loss: 0.9241 - val_mse: 0.9241 - val_mae: 0.7417\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.2469 - mse: 0.2469 - mae: 0.3711 - val_loss: 0.8999 - val_mse: 0.8999 - val_mae: 0.7494\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2464 - mse: 0.2464 - mae: 0.3716 - val_loss: 0.8375 - val_mse: 0.8375 - val_mae: 0.7281\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2092 - mse: 0.2092 - mae: 0.3436 - val_loss: 0.8106 - val_mse: 0.8106 - val_mae: 0.7204\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1849 - mse: 0.1849 - mae: 0.3200 - val_loss: 0.8018 - val_mse: 0.8018 - val_mae: 0.7045\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1731 - mse: 0.1731 - mae: 0.3103 - val_loss: 0.6833 - val_mse: 0.6833 - val_mae: 0.6550\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1700 - mse: 0.1700 - mae: 0.3092 - val_loss: 0.6576 - val_mse: 0.6576 - val_mae: 0.6470\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1535 - mse: 0.1535 - mae: 0.2935 - val_loss: 0.6359 - val_mse: 0.6359 - val_mae: 0.6218\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1461 - mse: 0.1461 - mae: 0.2861 - val_loss: 0.5930 - val_mse: 0.5930 - val_mae: 0.6010\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1514 - mse: 0.1514 - mae: 0.2891 - val_loss: 0.6291 - val_mse: 0.6291 - val_mae: 0.6212\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1234 - mse: 0.1234 - mae: 0.2624 - val_loss: 0.5587 - val_mse: 0.5587 - val_mae: 0.5811\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1224 - mse: 0.1224 - mae: 0.2631 - val_loss: 0.5463 - val_mse: 0.5463 - val_mae: 0.5787\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1193 - mse: 0.1193 - mae: 0.2557 - val_loss: 0.5107 - val_mse: 0.5107 - val_mae: 0.5526\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.1139 - mse: 0.1139 - mae: 0.2534 - val_loss: 0.5827 - val_mse: 0.5827 - val_mae: 0.5945\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.1010 - mse: 0.1010 - mae: 0.2390 - val_loss: 0.5029 - val_mse: 0.5029 - val_mae: 0.5513\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0999 - mse: 0.0999 - mae: 0.2376 - val_loss: 0.5558 - val_mse: 0.5558 - val_mae: 0.5821\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0985 - mse: 0.0985 - mae: 0.2370 - val_loss: 0.4827 - val_mse: 0.4827 - val_mae: 0.5351\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0926 - mse: 0.0926 - mae: 0.2280 - val_loss: 0.4563 - val_mse: 0.4563 - val_mae: 0.5130\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0863 - mse: 0.0863 - mae: 0.2181 - val_loss: 0.4368 - val_mse: 0.4368 - val_mae: 0.4995\n",
      "Epoch 29/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0802 - mse: 0.0802 - mae: 0.2108 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.5029\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0819 - mse: 0.0819 - mae: 0.2140 - val_loss: 0.4608 - val_mse: 0.4608 - val_mae: 0.5007\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1010 - mse: 0.1010 - mae: 0.2415 - val_loss: 0.4553 - val_mse: 0.4553 - val_mae: 0.5040\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0896 - mse: 0.0896 - mae: 0.2231 - val_loss: 0.4243 - val_mse: 0.4243 - val_mae: 0.4842\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.0840 - mse: 0.0840 - mae: 0.2166 - val_loss: 0.3930 - val_mse: 0.3930 - val_mae: 0.4616\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0810 - mse: 0.0810 - mae: 0.2128 - val_loss: 0.4135 - val_mse: 0.4135 - val_mae: 0.4714\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0775 - mse: 0.0775 - mae: 0.2074 - val_loss: 0.4552 - val_mse: 0.4552 - val_mae: 0.4956\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0755 - mse: 0.0755 - mae: 0.2049 - val_loss: 0.4243 - val_mse: 0.4243 - val_mae: 0.4819\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0809 - mse: 0.0809 - mae: 0.2144 - val_loss: 0.4292 - val_mse: 0.4292 - val_mae: 0.4796\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0808 - mse: 0.0808 - mae: 0.2136 - val_loss: 0.4092 - val_mse: 0.4092 - val_mae: 0.4609\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0725 - mse: 0.0725 - mae: 0.2022 - val_loss: 0.4226 - val_mse: 0.4226 - val_mae: 0.4870\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0633 - mse: 0.0633 - mae: 0.1864 - val_loss: 0.4236 - val_mse: 0.4236 - val_mae: 0.4714\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0691 - mse: 0.0691 - mae: 0.1928 - val_loss: 0.4081 - val_mse: 0.4081 - val_mae: 0.4715\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0618 - mse: 0.0618 - mae: 0.1840 - val_loss: 0.3977 - val_mse: 0.3977 - val_mae: 0.4557\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0581 - mse: 0.0581 - mae: 0.1786 - val_loss: 0.4038 - val_mse: 0.4038 - val_mae: 0.4623\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 192us/sample - loss: 4.0200 - mse: 4.0200 - mae: 1.3042 - val_loss: 2.5414 - val_mse: 2.5414 - val_mae: 1.2094\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.7224 - mse: 0.7224 - mae: 0.6444 - val_loss: 21.6844 - val_mse: 21.6844 - val_mae: 3.7707\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.5462 - mse: 0.5462 - mae: 0.5572 - val_loss: 23.7513 - val_mse: 23.7513 - val_mae: 4.1124\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4731 - mse: 0.4731 - mae: 0.5132 - val_loss: 10.0447 - val_mse: 10.0447 - val_mae: 2.4134\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.4190 - mse: 0.4190 - mae: 0.4801 - val_loss: 6.1140 - val_mse: 6.1140 - val_mae: 1.8659\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3660 - mse: 0.3660 - mae: 0.4516 - val_loss: 3.2982 - val_mse: 3.2982 - val_mae: 1.3189\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3417 - mse: 0.3417 - mae: 0.4312 - val_loss: 1.6998 - val_mse: 1.6998 - val_mae: 0.9322\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3132 - mse: 0.3132 - mae: 0.4157 - val_loss: 1.0557 - val_mse: 1.0557 - val_mae: 0.7776\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.2771 - mse: 0.2771 - mae: 0.3924 - val_loss: 1.0407 - val_mse: 1.0407 - val_mae: 0.7832\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2442 - mse: 0.2442 - mae: 0.3676 - val_loss: 0.9726 - val_mse: 0.9726 - val_mae: 0.7558\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2254 - mse: 0.2254 - mae: 0.3543 - val_loss: 0.9273 - val_mse: 0.9273 - val_mae: 0.7293\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.2114 - mse: 0.2114 - mae: 0.3448 - val_loss: 0.8580 - val_mse: 0.8580 - val_mae: 0.7132\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1891 - mse: 0.1891 - mae: 0.3247 - val_loss: 0.8426 - val_mse: 0.8426 - val_mae: 0.6863\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1830 - mse: 0.1830 - mae: 0.3206 - val_loss: 0.7381 - val_mse: 0.7381 - val_mae: 0.6643\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1782 - mse: 0.1782 - mae: 0.3160 - val_loss: 0.7108 - val_mse: 0.7108 - val_mae: 0.6448\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1539 - mse: 0.1539 - mae: 0.2918 - val_loss: 0.6772 - val_mse: 0.6772 - val_mae: 0.6177\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1595 - mse: 0.1595 - mae: 0.2988 - val_loss: 0.6381 - val_mse: 0.6381 - val_mae: 0.5955\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1388 - mse: 0.1388 - mae: 0.2792 - val_loss: 0.6052 - val_mse: 0.6052 - val_mae: 0.5796\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1288 - mse: 0.1288 - mae: 0.2690 - val_loss: 0.5863 - val_mse: 0.5863 - val_mae: 0.5776\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1276 - mse: 0.1276 - mae: 0.2676 - val_loss: 0.5788 - val_mse: 0.5788 - val_mae: 0.5680\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1231 - mse: 0.1231 - mae: 0.2621 - val_loss: 0.6369 - val_mse: 0.6369 - val_mae: 0.5890\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.1300 - mse: 0.1300 - mae: 0.2715 - val_loss: 0.5158 - val_mse: 0.5158 - val_mae: 0.5393\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.1098 - mse: 0.1098 - mae: 0.2483 - val_loss: 0.5297 - val_mse: 0.5297 - val_mae: 0.5259\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1249 - mse: 0.1249 - mae: 0.2604 - val_loss: 0.6069 - val_mse: 0.6069 - val_mae: 0.5446\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1304 - mse: 0.1304 - mae: 0.2679 - val_loss: 0.6071 - val_mse: 0.6071 - val_mae: 0.5310\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1111 - mse: 0.1111 - mae: 0.2475 - val_loss: 0.4471 - val_mse: 0.4471 - val_mae: 0.4901\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0961 - mse: 0.0961 - mae: 0.2293 - val_loss: 0.4585 - val_mse: 0.4585 - val_mae: 0.4954\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.0863 - mse: 0.0863 - mae: 0.2200 - val_loss: 0.4771 - val_mse: 0.4771 - val_mae: 0.4826\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.1043 - mse: 0.1043 - mae: 0.2406 - val_loss: 0.5162 - val_mse: 0.5162 - val_mae: 0.4914\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1003 - mse: 0.1003 - mae: 0.2372 - val_loss: 0.4499 - val_mse: 0.4499 - val_mae: 0.4791\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0936 - mse: 0.0936 - mae: 0.2257 - val_loss: 0.4261 - val_mse: 0.4261 - val_mae: 0.4648\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0847 - mse: 0.0847 - mae: 0.2157 - val_loss: 0.4719 - val_mse: 0.4719 - val_mae: 0.4815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0834 - mse: 0.0834 - mae: 0.2137 - val_loss: 0.4615 - val_mse: 0.4615 - val_mae: 0.4750\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.0829 - mse: 0.0829 - mae: 0.2141 - val_loss: 0.4441 - val_mse: 0.4441 - val_mae: 0.4720\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0760 - mse: 0.0760 - mae: 0.2043 - val_loss: 0.4194 - val_mse: 0.4194 - val_mae: 0.4543\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 47us/sample - loss: 0.0772 - mse: 0.0772 - mae: 0.2037 - val_loss: 0.4563 - val_mse: 0.4563 - val_mae: 0.4847\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0760 - mse: 0.0760 - mae: 0.2043 - val_loss: 0.4679 - val_mse: 0.4679 - val_mae: 0.4637\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0718 - mse: 0.0718 - mae: 0.1969 - val_loss: 0.4334 - val_mse: 0.4334 - val_mae: 0.4642\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0713 - mse: 0.0713 - mae: 0.1986 - val_loss: 0.4548 - val_mse: 0.4548 - val_mae: 0.4819\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0735 - mse: 0.0735 - mae: 0.1996 - val_loss: 0.4264 - val_mse: 0.4264 - val_mae: 0.4562\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0633 - mse: 0.0633 - mae: 0.1851 - val_loss: 0.4472 - val_mse: 0.4472 - val_mae: 0.4589\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0706 - mse: 0.0706 - mae: 0.1929 - val_loss: 0.4383 - val_mse: 0.4383 - val_mae: 0.4631\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0657 - mse: 0.0657 - mae: 0.1889 - val_loss: 0.4294 - val_mse: 0.4294 - val_mae: 0.4567\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0693 - mse: 0.0693 - mae: 0.1971 - val_loss: 0.4067 - val_mse: 0.4067 - val_mae: 0.4400\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0691 - mse: 0.0691 - mae: 0.1973 - val_loss: 0.4148 - val_mse: 0.4148 - val_mae: 0.4404\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0628 - mse: 0.0628 - mae: 0.1840 - val_loss: 0.4174 - val_mse: 0.4174 - val_mae: 0.4466\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0566 - mse: 0.0566 - mae: 0.1764 - val_loss: 0.4075 - val_mse: 0.4075 - val_mae: 0.4405\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0563 - mse: 0.0563 - mae: 0.1763 - val_loss: 0.4218 - val_mse: 0.4218 - val_mae: 0.4517\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0555 - mse: 0.0555 - mae: 0.1743 - val_loss: 0.4245 - val_mse: 0.4245 - val_mae: 0.4341\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0499 - mse: 0.0499 - mae: 0.1631 - val_loss: 0.4100 - val_mse: 0.4100 - val_mae: 0.4384\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0520 - mse: 0.0520 - mae: 0.1676 - val_loss: 0.4036 - val_mse: 0.4036 - val_mae: 0.4327\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0558 - mse: 0.0558 - mae: 0.1747 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4408\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0620 - mse: 0.0620 - mae: 0.1827 - val_loss: 0.4060 - val_mse: 0.4060 - val_mae: 0.4357\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.0533 - mse: 0.0533 - mae: 0.1688 - val_loss: 0.4056 - val_mse: 0.4056 - val_mae: 0.4371\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0507 - mse: 0.0507 - mae: 0.1642 - val_loss: 0.3987 - val_mse: 0.3987 - val_mae: 0.4322\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0498 - mse: 0.0498 - mae: 0.1646 - val_loss: 0.4091 - val_mse: 0.4091 - val_mae: 0.4416\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0463 - mse: 0.0463 - mae: 0.1575 - val_loss: 0.4165 - val_mse: 0.4165 - val_mae: 0.4399\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0431 - mse: 0.0431 - mae: 0.1530 - val_loss: 0.4160 - val_mse: 0.4160 - val_mae: 0.4439\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0423 - mse: 0.0423 - mae: 0.1517 - val_loss: 0.4012 - val_mse: 0.4012 - val_mae: 0.4296\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0418 - mse: 0.0418 - mae: 0.1479 - val_loss: 0.4082 - val_mse: 0.4082 - val_mae: 0.4411\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.0425 - mse: 0.0425 - mae: 0.1503 - val_loss: 0.4349 - val_mse: 0.4349 - val_mae: 0.4425\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.0446 - mse: 0.0446 - mae: 0.1547 - val_loss: 0.4013 - val_mse: 0.4013 - val_mae: 0.4302\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.0460 - mse: 0.0460 - mae: 0.1578 - val_loss: 0.3971 - val_mse: 0.3971 - val_mae: 0.4315\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.0396 - mse: 0.0396 - mae: 0.1459 - val_loss: 0.4207 - val_mse: 0.4207 - val_mae: 0.4400\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.0421 - mse: 0.0421 - mae: 0.1485 - val_loss: 0.4049 - val_mse: 0.4049 - val_mae: 0.4332\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0402 - mse: 0.0402 - mae: 0.1485 - val_loss: 0.4065 - val_mse: 0.4065 - val_mae: 0.4316\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0385 - mse: 0.0385 - mae: 0.1435 - val_loss: 0.4063 - val_mse: 0.4063 - val_mae: 0.4380\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0391 - mse: 0.0391 - mae: 0.1438 - val_loss: 0.4163 - val_mse: 0.4163 - val_mae: 0.4337\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0369 - mse: 0.0369 - mae: 0.1395 - val_loss: 0.4017 - val_mse: 0.4017 - val_mae: 0.4287\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0420 - mse: 0.0420 - mae: 0.1546 - val_loss: 0.4019 - val_mse: 0.4019 - val_mae: 0.4377\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0397 - mse: 0.0397 - mae: 0.1484 - val_loss: 0.4223 - val_mse: 0.4223 - val_mae: 0.4559\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0414 - mse: 0.0414 - mae: 0.1522 - val_loss: 0.4149 - val_mse: 0.4149 - val_mae: 0.4377\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.0431 - mse: 0.0431 - mae: 0.1541 - val_loss: 0.4184 - val_mse: 0.4184 - val_mae: 0.4353\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 191us/sample - loss: 3.3018 - mse: 3.3018 - mae: 1.2273 - val_loss: 3.8481 - val_mse: 3.8481 - val_mae: 1.4670\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.6972 - mse: 0.6972 - mae: 0.6270 - val_loss: 2.9913 - val_mse: 2.9913 - val_mae: 1.1968\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.5292 - mse: 0.5292 - mae: 0.5431 - val_loss: 3.0020 - val_mse: 3.0020 - val_mae: 1.1826\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.4550 - mse: 0.4550 - mae: 0.5030 - val_loss: 2.4231 - val_mse: 2.4231 - val_mae: 1.1626\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3952 - mse: 0.3952 - mae: 0.4659 - val_loss: 1.5271 - val_mse: 1.5271 - val_mae: 0.9137\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3486 - mse: 0.3486 - mae: 0.4401 - val_loss: 1.4194 - val_mse: 1.4194 - val_mae: 0.8660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.3106 - mse: 0.3106 - mae: 0.4141 - val_loss: 1.1701 - val_mse: 1.1701 - val_mae: 0.8050\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.2873 - mse: 0.2873 - mae: 0.3981 - val_loss: 1.2758 - val_mse: 1.2758 - val_mae: 0.8087\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2749 - mse: 0.2749 - mae: 0.3910 - val_loss: 1.0270 - val_mse: 1.0270 - val_mae: 0.7923\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2606 - mse: 0.2606 - mae: 0.3777 - val_loss: 1.0852 - val_mse: 1.0852 - val_mae: 0.7811\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2328 - mse: 0.2328 - mae: 0.3567 - val_loss: 0.9157 - val_mse: 0.9157 - val_mae: 0.7576\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2185 - mse: 0.2185 - mae: 0.3486 - val_loss: 0.8362 - val_mse: 0.8362 - val_mae: 0.7100\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1909 - mse: 0.1909 - mae: 0.3268 - val_loss: 0.7766 - val_mse: 0.7766 - val_mae: 0.6901\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1718 - mse: 0.1718 - mae: 0.3099 - val_loss: 0.7099 - val_mse: 0.7099 - val_mae: 0.6553\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.1709 - mse: 0.1709 - mae: 0.3029 - val_loss: 0.7480 - val_mse: 0.7480 - val_mae: 0.6775\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1694 - mse: 0.1694 - mae: 0.3080 - val_loss: 0.6903 - val_mse: 0.6903 - val_mae: 0.6483\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1523 - mse: 0.1523 - mae: 0.2953 - val_loss: 0.6202 - val_mse: 0.6202 - val_mae: 0.6151\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1434 - mse: 0.1434 - mae: 0.2842 - val_loss: 0.5739 - val_mse: 0.5739 - val_mae: 0.5810\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1327 - mse: 0.1327 - mae: 0.2734 - val_loss: 0.5422 - val_mse: 0.5422 - val_mae: 0.5714\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1212 - mse: 0.1212 - mae: 0.2618 - val_loss: 0.5430 - val_mse: 0.5430 - val_mae: 0.5654\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1141 - mse: 0.1141 - mae: 0.2536 - val_loss: 0.5365 - val_mse: 0.5365 - val_mae: 0.5535\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.1141 - mse: 0.1141 - mae: 0.2522 - val_loss: 0.5092 - val_mse: 0.5092 - val_mae: 0.5462\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1110 - mse: 0.1110 - mae: 0.2497 - val_loss: 0.5168 - val_mse: 0.5168 - val_mae: 0.5438\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1181 - mse: 0.1181 - mae: 0.2588 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.5075\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1090 - mse: 0.1090 - mae: 0.2474 - val_loss: 0.4475 - val_mse: 0.4475 - val_mae: 0.4979\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.1017 - mse: 0.1017 - mae: 0.2380 - val_loss: 0.4450 - val_mse: 0.4450 - val_mae: 0.4855\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1049 - mse: 0.1049 - mae: 0.2448 - val_loss: 0.4438 - val_mse: 0.4438 - val_mae: 0.4829\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.1108 - mse: 0.1108 - mae: 0.2464 - val_loss: 0.4654 - val_mse: 0.4654 - val_mae: 0.4930\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.1176 - mse: 0.1176 - mae: 0.2534 - val_loss: 0.4160 - val_mse: 0.4160 - val_mae: 0.4666\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0858 - mse: 0.0858 - mae: 0.2178 - val_loss: 0.4166 - val_mse: 0.4166 - val_mae: 0.4725\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2249 - val_loss: 0.4164 - val_mse: 0.4164 - val_mae: 0.4672\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0901 - mse: 0.0901 - mae: 0.2235 - val_loss: 0.4497 - val_mse: 0.4497 - val_mae: 0.4791\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0814 - mse: 0.0814 - mae: 0.2141 - val_loss: 0.4180 - val_mse: 0.4180 - val_mae: 0.4630\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.0759 - mse: 0.0759 - mae: 0.2047 - val_loss: 0.4341 - val_mse: 0.4341 - val_mae: 0.4731\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.0701 - mse: 0.0701 - mae: 0.1989 - val_loss: 0.3923 - val_mse: 0.3923 - val_mae: 0.4411\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0677 - mse: 0.0677 - mae: 0.1941 - val_loss: 0.4064 - val_mse: 0.4064 - val_mae: 0.4539\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0667 - mse: 0.0667 - mae: 0.1943 - val_loss: 0.4155 - val_mse: 0.4155 - val_mae: 0.4666\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0604 - mse: 0.0604 - mae: 0.1835 - val_loss: 0.4204 - val_mse: 0.4204 - val_mae: 0.4520\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0659 - mse: 0.0659 - mae: 0.1902 - val_loss: 0.4382 - val_mse: 0.4382 - val_mae: 0.4663\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0660 - mse: 0.0660 - mae: 0.1910 - val_loss: 0.3912 - val_mse: 0.3912 - val_mae: 0.4377\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.0560 - mse: 0.0560 - mae: 0.1781 - val_loss: 0.4075 - val_mse: 0.4075 - val_mae: 0.4481\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0547 - mse: 0.0547 - mae: 0.1743 - val_loss: 0.3868 - val_mse: 0.3868 - val_mae: 0.4406\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0528 - mse: 0.0528 - mae: 0.1710 - val_loss: 0.4206 - val_mse: 0.4206 - val_mae: 0.4547\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0567 - mse: 0.0567 - mae: 0.1772 - val_loss: 0.3873 - val_mse: 0.3873 - val_mae: 0.4356\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0560 - mse: 0.0560 - mae: 0.1773 - val_loss: 0.4083 - val_mse: 0.4083 - val_mae: 0.4438\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0549 - mse: 0.0549 - mae: 0.1756 - val_loss: 0.4054 - val_mse: 0.4054 - val_mae: 0.4529\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0592 - mse: 0.0592 - mae: 0.1836 - val_loss: 0.4280 - val_mse: 0.4280 - val_mae: 0.4633\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0546 - mse: 0.0546 - mae: 0.1768 - val_loss: 0.3962 - val_mse: 0.3962 - val_mae: 0.4465\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.0545 - mse: 0.0545 - mae: 0.1767 - val_loss: 0.4002 - val_mse: 0.4002 - val_mae: 0.4415\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.0534 - mse: 0.0534 - mae: 0.1718 - val_loss: 0.3899 - val_mse: 0.3899 - val_mae: 0.4390\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 47us/sample - loss: 0.0489 - mse: 0.0489 - mae: 0.1654 - val_loss: 0.3937 - val_mse: 0.3937 - val_mae: 0.4358\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.0461 - mse: 0.0461 - mae: 0.1625 - val_loss: 0.3949 - val_mse: 0.3949 - val_mae: 0.4361\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 235us/sample - loss: 3.8330 - mse: 3.8330 - mae: 1.3101 - val_loss: 38.8286 - val_mse: 38.8287 - val_mae: 5.7231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.7406 - mse: 0.7406 - mae: 0.6478 - val_loss: 2.0564 - val_mse: 2.0564 - val_mae: 1.0576\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.5554 - mse: 0.5554 - mae: 0.5583 - val_loss: 2.2969 - val_mse: 2.2969 - val_mae: 1.1099\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.4675 - mse: 0.4675 - mae: 0.5097 - val_loss: 1.4714 - val_mse: 1.4714 - val_mae: 0.9286\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.4093 - mse: 0.4093 - mae: 0.4708 - val_loss: 1.3841 - val_mse: 1.3841 - val_mae: 0.8709\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.3653 - mse: 0.3653 - mae: 0.4511 - val_loss: 1.2287 - val_mse: 1.2287 - val_mae: 0.8357\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3330 - mse: 0.3330 - mae: 0.4279 - val_loss: 1.0526 - val_mse: 1.0526 - val_mae: 0.8203\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3037 - mse: 0.3037 - mae: 0.4111 - val_loss: 0.9681 - val_mse: 0.9681 - val_mae: 0.7907\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2733 - mse: 0.2733 - mae: 0.3909 - val_loss: 0.9227 - val_mse: 0.9227 - val_mae: 0.7572\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2488 - mse: 0.2488 - mae: 0.3688 - val_loss: 0.8733 - val_mse: 0.8733 - val_mae: 0.7562\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2172 - mse: 0.2172 - mae: 0.3471 - val_loss: 0.9038 - val_mse: 0.9038 - val_mae: 0.7443\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2006 - mse: 0.2006 - mae: 0.3323 - val_loss: 0.8263 - val_mse: 0.8263 - val_mae: 0.7249\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1882 - mse: 0.1882 - mae: 0.3213 - val_loss: 0.8607 - val_mse: 0.8607 - val_mae: 0.7241\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1769 - mse: 0.1769 - mae: 0.3122 - val_loss: 0.7616 - val_mse: 0.7616 - val_mae: 0.6923\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1622 - mse: 0.1622 - mae: 0.2998 - val_loss: 0.7512 - val_mse: 0.7512 - val_mae: 0.6881\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.1512 - mse: 0.1512 - mae: 0.2894 - val_loss: 0.7700 - val_mse: 0.7700 - val_mae: 0.6933\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1514 - mse: 0.1514 - mae: 0.2878 - val_loss: 0.5973 - val_mse: 0.5973 - val_mae: 0.5997\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.1361 - mse: 0.1361 - mae: 0.2743 - val_loss: 0.6039 - val_mse: 0.6039 - val_mae: 0.6022\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.1295 - mse: 0.1295 - mae: 0.2690 - val_loss: 0.5721 - val_mse: 0.5721 - val_mae: 0.5851\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.1234 - mse: 0.1234 - mae: 0.2614 - val_loss: 0.5222 - val_mse: 0.5222 - val_mae: 0.5537\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1147 - mse: 0.1147 - mae: 0.2507 - val_loss: 0.5062 - val_mse: 0.5062 - val_mae: 0.5393\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1248 - mse: 0.1248 - mae: 0.2658 - val_loss: 0.4729 - val_mse: 0.4729 - val_mae: 0.5293\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.1113 - mse: 0.1113 - mae: 0.2487 - val_loss: 0.4850 - val_mse: 0.4850 - val_mae: 0.5306\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1068 - mse: 0.1068 - mae: 0.2386 - val_loss: 0.4298 - val_mse: 0.4298 - val_mae: 0.4896\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0981 - mse: 0.0981 - mae: 0.2323 - val_loss: 0.4474 - val_mse: 0.4474 - val_mae: 0.5063\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0972 - mse: 0.0972 - mae: 0.2283 - val_loss: 0.4693 - val_mse: 0.4693 - val_mae: 0.5154\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1045 - mse: 0.1045 - mae: 0.2414 - val_loss: 0.4684 - val_mse: 0.4684 - val_mae: 0.5123\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.1051 - mse: 0.1051 - mae: 0.2379 - val_loss: 0.4152 - val_mse: 0.4152 - val_mae: 0.4721\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0934 - mse: 0.0934 - mae: 0.2243 - val_loss: 0.4226 - val_mse: 0.4226 - val_mae: 0.4805\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0953 - mse: 0.0953 - mae: 0.2271 - val_loss: 0.4220 - val_mse: 0.4220 - val_mae: 0.4710\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.0924 - mse: 0.0924 - mae: 0.2254 - val_loss: 0.4161 - val_mse: 0.4161 - val_mae: 0.4704\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0972 - mse: 0.0972 - mae: 0.2282 - val_loss: 0.4021 - val_mse: 0.4021 - val_mae: 0.4632\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.0876 - mse: 0.0876 - mae: 0.2162 - val_loss: 0.4079 - val_mse: 0.4079 - val_mae: 0.4641\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0825 - mse: 0.0825 - mae: 0.2130 - val_loss: 0.4191 - val_mse: 0.4191 - val_mae: 0.4710\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.0805 - mse: 0.0805 - mae: 0.2108 - val_loss: 0.3973 - val_mse: 0.3973 - val_mae: 0.4615\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.0725 - mse: 0.0725 - mae: 0.1994 - val_loss: 0.4023 - val_mse: 0.4023 - val_mae: 0.4597\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.0645 - mse: 0.0645 - mae: 0.1859 - val_loss: 0.3751 - val_mse: 0.3751 - val_mae: 0.4359\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.0680 - mse: 0.0680 - mae: 0.1921 - val_loss: 0.4006 - val_mse: 0.4006 - val_mae: 0.4524\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0781 - mse: 0.0781 - mae: 0.2065 - val_loss: 0.4026 - val_mse: 0.4026 - val_mae: 0.4482\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0756 - mse: 0.0756 - mae: 0.2026 - val_loss: 0.3836 - val_mse: 0.3836 - val_mae: 0.4425\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0737 - mse: 0.0737 - mae: 0.1979 - val_loss: 0.4090 - val_mse: 0.4090 - val_mae: 0.4551\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0677 - mse: 0.0677 - mae: 0.1936 - val_loss: 0.3761 - val_mse: 0.3761 - val_mae: 0.4414\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0655 - mse: 0.0655 - mae: 0.1901 - val_loss: 0.3844 - val_mse: 0.3844 - val_mae: 0.4421\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0601 - mse: 0.0601 - mae: 0.1832 - val_loss: 0.3725 - val_mse: 0.3725 - val_mae: 0.4340\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.0568 - mse: 0.0568 - mae: 0.1754 - val_loss: 0.3708 - val_mse: 0.3708 - val_mae: 0.4306\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0535 - mse: 0.0535 - mae: 0.1695 - val_loss: 0.3765 - val_mse: 0.3765 - val_mae: 0.4375\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0619 - mse: 0.0619 - mae: 0.1808 - val_loss: 0.3869 - val_mse: 0.3869 - val_mae: 0.4435\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0629 - mse: 0.0629 - mae: 0.1823 - val_loss: 0.3924 - val_mse: 0.3924 - val_mae: 0.4510\n",
      "Epoch 49/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.0599 - mse: 0.0599 - mae: 0.1825 - val_loss: 0.3671 - val_mse: 0.3671 - val_mae: 0.4296\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.0556 - mse: 0.0556 - mae: 0.1735 - val_loss: 0.3644 - val_mse: 0.3644 - val_mae: 0.4296\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.0492 - mse: 0.0492 - mae: 0.1624 - val_loss: 0.3605 - val_mse: 0.3605 - val_mae: 0.4254\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0473 - mse: 0.0473 - mae: 0.1597 - val_loss: 0.3633 - val_mse: 0.3633 - val_mae: 0.4259\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0552 - mse: 0.0552 - mae: 0.1709 - val_loss: 0.3715 - val_mse: 0.3715 - val_mae: 0.4274\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.0603 - mse: 0.0603 - mae: 0.1775 - val_loss: 0.4076 - val_mse: 0.4076 - val_mae: 0.4523\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0590 - mse: 0.0590 - mae: 0.1774 - val_loss: 0.3765 - val_mse: 0.3765 - val_mae: 0.4385\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0537 - mse: 0.0537 - mae: 0.1708 - val_loss: 0.3629 - val_mse: 0.3629 - val_mae: 0.4304\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.0555 - mse: 0.0555 - mae: 0.1750 - val_loss: 0.3992 - val_mse: 0.3992 - val_mae: 0.4527\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0570 - mse: 0.0570 - mae: 0.1736 - val_loss: 0.3567 - val_mse: 0.3567 - val_mae: 0.4226\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0565 - mse: 0.0565 - mae: 0.1742 - val_loss: 0.3919 - val_mse: 0.3919 - val_mae: 0.4392\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0599 - mse: 0.0599 - mae: 0.1782 - val_loss: 0.3695 - val_mse: 0.3695 - val_mae: 0.4296\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0510 - mse: 0.0510 - mae: 0.1653 - val_loss: 0.3757 - val_mse: 0.3757 - val_mae: 0.4396\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.0456 - mse: 0.0456 - mae: 0.1573 - val_loss: 0.3608 - val_mse: 0.3608 - val_mae: 0.4205\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0452 - mse: 0.0452 - mae: 0.1566 - val_loss: 0.3640 - val_mse: 0.3640 - val_mae: 0.4270\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0448 - mse: 0.0448 - mae: 0.1546 - val_loss: 0.3624 - val_mse: 0.3624 - val_mae: 0.4217\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0396 - mse: 0.0396 - mae: 0.1433 - val_loss: 0.3669 - val_mse: 0.3669 - val_mae: 0.4311\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0434 - mse: 0.0434 - mae: 0.1506 - val_loss: 0.3675 - val_mse: 0.3675 - val_mae: 0.4273\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.0434 - mse: 0.0434 - mae: 0.1503 - val_loss: 0.3741 - val_mse: 0.3741 - val_mae: 0.4373\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.0414 - mse: 0.0414 - mae: 0.1473 - val_loss: 0.3604 - val_mse: 0.3604 - val_mae: 0.4223\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 190us/sample - loss: 4.8888 - mse: 4.8888 - mae: 1.4849 - val_loss: 124.5927 - val_mse: 124.5927 - val_mae: 10.7836\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.7972 - mse: 0.7972 - mae: 0.6713 - val_loss: 58.8819 - val_mse: 58.8819 - val_mae: 7.0272\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.6011 - mse: 0.6011 - mae: 0.5781 - val_loss: 40.7069 - val_mse: 40.7069 - val_mae: 5.6302\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.4960 - mse: 0.4960 - mae: 0.5249 - val_loss: 7.5246 - val_mse: 7.5246 - val_mae: 2.3638\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.4358 - mse: 0.4358 - mae: 0.4954 - val_loss: 4.5661 - val_mse: 4.5661 - val_mae: 1.7995\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.3899 - mse: 0.3899 - mae: 0.4658 - val_loss: 3.2132 - val_mse: 3.2132 - val_mae: 1.4849\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.3488 - mse: 0.3488 - mae: 0.4376 - val_loss: 0.9859 - val_mse: 0.9859 - val_mae: 0.7889\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.3167 - mse: 0.3167 - mae: 0.4217 - val_loss: 0.8865 - val_mse: 0.8865 - val_mae: 0.7410\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.2951 - mse: 0.2951 - mae: 0.4052 - val_loss: 0.9012 - val_mse: 0.9012 - val_mae: 0.7331\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2772 - mse: 0.2772 - mae: 0.3941 - val_loss: 0.8564 - val_mse: 0.8564 - val_mae: 0.7361\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.2597 - mse: 0.2597 - mae: 0.3789 - val_loss: 0.8725 - val_mse: 0.8725 - val_mae: 0.7287\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2476 - mse: 0.2476 - mae: 0.3711 - val_loss: 0.9135 - val_mse: 0.9135 - val_mae: 0.7364\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.2312 - mse: 0.2312 - mae: 0.3548 - val_loss: 0.7461 - val_mse: 0.7461 - val_mae: 0.6734\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.2123 - mse: 0.2123 - mae: 0.3431 - val_loss: 0.6996 - val_mse: 0.6996 - val_mae: 0.6449\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 1s 51us/sample - loss: 0.1979 - mse: 0.1979 - mae: 0.3309 - val_loss: 0.6665 - val_mse: 0.6665 - val_mae: 0.6312\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.1766 - mse: 0.1766 - mae: 0.3130 - val_loss: 0.6138 - val_mse: 0.6138 - val_mae: 0.6010\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.1665 - mse: 0.1665 - mae: 0.3046 - val_loss: 0.5833 - val_mse: 0.5833 - val_mae: 0.5810\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.1692 - mse: 0.1692 - mae: 0.3031 - val_loss: 0.5836 - val_mse: 0.5836 - val_mae: 0.5825\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.1530 - mse: 0.1530 - mae: 0.2914 - val_loss: 0.5459 - val_mse: 0.5459 - val_mae: 0.5546\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 1s 53us/sample - loss: 0.1407 - mse: 0.1407 - mae: 0.2790 - val_loss: 0.5049 - val_mse: 0.5049 - val_mae: 0.5268\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 1s 53us/sample - loss: 0.1338 - mse: 0.1338 - mae: 0.2735 - val_loss: 0.5578 - val_mse: 0.5578 - val_mae: 0.5607\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.1301 - mse: 0.1301 - mae: 0.2672 - val_loss: 0.4792 - val_mse: 0.4792 - val_mae: 0.5130\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.1171 - mse: 0.1171 - mae: 0.2547 - val_loss: 0.5015 - val_mse: 0.5015 - val_mae: 0.5237\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.1213 - mse: 0.1213 - mae: 0.2559 - val_loss: 0.4828 - val_mse: 0.4828 - val_mae: 0.5148\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.1101 - mse: 0.1101 - mae: 0.2470 - val_loss: 0.4858 - val_mse: 0.4858 - val_mae: 0.5081\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.1067 - mse: 0.1067 - mae: 0.2441 - val_loss: 0.4479 - val_mse: 0.4479 - val_mae: 0.4951\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.1155 - mse: 0.1155 - mae: 0.2515 - val_loss: 0.5698 - val_mse: 0.5698 - val_mae: 0.5378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.1123 - mse: 0.1123 - mae: 0.2462 - val_loss: 0.4294 - val_mse: 0.4294 - val_mae: 0.4778\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0978 - mse: 0.0978 - mae: 0.2332 - val_loss: 0.4577 - val_mse: 0.4577 - val_mae: 0.4881\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 1s 52us/sample - loss: 0.0953 - mse: 0.0953 - mae: 0.2299 - val_loss: 0.4545 - val_mse: 0.4545 - val_mae: 0.4821\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.0929 - mse: 0.0929 - mae: 0.2242 - val_loss: 0.4279 - val_mse: 0.4279 - val_mae: 0.4674\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 1s 51us/sample - loss: 0.1008 - mse: 0.1008 - mae: 0.2345 - val_loss: 0.4390 - val_mse: 0.4390 - val_mae: 0.4755\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0982 - mse: 0.0982 - mae: 0.2321 - val_loss: 0.4489 - val_mse: 0.4489 - val_mae: 0.4811\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0920 - mse: 0.0920 - mae: 0.2256 - val_loss: 0.4487 - val_mse: 0.4487 - val_mae: 0.4767\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0867 - mse: 0.0867 - mae: 0.2181 - val_loss: 0.4036 - val_mse: 0.4036 - val_mae: 0.4499\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0814 - mse: 0.0814 - mae: 0.2138 - val_loss: 0.4271 - val_mse: 0.4271 - val_mae: 0.4633\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0840 - mse: 0.0840 - mae: 0.2148 - val_loss: 0.4338 - val_mse: 0.4338 - val_mae: 0.4680\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.0877 - mse: 0.0877 - mae: 0.2201 - val_loss: 0.4313 - val_mse: 0.4313 - val_mae: 0.4717\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0888 - mse: 0.0888 - mae: 0.2215 - val_loss: 0.4105 - val_mse: 0.4105 - val_mae: 0.4532\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0743 - mse: 0.0743 - mae: 0.2017 - val_loss: 0.4106 - val_mse: 0.4106 - val_mae: 0.4515\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0684 - mse: 0.0684 - mae: 0.1957 - val_loss: 0.3971 - val_mse: 0.3971 - val_mae: 0.4422\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.0686 - mse: 0.0686 - mae: 0.1955 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4547\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.0621 - mse: 0.0621 - mae: 0.1844 - val_loss: 0.4050 - val_mse: 0.4050 - val_mae: 0.4455\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0601 - mse: 0.0601 - mae: 0.1801 - val_loss: 0.4155 - val_mse: 0.4155 - val_mae: 0.4544\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0600 - mse: 0.0600 - mae: 0.1800 - val_loss: 0.4098 - val_mse: 0.4098 - val_mae: 0.4545\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0587 - mse: 0.0587 - mae: 0.1794 - val_loss: 0.4085 - val_mse: 0.4085 - val_mae: 0.4466\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0603 - mse: 0.0603 - mae: 0.1815 - val_loss: 0.3978 - val_mse: 0.3978 - val_mae: 0.4514\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0580 - mse: 0.0580 - mae: 0.1782 - val_loss: 0.4137 - val_mse: 0.4137 - val_mae: 0.4551\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.0639 - mse: 0.0639 - mae: 0.1849 - val_loss: 0.4058 - val_mse: 0.4058 - val_mae: 0.4512\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.0634 - mse: 0.0634 - mae: 0.1872 - val_loss: 0.4055 - val_mse: 0.4055 - val_mae: 0.4463\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 1s 52us/sample - loss: 0.0709 - mse: 0.0709 - mae: 0.1940 - val_loss: 0.3996 - val_mse: 0.3996 - val_mae: 0.4398\n",
      "Avg. MAE: 0.387571\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 4.1098 - mse: 4.1098 - mae: 1.3716 - val_loss: 42.0456 - val_mse: 42.0456 - val_mae: 6.1464\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.8749 - mse: 0.8749 - mae: 0.7027 - val_loss: 6.2284 - val_mse: 6.2284 - val_mae: 2.1388\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.6218 - mse: 0.6218 - mae: 0.5891 - val_loss: 2.9166 - val_mse: 2.9166 - val_mae: 1.4589\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.5251 - mse: 0.5251 - mae: 0.5460 - val_loss: 3.0104 - val_mse: 3.0104 - val_mae: 1.4961\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.4778 - mse: 0.4778 - mae: 0.5120 - val_loss: 1.4588 - val_mse: 1.4588 - val_mae: 1.0284\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4412 - mse: 0.4412 - mae: 0.4967 - val_loss: 1.2368 - val_mse: 1.2368 - val_mae: 0.9459\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4146 - mse: 0.4146 - mae: 0.4809 - val_loss: 0.9781 - val_mse: 0.9781 - val_mae: 0.8191\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3897 - mse: 0.3897 - mae: 0.4644 - val_loss: 0.9203 - val_mse: 0.9203 - val_mae: 0.7833\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3675 - mse: 0.3675 - mae: 0.4511 - val_loss: 0.8949 - val_mse: 0.8949 - val_mae: 0.7827\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3480 - mse: 0.3480 - mae: 0.4412 - val_loss: 0.8718 - val_mse: 0.8718 - val_mae: 0.7722\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3198 - mse: 0.3198 - mae: 0.4208 - val_loss: 0.9101 - val_mse: 0.9101 - val_mae: 0.7917\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3079 - mse: 0.3079 - mae: 0.4140 - val_loss: 0.8478 - val_mse: 0.8478 - val_mae: 0.7602\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2936 - mse: 0.2936 - mae: 0.4020 - val_loss: 0.8372 - val_mse: 0.8372 - val_mae: 0.7560\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2789 - mse: 0.2789 - mae: 0.3942 - val_loss: 0.7546 - val_mse: 0.7546 - val_mae: 0.7069\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2770 - mse: 0.2770 - mae: 0.3939 - val_loss: 0.7281 - val_mse: 0.7281 - val_mae: 0.6906\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2666 - mse: 0.2666 - mae: 0.3846 - val_loss: 0.7439 - val_mse: 0.7439 - val_mae: 0.7016\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2494 - mse: 0.2494 - mae: 0.3723 - val_loss: 0.6682 - val_mse: 0.6682 - val_mae: 0.6545\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2334 - mse: 0.2334 - mae: 0.3634 - val_loss: 0.6178 - val_mse: 0.6178 - val_mae: 0.6305\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2366 - mse: 0.2366 - mae: 0.3594 - val_loss: 0.6657 - val_mse: 0.6657 - val_mae: 0.6639\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2195 - mse: 0.2195 - mae: 0.3460 - val_loss: 0.6147 - val_mse: 0.6147 - val_mae: 0.6285\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2081 - mse: 0.2081 - mae: 0.3411 - val_loss: 0.5798 - val_mse: 0.5798 - val_mae: 0.6028\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1998 - mse: 0.1998 - mae: 0.3348 - val_loss: 0.5427 - val_mse: 0.5427 - val_mae: 0.5808\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1969 - mse: 0.1969 - mae: 0.3317 - val_loss: 0.5154 - val_mse: 0.5154 - val_mae: 0.5608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1984 - mse: 0.1984 - mae: 0.3327 - val_loss: 0.4957 - val_mse: 0.4957 - val_mae: 0.5450\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1710 - mse: 0.1710 - mae: 0.3103 - val_loss: 0.4963 - val_mse: 0.4963 - val_mae: 0.5527\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1650 - mse: 0.1650 - mae: 0.3064 - val_loss: 0.5001 - val_mse: 0.5001 - val_mae: 0.5504\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1617 - mse: 0.1617 - mae: 0.3009 - val_loss: 0.4809 - val_mse: 0.4809 - val_mae: 0.5349\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1576 - mse: 0.1576 - mae: 0.2943 - val_loss: 0.4774 - val_mse: 0.4774 - val_mae: 0.5261\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1533 - mse: 0.1533 - mae: 0.2937 - val_loss: 0.4475 - val_mse: 0.4475 - val_mae: 0.5087\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1498 - mse: 0.1498 - mae: 0.2887 - val_loss: 0.4474 - val_mse: 0.4474 - val_mae: 0.4924\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1593 - mse: 0.1593 - mae: 0.2965 - val_loss: 0.4494 - val_mse: 0.4494 - val_mae: 0.4968\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1753 - mse: 0.1753 - mae: 0.3088 - val_loss: 0.4384 - val_mse: 0.4384 - val_mae: 0.4962\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1666 - mse: 0.1666 - mae: 0.2984 - val_loss: 0.4641 - val_mse: 0.4641 - val_mae: 0.5216\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1499 - mse: 0.1499 - mae: 0.2890 - val_loss: 0.4337 - val_mse: 0.4337 - val_mae: 0.4926\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1452 - mse: 0.1452 - mae: 0.2838 - val_loss: 0.4210 - val_mse: 0.4210 - val_mae: 0.4815\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1472 - mse: 0.1472 - mae: 0.2881 - val_loss: 0.4286 - val_mse: 0.4286 - val_mae: 0.4914\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1383 - mse: 0.1383 - mae: 0.2797 - val_loss: 0.4234 - val_mse: 0.4234 - val_mae: 0.4852\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1363 - mse: 0.1363 - mae: 0.2775 - val_loss: 0.4227 - val_mse: 0.4227 - val_mae: 0.4735\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1220 - mse: 0.1220 - mae: 0.2616 - val_loss: 0.4242 - val_mse: 0.4242 - val_mae: 0.4851\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1191 - mse: 0.1191 - mae: 0.2581 - val_loss: 0.4380 - val_mse: 0.4380 - val_mae: 0.4923\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1158 - mse: 0.1158 - mae: 0.2572 - val_loss: 0.4135 - val_mse: 0.4135 - val_mae: 0.4648\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1102 - mse: 0.1102 - mae: 0.2498 - val_loss: 0.4282 - val_mse: 0.4282 - val_mae: 0.4772\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1069 - mse: 0.1069 - mae: 0.2465 - val_loss: 0.4185 - val_mse: 0.4185 - val_mae: 0.4716\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1124 - mse: 0.1124 - mae: 0.2540 - val_loss: 0.4308 - val_mse: 0.4308 - val_mae: 0.4715\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1049 - mse: 0.1049 - mae: 0.2432 - val_loss: 0.4216 - val_mse: 0.4216 - val_mae: 0.4713\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1008 - mse: 0.1008 - mae: 0.2388 - val_loss: 0.4116 - val_mse: 0.4116 - val_mae: 0.4653\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0992 - mse: 0.0992 - mae: 0.2358 - val_loss: 0.4320 - val_mse: 0.4320 - val_mae: 0.4769\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1007 - mse: 0.1007 - mae: 0.2357 - val_loss: 0.4145 - val_mse: 0.4145 - val_mae: 0.4656\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0901 - mse: 0.0901 - mae: 0.2257 - val_loss: 0.4198 - val_mse: 0.4198 - val_mae: 0.4639\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0914 - mse: 0.0914 - mae: 0.2274 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4662\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0908 - mse: 0.0908 - mae: 0.2260 - val_loss: 0.4065 - val_mse: 0.4065 - val_mae: 0.4590\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0935 - mse: 0.0935 - mae: 0.2274 - val_loss: 0.4216 - val_mse: 0.4216 - val_mae: 0.4671\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0936 - mse: 0.0936 - mae: 0.2249 - val_loss: 0.4048 - val_mse: 0.4048 - val_mae: 0.4591\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0995 - mse: 0.0995 - mae: 0.2343 - val_loss: 0.4251 - val_mse: 0.4251 - val_mae: 0.4738\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0871 - mse: 0.0871 - mae: 0.2221 - val_loss: 0.4147 - val_mse: 0.4147 - val_mae: 0.4616\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0852 - mse: 0.0852 - mae: 0.2179 - val_loss: 0.4049 - val_mse: 0.4049 - val_mae: 0.4550\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0828 - mse: 0.0828 - mae: 0.2131 - val_loss: 0.4321 - val_mse: 0.4321 - val_mae: 0.4703\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0882 - mse: 0.0882 - mae: 0.2195 - val_loss: 0.4276 - val_mse: 0.4276 - val_mae: 0.4694\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0871 - mse: 0.0871 - mae: 0.2196 - val_loss: 0.4126 - val_mse: 0.4126 - val_mae: 0.4691\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0846 - mse: 0.0846 - mae: 0.2153 - val_loss: 0.4256 - val_mse: 0.4256 - val_mae: 0.4659\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0762 - mse: 0.0762 - mae: 0.2056 - val_loss: 0.4137 - val_mse: 0.4137 - val_mae: 0.4628\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0778 - mse: 0.0778 - mae: 0.2054 - val_loss: 0.4158 - val_mse: 0.4158 - val_mae: 0.4623\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0734 - mse: 0.0734 - mae: 0.2022 - val_loss: 0.4049 - val_mse: 0.4049 - val_mae: 0.4575\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 3.8835 - mse: 3.8835 - mae: 1.3416 - val_loss: 5.0854 - val_mse: 5.0854 - val_mae: 1.8918\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.8379 - mse: 0.8379 - mae: 0.6908 - val_loss: 8.9358 - val_mse: 8.9358 - val_mae: 2.4499\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.6062 - mse: 0.6062 - mae: 0.5833 - val_loss: 7.1686 - val_mse: 7.1686 - val_mae: 2.3842\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.5309 - mse: 0.5309 - mae: 0.5485 - val_loss: 4.8270 - val_mse: 4.8270 - val_mae: 1.8618\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.4805 - mse: 0.4805 - mae: 0.5192 - val_loss: 3.4416 - val_mse: 3.4416 - val_mae: 1.5958\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4434 - mse: 0.4434 - mae: 0.5001 - val_loss: 2.0671 - val_mse: 2.0671 - val_mae: 1.2438\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4089 - mse: 0.4089 - mae: 0.4787 - val_loss: 1.7935 - val_mse: 1.7935 - val_mae: 1.1356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3842 - mse: 0.3842 - mae: 0.4648 - val_loss: 1.3328 - val_mse: 1.3328 - val_mae: 0.9736\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3600 - mse: 0.3600 - mae: 0.4477 - val_loss: 1.3500 - val_mse: 1.3500 - val_mae: 0.9811\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3384 - mse: 0.3384 - mae: 0.4347 - val_loss: 1.1757 - val_mse: 1.1757 - val_mae: 0.8992\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3209 - mse: 0.3209 - mae: 0.4235 - val_loss: 1.0889 - val_mse: 1.0889 - val_mae: 0.8660\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3051 - mse: 0.3051 - mae: 0.4132 - val_loss: 1.1255 - val_mse: 1.1255 - val_mae: 0.8918\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2967 - mse: 0.2967 - mae: 0.4068 - val_loss: 0.8972 - val_mse: 0.8972 - val_mae: 0.7838\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2824 - mse: 0.2824 - mae: 0.3977 - val_loss: 0.8163 - val_mse: 0.8163 - val_mae: 0.7347\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2639 - mse: 0.2639 - mae: 0.3839 - val_loss: 0.7787 - val_mse: 0.7787 - val_mae: 0.7157\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2549 - mse: 0.2549 - mae: 0.3778 - val_loss: 0.7624 - val_mse: 0.7624 - val_mae: 0.6980\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2458 - mse: 0.2458 - mae: 0.3719 - val_loss: 0.7191 - val_mse: 0.7191 - val_mae: 0.6762\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2371 - mse: 0.2371 - mae: 0.3650 - val_loss: 0.5915 - val_mse: 0.5915 - val_mae: 0.5972\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2222 - mse: 0.2222 - mae: 0.3515 - val_loss: 0.6684 - val_mse: 0.6684 - val_mae: 0.6411\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2147 - mse: 0.2147 - mae: 0.3474 - val_loss: 0.6121 - val_mse: 0.6121 - val_mae: 0.5959\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2170 - mse: 0.2170 - mae: 0.3501 - val_loss: 0.5844 - val_mse: 0.5844 - val_mae: 0.5787\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2043 - mse: 0.2043 - mae: 0.3386 - val_loss: 0.5699 - val_mse: 0.5699 - val_mae: 0.5868\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1912 - mse: 0.1912 - mae: 0.3272 - val_loss: 0.5556 - val_mse: 0.5556 - val_mae: 0.5729\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1912 - mse: 0.1912 - mae: 0.3261 - val_loss: 0.5490 - val_mse: 0.5490 - val_mae: 0.5520\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1834 - mse: 0.1834 - mae: 0.3215 - val_loss: 0.4867 - val_mse: 0.4867 - val_mae: 0.5224\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1851 - mse: 0.1851 - mae: 0.3220 - val_loss: 0.4926 - val_mse: 0.4926 - val_mae: 0.5358\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1936 - mse: 0.1936 - mae: 0.3279 - val_loss: 0.5237 - val_mse: 0.5237 - val_mae: 0.5483\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1741 - mse: 0.1741 - mae: 0.3113 - val_loss: 0.4633 - val_mse: 0.4633 - val_mae: 0.5015\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1719 - mse: 0.1719 - mae: 0.3120 - val_loss: 0.5344 - val_mse: 0.5344 - val_mae: 0.5158\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1663 - mse: 0.1663 - mae: 0.3064 - val_loss: 0.4742 - val_mse: 0.4742 - val_mae: 0.5091\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1502 - mse: 0.1502 - mae: 0.2871 - val_loss: 0.4796 - val_mse: 0.4796 - val_mae: 0.5163\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1443 - mse: 0.1443 - mae: 0.2840 - val_loss: 0.4793 - val_mse: 0.4793 - val_mae: 0.5006\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1388 - mse: 0.1388 - mae: 0.2791 - val_loss: 0.4802 - val_mse: 0.4802 - val_mae: 0.5180\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1406 - mse: 0.1406 - mae: 0.2824 - val_loss: 0.4626 - val_mse: 0.4626 - val_mae: 0.4862\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1336 - mse: 0.1336 - mae: 0.2725 - val_loss: 0.4384 - val_mse: 0.4384 - val_mae: 0.4779\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1359 - mse: 0.1359 - mae: 0.2756 - val_loss: 0.4573 - val_mse: 0.4573 - val_mae: 0.4995\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1347 - mse: 0.1347 - mae: 0.2728 - val_loss: 0.4433 - val_mse: 0.4433 - val_mae: 0.4879\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1279 - mse: 0.1279 - mae: 0.2696 - val_loss: 0.4632 - val_mse: 0.4632 - val_mae: 0.4852\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1306 - mse: 0.1306 - mae: 0.2707 - val_loss: 0.4491 - val_mse: 0.4491 - val_mae: 0.4815\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1259 - mse: 0.1259 - mae: 0.2630 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4659\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1278 - mse: 0.1278 - mae: 0.2644 - val_loss: 0.4719 - val_mse: 0.4719 - val_mae: 0.4811\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1192 - mse: 0.1192 - mae: 0.2592 - val_loss: 0.4030 - val_mse: 0.4030 - val_mae: 0.4492\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1153 - mse: 0.1153 - mae: 0.2521 - val_loss: 0.4354 - val_mse: 0.4354 - val_mae: 0.4736\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1319 - mse: 0.1319 - mae: 0.2582 - val_loss: 0.4775 - val_mse: 0.4775 - val_mae: 0.4988\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1414 - mse: 0.1414 - mae: 0.2780 - val_loss: 0.4297 - val_mse: 0.4297 - val_mae: 0.4695\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1199 - mse: 0.1199 - mae: 0.2608 - val_loss: 0.4374 - val_mse: 0.4374 - val_mae: 0.4740\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1115 - mse: 0.1115 - mae: 0.2500 - val_loss: 0.4204 - val_mse: 0.4204 - val_mae: 0.4667\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1031 - mse: 0.1031 - mae: 0.2408 - val_loss: 0.4204 - val_mse: 0.4204 - val_mae: 0.4648\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0899 - mse: 0.0899 - mae: 0.2232 - val_loss: 0.4150 - val_mse: 0.4150 - val_mae: 0.4619\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0897 - mse: 0.0897 - mae: 0.2239 - val_loss: 0.4348 - val_mse: 0.4348 - val_mae: 0.4556\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2241 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4507\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1003 - mse: 0.1003 - mae: 0.2340 - val_loss: 0.4326 - val_mse: 0.4326 - val_mae: 0.4706\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 3.8060 - mse: 3.8060 - mae: 1.3332 - val_loss: 2.9486 - val_mse: 2.9486 - val_mae: 1.2421\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.8839 - mse: 0.8839 - mae: 0.7037 - val_loss: 1.4890 - val_mse: 1.4890 - val_mae: 0.9209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.6096 - mse: 0.6096 - mae: 0.5896 - val_loss: 1.5346 - val_mse: 1.5346 - val_mae: 1.0003\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.5338 - mse: 0.5338 - mae: 0.5485 - val_loss: 1.2452 - val_mse: 1.2452 - val_mae: 0.9023\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.4714 - mse: 0.4714 - mae: 0.5088 - val_loss: 1.2340 - val_mse: 1.2340 - val_mae: 0.9144\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.4369 - mse: 0.4369 - mae: 0.4929 - val_loss: 1.1396 - val_mse: 1.1396 - val_mae: 0.8777\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4051 - mse: 0.4051 - mae: 0.4745 - val_loss: 1.0751 - val_mse: 1.0751 - val_mae: 0.8508\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3835 - mse: 0.3835 - mae: 0.4612 - val_loss: 1.0082 - val_mse: 1.0082 - val_mae: 0.8235\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.3611 - mse: 0.3611 - mae: 0.4486 - val_loss: 0.9736 - val_mse: 0.9736 - val_mae: 0.8060\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3388 - mse: 0.3388 - mae: 0.4338 - val_loss: 0.8916 - val_mse: 0.8916 - val_mae: 0.7680\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3219 - mse: 0.3219 - mae: 0.4243 - val_loss: 0.8622 - val_mse: 0.8622 - val_mae: 0.7547\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3011 - mse: 0.3011 - mae: 0.4084 - val_loss: 0.8665 - val_mse: 0.8665 - val_mae: 0.7642\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2860 - mse: 0.2860 - mae: 0.4003 - val_loss: 0.8363 - val_mse: 0.8363 - val_mae: 0.7460\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2684 - mse: 0.2684 - mae: 0.3870 - val_loss: 0.7979 - val_mse: 0.7979 - val_mae: 0.7272\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2567 - mse: 0.2567 - mae: 0.3799 - val_loss: 0.7568 - val_mse: 0.7568 - val_mae: 0.7091\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2488 - mse: 0.2488 - mae: 0.3737 - val_loss: 0.7109 - val_mse: 0.7109 - val_mae: 0.6786\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2386 - mse: 0.2386 - mae: 0.3641 - val_loss: 0.7229 - val_mse: 0.7229 - val_mae: 0.6918\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2263 - mse: 0.2263 - mae: 0.3594 - val_loss: 0.6263 - val_mse: 0.6263 - val_mae: 0.6277\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2221 - mse: 0.2221 - mae: 0.3511 - val_loss: 0.5794 - val_mse: 0.5794 - val_mae: 0.6053\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2087 - mse: 0.2087 - mae: 0.3389 - val_loss: 0.5543 - val_mse: 0.5543 - val_mae: 0.5823\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1993 - mse: 0.1993 - mae: 0.3328 - val_loss: 0.5394 - val_mse: 0.5394 - val_mae: 0.5698\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1982 - mse: 0.1982 - mae: 0.3320 - val_loss: 0.5707 - val_mse: 0.5707 - val_mae: 0.5948\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1872 - mse: 0.1872 - mae: 0.3246 - val_loss: 0.5212 - val_mse: 0.5212 - val_mae: 0.5554\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1834 - mse: 0.1834 - mae: 0.3215 - val_loss: 0.4982 - val_mse: 0.4982 - val_mae: 0.5460\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1761 - mse: 0.1761 - mae: 0.3142 - val_loss: 0.5167 - val_mse: 0.5167 - val_mae: 0.5555\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1699 - mse: 0.1699 - mae: 0.3111 - val_loss: 0.5396 - val_mse: 0.5396 - val_mae: 0.5636\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1780 - mse: 0.1780 - mae: 0.3183 - val_loss: 0.4740 - val_mse: 0.4740 - val_mae: 0.5200\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1822 - mse: 0.1822 - mae: 0.3230 - val_loss: 0.4786 - val_mse: 0.4786 - val_mae: 0.5111\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1826 - mse: 0.1826 - mae: 0.3251 - val_loss: 0.4537 - val_mse: 0.4537 - val_mae: 0.5121\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1586 - mse: 0.1586 - mae: 0.3011 - val_loss: 0.4992 - val_mse: 0.4992 - val_mae: 0.5448\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1490 - mse: 0.1490 - mae: 0.2926 - val_loss: 0.4419 - val_mse: 0.4419 - val_mae: 0.4953\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1319 - mse: 0.1319 - mae: 0.2736 - val_loss: 0.4622 - val_mse: 0.4622 - val_mae: 0.5018\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1396 - mse: 0.1396 - mae: 0.2791 - val_loss: 0.4784 - val_mse: 0.4784 - val_mae: 0.5211\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1329 - mse: 0.1329 - mae: 0.2744 - val_loss: 0.4577 - val_mse: 0.4577 - val_mae: 0.5032\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1310 - mse: 0.1310 - mae: 0.2709 - val_loss: 0.4171 - val_mse: 0.4171 - val_mae: 0.4718\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1338 - mse: 0.1338 - mae: 0.2758 - val_loss: 0.4418 - val_mse: 0.4418 - val_mae: 0.4920\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1299 - mse: 0.1299 - mae: 0.2718 - val_loss: 0.4561 - val_mse: 0.4561 - val_mae: 0.4984\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1252 - mse: 0.1252 - mae: 0.2646 - val_loss: 0.4233 - val_mse: 0.4233 - val_mae: 0.4716\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1255 - mse: 0.1255 - mae: 0.2646 - val_loss: 0.4372 - val_mse: 0.4372 - val_mae: 0.4836\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1254 - mse: 0.1254 - mae: 0.2682 - val_loss: 0.4302 - val_mse: 0.4302 - val_mae: 0.4776\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1207 - mse: 0.1207 - mae: 0.2617 - val_loss: 0.4061 - val_mse: 0.4061 - val_mae: 0.4596\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1093 - mse: 0.1093 - mae: 0.2481 - val_loss: 0.4181 - val_mse: 0.4181 - val_mae: 0.4667\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1023 - mse: 0.1023 - mae: 0.2379 - val_loss: 0.4173 - val_mse: 0.4173 - val_mae: 0.4673\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1064 - mse: 0.1064 - mae: 0.2451 - val_loss: 0.4165 - val_mse: 0.4165 - val_mae: 0.4703\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1062 - mse: 0.1062 - mae: 0.2470 - val_loss: 0.4080 - val_mse: 0.4080 - val_mae: 0.4588\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1044 - mse: 0.1044 - mae: 0.2436 - val_loss: 0.4104 - val_mse: 0.4104 - val_mae: 0.4621\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1042 - mse: 0.1042 - mae: 0.2448 - val_loss: 0.4047 - val_mse: 0.4047 - val_mae: 0.4590\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1027 - mse: 0.1027 - mae: 0.2417 - val_loss: 0.4040 - val_mse: 0.4040 - val_mae: 0.4561\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0994 - mse: 0.0994 - mae: 0.2395 - val_loss: 0.4480 - val_mse: 0.4480 - val_mae: 0.4802\n",
      "Epoch 50/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1104 - mse: 0.1104 - mae: 0.2565 - val_loss: 0.4312 - val_mse: 0.4312 - val_mae: 0.4795\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.0988 - mse: 0.0988 - mae: 0.2401 - val_loss: 0.4235 - val_mse: 0.4235 - val_mae: 0.4741\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.1047 - mse: 0.1047 - mae: 0.2472 - val_loss: 0.4397 - val_mse: 0.4397 - val_mae: 0.4799\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0973 - mse: 0.0973 - mae: 0.2339 - val_loss: 0.4032 - val_mse: 0.4032 - val_mae: 0.4582\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0789 - mse: 0.0789 - mae: 0.2127 - val_loss: 0.4059 - val_mse: 0.4059 - val_mae: 0.4522\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0777 - mse: 0.0777 - mae: 0.2084 - val_loss: 0.4181 - val_mse: 0.4181 - val_mae: 0.4631\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0784 - mse: 0.0784 - mae: 0.2127 - val_loss: 0.4042 - val_mse: 0.4042 - val_mae: 0.4549\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0794 - mse: 0.0794 - mae: 0.2135 - val_loss: 0.4289 - val_mse: 0.4289 - val_mae: 0.4740\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0837 - mse: 0.0837 - mae: 0.2186 - val_loss: 0.4226 - val_mse: 0.4226 - val_mae: 0.4672\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0800 - mse: 0.0800 - mae: 0.2124 - val_loss: 0.4074 - val_mse: 0.4074 - val_mae: 0.4543\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0735 - mse: 0.0735 - mae: 0.2043 - val_loss: 0.4158 - val_mse: 0.4158 - val_mae: 0.4597\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0781 - mse: 0.0781 - mae: 0.2124 - val_loss: 0.4133 - val_mse: 0.4133 - val_mae: 0.4603\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0742 - mse: 0.0742 - mae: 0.2060 - val_loss: 0.4130 - val_mse: 0.4130 - val_mae: 0.4587\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0694 - mse: 0.0694 - mae: 0.1995 - val_loss: 0.4039 - val_mse: 0.4039 - val_mae: 0.4566\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 106us/sample - loss: 4.3096 - mse: 4.3096 - mae: 1.3981 - val_loss: 58.7345 - val_mse: 58.7345 - val_mae: 7.3370\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.9447 - mse: 0.9447 - mae: 0.7143 - val_loss: 4.9586 - val_mse: 4.9586 - val_mae: 1.8530\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.6284 - mse: 0.6284 - mae: 0.5939 - val_loss: 1.7090 - val_mse: 1.7090 - val_mae: 1.0852\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.5455 - mse: 0.5455 - mae: 0.5523 - val_loss: 1.2940 - val_mse: 1.2940 - val_mae: 0.9350\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.4923 - mse: 0.4923 - mae: 0.5214 - val_loss: 1.4315 - val_mse: 1.4315 - val_mae: 0.9969\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4516 - mse: 0.4516 - mae: 0.5021 - val_loss: 1.2249 - val_mse: 1.2249 - val_mae: 0.9227\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4230 - mse: 0.4230 - mae: 0.4813 - val_loss: 1.4533 - val_mse: 1.4533 - val_mae: 1.0207\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3955 - mse: 0.3955 - mae: 0.4689 - val_loss: 1.1461 - val_mse: 1.1461 - val_mae: 0.8914\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3697 - mse: 0.3697 - mae: 0.4543 - val_loss: 0.9926 - val_mse: 0.9926 - val_mae: 0.8176\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3509 - mse: 0.3509 - mae: 0.4418 - val_loss: 0.9626 - val_mse: 0.9626 - val_mae: 0.8123\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3274 - mse: 0.3274 - mae: 0.4263 - val_loss: 0.9864 - val_mse: 0.9864 - val_mae: 0.8106\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3118 - mse: 0.3118 - mae: 0.4168 - val_loss: 0.9344 - val_mse: 0.9344 - val_mae: 0.7965\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3064 - mse: 0.3064 - mae: 0.4142 - val_loss: 0.8852 - val_mse: 0.8852 - val_mae: 0.7690\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2941 - mse: 0.2941 - mae: 0.4058 - val_loss: 0.9473 - val_mse: 0.9473 - val_mae: 0.7966\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2829 - mse: 0.2829 - mae: 0.3968 - val_loss: 0.9012 - val_mse: 0.9012 - val_mae: 0.7833\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2718 - mse: 0.2718 - mae: 0.3915 - val_loss: 0.7557 - val_mse: 0.7557 - val_mae: 0.7104\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2572 - mse: 0.2572 - mae: 0.3775 - val_loss: 0.6953 - val_mse: 0.6953 - val_mae: 0.6659\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2462 - mse: 0.2462 - mae: 0.3688 - val_loss: 0.7759 - val_mse: 0.7759 - val_mae: 0.7100\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2370 - mse: 0.2370 - mae: 0.3637 - val_loss: 0.7494 - val_mse: 0.7494 - val_mae: 0.7037\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2369 - mse: 0.2369 - mae: 0.3630 - val_loss: 0.6560 - val_mse: 0.6560 - val_mae: 0.6522\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2254 - mse: 0.2254 - mae: 0.3531 - val_loss: 0.6033 - val_mse: 0.6033 - val_mae: 0.6157\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2134 - mse: 0.2134 - mae: 0.3452 - val_loss: 0.5803 - val_mse: 0.5803 - val_mae: 0.6082\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2014 - mse: 0.2014 - mae: 0.3317 - val_loss: 0.6310 - val_mse: 0.6310 - val_mae: 0.6372\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1979 - mse: 0.1979 - mae: 0.3286 - val_loss: 0.5353 - val_mse: 0.5353 - val_mae: 0.5727\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1892 - mse: 0.1892 - mae: 0.3223 - val_loss: 0.5212 - val_mse: 0.5212 - val_mae: 0.5639\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1950 - mse: 0.1950 - mae: 0.3251 - val_loss: 0.5392 - val_mse: 0.5392 - val_mae: 0.5754\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1921 - mse: 0.1921 - mae: 0.3292 - val_loss: 0.5355 - val_mse: 0.5355 - val_mae: 0.5775\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1759 - mse: 0.1759 - mae: 0.3162 - val_loss: 0.5441 - val_mse: 0.5441 - val_mae: 0.5783\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1660 - mse: 0.1660 - mae: 0.3067 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.5241\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.1655 - mse: 0.1655 - mae: 0.3074 - val_loss: 0.4319 - val_mse: 0.4319 - val_mae: 0.4925\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1594 - mse: 0.1594 - mae: 0.2972 - val_loss: 0.4365 - val_mse: 0.4365 - val_mae: 0.4888\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1527 - mse: 0.1527 - mae: 0.2929 - val_loss: 0.4411 - val_mse: 0.4411 - val_mae: 0.4999\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1425 - mse: 0.1425 - mae: 0.2819 - val_loss: 0.4258 - val_mse: 0.4258 - val_mae: 0.4920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1328 - mse: 0.1328 - mae: 0.2727 - val_loss: 0.4351 - val_mse: 0.4351 - val_mae: 0.4920\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1295 - mse: 0.1295 - mae: 0.2690 - val_loss: 0.4305 - val_mse: 0.4305 - val_mae: 0.4901\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1225 - mse: 0.1225 - mae: 0.2596 - val_loss: 0.4441 - val_mse: 0.4441 - val_mae: 0.4929\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1347 - mse: 0.1347 - mae: 0.2749 - val_loss: 0.4398 - val_mse: 0.4398 - val_mae: 0.4907\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1366 - mse: 0.1366 - mae: 0.2743 - val_loss: 0.4276 - val_mse: 0.4276 - val_mae: 0.4784\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1384 - mse: 0.1384 - mae: 0.2762 - val_loss: 0.4477 - val_mse: 0.4477 - val_mae: 0.4880\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1299 - mse: 0.1299 - mae: 0.2688 - val_loss: 0.4168 - val_mse: 0.4168 - val_mae: 0.4704\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1279 - mse: 0.1279 - mae: 0.2652 - val_loss: 0.4145 - val_mse: 0.4145 - val_mae: 0.4667\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1165 - mse: 0.1165 - mae: 0.2577 - val_loss: 0.4124 - val_mse: 0.4124 - val_mae: 0.4720\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1106 - mse: 0.1106 - mae: 0.2512 - val_loss: 0.4008 - val_mse: 0.4008 - val_mae: 0.4574\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1078 - mse: 0.1078 - mae: 0.2456 - val_loss: 0.4024 - val_mse: 0.4024 - val_mae: 0.4608\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0982 - mse: 0.0982 - mae: 0.2339 - val_loss: 0.3957 - val_mse: 0.3957 - val_mae: 0.4545\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1021 - mse: 0.1021 - mae: 0.2384 - val_loss: 0.4061 - val_mse: 0.4061 - val_mae: 0.4610\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0989 - mse: 0.0989 - mae: 0.2369 - val_loss: 0.4161 - val_mse: 0.4161 - val_mae: 0.4706\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0984 - mse: 0.0984 - mae: 0.2356 - val_loss: 0.4163 - val_mse: 0.4163 - val_mae: 0.4717\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0970 - mse: 0.0970 - mae: 0.2358 - val_loss: 0.4101 - val_mse: 0.4101 - val_mae: 0.4592\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0965 - mse: 0.0965 - mae: 0.2322 - val_loss: 0.4066 - val_mse: 0.4066 - val_mae: 0.4633\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0954 - mse: 0.0954 - mae: 0.2317 - val_loss: 0.4170 - val_mse: 0.4170 - val_mae: 0.4707\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0931 - mse: 0.0931 - mae: 0.2285 - val_loss: 0.4326 - val_mse: 0.4326 - val_mae: 0.4824\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0928 - mse: 0.0928 - mae: 0.2325 - val_loss: 0.4051 - val_mse: 0.4051 - val_mae: 0.4590\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0861 - mse: 0.0861 - mae: 0.2184 - val_loss: 0.4064 - val_mse: 0.4064 - val_mae: 0.4602\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0860 - mse: 0.0860 - mae: 0.2162 - val_loss: 0.4308 - val_mse: 0.4308 - val_mae: 0.4780\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 104us/sample - loss: 5.0841 - mse: 5.0841 - mae: 1.4914 - val_loss: 9.8175 - val_mse: 9.8175 - val_mae: 1.7616\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 1.0266 - mse: 1.0266 - mae: 0.7241 - val_loss: 8.0064 - val_mse: 8.0064 - val_mae: 2.5418\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.6639 - mse: 0.6639 - mae: 0.6024 - val_loss: 16.3663 - val_mse: 16.3663 - val_mae: 3.7655\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.5502 - mse: 0.5502 - mae: 0.5501 - val_loss: 3.7687 - val_mse: 3.7687 - val_mae: 1.7423\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.4888 - mse: 0.4888 - mae: 0.5231 - val_loss: 2.6463 - val_mse: 2.6463 - val_mae: 1.4394\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.4527 - mse: 0.4527 - mae: 0.5003 - val_loss: 2.3945 - val_mse: 2.3945 - val_mae: 1.3602\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.4252 - mse: 0.4252 - mae: 0.4816 - val_loss: 2.0086 - val_mse: 2.0086 - val_mae: 1.2374\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.4023 - mse: 0.4023 - mae: 0.4736 - val_loss: 1.4697 - val_mse: 1.4697 - val_mae: 1.0364\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.3854 - mse: 0.3854 - mae: 0.4614 - val_loss: 1.2651 - val_mse: 1.2651 - val_mae: 0.9434\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.3667 - mse: 0.3667 - mae: 0.4500 - val_loss: 1.2681 - val_mse: 1.2681 - val_mae: 0.9384\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.3482 - mse: 0.3482 - mae: 0.4412 - val_loss: 1.1442 - val_mse: 1.1442 - val_mae: 0.8976\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.3282 - mse: 0.3282 - mae: 0.4266 - val_loss: 1.0437 - val_mse: 1.0437 - val_mae: 0.8480\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.3072 - mse: 0.3072 - mae: 0.4111 - val_loss: 1.0426 - val_mse: 1.0426 - val_mae: 0.8537\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2870 - mse: 0.2870 - mae: 0.3998 - val_loss: 0.8487 - val_mse: 0.8487 - val_mae: 0.7542\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2743 - mse: 0.2743 - mae: 0.3892 - val_loss: 0.8899 - val_mse: 0.8899 - val_mae: 0.7723\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2620 - mse: 0.2620 - mae: 0.3810 - val_loss: 0.8455 - val_mse: 0.8455 - val_mae: 0.7567\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.2515 - mse: 0.2515 - mae: 0.3747 - val_loss: 0.7168 - val_mse: 0.7168 - val_mae: 0.6870\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2501 - mse: 0.2501 - mae: 0.3728 - val_loss: 0.7784 - val_mse: 0.7784 - val_mae: 0.7019\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.2423 - mse: 0.2423 - mae: 0.3690 - val_loss: 0.6784 - val_mse: 0.6784 - val_mae: 0.6609\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2263 - mse: 0.2263 - mae: 0.3562 - val_loss: 0.6626 - val_mse: 0.6626 - val_mae: 0.6467\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2283 - mse: 0.2283 - mae: 0.3555 - val_loss: 0.7074 - val_mse: 0.7074 - val_mae: 0.6818\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2099 - mse: 0.2099 - mae: 0.3419 - val_loss: 0.6086 - val_mse: 0.6086 - val_mae: 0.6132\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2034 - mse: 0.2034 - mae: 0.3342 - val_loss: 0.6143 - val_mse: 0.6143 - val_mae: 0.6139\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1961 - mse: 0.1961 - mae: 0.3305 - val_loss: 0.5660 - val_mse: 0.5660 - val_mae: 0.5844\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.1953 - mse: 0.1953 - mae: 0.3320 - val_loss: 0.5142 - val_mse: 0.5142 - val_mae: 0.5437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1846 - mse: 0.1846 - mae: 0.3190 - val_loss: 0.5164 - val_mse: 0.5164 - val_mae: 0.5407\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.1823 - mse: 0.1823 - mae: 0.3190 - val_loss: 0.5584 - val_mse: 0.5584 - val_mae: 0.5760\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1749 - mse: 0.1749 - mae: 0.3122 - val_loss: 0.5163 - val_mse: 0.5163 - val_mae: 0.5434\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1635 - mse: 0.1635 - mae: 0.3031 - val_loss: 0.5370 - val_mse: 0.5370 - val_mae: 0.5553\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1639 - mse: 0.1639 - mae: 0.3034 - val_loss: 0.5327 - val_mse: 0.5327 - val_mae: 0.5508\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1594 - mse: 0.1594 - mae: 0.2966 - val_loss: 0.4746 - val_mse: 0.4746 - val_mae: 0.5186\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1475 - mse: 0.1475 - mae: 0.2861 - val_loss: 0.4829 - val_mse: 0.4829 - val_mae: 0.5215\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.1578 - mse: 0.1578 - mae: 0.2988 - val_loss: 0.4706 - val_mse: 0.4706 - val_mae: 0.5087\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1555 - mse: 0.1555 - mae: 0.2958 - val_loss: 0.4484 - val_mse: 0.4484 - val_mae: 0.4850\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1463 - mse: 0.1463 - mae: 0.2871 - val_loss: 0.4538 - val_mse: 0.4538 - val_mae: 0.4949\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1443 - mse: 0.1443 - mae: 0.2865 - val_loss: 0.4352 - val_mse: 0.4352 - val_mae: 0.4724\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1425 - mse: 0.1425 - mae: 0.2825 - val_loss: 0.4625 - val_mse: 0.4625 - val_mae: 0.4955\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1414 - mse: 0.1414 - mae: 0.2802 - val_loss: 0.5054 - val_mse: 0.5054 - val_mae: 0.5200\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.1364 - mse: 0.1364 - mae: 0.2790 - val_loss: 0.4284 - val_mse: 0.4284 - val_mae: 0.4747\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1442 - mse: 0.1442 - mae: 0.2854 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.4548\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1334 - mse: 0.1334 - mae: 0.2731 - val_loss: 0.4767 - val_mse: 0.4767 - val_mae: 0.4944\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.1312 - mse: 0.1312 - mae: 0.2732 - val_loss: 0.4447 - val_mse: 0.4447 - val_mae: 0.4704\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1209 - mse: 0.1209 - mae: 0.2603 - val_loss: 0.4356 - val_mse: 0.4356 - val_mae: 0.4740\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1216 - mse: 0.1216 - mae: 0.2553 - val_loss: 0.4425 - val_mse: 0.4425 - val_mae: 0.4605\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1178 - mse: 0.1178 - mae: 0.2538 - val_loss: 0.4211 - val_mse: 0.4211 - val_mae: 0.4692\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1128 - mse: 0.1128 - mae: 0.2493 - val_loss: 0.4186 - val_mse: 0.4186 - val_mae: 0.4526\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1125 - mse: 0.1125 - mae: 0.2512 - val_loss: 0.4125 - val_mse: 0.4125 - val_mae: 0.4593\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1098 - mse: 0.1098 - mae: 0.2487 - val_loss: 0.4362 - val_mse: 0.4362 - val_mae: 0.4621\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 0s 24us/sample - loss: 0.1117 - mse: 0.1117 - mae: 0.2497 - val_loss: 0.4262 - val_mse: 0.4262 - val_mae: 0.4633\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.1072 - mse: 0.1072 - mae: 0.2454 - val_loss: 0.4580 - val_mse: 0.4580 - val_mae: 0.4790\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1099 - mse: 0.1099 - mae: 0.2499 - val_loss: 0.4463 - val_mse: 0.4463 - val_mae: 0.4711\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1072 - mse: 0.1072 - mae: 0.2452 - val_loss: 0.4219 - val_mse: 0.4219 - val_mae: 0.4637\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.0987 - mse: 0.0987 - mae: 0.2346 - val_loss: 0.4341 - val_mse: 0.4341 - val_mae: 0.4692\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1017 - mse: 0.1017 - mae: 0.2396 - val_loss: 0.4179 - val_mse: 0.4179 - val_mae: 0.4452\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0928 - mse: 0.0928 - mae: 0.2272 - val_loss: 0.4212 - val_mse: 0.4212 - val_mae: 0.4637\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0967 - mse: 0.0967 - mae: 0.2302 - val_loss: 0.4214 - val_mse: 0.4214 - val_mae: 0.4499\n",
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0906 - mse: 0.0906 - mae: 0.2245 - val_loss: 0.4138 - val_mse: 0.4138 - val_mae: 0.4493\n",
      "Avg. MAE: 0.402004\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 163us/sample - loss: 1.9111 - mse: 1.9111 - mae: 1.0471 - val_loss: 4.6086 - val_mse: 4.6086 - val_mae: 1.9604\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.7903 - mse: 0.7903 - mae: 0.6752 - val_loss: 1.2562 - val_mse: 1.2562 - val_mae: 0.8138\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.6063 - mse: 0.6063 - mae: 0.5825 - val_loss: 1.2666 - val_mse: 1.2666 - val_mae: 0.9241\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.5153 - mse: 0.5153 - mae: 0.5410 - val_loss: 1.8305 - val_mse: 1.8305 - val_mae: 1.1655\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.4499 - mse: 0.4499 - mae: 0.4979 - val_loss: 1.1394 - val_mse: 1.1394 - val_mae: 0.8774\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4017 - mse: 0.4017 - mae: 0.4716 - val_loss: 1.2405 - val_mse: 1.2405 - val_mae: 0.9330\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3615 - mse: 0.3615 - mae: 0.4478 - val_loss: 1.1294 - val_mse: 1.1294 - val_mae: 0.8843\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3206 - mse: 0.3206 - mae: 0.4202 - val_loss: 1.0027 - val_mse: 1.0027 - val_mae: 0.8157\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2893 - mse: 0.2893 - mae: 0.4013 - val_loss: 0.9909 - val_mse: 0.9909 - val_mae: 0.8137\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2687 - mse: 0.2687 - mae: 0.3847 - val_loss: 1.0127 - val_mse: 1.0127 - val_mae: 0.8251\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2484 - mse: 0.2484 - mae: 0.3691 - val_loss: 0.9450 - val_mse: 0.9450 - val_mae: 0.7772\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2343 - mse: 0.2343 - mae: 0.3592 - val_loss: 1.0005 - val_mse: 1.0005 - val_mae: 0.8172\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2231 - mse: 0.2231 - mae: 0.3499 - val_loss: 0.9209 - val_mse: 0.9209 - val_mae: 0.7529\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2156 - mse: 0.2156 - mae: 0.3446 - val_loss: 0.9136 - val_mse: 0.9136 - val_mae: 0.7629\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2012 - mse: 0.2012 - mae: 0.3344 - val_loss: 0.9260 - val_mse: 0.9260 - val_mae: 0.7465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1977 - mse: 0.1977 - mae: 0.3299 - val_loss: 0.8988 - val_mse: 0.8988 - val_mae: 0.7399\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1746 - mse: 0.1746 - mae: 0.3146 - val_loss: 0.8963 - val_mse: 0.8963 - val_mae: 0.7416\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1746 - mse: 0.1746 - mae: 0.3114 - val_loss: 0.9069 - val_mse: 0.9069 - val_mae: 0.7388\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1561 - mse: 0.1561 - mae: 0.2951 - val_loss: 0.9032 - val_mse: 0.9032 - val_mae: 0.7434\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1464 - mse: 0.1464 - mae: 0.2875 - val_loss: 0.8795 - val_mse: 0.8795 - val_mae: 0.7288\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1390 - mse: 0.1390 - mae: 0.2802 - val_loss: 0.8558 - val_mse: 0.8558 - val_mae: 0.7237\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1273 - mse: 0.1273 - mae: 0.2672 - val_loss: 0.8332 - val_mse: 0.8332 - val_mae: 0.7122\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1202 - mse: 0.1202 - mae: 0.2618 - val_loss: 0.8227 - val_mse: 0.8227 - val_mae: 0.7014\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1120 - mse: 0.1120 - mae: 0.2526 - val_loss: 0.8230 - val_mse: 0.8230 - val_mae: 0.7027\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1077 - mse: 0.1077 - mae: 0.2486 - val_loss: 0.8135 - val_mse: 0.8135 - val_mae: 0.7052\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1106 - mse: 0.1106 - mae: 0.2503 - val_loss: 0.7738 - val_mse: 0.7738 - val_mae: 0.6888\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1110 - mse: 0.1110 - mae: 0.2491 - val_loss: 0.7733 - val_mse: 0.7733 - val_mae: 0.6860\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1051 - mse: 0.1051 - mae: 0.2445 - val_loss: 0.7676 - val_mse: 0.7676 - val_mae: 0.6898\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1122 - mse: 0.1122 - mae: 0.2530 - val_loss: 0.6926 - val_mse: 0.6926 - val_mae: 0.6497\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1113 - mse: 0.1113 - mae: 0.2530 - val_loss: 0.6858 - val_mse: 0.6858 - val_mae: 0.6387\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1089 - mse: 0.1089 - mae: 0.2522 - val_loss: 0.7033 - val_mse: 0.7033 - val_mae: 0.6585\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1084 - mse: 0.1084 - mae: 0.2460 - val_loss: 0.6714 - val_mse: 0.6714 - val_mae: 0.6393\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0933 - mse: 0.0933 - mae: 0.2291 - val_loss: 0.6300 - val_mse: 0.6300 - val_mae: 0.6176\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0933 - mse: 0.0933 - mae: 0.2318 - val_loss: 0.6175 - val_mse: 0.6175 - val_mae: 0.6143\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0856 - mse: 0.0856 - mae: 0.2197 - val_loss: 0.5845 - val_mse: 0.5845 - val_mae: 0.5874\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0782 - mse: 0.0782 - mae: 0.2095 - val_loss: 0.5672 - val_mse: 0.5672 - val_mae: 0.5829\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0800 - mse: 0.0800 - mae: 0.2132 - val_loss: 0.5763 - val_mse: 0.5763 - val_mae: 0.5852\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0778 - mse: 0.0778 - mae: 0.2086 - val_loss: 0.5565 - val_mse: 0.5565 - val_mae: 0.5721\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0773 - mse: 0.0773 - mae: 0.2111 - val_loss: 0.5504 - val_mse: 0.5504 - val_mae: 0.5738\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.0770 - mse: 0.0770 - mae: 0.2088 - val_loss: 0.5476 - val_mse: 0.5476 - val_mae: 0.5707\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0691 - mse: 0.0691 - mae: 0.1981 - val_loss: 0.5243 - val_mse: 0.5243 - val_mae: 0.5576\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0667 - mse: 0.0667 - mae: 0.1951 - val_loss: 0.5146 - val_mse: 0.5146 - val_mae: 0.5512\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0615 - mse: 0.0615 - mae: 0.1862 - val_loss: 0.5057 - val_mse: 0.5057 - val_mae: 0.5424\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0618 - mse: 0.0618 - mae: 0.1851 - val_loss: 0.4956 - val_mse: 0.4956 - val_mae: 0.5342\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0657 - mse: 0.0657 - mae: 0.1927 - val_loss: 0.5071 - val_mse: 0.5071 - val_mae: 0.5409\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0659 - mse: 0.0659 - mae: 0.1937 - val_loss: 0.5025 - val_mse: 0.5025 - val_mae: 0.5405\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0665 - mse: 0.0665 - mae: 0.1943 - val_loss: 0.4992 - val_mse: 0.4992 - val_mae: 0.5372\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0707 - mse: 0.0707 - mae: 0.2011 - val_loss: 0.4873 - val_mse: 0.4873 - val_mae: 0.5223\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0760 - mse: 0.0760 - mae: 0.2079 - val_loss: 0.4685 - val_mse: 0.4685 - val_mae: 0.5152\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0681 - mse: 0.0681 - mae: 0.1954 - val_loss: 0.4509 - val_mse: 0.4509 - val_mae: 0.4994\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0633 - mse: 0.0633 - mae: 0.1889 - val_loss: 0.4406 - val_mse: 0.4406 - val_mae: 0.4903\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0667 - mse: 0.0667 - mae: 0.1930 - val_loss: 0.4421 - val_mse: 0.4421 - val_mae: 0.4940\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0670 - mse: 0.0670 - mae: 0.1917 - val_loss: 0.4431 - val_mse: 0.4431 - val_mae: 0.4945\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0621 - mse: 0.0621 - mae: 0.1885 - val_loss: 0.4435 - val_mse: 0.4435 - val_mae: 0.4950\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0631 - mse: 0.0631 - mae: 0.1897 - val_loss: 0.4341 - val_mse: 0.4341 - val_mae: 0.4884\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0649 - mse: 0.0649 - mae: 0.1885 - val_loss: 0.4526 - val_mse: 0.4526 - val_mae: 0.4914\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0596 - mse: 0.0596 - mae: 0.1825 - val_loss: 0.4337 - val_mse: 0.4337 - val_mae: 0.4826\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0546 - mse: 0.0546 - mae: 0.1751 - val_loss: 0.4232 - val_mse: 0.4232 - val_mae: 0.4761\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0539 - mse: 0.0539 - mae: 0.1731 - val_loss: 0.4382 - val_mse: 0.4382 - val_mae: 0.4857\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0552 - mse: 0.0552 - mae: 0.1742 - val_loss: 0.4144 - val_mse: 0.4144 - val_mae: 0.4666\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0543 - mse: 0.0543 - mae: 0.1732 - val_loss: 0.4358 - val_mse: 0.4358 - val_mae: 0.4825\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0526 - mse: 0.0526 - mae: 0.1710 - val_loss: 0.4336 - val_mse: 0.4336 - val_mae: 0.4903\n",
      "Epoch 63/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0522 - mse: 0.0522 - mae: 0.1718 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.4784\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0491 - mse: 0.0491 - mae: 0.1667 - val_loss: 0.4218 - val_mse: 0.4218 - val_mae: 0.4761\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0502 - mse: 0.0502 - mae: 0.1669 - val_loss: 0.4155 - val_mse: 0.4155 - val_mae: 0.4701\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0520 - mse: 0.0520 - mae: 0.1671 - val_loss: 0.4163 - val_mse: 0.4163 - val_mae: 0.4774\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0599 - mse: 0.0599 - mae: 0.1756 - val_loss: 0.4318 - val_mse: 0.4318 - val_mae: 0.4815\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0583 - mse: 0.0583 - mae: 0.1811 - val_loss: 0.4212 - val_mse: 0.4212 - val_mae: 0.4781\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0554 - mse: 0.0554 - mae: 0.1751 - val_loss: 0.4152 - val_mse: 0.4152 - val_mae: 0.4669\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0603 - mse: 0.0603 - mae: 0.1773 - val_loss: 0.4376 - val_mse: 0.4376 - val_mae: 0.4751\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 209us/sample - loss: 1.8698 - mse: 1.8698 - mae: 1.0115 - val_loss: 1.9681 - val_mse: 1.9681 - val_mae: 1.1945\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.7450 - mse: 0.7450 - mae: 0.6549 - val_loss: 1.5654 - val_mse: 1.5654 - val_mae: 0.8810\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.5783 - mse: 0.5783 - mae: 0.5740 - val_loss: 1.1915 - val_mse: 1.1915 - val_mae: 0.7597\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4830 - mse: 0.4830 - mae: 0.5278 - val_loss: 1.0532 - val_mse: 1.0532 - val_mae: 0.7274\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4298 - mse: 0.4298 - mae: 0.4916 - val_loss: 1.1207 - val_mse: 1.1207 - val_mae: 0.7694\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3880 - mse: 0.3880 - mae: 0.4664 - val_loss: 1.4328 - val_mse: 1.4328 - val_mae: 0.8393\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3447 - mse: 0.3447 - mae: 0.4406 - val_loss: 1.1821 - val_mse: 1.1821 - val_mae: 0.7518\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.3161 - mse: 0.3161 - mae: 0.4201 - val_loss: 1.1298 - val_mse: 1.1298 - val_mae: 0.7374\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2936 - mse: 0.2936 - mae: 0.4076 - val_loss: 0.9934 - val_mse: 0.9934 - val_mae: 0.7166\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2757 - mse: 0.2757 - mae: 0.3918 - val_loss: 1.0066 - val_mse: 1.0066 - val_mae: 0.7118\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2511 - mse: 0.2511 - mae: 0.3765 - val_loss: 1.0019 - val_mse: 1.0019 - val_mae: 0.7283\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2259 - mse: 0.2259 - mae: 0.3555 - val_loss: 0.9329 - val_mse: 0.9329 - val_mae: 0.7377\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2098 - mse: 0.2098 - mae: 0.3422 - val_loss: 0.9626 - val_mse: 0.9626 - val_mae: 0.7333\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2029 - mse: 0.2029 - mae: 0.3344 - val_loss: 0.9264 - val_mse: 0.9264 - val_mae: 0.7343\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1912 - mse: 0.1912 - mae: 0.3269 - val_loss: 0.9508 - val_mse: 0.9508 - val_mae: 0.7302\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1803 - mse: 0.1803 - mae: 0.3206 - val_loss: 0.9316 - val_mse: 0.9316 - val_mae: 0.7441\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1684 - mse: 0.1684 - mae: 0.3086 - val_loss: 0.8964 - val_mse: 0.8964 - val_mae: 0.7351\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1571 - mse: 0.1571 - mae: 0.2985 - val_loss: 0.8871 - val_mse: 0.8871 - val_mae: 0.7296\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1475 - mse: 0.1475 - mae: 0.2861 - val_loss: 0.8952 - val_mse: 0.8952 - val_mae: 0.7204\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1409 - mse: 0.1409 - mae: 0.2805 - val_loss: 0.8820 - val_mse: 0.8820 - val_mae: 0.7371\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1438 - mse: 0.1438 - mae: 0.2850 - val_loss: 0.8907 - val_mse: 0.8907 - val_mae: 0.7220\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1394 - mse: 0.1394 - mae: 0.2781 - val_loss: 0.8608 - val_mse: 0.8608 - val_mae: 0.7116\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1284 - mse: 0.1284 - mae: 0.2694 - val_loss: 0.8505 - val_mse: 0.8505 - val_mae: 0.7202\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1198 - mse: 0.1198 - mae: 0.2599 - val_loss: 0.8152 - val_mse: 0.8152 - val_mae: 0.6993\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1154 - mse: 0.1154 - mae: 0.2556 - val_loss: 0.8063 - val_mse: 0.8063 - val_mae: 0.6947\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1146 - mse: 0.1146 - mae: 0.2525 - val_loss: 0.7376 - val_mse: 0.7376 - val_mae: 0.6652\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1077 - mse: 0.1077 - mae: 0.2471 - val_loss: 0.7295 - val_mse: 0.7295 - val_mae: 0.6678\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1063 - mse: 0.1063 - mae: 0.2448 - val_loss: 0.7373 - val_mse: 0.7373 - val_mae: 0.6700\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.0987 - mse: 0.0987 - mae: 0.2340 - val_loss: 0.7125 - val_mse: 0.7125 - val_mae: 0.6623\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.1007 - mse: 0.1007 - mae: 0.2375 - val_loss: 0.7218 - val_mse: 0.7218 - val_mae: 0.6562\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.0908 - mse: 0.0908 - mae: 0.2250 - val_loss: 0.6696 - val_mse: 0.6696 - val_mae: 0.6364\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0983 - mse: 0.0983 - mae: 0.2335 - val_loss: 0.7553 - val_mse: 0.7553 - val_mae: 0.6680\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1096 - mse: 0.1096 - mae: 0.2447 - val_loss: 0.6863 - val_mse: 0.6863 - val_mae: 0.6397\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1007 - mse: 0.1007 - mae: 0.2383 - val_loss: 0.6613 - val_mse: 0.6613 - val_mae: 0.6276\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2246 - val_loss: 0.6468 - val_mse: 0.6468 - val_mae: 0.6195\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0849 - mse: 0.0849 - mae: 0.2191 - val_loss: 0.6614 - val_mse: 0.6614 - val_mae: 0.6270\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0880 - mse: 0.0880 - mae: 0.2230 - val_loss: 0.6418 - val_mse: 0.6418 - val_mae: 0.6071\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0982 - mse: 0.0982 - mae: 0.2345 - val_loss: 0.5993 - val_mse: 0.5993 - val_mae: 0.5908\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0912 - mse: 0.0912 - mae: 0.2263 - val_loss: 0.6377 - val_mse: 0.6377 - val_mae: 0.6123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.0901 - mse: 0.0901 - mae: 0.2239 - val_loss: 0.5832 - val_mse: 0.5832 - val_mae: 0.5743\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0850 - mse: 0.0850 - mae: 0.2174 - val_loss: 0.6061 - val_mse: 0.6061 - val_mae: 0.5904\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2218 - val_loss: 0.5734 - val_mse: 0.5734 - val_mae: 0.5745\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0864 - mse: 0.0864 - mae: 0.2169 - val_loss: 0.5741 - val_mse: 0.5741 - val_mae: 0.5732\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0928 - mse: 0.0928 - mae: 0.2277 - val_loss: 0.5863 - val_mse: 0.5863 - val_mae: 0.5742\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0839 - mse: 0.0839 - mae: 0.2142 - val_loss: 0.5179 - val_mse: 0.5179 - val_mae: 0.5359\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0726 - mse: 0.0726 - mae: 0.2007 - val_loss: 0.5246 - val_mse: 0.5246 - val_mae: 0.5401\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0730 - mse: 0.0730 - mae: 0.1997 - val_loss: 0.5295 - val_mse: 0.5295 - val_mae: 0.5417\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0694 - mse: 0.0694 - mae: 0.1969 - val_loss: 0.5092 - val_mse: 0.5092 - val_mae: 0.5360\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0640 - mse: 0.0640 - mae: 0.1891 - val_loss: 0.5052 - val_mse: 0.5052 - val_mae: 0.5269\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0653 - mse: 0.0653 - mae: 0.1907 - val_loss: 0.5130 - val_mse: 0.5130 - val_mae: 0.5315\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0657 - mse: 0.0657 - mae: 0.1903 - val_loss: 0.5147 - val_mse: 0.5147 - val_mae: 0.5215\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0665 - mse: 0.0665 - mae: 0.1910 - val_loss: 0.5015 - val_mse: 0.5015 - val_mae: 0.5291\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0631 - mse: 0.0631 - mae: 0.1874 - val_loss: 0.5003 - val_mse: 0.5003 - val_mae: 0.5137\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0652 - mse: 0.0652 - mae: 0.1901 - val_loss: 0.4639 - val_mse: 0.4639 - val_mae: 0.4977\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0621 - mse: 0.0621 - mae: 0.1840 - val_loss: 0.4640 - val_mse: 0.4640 - val_mae: 0.5002\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0651 - mse: 0.0651 - mae: 0.1875 - val_loss: 0.4879 - val_mse: 0.4879 - val_mae: 0.5074\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0677 - mse: 0.0677 - mae: 0.1911 - val_loss: 0.4616 - val_mse: 0.4616 - val_mae: 0.4919\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0651 - mse: 0.0651 - mae: 0.1907 - val_loss: 0.4667 - val_mse: 0.4667 - val_mae: 0.4938\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0573 - mse: 0.0573 - mae: 0.1789 - val_loss: 0.4541 - val_mse: 0.4541 - val_mae: 0.4891\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0584 - mse: 0.0584 - mae: 0.1798 - val_loss: 0.4660 - val_mse: 0.4660 - val_mae: 0.4949\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0597 - mse: 0.0597 - mae: 0.1825 - val_loss: 0.4530 - val_mse: 0.4530 - val_mae: 0.4792\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0596 - mse: 0.0596 - mae: 0.1807 - val_loss: 0.4670 - val_mse: 0.4670 - val_mae: 0.4874\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0607 - mse: 0.0607 - mae: 0.1843 - val_loss: 0.4572 - val_mse: 0.4572 - val_mae: 0.4819\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0548 - mse: 0.0548 - mae: 0.1753 - val_loss: 0.4723 - val_mse: 0.4723 - val_mae: 0.4865\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0546 - mse: 0.0546 - mae: 0.1720 - val_loss: 0.4619 - val_mse: 0.4619 - val_mae: 0.4928\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0551 - mse: 0.0551 - mae: 0.1742 - val_loss: 0.4575 - val_mse: 0.4575 - val_mae: 0.4809\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0527 - mse: 0.0527 - mae: 0.1689 - val_loss: 0.4418 - val_mse: 0.4418 - val_mae: 0.4749\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0549 - mse: 0.0549 - mae: 0.1737 - val_loss: 0.4661 - val_mse: 0.4661 - val_mae: 0.4782\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0530 - mse: 0.0530 - mae: 0.1730 - val_loss: 0.4556 - val_mse: 0.4556 - val_mae: 0.4717\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0484 - mse: 0.0484 - mae: 0.1640 - val_loss: 0.4350 - val_mse: 0.4350 - val_mae: 0.4631\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0503 - mse: 0.0503 - mae: 0.1659 - val_loss: 0.4470 - val_mse: 0.4470 - val_mae: 0.4678\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0526 - mse: 0.0526 - mae: 0.1718 - val_loss: 0.4501 - val_mse: 0.4501 - val_mae: 0.4711\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0479 - mse: 0.0479 - mae: 0.1654 - val_loss: 0.4267 - val_mse: 0.4267 - val_mae: 0.4540\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0526 - mse: 0.0526 - mae: 0.1680 - val_loss: 0.4452 - val_mse: 0.4452 - val_mae: 0.4640\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0514 - mse: 0.0514 - mae: 0.1634 - val_loss: 0.4327 - val_mse: 0.4327 - val_mae: 0.4552\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0468 - mse: 0.0468 - mae: 0.1596 - val_loss: 0.4356 - val_mse: 0.4356 - val_mae: 0.4636\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0457 - mse: 0.0457 - mae: 0.1578 - val_loss: 0.4374 - val_mse: 0.4374 - val_mae: 0.4639\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0481 - mse: 0.0481 - mae: 0.1630 - val_loss: 0.4356 - val_mse: 0.4356 - val_mae: 0.4625\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0462 - mse: 0.0462 - mae: 0.1601 - val_loss: 0.4234 - val_mse: 0.4234 - val_mae: 0.4479\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0463 - mse: 0.0463 - mae: 0.1601 - val_loss: 0.4215 - val_mse: 0.4215 - val_mae: 0.4512\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0422 - mse: 0.0422 - mae: 0.1536 - val_loss: 0.4272 - val_mse: 0.4272 - val_mae: 0.4570\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0429 - mse: 0.0429 - mae: 0.1541 - val_loss: 0.4192 - val_mse: 0.4192 - val_mae: 0.4484\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0434 - mse: 0.0434 - mae: 0.1533 - val_loss: 0.4244 - val_mse: 0.4244 - val_mae: 0.4526\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0426 - mse: 0.0426 - mae: 0.1540 - val_loss: 0.4254 - val_mse: 0.4254 - val_mae: 0.4532\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0408 - mse: 0.0408 - mae: 0.1484 - val_loss: 0.4222 - val_mse: 0.4222 - val_mae: 0.4520\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0454 - mse: 0.0454 - mae: 0.1590 - val_loss: 0.4232 - val_mse: 0.4232 - val_mae: 0.4527\n",
      "Epoch 87/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0419 - mse: 0.0419 - mae: 0.1512 - val_loss: 0.4183 - val_mse: 0.4183 - val_mae: 0.4515\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0420 - mse: 0.0420 - mae: 0.1517 - val_loss: 0.4223 - val_mse: 0.4223 - val_mae: 0.4550\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0444 - mse: 0.0444 - mae: 0.1562 - val_loss: 0.4295 - val_mse: 0.4295 - val_mae: 0.4542\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0423 - mse: 0.0423 - mae: 0.1518 - val_loss: 0.4474 - val_mse: 0.4474 - val_mae: 0.4591\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0457 - mse: 0.0457 - mae: 0.1581 - val_loss: 0.4270 - val_mse: 0.4270 - val_mae: 0.4496\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0421 - mse: 0.0421 - mae: 0.1515 - val_loss: 0.4143 - val_mse: 0.4143 - val_mae: 0.4472\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0444 - mse: 0.0444 - mae: 0.1541 - val_loss: 0.4286 - val_mse: 0.4286 - val_mae: 0.4512\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0424 - mse: 0.0424 - mae: 0.1533 - val_loss: 0.4541 - val_mse: 0.4541 - val_mae: 0.4706\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0460 - mse: 0.0460 - mae: 0.1597 - val_loss: 0.4295 - val_mse: 0.4295 - val_mae: 0.4523\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0416 - mse: 0.0416 - mae: 0.1501 - val_loss: 0.4289 - val_mse: 0.4289 - val_mae: 0.4542\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0450 - mse: 0.0450 - mae: 0.1564 - val_loss: 0.4270 - val_mse: 0.4270 - val_mae: 0.4515\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0436 - mse: 0.0436 - mae: 0.1541 - val_loss: 0.4403 - val_mse: 0.4403 - val_mae: 0.4636\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0524 - mse: 0.0524 - mae: 0.1644 - val_loss: 0.4443 - val_mse: 0.4443 - val_mae: 0.4536\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0501 - mse: 0.0501 - mae: 0.1599 - val_loss: 0.4242 - val_mse: 0.4242 - val_mae: 0.4526\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0464 - mse: 0.0464 - mae: 0.1589 - val_loss: 0.4376 - val_mse: 0.4376 - val_mae: 0.4601\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0473 - mse: 0.0473 - mae: 0.1623 - val_loss: 0.4468 - val_mse: 0.4468 - val_mae: 0.4638\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 160us/sample - loss: 1.8413 - mse: 1.8413 - mae: 1.0088 - val_loss: 2.1366 - val_mse: 2.1366 - val_mae: 1.2406\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.7291 - mse: 0.7291 - mae: 0.6431 - val_loss: 2.6374 - val_mse: 2.6374 - val_mae: 1.4302\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.5612 - mse: 0.5612 - mae: 0.5668 - val_loss: 2.7726 - val_mse: 2.7726 - val_mae: 1.4722\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.4666 - mse: 0.4666 - mae: 0.5175 - val_loss: 1.8452 - val_mse: 1.8452 - val_mae: 1.1701\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4092 - mse: 0.4092 - mae: 0.4758 - val_loss: 1.2951 - val_mse: 1.2951 - val_mae: 0.9559\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3619 - mse: 0.3619 - mae: 0.4492 - val_loss: 1.3393 - val_mse: 1.3393 - val_mae: 0.9687\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3294 - mse: 0.3294 - mae: 0.4288 - val_loss: 1.0239 - val_mse: 1.0239 - val_mae: 0.8225\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2985 - mse: 0.2985 - mae: 0.4046 - val_loss: 1.0450 - val_mse: 1.0450 - val_mae: 0.8280\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2686 - mse: 0.2686 - mae: 0.3878 - val_loss: 0.9659 - val_mse: 0.9659 - val_mae: 0.7727\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2527 - mse: 0.2527 - mae: 0.3771 - val_loss: 0.9538 - val_mse: 0.9538 - val_mae: 0.7593\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2267 - mse: 0.2267 - mae: 0.3559 - val_loss: 0.9341 - val_mse: 0.9341 - val_mae: 0.7553\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2103 - mse: 0.2103 - mae: 0.3418 - val_loss: 0.9430 - val_mse: 0.9430 - val_mae: 0.7475\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2033 - mse: 0.2033 - mae: 0.3364 - val_loss: 0.9303 - val_mse: 0.9303 - val_mae: 0.7361\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1806 - mse: 0.1806 - mae: 0.3182 - val_loss: 0.9128 - val_mse: 0.9128 - val_mae: 0.7320\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1679 - mse: 0.1679 - mae: 0.3093 - val_loss: 0.9126 - val_mse: 0.9126 - val_mae: 0.7278\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1691 - mse: 0.1691 - mae: 0.3077 - val_loss: 0.8844 - val_mse: 0.8844 - val_mae: 0.7110\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1549 - mse: 0.1549 - mae: 0.2954 - val_loss: 0.8723 - val_mse: 0.8723 - val_mae: 0.7226\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1561 - mse: 0.1561 - mae: 0.2957 - val_loss: 0.8406 - val_mse: 0.8406 - val_mae: 0.7048\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1400 - mse: 0.1400 - mae: 0.2862 - val_loss: 0.8297 - val_mse: 0.8297 - val_mae: 0.6914\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1316 - mse: 0.1316 - mae: 0.2754 - val_loss: 0.7998 - val_mse: 0.7998 - val_mae: 0.6837\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1227 - mse: 0.1227 - mae: 0.2651 - val_loss: 0.7899 - val_mse: 0.7899 - val_mae: 0.6808\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1216 - mse: 0.1216 - mae: 0.2611 - val_loss: 0.7436 - val_mse: 0.7436 - val_mae: 0.6625\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1283 - mse: 0.1283 - mae: 0.2669 - val_loss: 0.7382 - val_mse: 0.7382 - val_mae: 0.6654\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1201 - mse: 0.1201 - mae: 0.2620 - val_loss: 0.7516 - val_mse: 0.7516 - val_mae: 0.6665\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1091 - mse: 0.1091 - mae: 0.2519 - val_loss: 0.7246 - val_mse: 0.7246 - val_mae: 0.6607\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1045 - mse: 0.1045 - mae: 0.2460 - val_loss: 0.7079 - val_mse: 0.7079 - val_mae: 0.6505\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0999 - mse: 0.0999 - mae: 0.2403 - val_loss: 0.6847 - val_mse: 0.6847 - val_mae: 0.6322\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0979 - mse: 0.0979 - mae: 0.2374 - val_loss: 0.6875 - val_mse: 0.6875 - val_mae: 0.6465\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0977 - mse: 0.0977 - mae: 0.2352 - val_loss: 0.6270 - val_mse: 0.6270 - val_mae: 0.6045\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0971 - mse: 0.0971 - mae: 0.2352 - val_loss: 0.6181 - val_mse: 0.6181 - val_mae: 0.6086\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1003 - mse: 0.1003 - mae: 0.2394 - val_loss: 0.6381 - val_mse: 0.6381 - val_mae: 0.6186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0903 - mse: 0.0903 - mae: 0.2288 - val_loss: 0.6243 - val_mse: 0.6243 - val_mae: 0.6094\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0862 - mse: 0.0862 - mae: 0.2224 - val_loss: 0.5828 - val_mse: 0.5828 - val_mae: 0.5872\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0863 - mse: 0.0863 - mae: 0.2250 - val_loss: 0.6263 - val_mse: 0.6263 - val_mae: 0.6076\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.0910 - mse: 0.0910 - mae: 0.2281 - val_loss: 0.5616 - val_mse: 0.5616 - val_mae: 0.5712\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0829 - mse: 0.0829 - mae: 0.2167 - val_loss: 0.5763 - val_mse: 0.5763 - val_mae: 0.5891\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0901 - mse: 0.0901 - mae: 0.2261 - val_loss: 0.5790 - val_mse: 0.5790 - val_mae: 0.5815\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0915 - mse: 0.0915 - mae: 0.2307 - val_loss: 0.5337 - val_mse: 0.5337 - val_mae: 0.5563\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0789 - mse: 0.0789 - mae: 0.2124 - val_loss: 0.5620 - val_mse: 0.5620 - val_mae: 0.5686\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0810 - mse: 0.0810 - mae: 0.2159 - val_loss: 0.5303 - val_mse: 0.5303 - val_mae: 0.5541\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0770 - mse: 0.0770 - mae: 0.2105 - val_loss: 0.5129 - val_mse: 0.5129 - val_mae: 0.5412\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0722 - mse: 0.0722 - mae: 0.2049 - val_loss: 0.5307 - val_mse: 0.5307 - val_mae: 0.5487\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0717 - mse: 0.0717 - mae: 0.2036 - val_loss: 0.5024 - val_mse: 0.5024 - val_mae: 0.5308\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0679 - mse: 0.0679 - mae: 0.1989 - val_loss: 0.4774 - val_mse: 0.4774 - val_mae: 0.5176\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0711 - mse: 0.0711 - mae: 0.2033 - val_loss: 0.4774 - val_mse: 0.4774 - val_mae: 0.5124\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0655 - mse: 0.0655 - mae: 0.1947 - val_loss: 0.4720 - val_mse: 0.4720 - val_mae: 0.5133\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0627 - mse: 0.0627 - mae: 0.1907 - val_loss: 0.4733 - val_mse: 0.4733 - val_mae: 0.5152\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0618 - mse: 0.0618 - mae: 0.1879 - val_loss: 0.4715 - val_mse: 0.4715 - val_mae: 0.5113\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0614 - mse: 0.0614 - mae: 0.1886 - val_loss: 0.4639 - val_mse: 0.4639 - val_mae: 0.5037\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0627 - mse: 0.0627 - mae: 0.1909 - val_loss: 0.4666 - val_mse: 0.4666 - val_mae: 0.5050\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0582 - mse: 0.0582 - mae: 0.1833 - val_loss: 0.4468 - val_mse: 0.4468 - val_mae: 0.4958\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0595 - mse: 0.0595 - mae: 0.1857 - val_loss: 0.4719 - val_mse: 0.4719 - val_mae: 0.5084\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0553 - mse: 0.0553 - mae: 0.1793 - val_loss: 0.4425 - val_mse: 0.4425 - val_mae: 0.4887\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0557 - mse: 0.0557 - mae: 0.1812 - val_loss: 0.4429 - val_mse: 0.4429 - val_mae: 0.4877\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0519 - mse: 0.0519 - mae: 0.1726 - val_loss: 0.4420 - val_mse: 0.4420 - val_mae: 0.4920\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0524 - mse: 0.0524 - mae: 0.1742 - val_loss: 0.4426 - val_mse: 0.4426 - val_mae: 0.4880\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0531 - mse: 0.0531 - mae: 0.1754 - val_loss: 0.4336 - val_mse: 0.4336 - val_mae: 0.4831\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0527 - mse: 0.0527 - mae: 0.1756 - val_loss: 0.4252 - val_mse: 0.4252 - val_mae: 0.4749\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0499 - mse: 0.0499 - mae: 0.1698 - val_loss: 0.4232 - val_mse: 0.4232 - val_mae: 0.4719\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0480 - mse: 0.0480 - mae: 0.1655 - val_loss: 0.4340 - val_mse: 0.4340 - val_mae: 0.4773\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0530 - mse: 0.0530 - mae: 0.1735 - val_loss: 0.4306 - val_mse: 0.4306 - val_mae: 0.4766\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0562 - mse: 0.0562 - mae: 0.1791 - val_loss: 0.4321 - val_mse: 0.4321 - val_mae: 0.4729\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0545 - mse: 0.0545 - mae: 0.1752 - val_loss: 0.4673 - val_mse: 0.4673 - val_mae: 0.5012\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0606 - mse: 0.0606 - mae: 0.1895 - val_loss: 0.4356 - val_mse: 0.4356 - val_mae: 0.4781\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0554 - mse: 0.0554 - mae: 0.1788 - val_loss: 0.4235 - val_mse: 0.4235 - val_mae: 0.4657\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0528 - mse: 0.0528 - mae: 0.1729 - val_loss: 0.4394 - val_mse: 0.4394 - val_mae: 0.4762\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0516 - mse: 0.0516 - mae: 0.1701 - val_loss: 0.4306 - val_mse: 0.4306 - val_mae: 0.4698\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0496 - mse: 0.0496 - mae: 0.1685 - val_loss: 0.4146 - val_mse: 0.4146 - val_mae: 0.4584\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0482 - mse: 0.0482 - mae: 0.1652 - val_loss: 0.4247 - val_mse: 0.4247 - val_mae: 0.4636\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0508 - mse: 0.0508 - mae: 0.1722 - val_loss: 0.4142 - val_mse: 0.4142 - val_mae: 0.4571\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0462 - mse: 0.0462 - mae: 0.1649 - val_loss: 0.4166 - val_mse: 0.4166 - val_mae: 0.4649\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.0442 - mse: 0.0442 - mae: 0.1608 - val_loss: 0.4250 - val_mse: 0.4250 - val_mae: 0.4643\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0466 - mse: 0.0466 - mae: 0.1638 - val_loss: 0.4279 - val_mse: 0.4279 - val_mae: 0.4640\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0430 - mse: 0.0430 - mae: 0.1587 - val_loss: 0.4159 - val_mse: 0.4159 - val_mae: 0.4552\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0438 - mse: 0.0438 - mae: 0.1588 - val_loss: 0.4373 - val_mse: 0.4373 - val_mae: 0.4728\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0485 - mse: 0.0485 - mae: 0.1668 - val_loss: 0.4385 - val_mse: 0.4385 - val_mae: 0.4724\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0464 - mse: 0.0464 - mae: 0.1623 - val_loss: 0.4278 - val_mse: 0.4278 - val_mae: 0.4629\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.0434 - mse: 0.0434 - mae: 0.1559 - val_loss: 0.4344 - val_mse: 0.4344 - val_mae: 0.4679\n",
      "Epoch 79/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0452 - mse: 0.0452 - mae: 0.1608 - val_loss: 0.4422 - val_mse: 0.4422 - val_mae: 0.4768\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0472 - mse: 0.0472 - mae: 0.1650 - val_loss: 0.4340 - val_mse: 0.4340 - val_mae: 0.4667\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 163us/sample - loss: 1.9556 - mse: 1.9556 - mae: 1.0422 - val_loss: 5.7291 - val_mse: 5.7291 - val_mae: 2.1857\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.7695 - mse: 0.7695 - mae: 0.6587 - val_loss: 1.4069 - val_mse: 1.4069 - val_mae: 0.9776\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.5909 - mse: 0.5909 - mae: 0.5807 - val_loss: 1.9485 - val_mse: 1.9485 - val_mae: 1.2106\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.5016 - mse: 0.5016 - mae: 0.5317 - val_loss: 1.9023 - val_mse: 1.9023 - val_mae: 1.1842\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4450 - mse: 0.4450 - mae: 0.4960 - val_loss: 1.7292 - val_mse: 1.7292 - val_mae: 1.1349\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3996 - mse: 0.3996 - mae: 0.4740 - val_loss: 1.2592 - val_mse: 1.2592 - val_mae: 0.9490\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3609 - mse: 0.3609 - mae: 0.4472 - val_loss: 1.2900 - val_mse: 1.2900 - val_mae: 0.9627\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3231 - mse: 0.3231 - mae: 0.4226 - val_loss: 1.1461 - val_mse: 1.1461 - val_mae: 0.8968\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2958 - mse: 0.2958 - mae: 0.4086 - val_loss: 1.0057 - val_mse: 1.0057 - val_mae: 0.8182\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2711 - mse: 0.2711 - mae: 0.3860 - val_loss: 0.9517 - val_mse: 0.9517 - val_mae: 0.7797\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2440 - mse: 0.2440 - mae: 0.3661 - val_loss: 0.9515 - val_mse: 0.9515 - val_mae: 0.7854\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2258 - mse: 0.2258 - mae: 0.3550 - val_loss: 0.9462 - val_mse: 0.9462 - val_mae: 0.7862\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2191 - mse: 0.2191 - mae: 0.3506 - val_loss: 0.8972 - val_mse: 0.8972 - val_mae: 0.7544\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1991 - mse: 0.1991 - mae: 0.3327 - val_loss: 0.8690 - val_mse: 0.8690 - val_mae: 0.7283\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1885 - mse: 0.1885 - mae: 0.3246 - val_loss: 0.9051 - val_mse: 0.9051 - val_mae: 0.7303\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1875 - mse: 0.1875 - mae: 0.3247 - val_loss: 0.8535 - val_mse: 0.8535 - val_mae: 0.7072\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1783 - mse: 0.1783 - mae: 0.3186 - val_loss: 0.8693 - val_mse: 0.8693 - val_mae: 0.7283\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1651 - mse: 0.1651 - mae: 0.3076 - val_loss: 0.8380 - val_mse: 0.8380 - val_mae: 0.7048\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1652 - mse: 0.1652 - mae: 0.3045 - val_loss: 0.8160 - val_mse: 0.8160 - val_mae: 0.6942\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1560 - mse: 0.1560 - mae: 0.2952 - val_loss: 0.8188 - val_mse: 0.8188 - val_mae: 0.6933\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1531 - mse: 0.1531 - mae: 0.2935 - val_loss: 0.7785 - val_mse: 0.7785 - val_mae: 0.6805\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1532 - mse: 0.1532 - mae: 0.2934 - val_loss: 0.7965 - val_mse: 0.7965 - val_mae: 0.6858\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1372 - mse: 0.1372 - mae: 0.2766 - val_loss: 0.7782 - val_mse: 0.7782 - val_mae: 0.6796\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1257 - mse: 0.1257 - mae: 0.2659 - val_loss: 0.7415 - val_mse: 0.7415 - val_mae: 0.6672\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1209 - mse: 0.1209 - mae: 0.2602 - val_loss: 0.7737 - val_mse: 0.7737 - val_mae: 0.6825\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1106 - mse: 0.1106 - mae: 0.2462 - val_loss: 0.7387 - val_mse: 0.7387 - val_mae: 0.6683\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1050 - mse: 0.1050 - mae: 0.2433 - val_loss: 0.7301 - val_mse: 0.7301 - val_mae: 0.6624\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1080 - mse: 0.1080 - mae: 0.2456 - val_loss: 0.7122 - val_mse: 0.7122 - val_mae: 0.6550\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1112 - mse: 0.1112 - mae: 0.2503 - val_loss: 0.7013 - val_mse: 0.7013 - val_mae: 0.6524\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1046 - mse: 0.1046 - mae: 0.2441 - val_loss: 0.6860 - val_mse: 0.6860 - val_mae: 0.6411\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1012 - mse: 0.1012 - mae: 0.2380 - val_loss: 0.7059 - val_mse: 0.7059 - val_mae: 0.6546\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0951 - mse: 0.0951 - mae: 0.2301 - val_loss: 0.6523 - val_mse: 0.6523 - val_mae: 0.6270\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0939 - mse: 0.0939 - mae: 0.2257 - val_loss: 0.6224 - val_mse: 0.6224 - val_mae: 0.6106\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2220 - val_loss: 0.6299 - val_mse: 0.6299 - val_mae: 0.6128\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0906 - mse: 0.0906 - mae: 0.2258 - val_loss: 0.5801 - val_mse: 0.5801 - val_mae: 0.5858\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0839 - mse: 0.0839 - mae: 0.2187 - val_loss: 0.5948 - val_mse: 0.5948 - val_mae: 0.5937\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0780 - mse: 0.0780 - mae: 0.2094 - val_loss: 0.5736 - val_mse: 0.5736 - val_mae: 0.5844\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0832 - mse: 0.0832 - mae: 0.2182 - val_loss: 0.5704 - val_mse: 0.5704 - val_mae: 0.5786\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0820 - mse: 0.0820 - mae: 0.2168 - val_loss: 0.5769 - val_mse: 0.5769 - val_mae: 0.5746\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0779 - mse: 0.0779 - mae: 0.2094 - val_loss: 0.5561 - val_mse: 0.5561 - val_mae: 0.5679\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0800 - mse: 0.0800 - mae: 0.2125 - val_loss: 0.5642 - val_mse: 0.5642 - val_mae: 0.5737\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0798 - mse: 0.0798 - mae: 0.2103 - val_loss: 0.5493 - val_mse: 0.5493 - val_mae: 0.5644\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0747 - mse: 0.0747 - mae: 0.2050 - val_loss: 0.5565 - val_mse: 0.5565 - val_mae: 0.5752\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0726 - mse: 0.0726 - mae: 0.2029 - val_loss: 0.5261 - val_mse: 0.5261 - val_mae: 0.5497\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0766 - mse: 0.0766 - mae: 0.2040 - val_loss: 0.5485 - val_mse: 0.5485 - val_mae: 0.5608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0807 - mse: 0.0807 - mae: 0.2100 - val_loss: 0.5136 - val_mse: 0.5136 - val_mae: 0.5450\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0764 - mse: 0.0764 - mae: 0.2064 - val_loss: 0.5301 - val_mse: 0.5301 - val_mae: 0.5534\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0739 - mse: 0.0739 - mae: 0.2017 - val_loss: 0.4866 - val_mse: 0.4866 - val_mae: 0.5281\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0732 - mse: 0.0732 - mae: 0.2016 - val_loss: 0.4705 - val_mse: 0.4705 - val_mae: 0.5150\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0679 - mse: 0.0679 - mae: 0.1947 - val_loss: 0.4573 - val_mse: 0.4573 - val_mae: 0.5024\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0675 - mse: 0.0675 - mae: 0.1948 - val_loss: 0.4742 - val_mse: 0.4742 - val_mae: 0.5177\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0626 - mse: 0.0626 - mae: 0.1877 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.5086\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0629 - mse: 0.0629 - mae: 0.1867 - val_loss: 0.4488 - val_mse: 0.4488 - val_mae: 0.4990\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0639 - mse: 0.0639 - mae: 0.1899 - val_loss: 0.4413 - val_mse: 0.4413 - val_mae: 0.4945\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0617 - mse: 0.0617 - mae: 0.1873 - val_loss: 0.4442 - val_mse: 0.4442 - val_mae: 0.4951\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0624 - mse: 0.0624 - mae: 0.1864 - val_loss: 0.4662 - val_mse: 0.4662 - val_mae: 0.5141\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0630 - mse: 0.0630 - mae: 0.1883 - val_loss: 0.4611 - val_mse: 0.4611 - val_mae: 0.5125\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0581 - mse: 0.0581 - mae: 0.1796 - val_loss: 0.4426 - val_mse: 0.4426 - val_mae: 0.4970\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0569 - mse: 0.0569 - mae: 0.1766 - val_loss: 0.4383 - val_mse: 0.4383 - val_mae: 0.4885\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0610 - mse: 0.0610 - mae: 0.1845 - val_loss: 0.4184 - val_mse: 0.4184 - val_mae: 0.4698\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0630 - mse: 0.0630 - mae: 0.1900 - val_loss: 0.4295 - val_mse: 0.4295 - val_mae: 0.4791\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0614 - mse: 0.0614 - mae: 0.1848 - val_loss: 0.4085 - val_mse: 0.4085 - val_mae: 0.4664\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0563 - mse: 0.0563 - mae: 0.1773 - val_loss: 0.4195 - val_mse: 0.4195 - val_mae: 0.4772\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0510 - mse: 0.0510 - mae: 0.1679 - val_loss: 0.4121 - val_mse: 0.4121 - val_mae: 0.4710\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0513 - mse: 0.0513 - mae: 0.1681 - val_loss: 0.4329 - val_mse: 0.4329 - val_mae: 0.4857\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0512 - mse: 0.0512 - mae: 0.1688 - val_loss: 0.4242 - val_mse: 0.4242 - val_mae: 0.4758\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0463 - mse: 0.0463 - mae: 0.1594 - val_loss: 0.4311 - val_mse: 0.4311 - val_mae: 0.4837\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0489 - mse: 0.0489 - mae: 0.1632 - val_loss: 0.4133 - val_mse: 0.4133 - val_mae: 0.4710\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0467 - mse: 0.0467 - mae: 0.1609 - val_loss: 0.4105 - val_mse: 0.4105 - val_mae: 0.4652\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0542 - mse: 0.0542 - mae: 0.1713 - val_loss: 0.4108 - val_mse: 0.4108 - val_mae: 0.4601\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0667 - mse: 0.0667 - mae: 0.1916 - val_loss: 0.4155 - val_mse: 0.4155 - val_mae: 0.4687\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0626 - mse: 0.0626 - mae: 0.1880 - val_loss: 0.4068 - val_mse: 0.4068 - val_mae: 0.4600\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0618 - mse: 0.0618 - mae: 0.1820 - val_loss: 0.4106 - val_mse: 0.4106 - val_mae: 0.4645\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0569 - mse: 0.0569 - mae: 0.1765 - val_loss: 0.4226 - val_mse: 0.4226 - val_mae: 0.4742\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0585 - mse: 0.0585 - mae: 0.1809 - val_loss: 0.4172 - val_mse: 0.4172 - val_mae: 0.4682\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0500 - mse: 0.0500 - mae: 0.1662 - val_loss: 0.4072 - val_mse: 0.4072 - val_mae: 0.4572\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0509 - mse: 0.0509 - mae: 0.1684 - val_loss: 0.4108 - val_mse: 0.4108 - val_mae: 0.4655\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0467 - mse: 0.0467 - mae: 0.1625 - val_loss: 0.3986 - val_mse: 0.3986 - val_mae: 0.4586\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0430 - mse: 0.0430 - mae: 0.1543 - val_loss: 0.4128 - val_mse: 0.4128 - val_mae: 0.4668\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0449 - mse: 0.0449 - mae: 0.1579 - val_loss: 0.4023 - val_mse: 0.4023 - val_mae: 0.4576\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0417 - mse: 0.0417 - mae: 0.1502 - val_loss: 0.4203 - val_mse: 0.4203 - val_mae: 0.4771\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0425 - mse: 0.0425 - mae: 0.1539 - val_loss: 0.3835 - val_mse: 0.3835 - val_mae: 0.4415\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0393 - mse: 0.0393 - mae: 0.1457 - val_loss: 0.3941 - val_mse: 0.3941 - val_mae: 0.4514\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0449 - mse: 0.0449 - mae: 0.1562 - val_loss: 0.3915 - val_mse: 0.3915 - val_mae: 0.4479\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0409 - mse: 0.0409 - mae: 0.1492 - val_loss: 0.3844 - val_mse: 0.3844 - val_mae: 0.4428\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0403 - mse: 0.0403 - mae: 0.1479 - val_loss: 0.4046 - val_mse: 0.4046 - val_mae: 0.4594\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0438 - mse: 0.0438 - mae: 0.1557 - val_loss: 0.4075 - val_mse: 0.4075 - val_mae: 0.4634\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.0448 - mse: 0.0448 - mae: 0.1567 - val_loss: 0.4027 - val_mse: 0.4027 - val_mae: 0.4608\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.0546 - mse: 0.0546 - mae: 0.1753 - val_loss: 0.3948 - val_mse: 0.3948 - val_mae: 0.4560\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.0501 - mse: 0.0501 - mae: 0.1644 - val_loss: 0.3883 - val_mse: 0.3883 - val_mae: 0.4539\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0468 - mse: 0.0468 - mae: 0.1593 - val_loss: 0.3795 - val_mse: 0.3795 - val_mae: 0.4453\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0443 - mse: 0.0443 - mae: 0.1565 - val_loss: 0.3993 - val_mse: 0.3993 - val_mae: 0.4594\n",
      "Epoch 93/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0413 - mse: 0.0413 - mae: 0.1521 - val_loss: 0.3770 - val_mse: 0.3770 - val_mae: 0.4396\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0373 - mse: 0.0373 - mae: 0.1439 - val_loss: 0.3872 - val_mse: 0.3872 - val_mae: 0.4467\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0404 - mse: 0.0404 - mae: 0.1499 - val_loss: 0.3907 - val_mse: 0.3907 - val_mae: 0.4517\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0385 - mse: 0.0385 - mae: 0.1455 - val_loss: 0.3784 - val_mse: 0.3784 - val_mae: 0.4441\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0371 - mse: 0.0371 - mae: 0.1420 - val_loss: 0.4017 - val_mse: 0.4017 - val_mae: 0.4566\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0415 - mse: 0.0415 - mae: 0.1479 - val_loss: 0.3885 - val_mse: 0.3885 - val_mae: 0.4527\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0396 - mse: 0.0396 - mae: 0.1472 - val_loss: 0.3953 - val_mse: 0.3953 - val_mae: 0.4546\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0429 - mse: 0.0429 - mae: 0.1529 - val_loss: 0.3897 - val_mse: 0.3897 - val_mae: 0.4486\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0402 - mse: 0.0402 - mae: 0.1475 - val_loss: 0.3776 - val_mse: 0.3776 - val_mae: 0.4397\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.0392 - mse: 0.0392 - mae: 0.1463 - val_loss: 0.3865 - val_mse: 0.3865 - val_mae: 0.4451\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.0377 - mse: 0.0377 - mae: 0.1425 - val_loss: 0.3883 - val_mse: 0.3883 - val_mae: 0.4447\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 213us/sample - loss: 1.7773 - mse: 1.7773 - mae: 1.0127 - val_loss: 1.2000 - val_mse: 1.2000 - val_mae: 0.8835\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.7512 - mse: 0.7512 - mae: 0.6589 - val_loss: 2.1493 - val_mse: 2.1493 - val_mae: 1.2668\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.5777 - mse: 0.5777 - mae: 0.5643 - val_loss: 1.7953 - val_mse: 1.7953 - val_mae: 0.9758\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.5019 - mse: 0.5019 - mae: 0.5259 - val_loss: 1.3010 - val_mse: 1.3010 - val_mae: 0.9285\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.4255 - mse: 0.4255 - mae: 0.4842 - val_loss: 1.2239 - val_mse: 1.2239 - val_mae: 0.8269\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.3784 - mse: 0.3784 - mae: 0.4568 - val_loss: 1.1844 - val_mse: 1.1844 - val_mae: 0.8310\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.3403 - mse: 0.3403 - mae: 0.4290 - val_loss: 1.0408 - val_mse: 1.0408 - val_mae: 0.7856\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.3070 - mse: 0.3070 - mae: 0.4123 - val_loss: 1.0154 - val_mse: 1.0154 - val_mae: 0.7806\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2818 - mse: 0.2818 - mae: 0.3950 - val_loss: 1.0106 - val_mse: 1.0106 - val_mae: 0.7756\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2605 - mse: 0.2605 - mae: 0.3778 - val_loss: 1.0418 - val_mse: 1.0418 - val_mae: 0.7643\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2453 - mse: 0.2453 - mae: 0.3686 - val_loss: 0.9516 - val_mse: 0.9516 - val_mae: 0.7419\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.2235 - mse: 0.2235 - mae: 0.3503 - val_loss: 1.0873 - val_mse: 1.0873 - val_mae: 0.7634\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.2238 - mse: 0.2238 - mae: 0.3502 - val_loss: 0.8723 - val_mse: 0.8723 - val_mae: 0.7221\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1981 - mse: 0.1981 - mae: 0.3345 - val_loss: 0.8701 - val_mse: 0.8701 - val_mae: 0.7226\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1956 - mse: 0.1956 - mae: 0.3275 - val_loss: 0.8709 - val_mse: 0.8709 - val_mae: 0.7221\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1765 - mse: 0.1765 - mae: 0.3135 - val_loss: 0.8572 - val_mse: 0.8572 - val_mae: 0.7193\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1669 - mse: 0.1669 - mae: 0.3059 - val_loss: 0.8578 - val_mse: 0.8578 - val_mae: 0.7198\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1720 - mse: 0.1720 - mae: 0.3064 - val_loss: 0.9083 - val_mse: 0.9083 - val_mae: 0.7421\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.1699 - mse: 0.1699 - mae: 0.3079 - val_loss: 0.8641 - val_mse: 0.8641 - val_mae: 0.7240\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1614 - mse: 0.1614 - mae: 0.3028 - val_loss: 0.8697 - val_mse: 0.8697 - val_mae: 0.7314\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.1527 - mse: 0.1527 - mae: 0.2941 - val_loss: 0.8562 - val_mse: 0.8562 - val_mae: 0.7160\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1418 - mse: 0.1418 - mae: 0.2802 - val_loss: 0.8516 - val_mse: 0.8516 - val_mae: 0.7205\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1371 - mse: 0.1371 - mae: 0.2762 - val_loss: 0.8477 - val_mse: 0.8477 - val_mae: 0.7202\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1247 - mse: 0.1247 - mae: 0.2621 - val_loss: 0.8554 - val_mse: 0.8554 - val_mae: 0.7216\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1153 - mse: 0.1153 - mae: 0.2540 - val_loss: 0.8492 - val_mse: 0.8492 - val_mae: 0.7167\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.1110 - mse: 0.1110 - mae: 0.2504 - val_loss: 0.8032 - val_mse: 0.8032 - val_mae: 0.6963\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1133 - mse: 0.1133 - mae: 0.2525 - val_loss: 0.8254 - val_mse: 0.8254 - val_mae: 0.7116\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1039 - mse: 0.1039 - mae: 0.2433 - val_loss: 0.7885 - val_mse: 0.7885 - val_mae: 0.6923\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0991 - mse: 0.0991 - mae: 0.2383 - val_loss: 0.7552 - val_mse: 0.7552 - val_mae: 0.6751\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.1018 - mse: 0.1018 - mae: 0.2406 - val_loss: 0.7385 - val_mse: 0.7385 - val_mae: 0.6674\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0983 - mse: 0.0983 - mae: 0.2333 - val_loss: 0.7267 - val_mse: 0.7267 - val_mae: 0.6628\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0870 - mse: 0.0870 - mae: 0.2204 - val_loss: 0.7299 - val_mse: 0.7299 - val_mae: 0.6610\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0922 - mse: 0.0922 - mae: 0.2284 - val_loss: 0.6858 - val_mse: 0.6858 - val_mae: 0.6409\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0857 - mse: 0.0857 - mae: 0.2194 - val_loss: 0.6915 - val_mse: 0.6915 - val_mae: 0.6399\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0886 - mse: 0.0886 - mae: 0.2215 - val_loss: 0.6854 - val_mse: 0.6854 - val_mae: 0.6363\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0862 - mse: 0.0862 - mae: 0.2212 - val_loss: 0.6300 - val_mse: 0.6300 - val_mae: 0.6059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0791 - mse: 0.0791 - mae: 0.2096 - val_loss: 0.6189 - val_mse: 0.6189 - val_mae: 0.6007\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.0873 - mse: 0.0873 - mae: 0.2209 - val_loss: 0.6062 - val_mse: 0.6062 - val_mae: 0.5971\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0850 - mse: 0.0850 - mae: 0.2186 - val_loss: 0.5745 - val_mse: 0.5745 - val_mae: 0.5749\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.0848 - mse: 0.0848 - mae: 0.2161 - val_loss: 0.5598 - val_mse: 0.5598 - val_mae: 0.5762\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0854 - mse: 0.0854 - mae: 0.2197 - val_loss: 0.5562 - val_mse: 0.5562 - val_mae: 0.5621\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0804 - mse: 0.0804 - mae: 0.2130 - val_loss: 0.5538 - val_mse: 0.5538 - val_mae: 0.5530\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0764 - mse: 0.0764 - mae: 0.2062 - val_loss: 0.5394 - val_mse: 0.5394 - val_mae: 0.5474\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0740 - mse: 0.0740 - mae: 0.2011 - val_loss: 0.5342 - val_mse: 0.5342 - val_mae: 0.5458\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0700 - mse: 0.0700 - mae: 0.1953 - val_loss: 0.5183 - val_mse: 0.5183 - val_mae: 0.5438\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0760 - mse: 0.0760 - mae: 0.2041 - val_loss: 0.5020 - val_mse: 0.5020 - val_mae: 0.5296\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0677 - mse: 0.0677 - mae: 0.1959 - val_loss: 0.4853 - val_mse: 0.4853 - val_mae: 0.5203\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0729 - mse: 0.0729 - mae: 0.2016 - val_loss: 0.5047 - val_mse: 0.5047 - val_mae: 0.5328\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0688 - mse: 0.0688 - mae: 0.1958 - val_loss: 0.4848 - val_mse: 0.4848 - val_mae: 0.5159\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0644 - mse: 0.0644 - mae: 0.1898 - val_loss: 0.5036 - val_mse: 0.5036 - val_mae: 0.5333\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0640 - mse: 0.0640 - mae: 0.1899 - val_loss: 0.4466 - val_mse: 0.4466 - val_mae: 0.4965\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0616 - mse: 0.0616 - mae: 0.1845 - val_loss: 0.4536 - val_mse: 0.4536 - val_mae: 0.4993\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0617 - mse: 0.0617 - mae: 0.1847 - val_loss: 0.4415 - val_mse: 0.4415 - val_mae: 0.4927\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0570 - mse: 0.0570 - mae: 0.1781 - val_loss: 0.4231 - val_mse: 0.4231 - val_mae: 0.4757\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0565 - mse: 0.0565 - mae: 0.1774 - val_loss: 0.4524 - val_mse: 0.4524 - val_mae: 0.4954\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0554 - mse: 0.0554 - mae: 0.1750 - val_loss: 0.4375 - val_mse: 0.4375 - val_mae: 0.4837\n",
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0564 - mse: 0.0564 - mae: 0.1766 - val_loss: 0.4416 - val_mse: 0.4416 - val_mae: 0.4882\n",
      "Epoch 58/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0552 - mse: 0.0552 - mae: 0.1753 - val_loss: 0.4339 - val_mse: 0.4339 - val_mae: 0.4849\n",
      "Epoch 59/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0636 - mse: 0.0636 - mae: 0.1845 - val_loss: 0.4522 - val_mse: 0.4522 - val_mae: 0.4851\n",
      "Epoch 60/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0625 - mse: 0.0625 - mae: 0.1826 - val_loss: 0.4312 - val_mse: 0.4312 - val_mae: 0.4744\n",
      "Epoch 61/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.0633 - mse: 0.0633 - mae: 0.1866 - val_loss: 0.4173 - val_mse: 0.4173 - val_mae: 0.4638\n",
      "Epoch 62/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0630 - mse: 0.0630 - mae: 0.1858 - val_loss: 0.4228 - val_mse: 0.4228 - val_mae: 0.4699\n",
      "Epoch 63/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0616 - mse: 0.0616 - mae: 0.1870 - val_loss: 0.4309 - val_mse: 0.4309 - val_mae: 0.4775\n",
      "Epoch 64/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0554 - mse: 0.0554 - mae: 0.1769 - val_loss: 0.4264 - val_mse: 0.4264 - val_mae: 0.4689\n",
      "Epoch 65/3000\n",
      "10664/10664 [==============================] - 0s 24us/sample - loss: 0.0502 - mse: 0.0502 - mae: 0.1664 - val_loss: 0.4119 - val_mse: 0.4119 - val_mae: 0.4611\n",
      "Epoch 66/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0486 - mse: 0.0486 - mae: 0.1630 - val_loss: 0.4198 - val_mse: 0.4198 - val_mae: 0.4628\n",
      "Epoch 67/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0495 - mse: 0.0495 - mae: 0.1659 - val_loss: 0.4209 - val_mse: 0.4209 - val_mae: 0.4662\n",
      "Epoch 68/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0551 - mse: 0.0551 - mae: 0.1733 - val_loss: 0.4192 - val_mse: 0.4192 - val_mae: 0.4593\n",
      "Epoch 69/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0488 - mse: 0.0488 - mae: 0.1649 - val_loss: 0.4187 - val_mse: 0.4187 - val_mae: 0.4607\n",
      "Epoch 70/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0519 - mse: 0.0519 - mae: 0.1703 - val_loss: 0.4192 - val_mse: 0.4192 - val_mae: 0.4608\n",
      "Epoch 71/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0454 - mse: 0.0454 - mae: 0.1583 - val_loss: 0.4428 - val_mse: 0.4428 - val_mae: 0.4722\n",
      "Epoch 72/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.0511 - mse: 0.0511 - mae: 0.1693 - val_loss: 0.4118 - val_mse: 0.4118 - val_mae: 0.4537\n",
      "Epoch 73/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0476 - mse: 0.0476 - mae: 0.1630 - val_loss: 0.4141 - val_mse: 0.4141 - val_mae: 0.4564\n",
      "Epoch 74/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0483 - mse: 0.0483 - mae: 0.1634 - val_loss: 0.4128 - val_mse: 0.4128 - val_mae: 0.4512\n",
      "Epoch 75/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0514 - mse: 0.0514 - mae: 0.1690 - val_loss: 0.4170 - val_mse: 0.4170 - val_mae: 0.4587\n",
      "Epoch 76/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0517 - mse: 0.0517 - mae: 0.1678 - val_loss: 0.4112 - val_mse: 0.4112 - val_mae: 0.4545\n",
      "Epoch 77/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0499 - mse: 0.0499 - mae: 0.1660 - val_loss: 0.4184 - val_mse: 0.4184 - val_mae: 0.4549\n",
      "Epoch 78/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0469 - mse: 0.0469 - mae: 0.1608 - val_loss: 0.4044 - val_mse: 0.4044 - val_mae: 0.4444\n",
      "Epoch 79/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0475 - mse: 0.0475 - mae: 0.1637 - val_loss: 0.4048 - val_mse: 0.4048 - val_mae: 0.4428\n",
      "Epoch 80/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0505 - mse: 0.0505 - mae: 0.1657 - val_loss: 0.4103 - val_mse: 0.4103 - val_mae: 0.4488\n",
      "Epoch 81/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0532 - mse: 0.0532 - mae: 0.1734 - val_loss: 0.4012 - val_mse: 0.4012 - val_mae: 0.4442\n",
      "Epoch 82/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0443 - mse: 0.0443 - mae: 0.1575 - val_loss: 0.4190 - val_mse: 0.4190 - val_mae: 0.4604\n",
      "Epoch 83/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0429 - mse: 0.0429 - mae: 0.1552 - val_loss: 0.4003 - val_mse: 0.4003 - val_mae: 0.4444\n",
      "Epoch 84/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.0419 - mse: 0.0419 - mae: 0.1534 - val_loss: 0.4197 - val_mse: 0.4197 - val_mae: 0.4506\n",
      "Epoch 85/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0440 - mse: 0.0440 - mae: 0.1550 - val_loss: 0.4118 - val_mse: 0.4118 - val_mae: 0.4500\n",
      "Epoch 86/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0417 - mse: 0.0417 - mae: 0.1511 - val_loss: 0.4190 - val_mse: 0.4190 - val_mae: 0.4555\n",
      "Epoch 87/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0462 - mse: 0.0462 - mae: 0.1579 - val_loss: 0.4075 - val_mse: 0.4075 - val_mae: 0.4465\n",
      "Epoch 88/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0440 - mse: 0.0440 - mae: 0.1522 - val_loss: 0.4068 - val_mse: 0.4068 - val_mae: 0.4493\n",
      "Epoch 89/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0425 - mse: 0.0425 - mae: 0.1537 - val_loss: 0.4124 - val_mse: 0.4124 - val_mae: 0.4484\n",
      "Epoch 90/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0417 - mse: 0.0417 - mae: 0.1515 - val_loss: 0.4165 - val_mse: 0.4165 - val_mae: 0.4493\n",
      "Epoch 91/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.0403 - mse: 0.0403 - mae: 0.1491 - val_loss: 0.4001 - val_mse: 0.4001 - val_mae: 0.4381\n",
      "Epoch 92/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0397 - mse: 0.0397 - mae: 0.1482 - val_loss: 0.4017 - val_mse: 0.4017 - val_mae: 0.4388\n",
      "Epoch 93/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0400 - mse: 0.0400 - mae: 0.1472 - val_loss: 0.4049 - val_mse: 0.4049 - val_mae: 0.4402\n",
      "Epoch 94/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0405 - mse: 0.0405 - mae: 0.1499 - val_loss: 0.4078 - val_mse: 0.4078 - val_mae: 0.4416\n",
      "Epoch 95/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0438 - mse: 0.0438 - mae: 0.1555 - val_loss: 0.4092 - val_mse: 0.4092 - val_mae: 0.4442\n",
      "Epoch 96/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0420 - mse: 0.0420 - mae: 0.1526 - val_loss: 0.4059 - val_mse: 0.4059 - val_mae: 0.4440\n",
      "Epoch 97/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0420 - mse: 0.0420 - mae: 0.1523 - val_loss: 0.4127 - val_mse: 0.4127 - val_mae: 0.4468\n",
      "Epoch 98/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0394 - mse: 0.0394 - mae: 0.1480 - val_loss: 0.4012 - val_mse: 0.4012 - val_mae: 0.4392\n",
      "Epoch 99/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0395 - mse: 0.0395 - mae: 0.1464 - val_loss: 0.3954 - val_mse: 0.3954 - val_mae: 0.4358\n",
      "Epoch 100/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0409 - mse: 0.0409 - mae: 0.1480 - val_loss: 0.4116 - val_mse: 0.4116 - val_mae: 0.4419\n",
      "Epoch 101/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0407 - mse: 0.0407 - mae: 0.1499 - val_loss: 0.3949 - val_mse: 0.3949 - val_mae: 0.4391\n",
      "Epoch 102/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0365 - mse: 0.0365 - mae: 0.1426 - val_loss: 0.4065 - val_mse: 0.4065 - val_mae: 0.4386\n",
      "Epoch 103/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0351 - mse: 0.0351 - mae: 0.1385 - val_loss: 0.3941 - val_mse: 0.3941 - val_mae: 0.4319\n",
      "Epoch 104/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0325 - mse: 0.0325 - mae: 0.1324 - val_loss: 0.3975 - val_mse: 0.3975 - val_mae: 0.4341\n",
      "Epoch 105/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0311 - mse: 0.0311 - mae: 0.1296 - val_loss: 0.4005 - val_mse: 0.4005 - val_mae: 0.4390\n",
      "Epoch 106/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0310 - mse: 0.0310 - mae: 0.1294 - val_loss: 0.3990 - val_mse: 0.3990 - val_mae: 0.4315\n",
      "Epoch 107/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0326 - mse: 0.0326 - mae: 0.1312 - val_loss: 0.3980 - val_mse: 0.3980 - val_mae: 0.4331\n",
      "Epoch 108/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0295 - mse: 0.0295 - mae: 0.1266 - val_loss: 0.3874 - val_mse: 0.3874 - val_mae: 0.4275\n",
      "Epoch 109/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0293 - mse: 0.0293 - mae: 0.1266 - val_loss: 0.3921 - val_mse: 0.3921 - val_mae: 0.4306\n",
      "Epoch 110/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0290 - mse: 0.0290 - mae: 0.1252 - val_loss: 0.4022 - val_mse: 0.4022 - val_mae: 0.4363\n",
      "Epoch 111/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0272 - mse: 0.0272 - mae: 0.1219 - val_loss: 0.3933 - val_mse: 0.3933 - val_mae: 0.4329\n",
      "Epoch 112/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0300 - mse: 0.0300 - mae: 0.1277 - val_loss: 0.3995 - val_mse: 0.3995 - val_mae: 0.4347\n",
      "Epoch 113/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0298 - mse: 0.0298 - mae: 0.1277 - val_loss: 0.4046 - val_mse: 0.4046 - val_mae: 0.4372\n",
      "Epoch 114/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0337 - mse: 0.0337 - mae: 0.1358 - val_loss: 0.3956 - val_mse: 0.3956 - val_mae: 0.4328\n",
      "Epoch 115/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0367 - mse: 0.0367 - mae: 0.1419 - val_loss: 0.4005 - val_mse: 0.4005 - val_mae: 0.4318\n",
      "Epoch 116/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0327 - mse: 0.0327 - mae: 0.1347 - val_loss: 0.3971 - val_mse: 0.3971 - val_mae: 0.4305\n",
      "Epoch 117/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0335 - mse: 0.0335 - mae: 0.1362 - val_loss: 0.3873 - val_mse: 0.3873 - val_mae: 0.4282\n",
      "Epoch 118/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0365 - mse: 0.0365 - mae: 0.1423 - val_loss: 0.4039 - val_mse: 0.4039 - val_mae: 0.4377\n",
      "Epoch 119/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0329 - mse: 0.0329 - mae: 0.1344 - val_loss: 0.3987 - val_mse: 0.3987 - val_mae: 0.4362\n",
      "Epoch 120/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0309 - mse: 0.0309 - mae: 0.1315 - val_loss: 0.3949 - val_mse: 0.3949 - val_mae: 0.4301\n",
      "Epoch 121/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0293 - mse: 0.0293 - mae: 0.1252 - val_loss: 0.3874 - val_mse: 0.3874 - val_mae: 0.4286\n",
      "Epoch 122/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0348 - mse: 0.0348 - mae: 0.1345 - val_loss: 0.3934 - val_mse: 0.3934 - val_mae: 0.4334\n",
      "Epoch 123/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0317 - mse: 0.0317 - mae: 0.1315 - val_loss: 0.3979 - val_mse: 0.3979 - val_mae: 0.4344\n",
      "Epoch 124/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0302 - mse: 0.0302 - mae: 0.1289 - val_loss: 0.3960 - val_mse: 0.3960 - val_mae: 0.4320\n",
      "Epoch 125/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0309 - mse: 0.0309 - mae: 0.1304 - val_loss: 0.3896 - val_mse: 0.3896 - val_mae: 0.4253\n",
      "Epoch 126/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0310 - mse: 0.0310 - mae: 0.1274 - val_loss: 0.3862 - val_mse: 0.3862 - val_mae: 0.4276\n",
      "Epoch 127/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0306 - mse: 0.0306 - mae: 0.1289 - val_loss: 0.3912 - val_mse: 0.3912 - val_mae: 0.4274\n",
      "Epoch 128/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0315 - mse: 0.0315 - mae: 0.1310 - val_loss: 0.3971 - val_mse: 0.3971 - val_mae: 0.4320\n",
      "Epoch 129/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0318 - mse: 0.0318 - mae: 0.1331 - val_loss: 0.3896 - val_mse: 0.3896 - val_mae: 0.4239\n",
      "Epoch 130/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0306 - mse: 0.0306 - mae: 0.1301 - val_loss: 0.3849 - val_mse: 0.3849 - val_mae: 0.4231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0321 - mse: 0.0321 - mae: 0.1338 - val_loss: 0.3959 - val_mse: 0.3959 - val_mae: 0.4325\n",
      "Epoch 132/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.0327 - mse: 0.0327 - mae: 0.1332 - val_loss: 0.3882 - val_mse: 0.3882 - val_mae: 0.4258\n",
      "Epoch 133/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0295 - mse: 0.0295 - mae: 0.1255 - val_loss: 0.3814 - val_mse: 0.3814 - val_mae: 0.4261\n",
      "Epoch 134/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0319 - mse: 0.0319 - mae: 0.1300 - val_loss: 0.4076 - val_mse: 0.4076 - val_mae: 0.4400\n",
      "Epoch 135/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0300 - mse: 0.0300 - mae: 0.1290 - val_loss: 0.3934 - val_mse: 0.3934 - val_mae: 0.4300\n",
      "Epoch 136/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0292 - mse: 0.0292 - mae: 0.1266 - val_loss: 0.3989 - val_mse: 0.3989 - val_mae: 0.4310\n",
      "Epoch 137/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0304 - mse: 0.0304 - mae: 0.1271 - val_loss: 0.3955 - val_mse: 0.3955 - val_mae: 0.4343\n",
      "Epoch 138/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0347 - mse: 0.0347 - mae: 0.1362 - val_loss: 0.3991 - val_mse: 0.3991 - val_mae: 0.4360\n",
      "Epoch 139/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0343 - mse: 0.0343 - mae: 0.1370 - val_loss: 0.3927 - val_mse: 0.3927 - val_mae: 0.4295\n",
      "Epoch 140/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0357 - mse: 0.0357 - mae: 0.1370 - val_loss: 0.4043 - val_mse: 0.4043 - val_mae: 0.4405\n",
      "Epoch 141/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0359 - mse: 0.0359 - mae: 0.1385 - val_loss: 0.4019 - val_mse: 0.4019 - val_mae: 0.4423\n",
      "Epoch 142/3000\n",
      "10664/10664 [==============================] - 0s 21us/sample - loss: 0.0363 - mse: 0.0363 - mae: 0.1410 - val_loss: 0.3917 - val_mse: 0.3917 - val_mae: 0.4272\n",
      "Epoch 143/3000\n",
      "10664/10664 [==============================] - 0s 22us/sample - loss: 0.0325 - mse: 0.0325 - mae: 0.1329 - val_loss: 0.3887 - val_mse: 0.3887 - val_mae: 0.4314\n",
      "Avg. MAE: 0.394303\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 71us/sample - loss: 3.3348 - mse: 3.3348 - mae: 1.3343 - val_loss: 7.6170 - val_mse: 7.6170 - val_mae: 2.2737\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 1.3270 - mse: 1.3270 - mae: 0.8404 - val_loss: 3.4848 - val_mse: 3.4848 - val_mae: 1.3843\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.9656 - mse: 0.9656 - mae: 0.7082 - val_loss: 2.3896 - val_mse: 2.3896 - val_mae: 1.1985\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.6892 - mse: 0.6892 - mae: 0.6203 - val_loss: 7.4683 - val_mse: 7.4683 - val_mae: 2.3757\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.6363 - mse: 0.6363 - mae: 0.5952 - val_loss: 2.4173 - val_mse: 2.4173 - val_mae: 1.2829\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.5773 - mse: 0.5773 - mae: 0.5664 - val_loss: 1.6135 - val_mse: 1.6135 - val_mae: 1.0504\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.5387 - mse: 0.5387 - mae: 0.5483 - val_loss: 2.5899 - val_mse: 2.5899 - val_mae: 1.3982\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.5180 - mse: 0.5180 - mae: 0.5346 - val_loss: 1.7046 - val_mse: 1.7046 - val_mae: 1.1093\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4961 - mse: 0.4961 - mae: 0.5253 - val_loss: 1.3217 - val_mse: 1.3217 - val_mae: 0.9728\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4835 - mse: 0.4835 - mae: 0.5226 - val_loss: 1.6007 - val_mse: 1.6007 - val_mae: 1.0934\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4677 - mse: 0.4677 - mae: 0.5075 - val_loss: 1.1702 - val_mse: 1.1702 - val_mae: 0.9183\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4571 - mse: 0.4571 - mae: 0.5022 - val_loss: 1.1973 - val_mse: 1.1973 - val_mae: 0.9331\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4470 - mse: 0.4470 - mae: 0.4988 - val_loss: 1.2905 - val_mse: 1.2905 - val_mae: 0.9778\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4362 - mse: 0.4362 - mae: 0.4912 - val_loss: 1.1805 - val_mse: 1.1805 - val_mae: 0.9299\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4248 - mse: 0.4248 - mae: 0.4849 - val_loss: 1.0632 - val_mse: 1.0632 - val_mae: 0.8742\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4124 - mse: 0.4124 - mae: 0.4770 - val_loss: 1.0915 - val_mse: 1.0915 - val_mae: 0.8887\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4037 - mse: 0.4037 - mae: 0.4733 - val_loss: 0.9499 - val_mse: 0.9499 - val_mae: 0.8199\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3958 - mse: 0.3958 - mae: 0.4667 - val_loss: 0.9074 - val_mse: 0.9074 - val_mae: 0.7968\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3856 - mse: 0.3856 - mae: 0.4617 - val_loss: 0.9099 - val_mse: 0.9099 - val_mae: 0.7966\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3797 - mse: 0.3797 - mae: 0.4593 - val_loss: 0.8672 - val_mse: 0.8672 - val_mae: 0.7763\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3700 - mse: 0.3700 - mae: 0.4536 - val_loss: 0.8300 - val_mse: 0.8300 - val_mae: 0.7563\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3623 - mse: 0.3623 - mae: 0.4476 - val_loss: 0.8047 - val_mse: 0.8047 - val_mae: 0.7418\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3566 - mse: 0.3566 - mae: 0.4472 - val_loss: 0.7918 - val_mse: 0.7918 - val_mae: 0.7353\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3462 - mse: 0.3462 - mae: 0.4360 - val_loss: 0.7211 - val_mse: 0.7211 - val_mae: 0.6931\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3412 - mse: 0.3412 - mae: 0.4386 - val_loss: 0.7602 - val_mse: 0.7602 - val_mae: 0.7165\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3358 - mse: 0.3358 - mae: 0.4332 - val_loss: 0.7046 - val_mse: 0.7046 - val_mae: 0.6856\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3242 - mse: 0.3242 - mae: 0.4236 - val_loss: 0.6865 - val_mse: 0.6865 - val_mae: 0.6721\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3227 - mse: 0.3227 - mae: 0.4251 - val_loss: 0.6584 - val_mse: 0.6584 - val_mae: 0.6560\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3195 - mse: 0.3195 - mae: 0.4256 - val_loss: 0.6574 - val_mse: 0.6574 - val_mae: 0.6581\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3119 - mse: 0.3119 - mae: 0.4160 - val_loss: 0.6562 - val_mse: 0.6562 - val_mae: 0.6508\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3085 - mse: 0.3085 - mae: 0.4168 - val_loss: 0.6221 - val_mse: 0.6221 - val_mae: 0.6331\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3028 - mse: 0.3028 - mae: 0.4126 - val_loss: 0.6010 - val_mse: 0.6010 - val_mae: 0.6218\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2933 - mse: 0.2933 - mae: 0.4074 - val_loss: 0.6547 - val_mse: 0.6547 - val_mae: 0.6489\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2920 - mse: 0.2920 - mae: 0.4083 - val_loss: 0.5931 - val_mse: 0.5931 - val_mae: 0.6143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2800 - mse: 0.2800 - mae: 0.3953 - val_loss: 0.5773 - val_mse: 0.5773 - val_mae: 0.6051\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2725 - mse: 0.2725 - mae: 0.3917 - val_loss: 0.5853 - val_mse: 0.5853 - val_mae: 0.6100\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2735 - mse: 0.2735 - mae: 0.3936 - val_loss: 0.5601 - val_mse: 0.5601 - val_mae: 0.5930\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2665 - mse: 0.2665 - mae: 0.3869 - val_loss: 0.5559 - val_mse: 0.5559 - val_mae: 0.5914\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2669 - mse: 0.2669 - mae: 0.3861 - val_loss: 0.5563 - val_mse: 0.5563 - val_mae: 0.5937\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2638 - mse: 0.2638 - mae: 0.3851 - val_loss: 0.5656 - val_mse: 0.5656 - val_mae: 0.5924\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2612 - mse: 0.2612 - mae: 0.3855 - val_loss: 0.5678 - val_mse: 0.5678 - val_mae: 0.5946\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2606 - mse: 0.2606 - mae: 0.3821 - val_loss: 0.5524 - val_mse: 0.5524 - val_mae: 0.5883\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2505 - mse: 0.2505 - mae: 0.3772 - val_loss: 0.5316 - val_mse: 0.5316 - val_mae: 0.5671\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2576 - mse: 0.2576 - mae: 0.3783 - val_loss: 0.5267 - val_mse: 0.5267 - val_mae: 0.5704\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2533 - mse: 0.2533 - mae: 0.3817 - val_loss: 0.5216 - val_mse: 0.5216 - val_mae: 0.5686\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2422 - mse: 0.2422 - mae: 0.3675 - val_loss: 0.5286 - val_mse: 0.5286 - val_mae: 0.5695\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2405 - mse: 0.2405 - mae: 0.3689 - val_loss: 0.5255 - val_mse: 0.5255 - val_mae: 0.5658\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2307 - mse: 0.2307 - mae: 0.3584 - val_loss: 0.5230 - val_mse: 0.5230 - val_mae: 0.5631\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2358 - mse: 0.2358 - mae: 0.3660 - val_loss: 0.5097 - val_mse: 0.5097 - val_mae: 0.5558\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2345 - mse: 0.2345 - mae: 0.3634 - val_loss: 0.4851 - val_mse: 0.4851 - val_mae: 0.5382\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2280 - mse: 0.2280 - mae: 0.3585 - val_loss: 0.5108 - val_mse: 0.5108 - val_mae: 0.5564\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2321 - mse: 0.2321 - mae: 0.3610 - val_loss: 0.5078 - val_mse: 0.5078 - val_mae: 0.5531\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2287 - mse: 0.2287 - mae: 0.3598 - val_loss: 0.5066 - val_mse: 0.5066 - val_mae: 0.5510\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2257 - mse: 0.2257 - mae: 0.3566 - val_loss: 0.5160 - val_mse: 0.5160 - val_mae: 0.5653\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2286 - mse: 0.2286 - mae: 0.3630 - val_loss: 0.4886 - val_mse: 0.4886 - val_mae: 0.5441\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2210 - mse: 0.2210 - mae: 0.3564 - val_loss: 0.4618 - val_mse: 0.4618 - val_mae: 0.5216\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2202 - mse: 0.2202 - mae: 0.3564 - val_loss: 0.4690 - val_mse: 0.4690 - val_mae: 0.5291\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2201 - mse: 0.2201 - mae: 0.3538 - val_loss: 0.4805 - val_mse: 0.4805 - val_mae: 0.5294\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2174 - mse: 0.2174 - mae: 0.3543 - val_loss: 0.4854 - val_mse: 0.4854 - val_mae: 0.5313\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2152 - mse: 0.2152 - mae: 0.3497 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.5249\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2257 - mse: 0.2257 - mae: 0.3525 - val_loss: 0.4866 - val_mse: 0.4866 - val_mae: 0.5368\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2436 - mse: 0.2436 - mae: 0.3601 - val_loss: 0.4906 - val_mse: 0.4906 - val_mae: 0.5426\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2313 - mse: 0.2313 - mae: 0.3588 - val_loss: 0.4958 - val_mse: 0.4958 - val_mae: 0.5396\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2169 - mse: 0.2169 - mae: 0.3504 - val_loss: 0.4957 - val_mse: 0.4957 - val_mae: 0.5364\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2080 - mse: 0.2080 - mae: 0.3435 - val_loss: 0.4918 - val_mse: 0.4918 - val_mae: 0.5326\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2050 - mse: 0.2050 - mae: 0.3410 - val_loss: 0.4708 - val_mse: 0.4708 - val_mae: 0.5232\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 70us/sample - loss: 3.4654 - mse: 3.4654 - mae: 1.3793 - val_loss: 13.2828 - val_mse: 13.2828 - val_mae: 3.2780\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 1.4012 - mse: 1.4012 - mae: 0.8809 - val_loss: 4.4179 - val_mse: 4.4179 - val_mae: 1.6390\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.9382 - mse: 0.9382 - mae: 0.7079 - val_loss: 3.9310 - val_mse: 3.9310 - val_mae: 1.6227\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.7139 - mse: 0.7139 - mae: 0.6399 - val_loss: 9.0827 - val_mse: 9.0827 - val_mae: 2.6188\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.6342 - mse: 0.6342 - mae: 0.5981 - val_loss: 2.5855 - val_mse: 2.5855 - val_mae: 1.3540\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.5892 - mse: 0.5892 - mae: 0.5783 - val_loss: 2.5520 - val_mse: 2.5520 - val_mae: 1.3605\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.5390 - mse: 0.5390 - mae: 0.5533 - val_loss: 3.7738 - val_mse: 3.7738 - val_mae: 1.6741\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.5189 - mse: 0.5189 - mae: 0.5386 - val_loss: 2.3726 - val_mse: 2.3726 - val_mae: 1.3425\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.5077 - mse: 0.5077 - mae: 0.5338 - val_loss: 2.3962 - val_mse: 2.3962 - val_mae: 1.3509\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4886 - mse: 0.4886 - mae: 0.5237 - val_loss: 2.5280 - val_mse: 2.5280 - val_mae: 1.3707\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4732 - mse: 0.4732 - mae: 0.5181 - val_loss: 1.8616 - val_mse: 1.8616 - val_mae: 1.1867\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4597 - mse: 0.4597 - mae: 0.5093 - val_loss: 2.0130 - val_mse: 2.0130 - val_mae: 1.2457\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4475 - mse: 0.4475 - mae: 0.4999 - val_loss: 1.8766 - val_mse: 1.8766 - val_mae: 1.1976\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.4350 - mse: 0.4350 - mae: 0.4936 - val_loss: 1.8150 - val_mse: 1.8150 - val_mae: 1.1783\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4227 - mse: 0.4227 - mae: 0.4860 - val_loss: 1.7130 - val_mse: 1.7130 - val_mae: 1.1381\n",
      "Epoch 16/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4167 - mse: 0.4167 - mae: 0.4822 - val_loss: 1.5898 - val_mse: 1.5898 - val_mae: 1.0927\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4064 - mse: 0.4064 - mae: 0.4763 - val_loss: 1.3667 - val_mse: 1.3667 - val_mae: 1.0059\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3981 - mse: 0.3981 - mae: 0.4737 - val_loss: 1.2916 - val_mse: 1.2916 - val_mae: 0.9719\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3877 - mse: 0.3877 - mae: 0.4648 - val_loss: 1.1840 - val_mse: 1.1840 - val_mae: 0.9193\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.3812 - mse: 0.3812 - mae: 0.4615 - val_loss: 1.2277 - val_mse: 1.2277 - val_mae: 0.9336\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3723 - mse: 0.3723 - mae: 0.4581 - val_loss: 1.1400 - val_mse: 1.1400 - val_mae: 0.9007\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3635 - mse: 0.3635 - mae: 0.4516 - val_loss: 1.0808 - val_mse: 1.0808 - val_mae: 0.8681\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3584 - mse: 0.3584 - mae: 0.4471 - val_loss: 1.0037 - val_mse: 1.0037 - val_mae: 0.8272\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3486 - mse: 0.3486 - mae: 0.4418 - val_loss: 0.9638 - val_mse: 0.9638 - val_mae: 0.8096\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3403 - mse: 0.3403 - mae: 0.4368 - val_loss: 0.8962 - val_mse: 0.8962 - val_mae: 0.7775\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3311 - mse: 0.3311 - mae: 0.4302 - val_loss: 0.8707 - val_mse: 0.8707 - val_mae: 0.7636\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3262 - mse: 0.3262 - mae: 0.4276 - val_loss: 0.8435 - val_mse: 0.8435 - val_mae: 0.7478\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3198 - mse: 0.3198 - mae: 0.4243 - val_loss: 0.8041 - val_mse: 0.8041 - val_mae: 0.7215\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3162 - mse: 0.3162 - mae: 0.4200 - val_loss: 0.7647 - val_mse: 0.7647 - val_mae: 0.7032\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3122 - mse: 0.3122 - mae: 0.4189 - val_loss: 0.7435 - val_mse: 0.7435 - val_mae: 0.6861\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3044 - mse: 0.3044 - mae: 0.4125 - val_loss: 0.6942 - val_mse: 0.6942 - val_mae: 0.6630\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3040 - mse: 0.3040 - mae: 0.4139 - val_loss: 0.7262 - val_mse: 0.7262 - val_mae: 0.6720\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2996 - mse: 0.2996 - mae: 0.4120 - val_loss: 0.6861 - val_mse: 0.6861 - val_mae: 0.6620\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2954 - mse: 0.2954 - mae: 0.4086 - val_loss: 0.7211 - val_mse: 0.7211 - val_mae: 0.6654\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2869 - mse: 0.2869 - mae: 0.4021 - val_loss: 0.6547 - val_mse: 0.6547 - val_mae: 0.6428\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2796 - mse: 0.2796 - mae: 0.3957 - val_loss: 0.6761 - val_mse: 0.6761 - val_mae: 0.6495\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2826 - mse: 0.2826 - mae: 0.4023 - val_loss: 0.6386 - val_mse: 0.6386 - val_mae: 0.6245\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2712 - mse: 0.2712 - mae: 0.3903 - val_loss: 0.6165 - val_mse: 0.6165 - val_mae: 0.6130\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2696 - mse: 0.2696 - mae: 0.3907 - val_loss: 0.6211 - val_mse: 0.6211 - val_mae: 0.6142\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2641 - mse: 0.2641 - mae: 0.3852 - val_loss: 0.6226 - val_mse: 0.6226 - val_mae: 0.6111\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2607 - mse: 0.2607 - mae: 0.3825 - val_loss: 0.5891 - val_mse: 0.5891 - val_mae: 0.5998\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2547 - mse: 0.2547 - mae: 0.3777 - val_loss: 0.6137 - val_mse: 0.6137 - val_mae: 0.6173\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2509 - mse: 0.2509 - mae: 0.3792 - val_loss: 0.5945 - val_mse: 0.5945 - val_mae: 0.6047\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2502 - mse: 0.2502 - mae: 0.3789 - val_loss: 0.5558 - val_mse: 0.5558 - val_mae: 0.5796\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2476 - mse: 0.2476 - mae: 0.3741 - val_loss: 0.5777 - val_mse: 0.5777 - val_mae: 0.5836\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2401 - mse: 0.2401 - mae: 0.3689 - val_loss: 0.5516 - val_mse: 0.5516 - val_mae: 0.5780\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2387 - mse: 0.2387 - mae: 0.3680 - val_loss: 0.5474 - val_mse: 0.5474 - val_mae: 0.5686\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2339 - mse: 0.2339 - mae: 0.3658 - val_loss: 0.5398 - val_mse: 0.5398 - val_mae: 0.5663\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2271 - mse: 0.2271 - mae: 0.3558 - val_loss: 0.5627 - val_mse: 0.5627 - val_mae: 0.5829\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2294 - mse: 0.2294 - mae: 0.3644 - val_loss: 0.5173 - val_mse: 0.5173 - val_mae: 0.5501\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2337 - mse: 0.2337 - mae: 0.3635 - val_loss: 0.5140 - val_mse: 0.5140 - val_mae: 0.5498\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2259 - mse: 0.2259 - mae: 0.3586 - val_loss: 0.5439 - val_mse: 0.5439 - val_mae: 0.5632\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2194 - mse: 0.2194 - mae: 0.3500 - val_loss: 0.5532 - val_mse: 0.5532 - val_mae: 0.5714\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2251 - mse: 0.2251 - mae: 0.3563 - val_loss: 0.5456 - val_mse: 0.5456 - val_mae: 0.5596\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2139 - mse: 0.2139 - mae: 0.3458 - val_loss: 0.5178 - val_mse: 0.5178 - val_mae: 0.5514\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2167 - mse: 0.2167 - mae: 0.3488 - val_loss: 0.5533 - val_mse: 0.5533 - val_mae: 0.5542\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2145 - mse: 0.2145 - mae: 0.3493 - val_loss: 0.4891 - val_mse: 0.4891 - val_mae: 0.5351\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2075 - mse: 0.2075 - mae: 0.3400 - val_loss: 0.5467 - val_mse: 0.5467 - val_mae: 0.5523\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2031 - mse: 0.2031 - mae: 0.3396 - val_loss: 0.5205 - val_mse: 0.5205 - val_mae: 0.5398\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2019 - mse: 0.2019 - mae: 0.3361 - val_loss: 0.5269 - val_mse: 0.5269 - val_mae: 0.5478\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2100 - mse: 0.2100 - mae: 0.3453 - val_loss: 0.5177 - val_mse: 0.5177 - val_mae: 0.5471\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2095 - mse: 0.2095 - mae: 0.3448 - val_loss: 0.5046 - val_mse: 0.5046 - val_mae: 0.5389\n",
      "Epoch 63/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2046 - mse: 0.2046 - mae: 0.3398 - val_loss: 0.5253 - val_mse: 0.5253 - val_mae: 0.5523\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2074 - mse: 0.2074 - mae: 0.3414 - val_loss: 0.5377 - val_mse: 0.5377 - val_mae: 0.5579\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1963 - mse: 0.1963 - mae: 0.3357 - val_loss: 0.4644 - val_mse: 0.4644 - val_mae: 0.5084\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1934 - mse: 0.1934 - mae: 0.3297 - val_loss: 0.5234 - val_mse: 0.5234 - val_mae: 0.5338\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1989 - mse: 0.1989 - mae: 0.3357 - val_loss: 0.5033 - val_mse: 0.5033 - val_mae: 0.5330\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2076 - mse: 0.2076 - mae: 0.3387 - val_loss: 0.5450 - val_mse: 0.5450 - val_mae: 0.5588\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1983 - mse: 0.1983 - mae: 0.3353 - val_loss: 0.4705 - val_mse: 0.4705 - val_mae: 0.5133\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1922 - mse: 0.1922 - mae: 0.3250 - val_loss: 0.5188 - val_mse: 0.5188 - val_mae: 0.5304\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1913 - mse: 0.1913 - mae: 0.3288 - val_loss: 0.4825 - val_mse: 0.4825 - val_mae: 0.5194\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1889 - mse: 0.1889 - mae: 0.3281 - val_loss: 0.4803 - val_mse: 0.4803 - val_mae: 0.5154\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1881 - mse: 0.1881 - mae: 0.3273 - val_loss: 0.4749 - val_mse: 0.4749 - val_mae: 0.5157\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1791 - mse: 0.1791 - mae: 0.3184 - val_loss: 0.4717 - val_mse: 0.4717 - val_mae: 0.5122\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1738 - mse: 0.1738 - mae: 0.3136 - val_loss: 0.4823 - val_mse: 0.4823 - val_mae: 0.5207\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 72us/sample - loss: 3.2825 - mse: 3.2825 - mae: 1.3481 - val_loss: 7.4484 - val_mse: 7.4484 - val_mae: 2.2743\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 1.3478 - mse: 1.3478 - mae: 0.8452 - val_loss: 4.0881 - val_mse: 4.0881 - val_mae: 1.4235\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.9493 - mse: 0.9493 - mae: 0.7068 - val_loss: 3.7976 - val_mse: 3.7976 - val_mae: 1.5885\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.7329 - mse: 0.7329 - mae: 0.6459 - val_loss: 5.8471 - val_mse: 5.8471 - val_mae: 2.1156\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.6185 - mse: 0.6185 - mae: 0.5807 - val_loss: 1.6262 - val_mse: 1.6262 - val_mae: 0.9667\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.5920 - mse: 0.5920 - mae: 0.5747 - val_loss: 2.5408 - val_mse: 2.5408 - val_mae: 1.3489\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.5471 - mse: 0.5471 - mae: 0.5584 - val_loss: 3.1479 - val_mse: 3.1479 - val_mae: 1.5553\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.5231 - mse: 0.5231 - mae: 0.5359 - val_loss: 1.7862 - val_mse: 1.7862 - val_mae: 1.1375\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.5079 - mse: 0.5079 - mae: 0.5336 - val_loss: 2.0378 - val_mse: 2.0378 - val_mae: 1.2303\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4894 - mse: 0.4894 - mae: 0.5222 - val_loss: 1.7792 - val_mse: 1.7792 - val_mae: 1.1455\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4726 - mse: 0.4726 - mae: 0.5106 - val_loss: 1.5366 - val_mse: 1.5366 - val_mae: 1.0663\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4584 - mse: 0.4584 - mae: 0.5053 - val_loss: 1.4079 - val_mse: 1.4079 - val_mae: 1.0115\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4465 - mse: 0.4465 - mae: 0.4977 - val_loss: 1.3813 - val_mse: 1.3813 - val_mae: 1.0096\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4360 - mse: 0.4360 - mae: 0.4930 - val_loss: 1.3752 - val_mse: 1.3752 - val_mae: 1.0114\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4281 - mse: 0.4281 - mae: 0.4901 - val_loss: 1.2633 - val_mse: 1.2633 - val_mae: 0.9632\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4206 - mse: 0.4206 - mae: 0.4815 - val_loss: 1.2074 - val_mse: 1.2074 - val_mae: 0.9376\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4058 - mse: 0.4058 - mae: 0.4745 - val_loss: 1.1720 - val_mse: 1.1720 - val_mae: 0.9231\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3966 - mse: 0.3966 - mae: 0.4710 - val_loss: 1.1561 - val_mse: 1.1561 - val_mae: 0.9172\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3884 - mse: 0.3884 - mae: 0.4655 - val_loss: 1.0782 - val_mse: 1.0782 - val_mae: 0.8818\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3813 - mse: 0.3813 - mae: 0.4630 - val_loss: 1.0293 - val_mse: 1.0293 - val_mae: 0.8600\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3719 - mse: 0.3719 - mae: 0.4574 - val_loss: 0.9329 - val_mse: 0.9329 - val_mae: 0.8073\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3678 - mse: 0.3678 - mae: 0.4510 - val_loss: 0.9383 - val_mse: 0.9383 - val_mae: 0.8130\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3674 - mse: 0.3674 - mae: 0.4564 - val_loss: 0.9831 - val_mse: 0.9831 - val_mae: 0.8376\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3560 - mse: 0.3560 - mae: 0.4463 - val_loss: 0.8045 - val_mse: 0.8045 - val_mae: 0.7397\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3462 - mse: 0.3462 - mae: 0.4417 - val_loss: 0.9344 - val_mse: 0.9344 - val_mae: 0.8106\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3374 - mse: 0.3374 - mae: 0.4355 - val_loss: 0.8012 - val_mse: 0.8012 - val_mae: 0.7411\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3268 - mse: 0.3268 - mae: 0.4274 - val_loss: 0.7963 - val_mse: 0.7963 - val_mae: 0.7371\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3222 - mse: 0.3222 - mae: 0.4258 - val_loss: 0.7502 - val_mse: 0.7502 - val_mae: 0.7126\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3180 - mse: 0.3180 - mae: 0.4208 - val_loss: 0.7278 - val_mse: 0.7278 - val_mae: 0.6975\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3116 - mse: 0.3116 - mae: 0.4204 - val_loss: 0.7364 - val_mse: 0.7364 - val_mae: 0.7060\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3029 - mse: 0.3029 - mae: 0.4133 - val_loss: 0.6694 - val_mse: 0.6694 - val_mae: 0.6643\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2961 - mse: 0.2961 - mae: 0.4074 - val_loss: 0.6820 - val_mse: 0.6820 - val_mae: 0.6718\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2887 - mse: 0.2887 - mae: 0.4024 - val_loss: 0.6536 - val_mse: 0.6536 - val_mae: 0.6520\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2849 - mse: 0.2849 - mae: 0.4003 - val_loss: 0.6683 - val_mse: 0.6683 - val_mae: 0.6616\n",
      "Epoch 35/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2819 - mse: 0.2819 - mae: 0.3964 - val_loss: 0.6190 - val_mse: 0.6190 - val_mae: 0.6295\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2816 - mse: 0.2816 - mae: 0.3985 - val_loss: 0.6848 - val_mse: 0.6848 - val_mae: 0.6686\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2921 - mse: 0.2921 - mae: 0.4064 - val_loss: 0.6159 - val_mse: 0.6159 - val_mae: 0.6262\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2772 - mse: 0.2772 - mae: 0.3987 - val_loss: 0.5945 - val_mse: 0.5945 - val_mae: 0.6128\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2717 - mse: 0.2717 - mae: 0.3904 - val_loss: 0.6046 - val_mse: 0.6046 - val_mae: 0.6174\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2669 - mse: 0.2669 - mae: 0.3906 - val_loss: 0.5467 - val_mse: 0.5467 - val_mae: 0.5820\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2734 - mse: 0.2734 - mae: 0.3961 - val_loss: 0.5722 - val_mse: 0.5722 - val_mae: 0.5955\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2665 - mse: 0.2665 - mae: 0.3881 - val_loss: 0.5831 - val_mse: 0.5831 - val_mae: 0.6017\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2580 - mse: 0.2580 - mae: 0.3838 - val_loss: 0.5761 - val_mse: 0.5761 - val_mae: 0.5915\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2601 - mse: 0.2601 - mae: 0.3878 - val_loss: 0.5448 - val_mse: 0.5448 - val_mae: 0.5734\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2506 - mse: 0.2506 - mae: 0.3750 - val_loss: 0.5297 - val_mse: 0.5297 - val_mae: 0.5637\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2441 - mse: 0.2441 - mae: 0.3693 - val_loss: 0.5143 - val_mse: 0.5143 - val_mae: 0.5556\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2435 - mse: 0.2435 - mae: 0.3690 - val_loss: 0.5119 - val_mse: 0.5119 - val_mae: 0.5508\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2530 - mse: 0.2530 - mae: 0.3722 - val_loss: 0.5419 - val_mse: 0.5419 - val_mae: 0.5668\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2519 - mse: 0.2519 - mae: 0.3776 - val_loss: 0.5170 - val_mse: 0.5170 - val_mae: 0.5552\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2421 - mse: 0.2421 - mae: 0.3672 - val_loss: 0.5198 - val_mse: 0.5198 - val_mae: 0.5532\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2321 - mse: 0.2321 - mae: 0.3641 - val_loss: 0.5122 - val_mse: 0.5122 - val_mae: 0.5461\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2326 - mse: 0.2326 - mae: 0.3574 - val_loss: 0.5005 - val_mse: 0.5005 - val_mae: 0.5388\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2284 - mse: 0.2284 - mae: 0.3561 - val_loss: 0.5364 - val_mse: 0.5364 - val_mae: 0.5605\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2308 - mse: 0.2308 - mae: 0.3619 - val_loss: 0.5288 - val_mse: 0.5288 - val_mae: 0.5527\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2242 - mse: 0.2242 - mae: 0.3557 - val_loss: 0.5001 - val_mse: 0.5001 - val_mae: 0.5367\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2200 - mse: 0.2200 - mae: 0.3545 - val_loss: 0.5053 - val_mse: 0.5053 - val_mae: 0.5416\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2115 - mse: 0.2115 - mae: 0.3449 - val_loss: 0.4923 - val_mse: 0.4923 - val_mae: 0.5318\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2132 - mse: 0.2132 - mae: 0.3478 - val_loss: 0.4826 - val_mse: 0.4826 - val_mae: 0.5237\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2099 - mse: 0.2099 - mae: 0.3423 - val_loss: 0.4927 - val_mse: 0.4927 - val_mae: 0.5264\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.2063 - mse: 0.2063 - mae: 0.3400 - val_loss: 0.5006 - val_mse: 0.5006 - val_mae: 0.5307\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2113 - mse: 0.2113 - mae: 0.3455 - val_loss: 0.5042 - val_mse: 0.5042 - val_mae: 0.5340\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2061 - mse: 0.2061 - mae: 0.3432 - val_loss: 0.4974 - val_mse: 0.4974 - val_mae: 0.5247\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2062 - mse: 0.2062 - mae: 0.3385 - val_loss: 0.4740 - val_mse: 0.4740 - val_mae: 0.5157\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2140 - mse: 0.2140 - mae: 0.3494 - val_loss: 0.5014 - val_mse: 0.5014 - val_mae: 0.5313\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2090 - mse: 0.2090 - mae: 0.3468 - val_loss: 0.5121 - val_mse: 0.5121 - val_mae: 0.5382\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2113 - mse: 0.2113 - mae: 0.3465 - val_loss: 0.4951 - val_mse: 0.4951 - val_mae: 0.5241\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1968 - mse: 0.1968 - mae: 0.3338 - val_loss: 0.4713 - val_mse: 0.4713 - val_mae: 0.5128\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1965 - mse: 0.1965 - mae: 0.3340 - val_loss: 0.4676 - val_mse: 0.4676 - val_mae: 0.5059\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1962 - mse: 0.1962 - mae: 0.3367 - val_loss: 0.4869 - val_mse: 0.4869 - val_mae: 0.5147\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2011 - mse: 0.2011 - mae: 0.3390 - val_loss: 0.4789 - val_mse: 0.4789 - val_mae: 0.5087\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1806 - mse: 0.1806 - mae: 0.3198 - val_loss: 0.4941 - val_mse: 0.4941 - val_mae: 0.5230\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1844 - mse: 0.1844 - mae: 0.3254 - val_loss: 0.5063 - val_mse: 0.5063 - val_mae: 0.5272\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1853 - mse: 0.1853 - mae: 0.3248 - val_loss: 0.4921 - val_mse: 0.4921 - val_mae: 0.5230\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1836 - mse: 0.1836 - mae: 0.3256 - val_loss: 0.4685 - val_mse: 0.4685 - val_mae: 0.4977\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1874 - mse: 0.1874 - mae: 0.3238 - val_loss: 0.4909 - val_mse: 0.4909 - val_mae: 0.5268\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1738 - mse: 0.1738 - mae: 0.3163 - val_loss: 0.4610 - val_mse: 0.4610 - val_mae: 0.4974\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1784 - mse: 0.1784 - mae: 0.3180 - val_loss: 0.4476 - val_mse: 0.4476 - val_mae: 0.4952\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1708 - mse: 0.1708 - mae: 0.3115 - val_loss: 0.4556 - val_mse: 0.4556 - val_mae: 0.4968\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1712 - mse: 0.1712 - mae: 0.3116 - val_loss: 0.4666 - val_mse: 0.4666 - val_mae: 0.5024\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1668 - mse: 0.1668 - mae: 0.3065 - val_loss: 0.4453 - val_mse: 0.4453 - val_mae: 0.4893\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1635 - mse: 0.1635 - mae: 0.3066 - val_loss: 0.4603 - val_mse: 0.4603 - val_mae: 0.4927\n",
      "Epoch 82/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1649 - mse: 0.1649 - mae: 0.3071 - val_loss: 0.4457 - val_mse: 0.4457 - val_mae: 0.4870\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1604 - mse: 0.1604 - mae: 0.3026 - val_loss: 0.4476 - val_mse: 0.4476 - val_mae: 0.4830\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1593 - mse: 0.1593 - mae: 0.3010 - val_loss: 0.4516 - val_mse: 0.4516 - val_mae: 0.4882\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1603 - mse: 0.1603 - mae: 0.3012 - val_loss: 0.4448 - val_mse: 0.4448 - val_mae: 0.4823\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1597 - mse: 0.1597 - mae: 0.2979 - val_loss: 0.4615 - val_mse: 0.4615 - val_mae: 0.4930\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1556 - mse: 0.1556 - mae: 0.2944 - val_loss: 0.4827 - val_mse: 0.4827 - val_mae: 0.5016\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1642 - mse: 0.1642 - mae: 0.3092 - val_loss: 0.4867 - val_mse: 0.4867 - val_mae: 0.5138\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 10us/sample - loss: 0.1672 - mse: 0.1672 - mae: 0.3107 - val_loss: 0.4703 - val_mse: 0.4703 - val_mae: 0.4993\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1659 - mse: 0.1659 - mae: 0.3086 - val_loss: 0.4382 - val_mse: 0.4382 - val_mae: 0.4818\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1612 - mse: 0.1612 - mae: 0.3044 - val_loss: 0.4780 - val_mse: 0.4780 - val_mae: 0.4889\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1663 - mse: 0.1663 - mae: 0.3049 - val_loss: 0.4480 - val_mse: 0.4480 - val_mae: 0.4838\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1625 - mse: 0.1625 - mae: 0.3019 - val_loss: 0.4703 - val_mse: 0.4703 - val_mae: 0.5004\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1637 - mse: 0.1637 - mae: 0.3068 - val_loss: 0.4574 - val_mse: 0.4574 - val_mae: 0.4955\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1555 - mse: 0.1555 - mae: 0.2965 - val_loss: 0.4938 - val_mse: 0.4938 - val_mae: 0.5125\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1690 - mse: 0.1690 - mae: 0.3114 - val_loss: 0.4521 - val_mse: 0.4521 - val_mae: 0.4890\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1629 - mse: 0.1629 - mae: 0.3042 - val_loss: 0.4624 - val_mse: 0.4624 - val_mae: 0.4871\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1537 - mse: 0.1537 - mae: 0.2962 - val_loss: 0.4661 - val_mse: 0.4661 - val_mae: 0.4863\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1550 - mse: 0.1550 - mae: 0.2959 - val_loss: 0.4724 - val_mse: 0.4724 - val_mae: 0.4963\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1575 - mse: 0.1575 - mae: 0.3031 - val_loss: 0.4796 - val_mse: 0.4796 - val_mae: 0.4975\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 69us/sample - loss: 3.1469 - mse: 3.1469 - mae: 1.3127 - val_loss: 17.7732 - val_mse: 17.7732 - val_mae: 3.8375\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 1.3728 - mse: 1.3728 - mae: 0.8262 - val_loss: 3.3452 - val_mse: 3.3452 - val_mae: 1.3329\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.9737 - mse: 0.9737 - mae: 0.7150 - val_loss: 4.1512 - val_mse: 4.1512 - val_mae: 1.6802\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.7023 - mse: 0.7023 - mae: 0.6268 - val_loss: 7.6675 - val_mse: 7.6675 - val_mae: 2.4513\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.6061 - mse: 0.6061 - mae: 0.5812 - val_loss: 2.1724 - val_mse: 2.1724 - val_mae: 1.2251\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.5711 - mse: 0.5711 - mae: 0.5671 - val_loss: 3.1449 - val_mse: 3.1449 - val_mae: 1.5142\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.5352 - mse: 0.5352 - mae: 0.5429 - val_loss: 3.1752 - val_mse: 3.1752 - val_mae: 1.5540\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.5102 - mse: 0.5102 - mae: 0.5331 - val_loss: 2.6548 - val_mse: 2.6548 - val_mae: 1.4332\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4937 - mse: 0.4937 - mae: 0.5295 - val_loss: 2.5893 - val_mse: 2.5893 - val_mae: 1.4156\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4755 - mse: 0.4755 - mae: 0.5128 - val_loss: 1.9916 - val_mse: 1.9916 - val_mae: 1.2336\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4616 - mse: 0.4616 - mae: 0.5053 - val_loss: 2.0861 - val_mse: 2.0861 - val_mae: 1.2731\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4529 - mse: 0.4529 - mae: 0.5028 - val_loss: 1.8501 - val_mse: 1.8501 - val_mae: 1.1921\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4417 - mse: 0.4417 - mae: 0.4964 - val_loss: 1.6380 - val_mse: 1.6380 - val_mae: 1.1135\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.4298 - mse: 0.4298 - mae: 0.4868 - val_loss: 1.5901 - val_mse: 1.5901 - val_mae: 1.0969\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4212 - mse: 0.4212 - mae: 0.4863 - val_loss: 1.4856 - val_mse: 1.4856 - val_mae: 1.0584\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4136 - mse: 0.4136 - mae: 0.4779 - val_loss: 1.3094 - val_mse: 1.3094 - val_mae: 0.9862\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.4034 - mse: 0.4034 - mae: 0.4737 - val_loss: 1.3382 - val_mse: 1.3382 - val_mae: 0.9971\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3928 - mse: 0.3928 - mae: 0.4695 - val_loss: 1.2251 - val_mse: 1.2251 - val_mae: 0.9508\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3851 - mse: 0.3851 - mae: 0.4618 - val_loss: 1.1193 - val_mse: 1.1193 - val_mae: 0.8993\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3740 - mse: 0.3740 - mae: 0.4557 - val_loss: 1.1223 - val_mse: 1.1223 - val_mae: 0.9042\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3683 - mse: 0.3683 - mae: 0.4533 - val_loss: 1.0407 - val_mse: 1.0407 - val_mae: 0.8677\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3601 - mse: 0.3601 - mae: 0.4485 - val_loss: 0.9532 - val_mse: 0.9532 - val_mae: 0.8208\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3544 - mse: 0.3544 - mae: 0.4441 - val_loss: 0.9977 - val_mse: 0.9977 - val_mae: 0.8433\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3445 - mse: 0.3445 - mae: 0.4374 - val_loss: 0.8974 - val_mse: 0.8974 - val_mae: 0.7915\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.3416 - mse: 0.3416 - mae: 0.4363 - val_loss: 0.8412 - val_mse: 0.8412 - val_mae: 0.7605\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3305 - mse: 0.3305 - mae: 0.4299 - val_loss: 0.8442 - val_mse: 0.8442 - val_mae: 0.7629\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3256 - mse: 0.3256 - mae: 0.4258 - val_loss: 0.7763 - val_mse: 0.7763 - val_mae: 0.7248\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3178 - mse: 0.3178 - mae: 0.4219 - val_loss: 0.7913 - val_mse: 0.7913 - val_mae: 0.7338\n",
      "Epoch 29/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3127 - mse: 0.3127 - mae: 0.4183 - val_loss: 0.7513 - val_mse: 0.7513 - val_mae: 0.7081\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.3045 - mse: 0.3045 - mae: 0.4135 - val_loss: 0.7148 - val_mse: 0.7148 - val_mae: 0.6843\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3040 - mse: 0.3040 - mae: 0.4117 - val_loss: 0.6996 - val_mse: 0.6996 - val_mae: 0.6782\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2951 - mse: 0.2951 - mae: 0.4060 - val_loss: 0.6912 - val_mse: 0.6912 - val_mae: 0.6740\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2940 - mse: 0.2940 - mae: 0.4068 - val_loss: 0.6337 - val_mse: 0.6337 - val_mae: 0.6374\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2884 - mse: 0.2884 - mae: 0.4010 - val_loss: 0.6883 - val_mse: 0.6883 - val_mae: 0.6729\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2847 - mse: 0.2847 - mae: 0.4024 - val_loss: 0.6414 - val_mse: 0.6414 - val_mae: 0.6433\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2747 - mse: 0.2747 - mae: 0.3961 - val_loss: 0.6305 - val_mse: 0.6305 - val_mae: 0.6384\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2738 - mse: 0.2738 - mae: 0.3916 - val_loss: 0.6295 - val_mse: 0.6295 - val_mae: 0.6340\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2752 - mse: 0.2752 - mae: 0.3968 - val_loss: 0.6044 - val_mse: 0.6044 - val_mae: 0.6171\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2695 - mse: 0.2695 - mae: 0.3898 - val_loss: 0.5702 - val_mse: 0.5702 - val_mae: 0.5956\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2676 - mse: 0.2676 - mae: 0.3878 - val_loss: 0.5920 - val_mse: 0.5920 - val_mae: 0.6121\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2640 - mse: 0.2640 - mae: 0.3842 - val_loss: 0.5401 - val_mse: 0.5401 - val_mae: 0.5729\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2577 - mse: 0.2577 - mae: 0.3797 - val_loss: 0.5488 - val_mse: 0.5488 - val_mae: 0.5818\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2607 - mse: 0.2607 - mae: 0.3860 - val_loss: 0.5538 - val_mse: 0.5538 - val_mae: 0.5785\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2536 - mse: 0.2536 - mae: 0.3725 - val_loss: 0.5303 - val_mse: 0.5303 - val_mae: 0.5635\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2525 - mse: 0.2525 - mae: 0.3731 - val_loss: 0.5605 - val_mse: 0.5605 - val_mae: 0.5855\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2478 - mse: 0.2478 - mae: 0.3728 - val_loss: 0.5413 - val_mse: 0.5413 - val_mae: 0.5747\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2461 - mse: 0.2461 - mae: 0.3711 - val_loss: 0.5264 - val_mse: 0.5264 - val_mae: 0.5619\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2341 - mse: 0.2341 - mae: 0.3656 - val_loss: 0.5127 - val_mse: 0.5127 - val_mae: 0.5524\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2308 - mse: 0.2308 - mae: 0.3598 - val_loss: 0.5272 - val_mse: 0.5272 - val_mae: 0.5540\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2281 - mse: 0.2281 - mae: 0.3601 - val_loss: 0.4920 - val_mse: 0.4920 - val_mae: 0.5374\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2241 - mse: 0.2241 - mae: 0.3525 - val_loss: 0.5224 - val_mse: 0.5224 - val_mae: 0.5505\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2321 - mse: 0.2321 - mae: 0.3573 - val_loss: 0.5031 - val_mse: 0.5031 - val_mae: 0.5374\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2342 - mse: 0.2342 - mae: 0.3630 - val_loss: 0.5493 - val_mse: 0.5493 - val_mae: 0.5624\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2389 - mse: 0.2389 - mae: 0.3719 - val_loss: 0.5332 - val_mse: 0.5332 - val_mae: 0.5544\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2358 - mse: 0.2358 - mae: 0.3657 - val_loss: 0.5192 - val_mse: 0.5192 - val_mae: 0.5386\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2377 - mse: 0.2377 - mae: 0.3640 - val_loss: 0.4852 - val_mse: 0.4852 - val_mae: 0.5261\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2341 - mse: 0.2341 - mae: 0.3585 - val_loss: 0.5114 - val_mse: 0.5114 - val_mae: 0.5422\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2246 - mse: 0.2246 - mae: 0.3561 - val_loss: 0.4968 - val_mse: 0.4968 - val_mae: 0.5335\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2295 - mse: 0.2295 - mae: 0.3578 - val_loss: 0.5093 - val_mse: 0.5093 - val_mae: 0.5338\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2291 - mse: 0.2291 - mae: 0.3620 - val_loss: 0.4911 - val_mse: 0.4911 - val_mae: 0.5281\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2162 - mse: 0.2162 - mae: 0.3512 - val_loss: 0.4655 - val_mse: 0.4655 - val_mae: 0.5106\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2079 - mse: 0.2079 - mae: 0.3431 - val_loss: 0.4587 - val_mse: 0.4587 - val_mae: 0.5049\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2008 - mse: 0.2008 - mae: 0.3370 - val_loss: 0.4491 - val_mse: 0.4491 - val_mae: 0.4939\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1998 - mse: 0.1998 - mae: 0.3378 - val_loss: 0.4793 - val_mse: 0.4793 - val_mae: 0.5126\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2027 - mse: 0.2027 - mae: 0.3373 - val_loss: 0.4724 - val_mse: 0.4724 - val_mae: 0.5192\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2150 - mse: 0.2150 - mae: 0.3463 - val_loss: 0.4854 - val_mse: 0.4854 - val_mae: 0.5205\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2077 - mse: 0.2077 - mae: 0.3425 - val_loss: 0.4829 - val_mse: 0.4829 - val_mae: 0.5206\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.1998 - mse: 0.1998 - mae: 0.3371 - val_loss: 0.4561 - val_mse: 0.4561 - val_mae: 0.5027\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1902 - mse: 0.1902 - mae: 0.3300 - val_loss: 0.5004 - val_mse: 0.5004 - val_mae: 0.5182\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2095 - mse: 0.2095 - mae: 0.3480 - val_loss: 0.4888 - val_mse: 0.4888 - val_mae: 0.5137\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.2053 - mse: 0.2053 - mae: 0.3438 - val_loss: 0.4959 - val_mse: 0.4959 - val_mae: 0.5175\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2110 - mse: 0.2110 - mae: 0.3492 - val_loss: 0.4576 - val_mse: 0.4576 - val_mae: 0.4935\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 9us/sample - loss: 0.1959 - mse: 0.1959 - mae: 0.3342 - val_loss: 0.4566 - val_mse: 0.4566 - val_mae: 0.4991\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 70us/sample - loss: 2.4937 - mse: 2.4937 - mae: 1.1458 - val_loss: 6.4384 - val_mse: 6.4384 - val_mae: 1.5691\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 1.2474 - mse: 1.2474 - mae: 0.8147 - val_loss: 5.7648 - val_mse: 5.7648 - val_mae: 1.8170\n",
      "Epoch 3/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.8340 - mse: 0.8340 - mae: 0.6791 - val_loss: 1.6851 - val_mse: 1.6851 - val_mae: 1.0125\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.6728 - mse: 0.6728 - mae: 0.6133 - val_loss: 1.4568 - val_mse: 1.4568 - val_mae: 0.9709\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.5892 - mse: 0.5892 - mae: 0.5774 - val_loss: 1.4951 - val_mse: 1.4951 - val_mae: 1.0201\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.5354 - mse: 0.5354 - mae: 0.5524 - val_loss: 2.4761 - val_mse: 2.4761 - val_mae: 1.3838\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.5089 - mse: 0.5089 - mae: 0.5311 - val_loss: 2.2202 - val_mse: 2.2202 - val_mae: 1.3189\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 10us/sample - loss: 0.4898 - mse: 0.4898 - mae: 0.5245 - val_loss: 1.8858 - val_mse: 1.8858 - val_mae: 1.2146\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.4678 - mse: 0.4678 - mae: 0.5126 - val_loss: 1.7142 - val_mse: 1.7142 - val_mae: 1.1492\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.4543 - mse: 0.4543 - mae: 0.5013 - val_loss: 1.4123 - val_mse: 1.4123 - val_mae: 1.0350\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.4417 - mse: 0.4417 - mae: 0.4976 - val_loss: 1.6890 - val_mse: 1.6890 - val_mae: 1.1410\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.4268 - mse: 0.4268 - mae: 0.4875 - val_loss: 1.2391 - val_mse: 1.2391 - val_mae: 0.9573\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.4182 - mse: 0.4182 - mae: 0.4789 - val_loss: 1.4458 - val_mse: 1.4458 - val_mae: 1.0456\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.4046 - mse: 0.4046 - mae: 0.4748 - val_loss: 1.3126 - val_mse: 1.3126 - val_mae: 0.9881\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 10us/sample - loss: 0.3963 - mse: 0.3963 - mae: 0.4696 - val_loss: 1.3286 - val_mse: 1.3286 - val_mae: 0.9975\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.3831 - mse: 0.3831 - mae: 0.4583 - val_loss: 1.3895 - val_mse: 1.3895 - val_mae: 1.0211\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.3775 - mse: 0.3775 - mae: 0.4583 - val_loss: 1.2161 - val_mse: 1.2161 - val_mae: 0.9440\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.3698 - mse: 0.3698 - mae: 0.4512 - val_loss: 1.1635 - val_mse: 1.1635 - val_mae: 0.9207\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.3635 - mse: 0.3635 - mae: 0.4482 - val_loss: 1.2373 - val_mse: 1.2373 - val_mae: 0.9575\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.3529 - mse: 0.3529 - mae: 0.4417 - val_loss: 1.2179 - val_mse: 1.2179 - val_mae: 0.9473\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.3424 - mse: 0.3424 - mae: 0.4342 - val_loss: 1.1785 - val_mse: 1.1785 - val_mae: 0.9286\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.3327 - mse: 0.3327 - mae: 0.4291 - val_loss: 1.1203 - val_mse: 1.1203 - val_mae: 0.9036\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.3261 - mse: 0.3261 - mae: 0.4226 - val_loss: 1.0746 - val_mse: 1.0746 - val_mae: 0.8816\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.3194 - mse: 0.3194 - mae: 0.4195 - val_loss: 1.0839 - val_mse: 1.0839 - val_mae: 0.8817\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.3193 - mse: 0.3193 - mae: 0.4200 - val_loss: 0.9281 - val_mse: 0.9281 - val_mae: 0.8102\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.3177 - mse: 0.3177 - mae: 0.4190 - val_loss: 0.9203 - val_mse: 0.9203 - val_mae: 0.8070\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.3213 - mse: 0.3213 - mae: 0.4241 - val_loss: 0.9925 - val_mse: 0.9925 - val_mae: 0.8306\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.3084 - mse: 0.3084 - mae: 0.4149 - val_loss: 0.8437 - val_mse: 0.8437 - val_mae: 0.7639\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2963 - mse: 0.2963 - mae: 0.4044 - val_loss: 0.9307 - val_mse: 0.9307 - val_mae: 0.8034\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2909 - mse: 0.2909 - mae: 0.4024 - val_loss: 0.8161 - val_mse: 0.8161 - val_mae: 0.7445\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.2862 - mse: 0.2862 - mae: 0.3990 - val_loss: 0.8572 - val_mse: 0.8572 - val_mae: 0.7676\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2745 - mse: 0.2745 - mae: 0.3932 - val_loss: 0.7912 - val_mse: 0.7912 - val_mae: 0.7328\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2801 - mse: 0.2801 - mae: 0.3959 - val_loss: 0.7868 - val_mse: 0.7868 - val_mae: 0.7293\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2724 - mse: 0.2724 - mae: 0.3914 - val_loss: 0.7305 - val_mse: 0.7305 - val_mae: 0.6943\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2653 - mse: 0.2653 - mae: 0.3869 - val_loss: 0.7561 - val_mse: 0.7561 - val_mae: 0.7137\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2619 - mse: 0.2619 - mae: 0.3829 - val_loss: 0.7597 - val_mse: 0.7597 - val_mae: 0.7165\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2584 - mse: 0.2584 - mae: 0.3782 - val_loss: 0.6641 - val_mse: 0.6641 - val_mae: 0.6599\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2582 - mse: 0.2582 - mae: 0.3816 - val_loss: 0.6594 - val_mse: 0.6594 - val_mae: 0.6563\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.2640 - mse: 0.2640 - mae: 0.3841 - val_loss: 0.6510 - val_mse: 0.6510 - val_mae: 0.6492\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2604 - mse: 0.2604 - mae: 0.3856 - val_loss: 0.6346 - val_mse: 0.6346 - val_mae: 0.6359\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2640 - mse: 0.2640 - mae: 0.3853 - val_loss: 0.6020 - val_mse: 0.6020 - val_mae: 0.6163\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.2490 - mse: 0.2490 - mae: 0.3745 - val_loss: 0.6381 - val_mse: 0.6381 - val_mae: 0.6355\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.2471 - mse: 0.2471 - mae: 0.3707 - val_loss: 0.5699 - val_mse: 0.5699 - val_mae: 0.6013\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.2481 - mse: 0.2481 - mae: 0.3732 - val_loss: 0.5918 - val_mse: 0.5918 - val_mae: 0.6118\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2426 - mse: 0.2426 - mae: 0.3686 - val_loss: 0.5433 - val_mse: 0.5433 - val_mae: 0.5737\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.2426 - mse: 0.2426 - mae: 0.3659 - val_loss: 0.5179 - val_mse: 0.5179 - val_mae: 0.5540\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2372 - mse: 0.2372 - mae: 0.3646 - val_loss: 0.5928 - val_mse: 0.5928 - val_mae: 0.6021\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.2298 - mse: 0.2298 - mae: 0.3601 - val_loss: 0.5506 - val_mse: 0.5506 - val_mae: 0.5825\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.2266 - mse: 0.2266 - mae: 0.3555 - val_loss: 0.5249 - val_mse: 0.5249 - val_mae: 0.5552\n",
      "Epoch 50/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2110 - mse: 0.2110 - mae: 0.3417 - val_loss: 0.5179 - val_mse: 0.5179 - val_mae: 0.5590\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.2097 - mse: 0.2097 - mae: 0.3415 - val_loss: 0.5220 - val_mse: 0.5220 - val_mae: 0.5555\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2168 - mse: 0.2168 - mae: 0.3473 - val_loss: 0.5251 - val_mse: 0.5251 - val_mae: 0.5628\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2108 - mse: 0.2108 - mae: 0.3448 - val_loss: 0.4983 - val_mse: 0.4983 - val_mae: 0.5344\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2117 - mse: 0.2117 - mae: 0.3465 - val_loss: 0.5061 - val_mse: 0.5061 - val_mae: 0.5503\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2062 - mse: 0.2062 - mae: 0.3425 - val_loss: 0.4925 - val_mse: 0.4925 - val_mae: 0.5339\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2019 - mse: 0.2019 - mae: 0.3383 - val_loss: 0.5140 - val_mse: 0.5140 - val_mae: 0.5463\n",
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1971 - mse: 0.1971 - mae: 0.3347 - val_loss: 0.4892 - val_mse: 0.4892 - val_mae: 0.5275\n",
      "Epoch 58/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1923 - mse: 0.1923 - mae: 0.3286 - val_loss: 0.4702 - val_mse: 0.4702 - val_mae: 0.5198\n",
      "Epoch 59/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.2030 - mse: 0.2030 - mae: 0.3408 - val_loss: 0.4663 - val_mse: 0.4663 - val_mae: 0.5132\n",
      "Epoch 60/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.2078 - mse: 0.2078 - mae: 0.3430 - val_loss: 0.4802 - val_mse: 0.4802 - val_mae: 0.5194\n",
      "Epoch 61/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1991 - mse: 0.1991 - mae: 0.3360 - val_loss: 0.4722 - val_mse: 0.4722 - val_mae: 0.5166\n",
      "Epoch 62/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1967 - mse: 0.1967 - mae: 0.3297 - val_loss: 0.4646 - val_mse: 0.4646 - val_mae: 0.5102\n",
      "Epoch 63/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1854 - mse: 0.1854 - mae: 0.3243 - val_loss: 0.4508 - val_mse: 0.4508 - val_mae: 0.4998\n",
      "Epoch 64/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1866 - mse: 0.1866 - mae: 0.3242 - val_loss: 0.4517 - val_mse: 0.4517 - val_mae: 0.4979\n",
      "Epoch 65/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.2002 - mse: 0.2002 - mae: 0.3357 - val_loss: 0.4651 - val_mse: 0.4651 - val_mae: 0.5113\n",
      "Epoch 66/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1937 - mse: 0.1937 - mae: 0.3326 - val_loss: 0.4579 - val_mse: 0.4579 - val_mae: 0.5041\n",
      "Epoch 67/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1906 - mse: 0.1906 - mae: 0.3250 - val_loss: 0.4756 - val_mse: 0.4756 - val_mae: 0.5201\n",
      "Epoch 68/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1985 - mse: 0.1985 - mae: 0.3312 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.5139\n",
      "Epoch 69/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1943 - mse: 0.1943 - mae: 0.3291 - val_loss: 0.4697 - val_mse: 0.4697 - val_mae: 0.5094\n",
      "Epoch 70/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1834 - mse: 0.1834 - mae: 0.3251 - val_loss: 0.4416 - val_mse: 0.4416 - val_mae: 0.4847\n",
      "Epoch 71/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1741 - mse: 0.1741 - mae: 0.3125 - val_loss: 0.4834 - val_mse: 0.4834 - val_mae: 0.4974\n",
      "Epoch 72/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1777 - mse: 0.1777 - mae: 0.3170 - val_loss: 0.4561 - val_mse: 0.4561 - val_mae: 0.4890\n",
      "Epoch 73/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1805 - mse: 0.1805 - mae: 0.3197 - val_loss: 0.4547 - val_mse: 0.4547 - val_mae: 0.4932\n",
      "Epoch 74/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1794 - mse: 0.1794 - mae: 0.3158 - val_loss: 0.4399 - val_mse: 0.4399 - val_mae: 0.4905\n",
      "Epoch 75/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1812 - mse: 0.1812 - mae: 0.3224 - val_loss: 0.4740 - val_mse: 0.4740 - val_mae: 0.5098\n",
      "Epoch 76/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1817 - mse: 0.1817 - mae: 0.3219 - val_loss: 0.4695 - val_mse: 0.4695 - val_mae: 0.4992\n",
      "Epoch 77/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1799 - mse: 0.1799 - mae: 0.3206 - val_loss: 0.4376 - val_mse: 0.4376 - val_mae: 0.4868\n",
      "Epoch 78/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1716 - mse: 0.1716 - mae: 0.3109 - val_loss: 0.4617 - val_mse: 0.4617 - val_mae: 0.4904\n",
      "Epoch 79/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1691 - mse: 0.1691 - mae: 0.3054 - val_loss: 0.4572 - val_mse: 0.4572 - val_mae: 0.4980\n",
      "Epoch 80/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1802 - mse: 0.1802 - mae: 0.3191 - val_loss: 0.4696 - val_mse: 0.4696 - val_mae: 0.5029\n",
      "Epoch 81/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1909 - mse: 0.1909 - mae: 0.3284 - val_loss: 0.4441 - val_mse: 0.4441 - val_mae: 0.4861\n",
      "Epoch 82/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1852 - mse: 0.1852 - mae: 0.3266 - val_loss: 0.4557 - val_mse: 0.4557 - val_mae: 0.4857\n",
      "Epoch 83/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1697 - mse: 0.1697 - mae: 0.3077 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4816\n",
      "Epoch 84/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1804 - mse: 0.1804 - mae: 0.3174 - val_loss: 0.4584 - val_mse: 0.4584 - val_mae: 0.4831\n",
      "Epoch 85/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1823 - mse: 0.1823 - mae: 0.3184 - val_loss: 0.4574 - val_mse: 0.4574 - val_mae: 0.4916\n",
      "Epoch 86/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1800 - mse: 0.1800 - mae: 0.3167 - val_loss: 0.4460 - val_mse: 0.4460 - val_mae: 0.4796\n",
      "Epoch 87/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1637 - mse: 0.1637 - mae: 0.3008 - val_loss: 0.4358 - val_mse: 0.4358 - val_mae: 0.4768\n",
      "Epoch 88/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1601 - mse: 0.1601 - mae: 0.2969 - val_loss: 0.4559 - val_mse: 0.4559 - val_mae: 0.4822\n",
      "Epoch 89/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1609 - mse: 0.1609 - mae: 0.2984 - val_loss: 0.4499 - val_mse: 0.4499 - val_mae: 0.4896\n",
      "Epoch 90/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1759 - mse: 0.1759 - mae: 0.3137 - val_loss: 0.4614 - val_mse: 0.4614 - val_mae: 0.4952\n",
      "Epoch 91/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1627 - mse: 0.1627 - mae: 0.3006 - val_loss: 0.4548 - val_mse: 0.4548 - val_mae: 0.4892\n",
      "Epoch 92/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1638 - mse: 0.1638 - mae: 0.2998 - val_loss: 0.4313 - val_mse: 0.4313 - val_mae: 0.4630\n",
      "Epoch 93/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1515 - mse: 0.1515 - mae: 0.2877 - val_loss: 0.4503 - val_mse: 0.4503 - val_mae: 0.4830\n",
      "Epoch 94/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1483 - mse: 0.1483 - mae: 0.2857 - val_loss: 0.4533 - val_mse: 0.4533 - val_mae: 0.4791\n",
      "Epoch 95/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1455 - mse: 0.1455 - mae: 0.2833 - val_loss: 0.4217 - val_mse: 0.4217 - val_mae: 0.4666\n",
      "Epoch 96/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1482 - mse: 0.1482 - mae: 0.2902 - val_loss: 0.4405 - val_mse: 0.4405 - val_mae: 0.4731\n",
      "Epoch 97/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1541 - mse: 0.1541 - mae: 0.2897 - val_loss: 0.4634 - val_mse: 0.4634 - val_mae: 0.4948\n",
      "Epoch 98/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1529 - mse: 0.1529 - mae: 0.2940 - val_loss: 0.4369 - val_mse: 0.4369 - val_mae: 0.4755\n",
      "Epoch 99/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1518 - mse: 0.1518 - mae: 0.2890 - val_loss: 0.4450 - val_mse: 0.4450 - val_mae: 0.4823\n",
      "Epoch 100/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1521 - mse: 0.1521 - mae: 0.2954 - val_loss: 0.4515 - val_mse: 0.4515 - val_mae: 0.4824\n",
      "Epoch 101/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1531 - mse: 0.1531 - mae: 0.2952 - val_loss: 0.4412 - val_mse: 0.4412 - val_mae: 0.4765\n",
      "Epoch 102/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1428 - mse: 0.1428 - mae: 0.2822 - val_loss: 0.4477 - val_mse: 0.4477 - val_mae: 0.4726\n",
      "Epoch 103/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1426 - mse: 0.1426 - mae: 0.2825 - val_loss: 0.4452 - val_mse: 0.4452 - val_mae: 0.4876\n",
      "Epoch 104/3000\n",
      "10664/10664 [==============================] - 0s 9us/sample - loss: 0.1441 - mse: 0.1441 - mae: 0.2867 - val_loss: 0.4462 - val_mse: 0.4462 - val_mae: 0.4712\n",
      "Epoch 105/3000\n",
      "10664/10664 [==============================] - 0s 8us/sample - loss: 0.1396 - mse: 0.1396 - mae: 0.2791 - val_loss: 0.4451 - val_mse: 0.4451 - val_mae: 0.4786\n",
      "Avg. MAE: 0.435874\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 2.2018 - mse: 2.2018 - mae: 1.1028 - val_loss: 3.4180 - val_mse: 3.4180 - val_mae: 1.3942\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 1.0856 - mse: 1.0856 - mae: 0.7882 - val_loss: 2.8354 - val_mse: 2.8354 - val_mae: 1.2862\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.8601 - mse: 0.8601 - mae: 0.7089 - val_loss: 1.8910 - val_mse: 1.8910 - val_mae: 1.0145\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.7370 - mse: 0.7370 - mae: 0.6494 - val_loss: 1.2611 - val_mse: 1.2611 - val_mae: 0.8224\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.6763 - mse: 0.6763 - mae: 0.6174 - val_loss: 1.1423 - val_mse: 1.1423 - val_mae: 0.8031\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6303 - mse: 0.6303 - mae: 0.5956 - val_loss: 1.1378 - val_mse: 1.1378 - val_mae: 0.8096\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6018 - mse: 0.6018 - mae: 0.5839 - val_loss: 1.1346 - val_mse: 1.1346 - val_mae: 0.8168\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5740 - mse: 0.5740 - mae: 0.5689 - val_loss: 1.1546 - val_mse: 1.1546 - val_mae: 0.8421\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.5533 - mse: 0.5533 - mae: 0.5569 - val_loss: 1.1778 - val_mse: 1.1778 - val_mae: 0.8645\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5306 - mse: 0.5306 - mae: 0.5455 - val_loss: 1.1676 - val_mse: 1.1676 - val_mae: 0.8646\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5141 - mse: 0.5141 - mae: 0.5378 - val_loss: 1.1454 - val_mse: 1.1454 - val_mae: 0.8564\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4995 - mse: 0.4995 - mae: 0.5292 - val_loss: 1.1357 - val_mse: 1.1357 - val_mae: 0.8551\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4854 - mse: 0.4854 - mae: 0.5231 - val_loss: 1.1317 - val_mse: 1.1317 - val_mae: 0.8576\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4682 - mse: 0.4682 - mae: 0.5124 - val_loss: 1.1243 - val_mse: 1.1243 - val_mae: 0.8564\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4575 - mse: 0.4575 - mae: 0.5065 - val_loss: 1.0751 - val_mse: 1.0751 - val_mae: 0.8298\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4451 - mse: 0.4451 - mae: 0.5000 - val_loss: 1.0300 - val_mse: 1.0300 - val_mae: 0.8028\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4334 - mse: 0.4334 - mae: 0.4945 - val_loss: 1.0136 - val_mse: 1.0136 - val_mae: 0.7922\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4215 - mse: 0.4215 - mae: 0.4870 - val_loss: 1.0051 - val_mse: 1.0051 - val_mae: 0.7922\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4092 - mse: 0.4092 - mae: 0.4803 - val_loss: 0.9902 - val_mse: 0.9902 - val_mae: 0.7854\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4040 - mse: 0.4040 - mae: 0.4766 - val_loss: 0.9736 - val_mse: 0.9736 - val_mae: 0.7769\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3923 - mse: 0.3923 - mae: 0.4701 - val_loss: 0.9606 - val_mse: 0.9606 - val_mae: 0.7693\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3850 - mse: 0.3850 - mae: 0.4667 - val_loss: 0.9509 - val_mse: 0.9509 - val_mae: 0.7627\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3774 - mse: 0.3774 - mae: 0.4636 - val_loss: 0.9329 - val_mse: 0.9329 - val_mae: 0.7492\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3700 - mse: 0.3700 - mae: 0.4588 - val_loss: 0.9168 - val_mse: 0.9168 - val_mae: 0.7401\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3593 - mse: 0.3593 - mae: 0.4509 - val_loss: 0.9033 - val_mse: 0.9033 - val_mae: 0.7380\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3525 - mse: 0.3525 - mae: 0.4473 - val_loss: 0.9005 - val_mse: 0.9005 - val_mae: 0.7350\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3460 - mse: 0.3460 - mae: 0.4434 - val_loss: 0.8917 - val_mse: 0.8917 - val_mae: 0.7329\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3397 - mse: 0.3397 - mae: 0.4387 - val_loss: 0.8795 - val_mse: 0.8795 - val_mae: 0.7306\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3314 - mse: 0.3314 - mae: 0.4332 - val_loss: 0.8759 - val_mse: 0.8759 - val_mae: 0.7306\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3285 - mse: 0.3285 - mae: 0.4329 - val_loss: 0.8711 - val_mse: 0.8711 - val_mae: 0.7252\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3201 - mse: 0.3201 - mae: 0.4264 - val_loss: 0.8639 - val_mse: 0.8639 - val_mae: 0.7250\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3154 - mse: 0.3154 - mae: 0.4226 - val_loss: 0.8549 - val_mse: 0.8549 - val_mae: 0.7202\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3096 - mse: 0.3096 - mae: 0.4188 - val_loss: 0.8462 - val_mse: 0.8462 - val_mae: 0.7132\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3055 - mse: 0.3055 - mae: 0.4163 - val_loss: 0.8406 - val_mse: 0.8406 - val_mae: 0.7135\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3006 - mse: 0.3006 - mae: 0.4127 - val_loss: 0.8422 - val_mse: 0.8422 - val_mae: 0.7132\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2950 - mse: 0.2950 - mae: 0.4098 - val_loss: 0.8402 - val_mse: 0.8402 - val_mae: 0.7122\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2904 - mse: 0.2904 - mae: 0.4066 - val_loss: 0.8319 - val_mse: 0.8319 - val_mae: 0.7126\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2841 - mse: 0.2841 - mae: 0.4013 - val_loss: 0.8271 - val_mse: 0.8271 - val_mae: 0.7099\n",
      "Epoch 39/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2807 - mse: 0.2807 - mae: 0.3993 - val_loss: 0.8210 - val_mse: 0.8210 - val_mae: 0.7065\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2755 - mse: 0.2755 - mae: 0.3956 - val_loss: 0.8181 - val_mse: 0.8181 - val_mae: 0.7047\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2738 - mse: 0.2738 - mae: 0.3953 - val_loss: 0.8067 - val_mse: 0.8067 - val_mae: 0.7003\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2692 - mse: 0.2692 - mae: 0.3926 - val_loss: 0.8087 - val_mse: 0.8087 - val_mae: 0.6994\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2645 - mse: 0.2645 - mae: 0.3892 - val_loss: 0.8101 - val_mse: 0.8101 - val_mae: 0.6992\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2591 - mse: 0.2591 - mae: 0.3849 - val_loss: 0.7985 - val_mse: 0.7985 - val_mae: 0.6956\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2611 - mse: 0.2611 - mae: 0.3864 - val_loss: 0.8046 - val_mse: 0.8046 - val_mae: 0.6963\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2559 - mse: 0.2559 - mae: 0.3816 - val_loss: 0.8041 - val_mse: 0.8041 - val_mae: 0.6945\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2515 - mse: 0.2515 - mae: 0.3792 - val_loss: 0.7942 - val_mse: 0.7942 - val_mae: 0.6936\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2529 - mse: 0.2529 - mae: 0.3798 - val_loss: 0.7883 - val_mse: 0.7883 - val_mae: 0.6928\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2479 - mse: 0.2479 - mae: 0.3761 - val_loss: 0.7908 - val_mse: 0.7908 - val_mae: 0.6940\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2423 - mse: 0.2423 - mae: 0.3734 - val_loss: 0.7941 - val_mse: 0.7941 - val_mae: 0.6939\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2397 - mse: 0.2397 - mae: 0.3697 - val_loss: 0.7859 - val_mse: 0.7859 - val_mae: 0.6907\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2362 - mse: 0.2362 - mae: 0.3670 - val_loss: 0.7936 - val_mse: 0.7936 - val_mae: 0.6928\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2354 - mse: 0.2354 - mae: 0.3671 - val_loss: 0.7816 - val_mse: 0.7816 - val_mae: 0.6872\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2302 - mse: 0.2302 - mae: 0.3621 - val_loss: 0.7835 - val_mse: 0.7835 - val_mae: 0.6893\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2299 - mse: 0.2299 - mae: 0.3637 - val_loss: 0.7791 - val_mse: 0.7791 - val_mae: 0.6911\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2278 - mse: 0.2278 - mae: 0.3618 - val_loss: 0.7767 - val_mse: 0.7767 - val_mae: 0.6875\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2302 - mse: 0.2302 - mae: 0.3651 - val_loss: 0.7777 - val_mse: 0.7777 - val_mae: 0.6860\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2232 - mse: 0.2232 - mae: 0.3558 - val_loss: 0.7676 - val_mse: 0.7676 - val_mae: 0.6837\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2256 - mse: 0.2256 - mae: 0.3583 - val_loss: 0.7839 - val_mse: 0.7839 - val_mae: 0.6935\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2263 - mse: 0.2263 - mae: 0.3583 - val_loss: 0.7683 - val_mse: 0.7683 - val_mae: 0.6876\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2240 - mse: 0.2240 - mae: 0.3574 - val_loss: 0.7770 - val_mse: 0.7770 - val_mae: 0.6897\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2146 - mse: 0.2146 - mae: 0.3498 - val_loss: 0.7703 - val_mse: 0.7703 - val_mae: 0.6861\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2106 - mse: 0.2106 - mae: 0.3476 - val_loss: 0.7623 - val_mse: 0.7623 - val_mae: 0.6839\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2066 - mse: 0.2066 - mae: 0.3439 - val_loss: 0.7710 - val_mse: 0.7710 - val_mae: 0.6865\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2074 - mse: 0.2074 - mae: 0.3449 - val_loss: 0.7420 - val_mse: 0.7420 - val_mae: 0.6724\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2052 - mse: 0.2052 - mae: 0.3422 - val_loss: 0.7581 - val_mse: 0.7581 - val_mae: 0.6777\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.2012 - mse: 0.2012 - mae: 0.3399 - val_loss: 0.7541 - val_mse: 0.7541 - val_mae: 0.6760\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.2006 - mse: 0.2006 - mae: 0.3398 - val_loss: 0.7375 - val_mse: 0.7375 - val_mae: 0.6690\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1968 - mse: 0.1968 - mae: 0.3374 - val_loss: 0.7551 - val_mse: 0.7551 - val_mae: 0.6750\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1976 - mse: 0.1976 - mae: 0.3374 - val_loss: 0.7484 - val_mse: 0.7484 - val_mae: 0.6721\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1931 - mse: 0.1931 - mae: 0.3336 - val_loss: 0.7334 - val_mse: 0.7334 - val_mae: 0.6660\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1911 - mse: 0.1911 - mae: 0.3311 - val_loss: 0.7338 - val_mse: 0.7338 - val_mae: 0.6628\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1921 - mse: 0.1921 - mae: 0.3335 - val_loss: 0.7154 - val_mse: 0.7154 - val_mae: 0.6532\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1918 - mse: 0.1918 - mae: 0.3314 - val_loss: 0.7067 - val_mse: 0.7067 - val_mae: 0.6494\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1862 - mse: 0.1862 - mae: 0.3281 - val_loss: 0.7216 - val_mse: 0.7216 - val_mae: 0.6573\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1856 - mse: 0.1856 - mae: 0.3270 - val_loss: 0.7121 - val_mse: 0.7121 - val_mae: 0.6496\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1811 - mse: 0.1811 - mae: 0.3219 - val_loss: 0.7059 - val_mse: 0.7059 - val_mae: 0.6455\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1819 - mse: 0.1819 - mae: 0.3228 - val_loss: 0.7087 - val_mse: 0.7087 - val_mae: 0.6471\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1786 - mse: 0.1786 - mae: 0.3197 - val_loss: 0.7075 - val_mse: 0.7075 - val_mae: 0.6482\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1787 - mse: 0.1787 - mae: 0.3197 - val_loss: 0.6909 - val_mse: 0.6909 - val_mae: 0.6394\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1742 - mse: 0.1742 - mae: 0.3159 - val_loss: 0.6993 - val_mse: 0.6993 - val_mae: 0.6430\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1732 - mse: 0.1732 - mae: 0.3154 - val_loss: 0.6698 - val_mse: 0.6698 - val_mae: 0.6269\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1742 - mse: 0.1742 - mae: 0.3158 - val_loss: 0.6817 - val_mse: 0.6817 - val_mae: 0.6333\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1696 - mse: 0.1696 - mae: 0.3117 - val_loss: 0.6690 - val_mse: 0.6690 - val_mae: 0.6273\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1693 - mse: 0.1693 - mae: 0.3115 - val_loss: 0.6742 - val_mse: 0.6742 - val_mae: 0.6271\n",
      "Epoch 86/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1655 - mse: 0.1655 - mae: 0.3092 - val_loss: 0.6571 - val_mse: 0.6571 - val_mae: 0.6193\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1665 - mse: 0.1665 - mae: 0.3074 - val_loss: 0.6735 - val_mse: 0.6735 - val_mae: 0.6277\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1699 - mse: 0.1699 - mae: 0.3124 - val_loss: 0.6557 - val_mse: 0.6557 - val_mae: 0.6172\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1656 - mse: 0.1656 - mae: 0.3073 - val_loss: 0.6636 - val_mse: 0.6636 - val_mae: 0.6196\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1663 - mse: 0.1663 - mae: 0.3083 - val_loss: 0.6487 - val_mse: 0.6487 - val_mae: 0.6117\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1627 - mse: 0.1627 - mae: 0.3059 - val_loss: 0.6555 - val_mse: 0.6555 - val_mae: 0.6155\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1603 - mse: 0.1603 - mae: 0.3033 - val_loss: 0.6416 - val_mse: 0.6416 - val_mae: 0.6097\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1611 - mse: 0.1611 - mae: 0.3037 - val_loss: 0.6482 - val_mse: 0.6482 - val_mae: 0.6108\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1583 - mse: 0.1583 - mae: 0.3005 - val_loss: 0.6439 - val_mse: 0.6439 - val_mae: 0.6083\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1623 - mse: 0.1623 - mae: 0.3065 - val_loss: 0.6338 - val_mse: 0.6338 - val_mae: 0.6030\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1573 - mse: 0.1573 - mae: 0.2999 - val_loss: 0.6416 - val_mse: 0.6416 - val_mae: 0.6082\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1581 - mse: 0.1581 - mae: 0.3014 - val_loss: 0.6436 - val_mse: 0.6436 - val_mae: 0.6074\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1569 - mse: 0.1569 - mae: 0.2994 - val_loss: 0.6272 - val_mse: 0.6272 - val_mae: 0.5984\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1521 - mse: 0.1521 - mae: 0.2947 - val_loss: 0.6415 - val_mse: 0.6415 - val_mae: 0.6047\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1532 - mse: 0.1532 - mae: 0.2963 - val_loss: 0.6235 - val_mse: 0.6235 - val_mae: 0.5960\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1546 - mse: 0.1546 - mae: 0.2979 - val_loss: 0.6237 - val_mse: 0.6237 - val_mae: 0.5954\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1496 - mse: 0.1496 - mae: 0.2923 - val_loss: 0.6271 - val_mse: 0.6271 - val_mae: 0.5977\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1492 - mse: 0.1492 - mae: 0.2922 - val_loss: 0.6078 - val_mse: 0.6078 - val_mae: 0.5861\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1496 - mse: 0.1496 - mae: 0.2925 - val_loss: 0.6174 - val_mse: 0.6174 - val_mae: 0.5913\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1515 - mse: 0.1515 - mae: 0.2947 - val_loss: 0.6199 - val_mse: 0.6199 - val_mae: 0.5932\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1455 - mse: 0.1455 - mae: 0.2893 - val_loss: 0.6006 - val_mse: 0.6006 - val_mae: 0.5837\n",
      "Epoch 107/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1464 - mse: 0.1464 - mae: 0.2898 - val_loss: 0.6046 - val_mse: 0.6046 - val_mae: 0.5831\n",
      "Epoch 108/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1416 - mse: 0.1416 - mae: 0.2842 - val_loss: 0.5899 - val_mse: 0.5899 - val_mae: 0.5761\n",
      "Epoch 109/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1434 - mse: 0.1434 - mae: 0.2871 - val_loss: 0.5983 - val_mse: 0.5983 - val_mae: 0.5816\n",
      "Epoch 110/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1399 - mse: 0.1399 - mae: 0.2827 - val_loss: 0.5902 - val_mse: 0.5902 - val_mae: 0.5741\n",
      "Epoch 111/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1477 - mse: 0.1477 - mae: 0.2913 - val_loss: 0.5883 - val_mse: 0.5883 - val_mae: 0.5722\n",
      "Epoch 112/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1428 - mse: 0.1428 - mae: 0.2849 - val_loss: 0.6040 - val_mse: 0.6040 - val_mae: 0.5852\n",
      "Epoch 113/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1396 - mse: 0.1396 - mae: 0.2832 - val_loss: 0.5828 - val_mse: 0.5828 - val_mae: 0.5702\n",
      "Epoch 114/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1391 - mse: 0.1391 - mae: 0.2812 - val_loss: 0.5954 - val_mse: 0.5954 - val_mae: 0.5777\n",
      "Epoch 115/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1399 - mse: 0.1399 - mae: 0.2828 - val_loss: 0.5891 - val_mse: 0.5891 - val_mae: 0.5756\n",
      "Epoch 116/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1415 - mse: 0.1415 - mae: 0.2844 - val_loss: 0.5900 - val_mse: 0.5900 - val_mae: 0.5745\n",
      "Epoch 117/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1419 - mse: 0.1419 - mae: 0.2859 - val_loss: 0.5826 - val_mse: 0.5826 - val_mae: 0.5715\n",
      "Epoch 118/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1393 - mse: 0.1393 - mae: 0.2827 - val_loss: 0.5810 - val_mse: 0.5810 - val_mae: 0.5708\n",
      "Epoch 119/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1394 - mse: 0.1394 - mae: 0.2829 - val_loss: 0.5692 - val_mse: 0.5692 - val_mae: 0.5621\n",
      "Epoch 120/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.1457 - mse: 0.1457 - mae: 0.2898 - val_loss: 0.5921 - val_mse: 0.5921 - val_mae: 0.5777\n",
      "Epoch 121/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1378 - mse: 0.1378 - mae: 0.2817 - val_loss: 0.5798 - val_mse: 0.5798 - val_mae: 0.5668\n",
      "Epoch 122/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.1414 - mse: 0.1414 - mae: 0.2856 - val_loss: 0.5853 - val_mse: 0.5853 - val_mae: 0.5720\n",
      "Epoch 123/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1398 - mse: 0.1398 - mae: 0.2839 - val_loss: 0.5603 - val_mse: 0.5603 - val_mae: 0.5538\n",
      "Epoch 124/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1378 - mse: 0.1378 - mae: 0.2820 - val_loss: 0.5891 - val_mse: 0.5891 - val_mae: 0.5738\n",
      "Epoch 125/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1363 - mse: 0.1363 - mae: 0.2799 - val_loss: 0.5583 - val_mse: 0.5583 - val_mae: 0.5501\n",
      "Epoch 126/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1382 - mse: 0.1382 - mae: 0.2807 - val_loss: 0.5914 - val_mse: 0.5914 - val_mae: 0.5754\n",
      "Epoch 127/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1393 - mse: 0.1393 - mae: 0.2832 - val_loss: 0.5606 - val_mse: 0.5606 - val_mae: 0.5525\n",
      "Epoch 128/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1343 - mse: 0.1343 - mae: 0.2771 - val_loss: 0.5804 - val_mse: 0.5804 - val_mae: 0.5703\n",
      "Epoch 129/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1288 - mse: 0.1288 - mae: 0.2724 - val_loss: 0.5580 - val_mse: 0.5580 - val_mae: 0.5519\n",
      "Epoch 130/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1280 - mse: 0.1280 - mae: 0.2700 - val_loss: 0.5736 - val_mse: 0.5736 - val_mae: 0.5630\n",
      "Epoch 131/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1306 - mse: 0.1306 - mae: 0.2737 - val_loss: 0.5721 - val_mse: 0.5721 - val_mae: 0.5604\n",
      "Epoch 132/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1317 - mse: 0.1317 - mae: 0.2748 - val_loss: 0.5798 - val_mse: 0.5798 - val_mae: 0.5658\n",
      "Epoch 133/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1306 - mse: 0.1306 - mae: 0.2729 - val_loss: 0.5739 - val_mse: 0.5739 - val_mae: 0.5610\n",
      "Epoch 134/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1360 - mse: 0.1360 - mae: 0.2795 - val_loss: 0.5599 - val_mse: 0.5599 - val_mae: 0.5530\n",
      "Epoch 135/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1276 - mse: 0.1276 - mae: 0.2700 - val_loss: 0.5771 - val_mse: 0.5771 - val_mae: 0.5631\n",
      "Epoch 136/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1286 - mse: 0.1286 - mae: 0.2719 - val_loss: 0.5714 - val_mse: 0.5714 - val_mae: 0.5593\n",
      "Epoch 137/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1279 - mse: 0.1279 - mae: 0.2723 - val_loss: 0.5696 - val_mse: 0.5696 - val_mae: 0.5559\n",
      "Epoch 138/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1265 - mse: 0.1265 - mae: 0.2693 - val_loss: 0.5697 - val_mse: 0.5697 - val_mae: 0.5564\n",
      "Epoch 139/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1246 - mse: 0.1246 - mae: 0.2675 - val_loss: 0.5568 - val_mse: 0.5568 - val_mae: 0.5490\n",
      "Epoch 140/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1214 - mse: 0.1214 - mae: 0.2628 - val_loss: 0.5664 - val_mse: 0.5664 - val_mae: 0.5557\n",
      "Epoch 141/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1239 - mse: 0.1239 - mae: 0.2672 - val_loss: 0.5645 - val_mse: 0.5645 - val_mae: 0.5546\n",
      "Epoch 142/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1244 - mse: 0.1244 - mae: 0.2680 - val_loss: 0.5675 - val_mse: 0.5675 - val_mae: 0.5549\n",
      "Epoch 143/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1199 - mse: 0.1199 - mae: 0.2613 - val_loss: 0.5716 - val_mse: 0.5716 - val_mae: 0.5538\n",
      "Epoch 144/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1217 - mse: 0.1217 - mae: 0.2649 - val_loss: 0.5608 - val_mse: 0.5608 - val_mae: 0.5506\n",
      "Epoch 145/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1212 - mse: 0.1212 - mae: 0.2644 - val_loss: 0.5606 - val_mse: 0.5606 - val_mae: 0.5490\n",
      "Epoch 146/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1186 - mse: 0.1186 - mae: 0.2604 - val_loss: 0.5659 - val_mse: 0.5659 - val_mae: 0.5535\n",
      "Epoch 147/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1166 - mse: 0.1166 - mae: 0.2588 - val_loss: 0.5621 - val_mse: 0.5621 - val_mae: 0.5478\n",
      "Epoch 148/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1192 - mse: 0.1192 - mae: 0.2610 - val_loss: 0.5766 - val_mse: 0.5766 - val_mae: 0.5581\n",
      "Epoch 149/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1220 - mse: 0.1220 - mae: 0.2649 - val_loss: 0.5555 - val_mse: 0.5555 - val_mae: 0.5444\n",
      "Epoch 150/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1217 - mse: 0.1217 - mae: 0.2639 - val_loss: 0.5668 - val_mse: 0.5668 - val_mae: 0.5536\n",
      "Epoch 151/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1181 - mse: 0.1181 - mae: 0.2594 - val_loss: 0.5685 - val_mse: 0.5685 - val_mae: 0.5531\n",
      "Epoch 152/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1159 - mse: 0.1159 - mae: 0.2579 - val_loss: 0.5691 - val_mse: 0.5691 - val_mae: 0.5513\n",
      "Epoch 153/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1159 - mse: 0.1159 - mae: 0.2568 - val_loss: 0.5665 - val_mse: 0.5665 - val_mae: 0.5507\n",
      "Epoch 154/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1181 - mse: 0.1181 - mae: 0.2595 - val_loss: 0.5656 - val_mse: 0.5656 - val_mae: 0.5503\n",
      "Epoch 155/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1182 - mse: 0.1182 - mae: 0.2603 - val_loss: 0.5679 - val_mse: 0.5679 - val_mae: 0.5536\n",
      "Epoch 156/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1146 - mse: 0.1146 - mae: 0.2554 - val_loss: 0.5579 - val_mse: 0.5579 - val_mae: 0.5428\n",
      "Epoch 157/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1143 - mse: 0.1143 - mae: 0.2556 - val_loss: 0.5656 - val_mse: 0.5656 - val_mae: 0.5481\n",
      "Epoch 158/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1171 - mse: 0.1171 - mae: 0.2585 - val_loss: 0.5675 - val_mse: 0.5675 - val_mae: 0.5529\n",
      "Epoch 159/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1145 - mse: 0.1145 - mae: 0.2569 - val_loss: 0.5597 - val_mse: 0.5597 - val_mae: 0.5451\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 110us/sample - loss: 2.1868 - mse: 2.1868 - mae: 1.0970 - val_loss: 2.8537 - val_mse: 2.8537 - val_mae: 1.2096\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 1.0731 - mse: 1.0731 - mae: 0.7836 - val_loss: 1.7698 - val_mse: 1.7698 - val_mae: 0.9697\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.8422 - mse: 0.8422 - mae: 0.7020 - val_loss: 1.1944 - val_mse: 1.1944 - val_mae: 0.7948\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.7346 - mse: 0.7346 - mae: 0.6522 - val_loss: 1.0393 - val_mse: 1.0393 - val_mae: 0.7609\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6764 - mse: 0.6764 - mae: 0.6281 - val_loss: 1.0384 - val_mse: 1.0384 - val_mae: 0.7607\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6252 - mse: 0.6252 - mae: 0.6033 - val_loss: 1.0687 - val_mse: 1.0687 - val_mae: 0.7612\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5903 - mse: 0.5903 - mae: 0.5873 - val_loss: 1.0698 - val_mse: 1.0698 - val_mae: 0.7614\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5650 - mse: 0.5650 - mae: 0.5718 - val_loss: 1.0343 - val_mse: 1.0343 - val_mae: 0.7567\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5412 - mse: 0.5412 - mae: 0.5583 - val_loss: 1.0049 - val_mse: 1.0049 - val_mae: 0.7533\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5195 - mse: 0.5195 - mae: 0.5446 - val_loss: 0.9818 - val_mse: 0.9818 - val_mae: 0.7490\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5009 - mse: 0.5009 - mae: 0.5345 - val_loss: 0.9705 - val_mse: 0.9705 - val_mae: 0.7500\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4834 - mse: 0.4834 - mae: 0.5257 - val_loss: 0.9705 - val_mse: 0.9705 - val_mae: 0.7509\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4706 - mse: 0.4706 - mae: 0.5196 - val_loss: 0.9691 - val_mse: 0.9691 - val_mae: 0.7511\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4556 - mse: 0.4556 - mae: 0.5101 - val_loss: 0.9601 - val_mse: 0.9601 - val_mae: 0.7483\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4433 - mse: 0.4433 - mae: 0.5030 - val_loss: 0.9469 - val_mse: 0.9469 - val_mae: 0.7430\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4331 - mse: 0.4331 - mae: 0.4959 - val_loss: 0.9319 - val_mse: 0.9319 - val_mae: 0.7350\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4224 - mse: 0.4224 - mae: 0.4901 - val_loss: 0.9225 - val_mse: 0.9225 - val_mae: 0.7312\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4123 - mse: 0.4123 - mae: 0.4847 - val_loss: 0.9146 - val_mse: 0.9146 - val_mae: 0.7256\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4038 - mse: 0.4038 - mae: 0.4796 - val_loss: 0.9124 - val_mse: 0.9124 - val_mae: 0.7193\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3943 - mse: 0.3943 - mae: 0.4729 - val_loss: 0.9164 - val_mse: 0.9164 - val_mae: 0.7156\n",
      "Epoch 21/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3901 - mse: 0.3901 - mae: 0.4701 - val_loss: 0.9199 - val_mse: 0.9199 - val_mae: 0.7164\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3786 - mse: 0.3786 - mae: 0.4634 - val_loss: 0.9149 - val_mse: 0.9149 - val_mae: 0.7182\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3738 - mse: 0.3738 - mae: 0.4610 - val_loss: 0.9148 - val_mse: 0.9148 - val_mae: 0.7135\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3651 - mse: 0.3651 - mae: 0.4554 - val_loss: 0.9156 - val_mse: 0.9156 - val_mae: 0.7099\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3558 - mse: 0.3558 - mae: 0.4494 - val_loss: 0.9195 - val_mse: 0.9195 - val_mae: 0.7100\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3487 - mse: 0.3487 - mae: 0.4444 - val_loss: 0.9208 - val_mse: 0.9208 - val_mae: 0.7118\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3425 - mse: 0.3425 - mae: 0.4406 - val_loss: 0.9140 - val_mse: 0.9140 - val_mae: 0.7117\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3383 - mse: 0.3383 - mae: 0.4377 - val_loss: 0.9111 - val_mse: 0.9111 - val_mae: 0.7140\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3304 - mse: 0.3304 - mae: 0.4320 - val_loss: 0.9204 - val_mse: 0.9204 - val_mae: 0.7158\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3246 - mse: 0.3246 - mae: 0.4284 - val_loss: 0.9346 - val_mse: 0.9346 - val_mae: 0.7163\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3204 - mse: 0.3204 - mae: 0.4253 - val_loss: 0.9388 - val_mse: 0.9388 - val_mae: 0.7174\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3131 - mse: 0.3131 - mae: 0.4210 - val_loss: 0.9353 - val_mse: 0.9353 - val_mae: 0.7199\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3096 - mse: 0.3096 - mae: 0.4186 - val_loss: 0.9396 - val_mse: 0.9396 - val_mae: 0.7208\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3048 - mse: 0.3048 - mae: 0.4154 - val_loss: 0.9469 - val_mse: 0.9469 - val_mae: 0.7221\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3006 - mse: 0.3006 - mae: 0.4127 - val_loss: 0.9455 - val_mse: 0.9455 - val_mae: 0.7233\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2969 - mse: 0.2969 - mae: 0.4099 - val_loss: 0.9512 - val_mse: 0.9512 - val_mae: 0.7259\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2956 - mse: 0.2956 - mae: 0.4090 - val_loss: 0.9512 - val_mse: 0.9512 - val_mae: 0.7271\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2866 - mse: 0.2866 - mae: 0.4024 - val_loss: 0.9584 - val_mse: 0.9584 - val_mae: 0.7278\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 108us/sample - loss: 2.2468 - mse: 2.2468 - mae: 1.1121 - val_loss: 2.9671 - val_mse: 2.9671 - val_mae: 1.2921\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 1.1252 - mse: 1.1252 - mae: 0.7978 - val_loss: 1.9954 - val_mse: 1.9954 - val_mae: 1.0697\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.8589 - mse: 0.8589 - mae: 0.7075 - val_loss: 1.2393 - val_mse: 1.2393 - val_mae: 0.8262\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.7491 - mse: 0.7491 - mae: 0.6577 - val_loss: 1.0089 - val_mse: 1.0089 - val_mae: 0.7684\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.6900 - mse: 0.6900 - mae: 0.6314 - val_loss: 0.9938 - val_mse: 0.9938 - val_mae: 0.7600\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6417 - mse: 0.6417 - mae: 0.6069 - val_loss: 1.0223 - val_mse: 1.0223 - val_mae: 0.7583\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6042 - mse: 0.6042 - mae: 0.5862 - val_loss: 1.0160 - val_mse: 1.0160 - val_mae: 0.7564\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5751 - mse: 0.5751 - mae: 0.5695 - val_loss: 0.9872 - val_mse: 0.9872 - val_mae: 0.7524\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5503 - mse: 0.5503 - mae: 0.5580 - val_loss: 0.9532 - val_mse: 0.9532 - val_mae: 0.7495\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5285 - mse: 0.5285 - mae: 0.5467 - val_loss: 0.9357 - val_mse: 0.9357 - val_mae: 0.7492\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5111 - mse: 0.5111 - mae: 0.5381 - val_loss: 0.9251 - val_mse: 0.9251 - val_mae: 0.7555\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4901 - mse: 0.4901 - mae: 0.5268 - val_loss: 0.9171 - val_mse: 0.9171 - val_mae: 0.7574\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4740 - mse: 0.4740 - mae: 0.5161 - val_loss: 0.9033 - val_mse: 0.9033 - val_mae: 0.7535\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4646 - mse: 0.4646 - mae: 0.5105 - val_loss: 0.8847 - val_mse: 0.8847 - val_mae: 0.7434\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4485 - mse: 0.4485 - mae: 0.5005 - val_loss: 0.8686 - val_mse: 0.8686 - val_mae: 0.7307\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4395 - mse: 0.4395 - mae: 0.4963 - val_loss: 0.8593 - val_mse: 0.8593 - val_mae: 0.7257\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4257 - mse: 0.4257 - mae: 0.4880 - val_loss: 0.8496 - val_mse: 0.8496 - val_mae: 0.7207\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.4178 - mse: 0.4178 - mae: 0.4837 - val_loss: 0.8400 - val_mse: 0.8400 - val_mae: 0.7129\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4046 - mse: 0.4046 - mae: 0.4760 - val_loss: 0.8363 - val_mse: 0.8363 - val_mae: 0.7023\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3946 - mse: 0.3946 - mae: 0.4703 - val_loss: 0.8318 - val_mse: 0.8318 - val_mae: 0.6971\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3877 - mse: 0.3877 - mae: 0.4655 - val_loss: 0.8341 - val_mse: 0.8341 - val_mae: 0.6952\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3790 - mse: 0.3790 - mae: 0.4614 - val_loss: 0.8421 - val_mse: 0.8421 - val_mae: 0.6953\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3726 - mse: 0.3726 - mae: 0.4567 - val_loss: 0.8502 - val_mse: 0.8502 - val_mae: 0.6973\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3642 - mse: 0.3642 - mae: 0.4518 - val_loss: 0.8532 - val_mse: 0.8532 - val_mae: 0.6961\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3571 - mse: 0.3571 - mae: 0.4467 - val_loss: 0.8560 - val_mse: 0.8560 - val_mae: 0.6960\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3519 - mse: 0.3519 - mae: 0.4444 - val_loss: 0.8669 - val_mse: 0.8669 - val_mae: 0.6992\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.3423 - mse: 0.3423 - mae: 0.4395 - val_loss: 0.8927 - val_mse: 0.8927 - val_mae: 0.7051\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3370 - mse: 0.3370 - mae: 0.4352 - val_loss: 0.8891 - val_mse: 0.8891 - val_mae: 0.7048\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3310 - mse: 0.3310 - mae: 0.4303 - val_loss: 0.8680 - val_mse: 0.8680 - val_mae: 0.7007\n",
      "Epoch 30/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3269 - mse: 0.3269 - mae: 0.4275 - val_loss: 0.8770 - val_mse: 0.8770 - val_mae: 0.7046\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 108us/sample - loss: 2.2452 - mse: 2.2452 - mae: 1.1151 - val_loss: 3.5786 - val_mse: 3.5786 - val_mae: 1.4309\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 1.1096 - mse: 1.1096 - mae: 0.7996 - val_loss: 3.1389 - val_mse: 3.1389 - val_mae: 1.3854\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.8566 - mse: 0.8566 - mae: 0.7071 - val_loss: 1.9125 - val_mse: 1.9125 - val_mae: 1.0185\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.7414 - mse: 0.7414 - mae: 0.6562 - val_loss: 1.1946 - val_mse: 1.1946 - val_mae: 0.7877\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6915 - mse: 0.6915 - mae: 0.6307 - val_loss: 1.0762 - val_mse: 1.0762 - val_mae: 0.7736\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6447 - mse: 0.6447 - mae: 0.6074 - val_loss: 1.0742 - val_mse: 1.0742 - val_mae: 0.7842\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.6097 - mse: 0.6097 - mae: 0.5902 - val_loss: 1.0891 - val_mse: 1.0891 - val_mae: 0.8033\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5832 - mse: 0.5832 - mae: 0.5751 - val_loss: 1.1416 - val_mse: 1.1416 - val_mae: 0.8523\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5575 - mse: 0.5575 - mae: 0.5608 - val_loss: 1.2150 - val_mse: 1.2150 - val_mae: 0.9005\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5426 - mse: 0.5426 - mae: 0.5513 - val_loss: 1.2092 - val_mse: 1.2092 - val_mae: 0.9017\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.5199 - mse: 0.5199 - mae: 0.5409 - val_loss: 1.1376 - val_mse: 1.1376 - val_mae: 0.8661\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.5024 - mse: 0.5024 - mae: 0.5326 - val_loss: 1.1011 - val_mse: 1.1011 - val_mae: 0.8468\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4885 - mse: 0.4885 - mae: 0.5252 - val_loss: 1.1022 - val_mse: 1.1022 - val_mae: 0.8515\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4725 - mse: 0.4725 - mae: 0.5144 - val_loss: 1.1134 - val_mse: 1.1134 - val_mae: 0.8598\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4583 - mse: 0.4583 - mae: 0.5062 - val_loss: 1.0942 - val_mse: 1.0942 - val_mae: 0.8511\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4492 - mse: 0.4492 - mae: 0.5020 - val_loss: 1.0586 - val_mse: 1.0586 - val_mae: 0.8334\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4358 - mse: 0.4358 - mae: 0.4937 - val_loss: 1.0036 - val_mse: 1.0036 - val_mae: 0.8024\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4251 - mse: 0.4251 - mae: 0.4883 - val_loss: 0.9791 - val_mse: 0.9791 - val_mae: 0.7870\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4151 - mse: 0.4151 - mae: 0.4822 - val_loss: 0.9633 - val_mse: 0.9633 - val_mae: 0.7778\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.4066 - mse: 0.4066 - mae: 0.4776 - val_loss: 0.9529 - val_mse: 0.9529 - val_mae: 0.7713\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3957 - mse: 0.3957 - mae: 0.4698 - val_loss: 0.9414 - val_mse: 0.9414 - val_mae: 0.7666\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3908 - mse: 0.3908 - mae: 0.4678 - val_loss: 0.9191 - val_mse: 0.9191 - val_mae: 0.7531\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3810 - mse: 0.3810 - mae: 0.4612 - val_loss: 0.8974 - val_mse: 0.8974 - val_mae: 0.7399\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3722 - mse: 0.3722 - mae: 0.4563 - val_loss: 0.8935 - val_mse: 0.8935 - val_mae: 0.7387\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3636 - mse: 0.3636 - mae: 0.4503 - val_loss: 0.8881 - val_mse: 0.8881 - val_mae: 0.7360\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3553 - mse: 0.3553 - mae: 0.4458 - val_loss: 0.8726 - val_mse: 0.8726 - val_mae: 0.7237\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.3486 - mse: 0.3486 - mae: 0.4412 - val_loss: 0.8627 - val_mse: 0.8627 - val_mae: 0.7143\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3430 - mse: 0.3430 - mae: 0.4363 - val_loss: 0.8614 - val_mse: 0.8614 - val_mae: 0.7138\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3372 - mse: 0.3372 - mae: 0.4332 - val_loss: 0.8602 - val_mse: 0.8602 - val_mae: 0.7145\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3296 - mse: 0.3296 - mae: 0.4292 - val_loss: 0.8548 - val_mse: 0.8548 - val_mae: 0.7107\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3273 - mse: 0.3273 - mae: 0.4278 - val_loss: 0.8514 - val_mse: 0.8514 - val_mae: 0.7038\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3182 - mse: 0.3182 - mae: 0.4217 - val_loss: 0.8474 - val_mse: 0.8474 - val_mae: 0.6974\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3146 - mse: 0.3146 - mae: 0.4197 - val_loss: 0.8418 - val_mse: 0.8418 - val_mae: 0.6993\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3087 - mse: 0.3087 - mae: 0.4143 - val_loss: 0.8425 - val_mse: 0.8425 - val_mae: 0.7023\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.3037 - mse: 0.3037 - mae: 0.4104 - val_loss: 0.8428 - val_mse: 0.8428 - val_mae: 0.6997\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2997 - mse: 0.2997 - mae: 0.4097 - val_loss: 0.8371 - val_mse: 0.8371 - val_mae: 0.6981\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2934 - mse: 0.2934 - mae: 0.4053 - val_loss: 0.8367 - val_mse: 0.8367 - val_mae: 0.6998\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2907 - mse: 0.2907 - mae: 0.4047 - val_loss: 0.8358 - val_mse: 0.8358 - val_mae: 0.7005\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2840 - mse: 0.2840 - mae: 0.3982 - val_loss: 0.8309 - val_mse: 0.8309 - val_mae: 0.7006\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2800 - mse: 0.2800 - mae: 0.3960 - val_loss: 0.8298 - val_mse: 0.8298 - val_mae: 0.6963\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2762 - mse: 0.2762 - mae: 0.3927 - val_loss: 0.8291 - val_mse: 0.8291 - val_mae: 0.6951\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2717 - mse: 0.2717 - mae: 0.3905 - val_loss: 0.8259 - val_mse: 0.8259 - val_mae: 0.6953\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2708 - mse: 0.2708 - mae: 0.3896 - val_loss: 0.8267 - val_mse: 0.8267 - val_mae: 0.6969\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2649 - mse: 0.2649 - mae: 0.3853 - val_loss: 0.8264 - val_mse: 0.8264 - val_mae: 0.6987\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2615 - mse: 0.2615 - mae: 0.3827 - val_loss: 0.8168 - val_mse: 0.8168 - val_mae: 0.6951\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2571 - mse: 0.2571 - mae: 0.3795 - val_loss: 0.8106 - val_mse: 0.8106 - val_mae: 0.6905\n",
      "Epoch 47/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2545 - mse: 0.2545 - mae: 0.3781 - val_loss: 0.8060 - val_mse: 0.8060 - val_mae: 0.6884\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2511 - mse: 0.2511 - mae: 0.3752 - val_loss: 0.8093 - val_mse: 0.8093 - val_mae: 0.6906\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2496 - mse: 0.2496 - mae: 0.3755 - val_loss: 0.8209 - val_mse: 0.8209 - val_mae: 0.6946\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2455 - mse: 0.2455 - mae: 0.3723 - val_loss: 0.8096 - val_mse: 0.8096 - val_mae: 0.6932\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2472 - mse: 0.2472 - mae: 0.3739 - val_loss: 0.8088 - val_mse: 0.8088 - val_mae: 0.6905\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2414 - mse: 0.2414 - mae: 0.3681 - val_loss: 0.8109 - val_mse: 0.8109 - val_mae: 0.6909\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2409 - mse: 0.2409 - mae: 0.3678 - val_loss: 0.7955 - val_mse: 0.7955 - val_mae: 0.6869\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2343 - mse: 0.2343 - mae: 0.3632 - val_loss: 0.8193 - val_mse: 0.8193 - val_mae: 0.6959\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2307 - mse: 0.2307 - mae: 0.3606 - val_loss: 0.7986 - val_mse: 0.7986 - val_mae: 0.6879\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2305 - mse: 0.2305 - mae: 0.3588 - val_loss: 0.8114 - val_mse: 0.8114 - val_mae: 0.6932\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2263 - mse: 0.2263 - mae: 0.3581 - val_loss: 0.8108 - val_mse: 0.8108 - val_mae: 0.6930\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2266 - mse: 0.2266 - mae: 0.3577 - val_loss: 0.7963 - val_mse: 0.7963 - val_mae: 0.6886\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2186 - mse: 0.2186 - mae: 0.3509 - val_loss: 0.8027 - val_mse: 0.8027 - val_mae: 0.6904\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2222 - mse: 0.2222 - mae: 0.3547 - val_loss: 0.7934 - val_mse: 0.7934 - val_mae: 0.6856\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2192 - mse: 0.2192 - mae: 0.3511 - val_loss: 0.7867 - val_mse: 0.7867 - val_mae: 0.6844\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2179 - mse: 0.2179 - mae: 0.3520 - val_loss: 0.7960 - val_mse: 0.7960 - val_mae: 0.6905\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2120 - mse: 0.2120 - mae: 0.3457 - val_loss: 0.7814 - val_mse: 0.7814 - val_mae: 0.6821\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 8us/sample - loss: 0.2129 - mse: 0.2129 - mae: 0.3448 - val_loss: 0.7925 - val_mse: 0.7925 - val_mae: 0.6867\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2093 - mse: 0.2093 - mae: 0.3447 - val_loss: 0.7640 - val_mse: 0.7640 - val_mae: 0.6760\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2053 - mse: 0.2053 - mae: 0.3405 - val_loss: 0.7713 - val_mse: 0.7713 - val_mae: 0.6779\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2065 - mse: 0.2065 - mae: 0.3408 - val_loss: 0.7841 - val_mse: 0.7841 - val_mae: 0.6843\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2011 - mse: 0.2011 - mae: 0.3383 - val_loss: 0.7773 - val_mse: 0.7773 - val_mae: 0.6806\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.2038 - mse: 0.2038 - mae: 0.3400 - val_loss: 0.7686 - val_mse: 0.7686 - val_mae: 0.6734\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1966 - mse: 0.1966 - mae: 0.3347 - val_loss: 0.7501 - val_mse: 0.7501 - val_mae: 0.6670\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1995 - mse: 0.1995 - mae: 0.3365 - val_loss: 0.7373 - val_mse: 0.7373 - val_mae: 0.6624\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1955 - mse: 0.1955 - mae: 0.3325 - val_loss: 0.7492 - val_mse: 0.7492 - val_mae: 0.6672\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1923 - mse: 0.1923 - mae: 0.3309 - val_loss: 0.7423 - val_mse: 0.7423 - val_mae: 0.6629\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1911 - mse: 0.1911 - mae: 0.3304 - val_loss: 0.7348 - val_mse: 0.7348 - val_mae: 0.6566\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1864 - mse: 0.1864 - mae: 0.3244 - val_loss: 0.7532 - val_mse: 0.7532 - val_mae: 0.6653\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1878 - mse: 0.1878 - mae: 0.3275 - val_loss: 0.7179 - val_mse: 0.7179 - val_mae: 0.6501\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1876 - mse: 0.1876 - mae: 0.3267 - val_loss: 0.7293 - val_mse: 0.7293 - val_mae: 0.6568\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1820 - mse: 0.1820 - mae: 0.3208 - val_loss: 0.7144 - val_mse: 0.7144 - val_mae: 0.6484\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1816 - mse: 0.1816 - mae: 0.3220 - val_loss: 0.7114 - val_mse: 0.7114 - val_mae: 0.6447\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1823 - mse: 0.1823 - mae: 0.3217 - val_loss: 0.7065 - val_mse: 0.7065 - val_mae: 0.6421\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1775 - mse: 0.1775 - mae: 0.3169 - val_loss: 0.7013 - val_mse: 0.7013 - val_mae: 0.6417\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1763 - mse: 0.1763 - mae: 0.3167 - val_loss: 0.6884 - val_mse: 0.6884 - val_mae: 0.6362\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1743 - mse: 0.1743 - mae: 0.3148 - val_loss: 0.6829 - val_mse: 0.6829 - val_mae: 0.6336\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1767 - mse: 0.1767 - mae: 0.3173 - val_loss: 0.6984 - val_mse: 0.6984 - val_mae: 0.6424\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1738 - mse: 0.1738 - mae: 0.3142 - val_loss: 0.6791 - val_mse: 0.6791 - val_mae: 0.6318\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1724 - mse: 0.1724 - mae: 0.3118 - val_loss: 0.6829 - val_mse: 0.6829 - val_mae: 0.6329\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.1748 - mse: 0.1748 - mae: 0.3143 - val_loss: 0.6616 - val_mse: 0.6616 - val_mae: 0.6243\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1724 - mse: 0.1724 - mae: 0.3133 - val_loss: 0.6644 - val_mse: 0.6644 - val_mae: 0.6251\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.1692 - mse: 0.1692 - mae: 0.3110 - val_loss: 0.6752 - val_mse: 0.6752 - val_mae: 0.6278\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 0s 4us/sample - loss: 0.1662 - mse: 0.1662 - mae: 0.3075 - val_loss: 0.6638 - val_mse: 0.6638 - val_mae: 0.6217\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1680 - mse: 0.1680 - mae: 0.3087 - val_loss: 0.6546 - val_mse: 0.6546 - val_mae: 0.6176\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1648 - mse: 0.1648 - mae: 0.3053 - val_loss: 0.6588 - val_mse: 0.6588 - val_mae: 0.6233\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1629 - mse: 0.1629 - mae: 0.3049 - val_loss: 0.6528 - val_mse: 0.6528 - val_mae: 0.6198\n",
      "Epoch 94/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1601 - mse: 0.1601 - mae: 0.3019 - val_loss: 0.6540 - val_mse: 0.6540 - val_mae: 0.6170\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1664 - mse: 0.1664 - mae: 0.3076 - val_loss: 0.6485 - val_mse: 0.6485 - val_mae: 0.6136\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1600 - mse: 0.1600 - mae: 0.3006 - val_loss: 0.6544 - val_mse: 0.6544 - val_mae: 0.6167\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1657 - mse: 0.1657 - mae: 0.3080 - val_loss: 0.6409 - val_mse: 0.6409 - val_mae: 0.6112\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1572 - mse: 0.1572 - mae: 0.2997 - val_loss: 0.6367 - val_mse: 0.6367 - val_mae: 0.6064\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1575 - mse: 0.1575 - mae: 0.2986 - val_loss: 0.6334 - val_mse: 0.6334 - val_mae: 0.6060\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1528 - mse: 0.1528 - mae: 0.2948 - val_loss: 0.6343 - val_mse: 0.6343 - val_mae: 0.6065\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1527 - mse: 0.1527 - mae: 0.2952 - val_loss: 0.6366 - val_mse: 0.6366 - val_mae: 0.6068\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.1534 - mse: 0.1534 - mae: 0.2961 - val_loss: 0.6211 - val_mse: 0.6211 - val_mae: 0.5974\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1528 - mse: 0.1528 - mae: 0.2946 - val_loss: 0.6250 - val_mse: 0.6250 - val_mae: 0.5970\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1545 - mse: 0.1545 - mae: 0.2964 - val_loss: 0.6145 - val_mse: 0.6145 - val_mae: 0.5930\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1523 - mse: 0.1523 - mae: 0.2938 - val_loss: 0.6239 - val_mse: 0.6239 - val_mae: 0.6014\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1574 - mse: 0.1574 - mae: 0.3004 - val_loss: 0.6168 - val_mse: 0.6168 - val_mae: 0.5952\n",
      "Epoch 107/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1501 - mse: 0.1501 - mae: 0.2927 - val_loss: 0.6160 - val_mse: 0.6160 - val_mae: 0.5956\n",
      "Epoch 108/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1520 - mse: 0.1520 - mae: 0.2937 - val_loss: 0.6050 - val_mse: 0.6050 - val_mae: 0.5881\n",
      "Epoch 109/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1535 - mse: 0.1535 - mae: 0.2970 - val_loss: 0.6125 - val_mse: 0.6125 - val_mae: 0.5926\n",
      "Epoch 110/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1502 - mse: 0.1502 - mae: 0.2941 - val_loss: 0.6026 - val_mse: 0.6026 - val_mae: 0.5866\n",
      "Epoch 111/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1490 - mse: 0.1490 - mae: 0.2924 - val_loss: 0.6089 - val_mse: 0.6089 - val_mae: 0.5903\n",
      "Epoch 112/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1492 - mse: 0.1492 - mae: 0.2932 - val_loss: 0.6061 - val_mse: 0.6061 - val_mae: 0.5880\n",
      "Epoch 113/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1468 - mse: 0.1468 - mae: 0.2893 - val_loss: 0.5859 - val_mse: 0.5859 - val_mae: 0.5753\n",
      "Epoch 114/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1503 - mse: 0.1503 - mae: 0.2932 - val_loss: 0.5963 - val_mse: 0.5963 - val_mae: 0.5781\n",
      "Epoch 115/3000\n",
      "10663/10663 [==============================] - 0s 5us/sample - loss: 0.1436 - mse: 0.1436 - mae: 0.2861 - val_loss: 0.6036 - val_mse: 0.6036 - val_mae: 0.5821\n",
      "Epoch 116/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1437 - mse: 0.1437 - mae: 0.2869 - val_loss: 0.5882 - val_mse: 0.5882 - val_mae: 0.5763\n",
      "Epoch 117/3000\n",
      "10663/10663 [==============================] - 0s 7us/sample - loss: 0.1401 - mse: 0.1401 - mae: 0.2817 - val_loss: 0.5935 - val_mse: 0.5935 - val_mae: 0.5798\n",
      "Epoch 118/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1391 - mse: 0.1391 - mae: 0.2820 - val_loss: 0.5881 - val_mse: 0.5881 - val_mae: 0.5773\n",
      "Epoch 119/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1401 - mse: 0.1401 - mae: 0.2829 - val_loss: 0.5928 - val_mse: 0.5928 - val_mae: 0.5805\n",
      "Epoch 120/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1381 - mse: 0.1381 - mae: 0.2800 - val_loss: 0.5869 - val_mse: 0.5869 - val_mae: 0.5749\n",
      "Epoch 121/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1411 - mse: 0.1411 - mae: 0.2825 - val_loss: 0.5883 - val_mse: 0.5883 - val_mae: 0.5735\n",
      "Epoch 122/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1410 - mse: 0.1410 - mae: 0.2848 - val_loss: 0.5890 - val_mse: 0.5890 - val_mae: 0.5742\n",
      "Epoch 123/3000\n",
      "10663/10663 [==============================] - 0s 6us/sample - loss: 0.1409 - mse: 0.1409 - mae: 0.2840 - val_loss: 0.5942 - val_mse: 0.5942 - val_mae: 0.5758\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 2.5283 - mse: 2.5283 - mae: 1.2122 - val_loss: 3.0594 - val_mse: 3.0594 - val_mae: 1.3124\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 1.1982 - mse: 1.1982 - mae: 0.8365 - val_loss: 3.0517 - val_mse: 3.0517 - val_mae: 1.3399\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.9024 - mse: 0.9024 - mae: 0.7269 - val_loss: 2.5551 - val_mse: 2.5551 - val_mae: 1.2155\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.7721 - mse: 0.7721 - mae: 0.6728 - val_loss: 1.9997 - val_mse: 1.9997 - val_mae: 1.0520\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.6974 - mse: 0.6974 - mae: 0.6344 - val_loss: 1.6507 - val_mse: 1.6507 - val_mae: 0.9445\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.6543 - mse: 0.6543 - mae: 0.6135 - val_loss: 1.5617 - val_mse: 1.5617 - val_mae: 0.9144\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.6187 - mse: 0.6187 - mae: 0.5934 - val_loss: 1.5276 - val_mse: 1.5276 - val_mae: 0.9016\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5955 - mse: 0.5955 - mae: 0.5811 - val_loss: 1.4362 - val_mse: 1.4362 - val_mae: 0.8750\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5697 - mse: 0.5697 - mae: 0.5674 - val_loss: 1.3262 - val_mse: 1.3262 - val_mae: 0.8454\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5480 - mse: 0.5480 - mae: 0.5554 - val_loss: 1.2732 - val_mse: 1.2732 - val_mae: 0.8285\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5311 - mse: 0.5311 - mae: 0.5450 - val_loss: 1.2432 - val_mse: 1.2432 - val_mae: 0.8178\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5162 - mse: 0.5162 - mae: 0.5366 - val_loss: 1.2107 - val_mse: 1.2107 - val_mae: 0.8081\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.5007 - mse: 0.5007 - mae: 0.5287 - val_loss: 1.1837 - val_mse: 1.1837 - val_mae: 0.8001\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4865 - mse: 0.4865 - mae: 0.5216 - val_loss: 1.1504 - val_mse: 1.1504 - val_mae: 0.7913\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4756 - mse: 0.4756 - mae: 0.5166 - val_loss: 1.1235 - val_mse: 1.1235 - val_mae: 0.7826\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4644 - mse: 0.4644 - mae: 0.5103 - val_loss: 1.0981 - val_mse: 1.0981 - val_mae: 0.7727\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4534 - mse: 0.4534 - mae: 0.5037 - val_loss: 1.0892 - val_mse: 1.0892 - val_mae: 0.7652\n",
      "Epoch 18/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4418 - mse: 0.4418 - mae: 0.4968 - val_loss: 1.0851 - val_mse: 1.0851 - val_mae: 0.7609\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4336 - mse: 0.4336 - mae: 0.4928 - val_loss: 1.0747 - val_mse: 1.0747 - val_mae: 0.7557\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4211 - mse: 0.4211 - mae: 0.4860 - val_loss: 1.0640 - val_mse: 1.0640 - val_mae: 0.7506\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4147 - mse: 0.4147 - mae: 0.4824 - val_loss: 1.0516 - val_mse: 1.0516 - val_mae: 0.7461\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.4062 - mse: 0.4062 - mae: 0.4775 - val_loss: 1.0582 - val_mse: 1.0582 - val_mae: 0.7454\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3956 - mse: 0.3956 - mae: 0.4702 - val_loss: 1.0650 - val_mse: 1.0650 - val_mae: 0.7446\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3893 - mse: 0.3893 - mae: 0.4680 - val_loss: 1.0510 - val_mse: 1.0510 - val_mae: 0.7378\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3842 - mse: 0.3842 - mae: 0.4646 - val_loss: 1.0313 - val_mse: 1.0313 - val_mae: 0.7307\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3765 - mse: 0.3765 - mae: 0.4607 - val_loss: 1.0295 - val_mse: 1.0295 - val_mae: 0.7284\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.3674 - mse: 0.3674 - mae: 0.4555 - val_loss: 1.0276 - val_mse: 1.0276 - val_mae: 0.7262\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3593 - mse: 0.3593 - mae: 0.4495 - val_loss: 1.0096 - val_mse: 1.0096 - val_mae: 0.7189\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3547 - mse: 0.3547 - mae: 0.4463 - val_loss: 0.9907 - val_mse: 0.9907 - val_mae: 0.7129\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3483 - mse: 0.3483 - mae: 0.4427 - val_loss: 0.9926 - val_mse: 0.9926 - val_mae: 0.7135\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3423 - mse: 0.3423 - mae: 0.4393 - val_loss: 0.9869 - val_mse: 0.9869 - val_mae: 0.7110\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3370 - mse: 0.3370 - mae: 0.4358 - val_loss: 0.9699 - val_mse: 0.9699 - val_mae: 0.7063\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3309 - mse: 0.3309 - mae: 0.4321 - val_loss: 0.9678 - val_mse: 0.9678 - val_mae: 0.7050\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3272 - mse: 0.3272 - mae: 0.4293 - val_loss: 0.9673 - val_mse: 0.9673 - val_mae: 0.7040\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3212 - mse: 0.3212 - mae: 0.4249 - val_loss: 0.9564 - val_mse: 0.9564 - val_mae: 0.7001\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3172 - mse: 0.3172 - mae: 0.4231 - val_loss: 0.9452 - val_mse: 0.9452 - val_mae: 0.6973\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3105 - mse: 0.3105 - mae: 0.4183 - val_loss: 0.9454 - val_mse: 0.9454 - val_mae: 0.6979\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3080 - mse: 0.3080 - mae: 0.4160 - val_loss: 0.9319 - val_mse: 0.9319 - val_mae: 0.6944\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.3035 - mse: 0.3035 - mae: 0.4144 - val_loss: 0.9062 - val_mse: 0.9062 - val_mae: 0.6873\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2986 - mse: 0.2986 - mae: 0.4100 - val_loss: 0.8873 - val_mse: 0.8873 - val_mae: 0.6829\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2961 - mse: 0.2961 - mae: 0.4091 - val_loss: 0.8767 - val_mse: 0.8767 - val_mae: 0.6800\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2911 - mse: 0.2911 - mae: 0.4062 - val_loss: 0.8791 - val_mse: 0.8791 - val_mae: 0.6806\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2864 - mse: 0.2864 - mae: 0.4029 - val_loss: 0.8768 - val_mse: 0.8768 - val_mae: 0.6807\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2809 - mse: 0.2809 - mae: 0.3985 - val_loss: 0.8501 - val_mse: 0.8501 - val_mae: 0.6734\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2781 - mse: 0.2781 - mae: 0.3970 - val_loss: 0.8395 - val_mse: 0.8395 - val_mae: 0.6715\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2725 - mse: 0.2725 - mae: 0.3933 - val_loss: 0.8423 - val_mse: 0.8423 - val_mae: 0.6726\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2723 - mse: 0.2723 - mae: 0.3943 - val_loss: 0.8091 - val_mse: 0.8091 - val_mae: 0.6614\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2696 - mse: 0.2696 - mae: 0.3911 - val_loss: 0.8085 - val_mse: 0.8085 - val_mae: 0.6617\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2650 - mse: 0.2650 - mae: 0.3874 - val_loss: 0.8174 - val_mse: 0.8174 - val_mae: 0.6634\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2604 - mse: 0.2604 - mae: 0.3837 - val_loss: 0.8061 - val_mse: 0.8061 - val_mae: 0.6606\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2562 - mse: 0.2562 - mae: 0.3804 - val_loss: 0.8013 - val_mse: 0.8013 - val_mae: 0.6595\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2515 - mse: 0.2515 - mae: 0.3770 - val_loss: 0.7841 - val_mse: 0.7841 - val_mae: 0.6536\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2490 - mse: 0.2490 - mae: 0.3758 - val_loss: 0.7723 - val_mse: 0.7723 - val_mae: 0.6511\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2503 - mse: 0.2503 - mae: 0.3766 - val_loss: 0.7691 - val_mse: 0.7691 - val_mae: 0.6501\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2439 - mse: 0.2439 - mae: 0.3717 - val_loss: 0.7782 - val_mse: 0.7782 - val_mae: 0.6518\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2415 - mse: 0.2415 - mae: 0.3692 - val_loss: 0.7706 - val_mse: 0.7706 - val_mae: 0.6471\n",
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2388 - mse: 0.2388 - mae: 0.3674 - val_loss: 0.7473 - val_mse: 0.7473 - val_mae: 0.6407\n",
      "Epoch 58/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2363 - mse: 0.2363 - mae: 0.3656 - val_loss: 0.7456 - val_mse: 0.7456 - val_mae: 0.6424\n",
      "Epoch 59/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2358 - mse: 0.2358 - mae: 0.3658 - val_loss: 0.7434 - val_mse: 0.7434 - val_mae: 0.6405\n",
      "Epoch 60/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2305 - mse: 0.2305 - mae: 0.3616 - val_loss: 0.7493 - val_mse: 0.7493 - val_mae: 0.6411\n",
      "Epoch 61/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2262 - mse: 0.2262 - mae: 0.3575 - val_loss: 0.7429 - val_mse: 0.7429 - val_mae: 0.6390\n",
      "Epoch 62/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2245 - mse: 0.2245 - mae: 0.3566 - val_loss: 0.7257 - val_mse: 0.7257 - val_mae: 0.6321\n",
      "Epoch 63/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2223 - mse: 0.2223 - mae: 0.3553 - val_loss: 0.7246 - val_mse: 0.7246 - val_mae: 0.6346\n",
      "Epoch 64/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2208 - mse: 0.2208 - mae: 0.3559 - val_loss: 0.7152 - val_mse: 0.7152 - val_mae: 0.6324\n",
      "Epoch 65/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2184 - mse: 0.2184 - mae: 0.3522 - val_loss: 0.7186 - val_mse: 0.7186 - val_mae: 0.6301\n",
      "Epoch 66/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2162 - mse: 0.2162 - mae: 0.3509 - val_loss: 0.7167 - val_mse: 0.7167 - val_mae: 0.6311\n",
      "Epoch 67/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2172 - mse: 0.2172 - mae: 0.3520 - val_loss: 0.7033 - val_mse: 0.7033 - val_mae: 0.6247\n",
      "Epoch 68/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2096 - mse: 0.2096 - mae: 0.3458 - val_loss: 0.6997 - val_mse: 0.6997 - val_mae: 0.6232\n",
      "Epoch 69/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2089 - mse: 0.2089 - mae: 0.3445 - val_loss: 0.7037 - val_mse: 0.7037 - val_mae: 0.6265\n",
      "Epoch 70/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2088 - mse: 0.2088 - mae: 0.3474 - val_loss: 0.6897 - val_mse: 0.6897 - val_mae: 0.6208\n",
      "Epoch 71/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2042 - mse: 0.2042 - mae: 0.3413 - val_loss: 0.6884 - val_mse: 0.6884 - val_mae: 0.6180\n",
      "Epoch 72/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.2046 - mse: 0.2046 - mae: 0.3408 - val_loss: 0.6841 - val_mse: 0.6841 - val_mae: 0.6170\n",
      "Epoch 73/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1996 - mse: 0.1996 - mae: 0.3373 - val_loss: 0.6845 - val_mse: 0.6845 - val_mae: 0.6176\n",
      "Epoch 74/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1985 - mse: 0.1985 - mae: 0.3372 - val_loss: 0.6811 - val_mse: 0.6811 - val_mae: 0.6164\n",
      "Epoch 75/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1970 - mse: 0.1970 - mae: 0.3359 - val_loss: 0.6625 - val_mse: 0.6625 - val_mae: 0.6090\n",
      "Epoch 76/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1942 - mse: 0.1942 - mae: 0.3319 - val_loss: 0.6755 - val_mse: 0.6755 - val_mae: 0.6150\n",
      "Epoch 77/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1939 - mse: 0.1939 - mae: 0.3334 - val_loss: 0.6673 - val_mse: 0.6673 - val_mae: 0.6099\n",
      "Epoch 78/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3339 - val_loss: 0.6599 - val_mse: 0.6599 - val_mae: 0.6066\n",
      "Epoch 79/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1911 - mse: 0.1911 - mae: 0.3299 - val_loss: 0.6546 - val_mse: 0.6546 - val_mae: 0.6023\n",
      "Epoch 80/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1897 - mse: 0.1897 - mae: 0.3298 - val_loss: 0.6452 - val_mse: 0.6452 - val_mae: 0.6023\n",
      "Epoch 81/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1902 - mse: 0.1902 - mae: 0.3302 - val_loss: 0.6498 - val_mse: 0.6498 - val_mae: 0.6034\n",
      "Epoch 82/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1833 - mse: 0.1833 - mae: 0.3231 - val_loss: 0.6406 - val_mse: 0.6406 - val_mae: 0.6013\n",
      "Epoch 83/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1846 - mse: 0.1846 - mae: 0.3251 - val_loss: 0.6411 - val_mse: 0.6411 - val_mae: 0.6001\n",
      "Epoch 84/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1850 - mse: 0.1850 - mae: 0.3267 - val_loss: 0.6384 - val_mse: 0.6384 - val_mae: 0.6007\n",
      "Epoch 85/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1788 - mse: 0.1788 - mae: 0.3206 - val_loss: 0.6189 - val_mse: 0.6189 - val_mae: 0.5928\n",
      "Epoch 86/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1771 - mse: 0.1771 - mae: 0.3185 - val_loss: 0.6219 - val_mse: 0.6219 - val_mae: 0.5927\n",
      "Epoch 87/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1774 - mse: 0.1774 - mae: 0.3196 - val_loss: 0.6118 - val_mse: 0.6118 - val_mae: 0.5906\n",
      "Epoch 88/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1753 - mse: 0.1753 - mae: 0.3172 - val_loss: 0.6106 - val_mse: 0.6106 - val_mae: 0.5896\n",
      "Epoch 89/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1746 - mse: 0.1746 - mae: 0.3161 - val_loss: 0.6071 - val_mse: 0.6071 - val_mae: 0.5873\n",
      "Epoch 90/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1726 - mse: 0.1726 - mae: 0.3150 - val_loss: 0.6126 - val_mse: 0.6126 - val_mae: 0.5894\n",
      "Epoch 91/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1700 - mse: 0.1700 - mae: 0.3116 - val_loss: 0.6093 - val_mse: 0.6093 - val_mae: 0.5884\n",
      "Epoch 92/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1682 - mse: 0.1682 - mae: 0.3093 - val_loss: 0.6099 - val_mse: 0.6099 - val_mae: 0.5862\n",
      "Epoch 93/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1658 - mse: 0.1658 - mae: 0.3081 - val_loss: 0.6012 - val_mse: 0.6012 - val_mae: 0.5813\n",
      "Epoch 94/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1650 - mse: 0.1650 - mae: 0.3064 - val_loss: 0.5920 - val_mse: 0.5920 - val_mae: 0.5800\n",
      "Epoch 95/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1680 - mse: 0.1680 - mae: 0.3101 - val_loss: 0.5869 - val_mse: 0.5869 - val_mae: 0.5768\n",
      "Epoch 96/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1624 - mse: 0.1624 - mae: 0.3046 - val_loss: 0.5927 - val_mse: 0.5927 - val_mae: 0.5794\n",
      "Epoch 97/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1660 - mse: 0.1660 - mae: 0.3087 - val_loss: 0.5820 - val_mse: 0.5820 - val_mae: 0.5728\n",
      "Epoch 98/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1629 - mse: 0.1629 - mae: 0.3048 - val_loss: 0.5761 - val_mse: 0.5761 - val_mae: 0.5715\n",
      "Epoch 99/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.1615 - mse: 0.1615 - mae: 0.3047 - val_loss: 0.5823 - val_mse: 0.5823 - val_mae: 0.5731\n",
      "Epoch 100/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1668 - mse: 0.1668 - mae: 0.3089 - val_loss: 0.5690 - val_mse: 0.5690 - val_mae: 0.5680\n",
      "Epoch 101/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1602 - mse: 0.1602 - mae: 0.3030 - val_loss: 0.5751 - val_mse: 0.5751 - val_mae: 0.5721\n",
      "Epoch 102/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1595 - mse: 0.1595 - mae: 0.3028 - val_loss: 0.5706 - val_mse: 0.5706 - val_mae: 0.5672\n",
      "Epoch 103/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.1562 - mse: 0.1562 - mae: 0.2991 - val_loss: 0.5773 - val_mse: 0.5773 - val_mae: 0.5707\n",
      "Epoch 104/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1553 - mse: 0.1553 - mae: 0.2973 - val_loss: 0.5657 - val_mse: 0.5657 - val_mae: 0.5634\n",
      "Epoch 105/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1534 - mse: 0.1534 - mae: 0.2959 - val_loss: 0.5642 - val_mse: 0.5642 - val_mae: 0.5639\n",
      "Epoch 106/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1561 - mse: 0.1561 - mae: 0.2980 - val_loss: 0.5699 - val_mse: 0.5699 - val_mae: 0.5706\n",
      "Epoch 107/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.1532 - mse: 0.1532 - mae: 0.2962 - val_loss: 0.5599 - val_mse: 0.5599 - val_mae: 0.5606\n",
      "Epoch 108/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1519 - mse: 0.1519 - mae: 0.2953 - val_loss: 0.5716 - val_mse: 0.5716 - val_mae: 0.5647\n",
      "Epoch 109/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1531 - mse: 0.1531 - mae: 0.2966 - val_loss: 0.5499 - val_mse: 0.5499 - val_mae: 0.5573\n",
      "Epoch 110/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1532 - mse: 0.1532 - mae: 0.2958 - val_loss: 0.5582 - val_mse: 0.5582 - val_mae: 0.5635\n",
      "Epoch 111/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1551 - mse: 0.1551 - mae: 0.2983 - val_loss: 0.5448 - val_mse: 0.5448 - val_mae: 0.5526\n",
      "Epoch 112/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1508 - mse: 0.1508 - mae: 0.2938 - val_loss: 0.5542 - val_mse: 0.5542 - val_mae: 0.5590\n",
      "Epoch 113/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1505 - mse: 0.1505 - mae: 0.2945 - val_loss: 0.5464 - val_mse: 0.5464 - val_mae: 0.5526\n",
      "Epoch 114/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1475 - mse: 0.1475 - mae: 0.2902 - val_loss: 0.5544 - val_mse: 0.5544 - val_mae: 0.5559\n",
      "Epoch 115/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1473 - mse: 0.1473 - mae: 0.2911 - val_loss: 0.5438 - val_mse: 0.5438 - val_mae: 0.5514\n",
      "Epoch 116/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1465 - mse: 0.1465 - mae: 0.2895 - val_loss: 0.5453 - val_mse: 0.5453 - val_mae: 0.5553\n",
      "Epoch 117/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1452 - mse: 0.1452 - mae: 0.2888 - val_loss: 0.5353 - val_mse: 0.5353 - val_mae: 0.5488\n",
      "Epoch 118/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1448 - mse: 0.1448 - mae: 0.2879 - val_loss: 0.5354 - val_mse: 0.5354 - val_mae: 0.5475\n",
      "Epoch 119/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1436 - mse: 0.1436 - mae: 0.2865 - val_loss: 0.5409 - val_mse: 0.5409 - val_mae: 0.5484\n",
      "Epoch 120/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1441 - mse: 0.1441 - mae: 0.2887 - val_loss: 0.5379 - val_mse: 0.5379 - val_mae: 0.5502\n",
      "Epoch 121/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1407 - mse: 0.1407 - mae: 0.2848 - val_loss: 0.5411 - val_mse: 0.5411 - val_mae: 0.5513\n",
      "Epoch 122/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1435 - mse: 0.1435 - mae: 0.2868 - val_loss: 0.5410 - val_mse: 0.5410 - val_mae: 0.5452\n",
      "Epoch 123/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1396 - mse: 0.1396 - mae: 0.2824 - val_loss: 0.5389 - val_mse: 0.5389 - val_mae: 0.5417\n",
      "Epoch 124/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1391 - mse: 0.1391 - mae: 0.2822 - val_loss: 0.5336 - val_mse: 0.5336 - val_mae: 0.5413\n",
      "Epoch 125/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1404 - mse: 0.1404 - mae: 0.2843 - val_loss: 0.5320 - val_mse: 0.5320 - val_mae: 0.5449\n",
      "Epoch 126/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1377 - mse: 0.1377 - mae: 0.2813 - val_loss: 0.5295 - val_mse: 0.5295 - val_mae: 0.5412\n",
      "Epoch 127/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1451 - mse: 0.1451 - mae: 0.2875 - val_loss: 0.5329 - val_mse: 0.5329 - val_mae: 0.5427\n",
      "Epoch 128/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1395 - mse: 0.1395 - mae: 0.2826 - val_loss: 0.5386 - val_mse: 0.5386 - val_mae: 0.5448\n",
      "Epoch 129/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1351 - mse: 0.1351 - mae: 0.2785 - val_loss: 0.5276 - val_mse: 0.5276 - val_mae: 0.5385\n",
      "Epoch 130/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.1360 - mse: 0.1360 - mae: 0.2783 - val_loss: 0.5289 - val_mse: 0.5289 - val_mae: 0.5399\n",
      "Epoch 131/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1352 - mse: 0.1352 - mae: 0.2794 - val_loss: 0.5309 - val_mse: 0.5309 - val_mae: 0.5420\n",
      "Epoch 132/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.1332 - mse: 0.1332 - mae: 0.2767 - val_loss: 0.5330 - val_mse: 0.5330 - val_mae: 0.5411\n",
      "Epoch 133/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1320 - mse: 0.1320 - mae: 0.2747 - val_loss: 0.5287 - val_mse: 0.5287 - val_mae: 0.5376\n",
      "Epoch 134/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1321 - mse: 0.1321 - mae: 0.2759 - val_loss: 0.5289 - val_mse: 0.5289 - val_mae: 0.5382\n",
      "Epoch 135/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1325 - mse: 0.1325 - mae: 0.2767 - val_loss: 0.5336 - val_mse: 0.5336 - val_mae: 0.5443\n",
      "Epoch 136/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1390 - mse: 0.1390 - mae: 0.2835 - val_loss: 0.5204 - val_mse: 0.5204 - val_mae: 0.5315\n",
      "Epoch 137/3000\n",
      "10664/10664 [==============================] - 0s 7us/sample - loss: 0.1369 - mse: 0.1369 - mae: 0.2794 - val_loss: 0.5319 - val_mse: 0.5319 - val_mae: 0.5440\n",
      "Epoch 138/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1338 - mse: 0.1338 - mae: 0.2780 - val_loss: 0.5110 - val_mse: 0.5110 - val_mae: 0.5255\n",
      "Epoch 139/3000\n",
      "10664/10664 [==============================] - 0s 5us/sample - loss: 0.1387 - mse: 0.1387 - mae: 0.2821 - val_loss: 0.5355 - val_mse: 0.5355 - val_mae: 0.5441\n",
      "Epoch 140/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1357 - mse: 0.1357 - mae: 0.2787 - val_loss: 0.5159 - val_mse: 0.5159 - val_mae: 0.5288\n",
      "Epoch 141/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1311 - mse: 0.1311 - mae: 0.2735 - val_loss: 0.5224 - val_mse: 0.5224 - val_mae: 0.5353\n",
      "Epoch 142/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1314 - mse: 0.1314 - mae: 0.2740 - val_loss: 0.5186 - val_mse: 0.5186 - val_mae: 0.5307\n",
      "Epoch 143/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1294 - mse: 0.1294 - mae: 0.2723 - val_loss: 0.5193 - val_mse: 0.5193 - val_mae: 0.5301\n",
      "Epoch 144/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1283 - mse: 0.1283 - mae: 0.2708 - val_loss: 0.5141 - val_mse: 0.5141 - val_mae: 0.5247\n",
      "Epoch 145/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1261 - mse: 0.1261 - mae: 0.2693 - val_loss: 0.5177 - val_mse: 0.5177 - val_mae: 0.5288\n",
      "Epoch 146/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1264 - mse: 0.1264 - mae: 0.2700 - val_loss: 0.5121 - val_mse: 0.5121 - val_mae: 0.5264\n",
      "Epoch 147/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1230 - mse: 0.1230 - mae: 0.2657 - val_loss: 0.5173 - val_mse: 0.5173 - val_mae: 0.5272\n",
      "Epoch 148/3000\n",
      "10664/10664 [==============================] - 0s 6us/sample - loss: 0.1239 - mse: 0.1239 - mae: 0.2659 - val_loss: 0.5208 - val_mse: 0.5208 - val_mae: 0.5287\n",
      "Avg. MAE: 0.538730\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 94s 9ms/sample - loss: 37.3662 - mse: 37.3661 - mae: 1.6250 - val_loss: 3.2419 - val_mse: 3.2419 - val_mae: 1.0140\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 96s 9ms/sample - loss: 0.8700 - mse: 0.8700 - mae: 0.6975 - val_loss: 0.8142 - val_mse: 0.8142 - val_mae: 0.6862\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.7907 - mse: 0.7907 - mae: 0.6701 - val_loss: 1.0090 - val_mse: 1.0090 - val_mae: 0.7163\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.7924 - mse: 0.7924 - mae: 0.6593 - val_loss: 1.9125 - val_mse: 1.9125 - val_mae: 0.8340\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.7678 - mse: 0.7678 - mae: 0.6413 - val_loss: 0.6627 - val_mse: 0.6627 - val_mae: 0.5948\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.6574 - mse: 0.6574 - mae: 0.6025 - val_loss: 0.5766 - val_mse: 0.5766 - val_mae: 0.5691\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.7496 - mse: 0.7496 - mae: 0.6253 - val_loss: 0.6685 - val_mse: 0.6685 - val_mae: 0.6253\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.6386 - mse: 0.6386 - mae: 0.5875 - val_loss: 0.7161 - val_mse: 0.7161 - val_mae: 0.5865\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.7272 - mse: 0.7272 - mae: 0.6211 - val_loss: 0.8207 - val_mse: 0.8207 - val_mae: 0.6700\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.6707 - mse: 0.6707 - mae: 0.5850 - val_loss: 0.5979 - val_mse: 0.5979 - val_mae: 0.5370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.6761 - mse: 0.6761 - mae: 0.5960 - val_loss: 0.6825 - val_mse: 0.6825 - val_mae: 0.6237\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6979 - mse: 0.6979 - mae: 0.6032 - val_loss: 0.6483 - val_mse: 0.6483 - val_mae: 0.5869\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6266 - mse: 0.6266 - mae: 0.5753 - val_loss: 0.5190 - val_mse: 0.5190 - val_mae: 0.5284\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6731 - mse: 0.6731 - mae: 0.5832 - val_loss: 0.8742 - val_mse: 0.8742 - val_mae: 0.6226\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.7725 - mse: 0.7725 - mae: 0.6000 - val_loss: 0.9723 - val_mse: 0.9723 - val_mae: 0.6675\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6846 - mse: 0.6846 - mae: 0.5861 - val_loss: 0.6899 - val_mse: 0.6899 - val_mae: 0.6119\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.7326 - mse: 0.7326 - mae: 0.5849 - val_loss: 0.5647 - val_mse: 0.5647 - val_mae: 0.5589\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6219 - mse: 0.6219 - mae: 0.5627 - val_loss: 0.5438 - val_mse: 0.5438 - val_mae: 0.5282\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6132 - mse: 0.6132 - mae: 0.5581 - val_loss: 0.9283 - val_mse: 0.9283 - val_mae: 0.6207\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6498 - mse: 0.6498 - mae: 0.5615 - val_loss: 0.4207 - val_mse: 0.4207 - val_mae: 0.4773\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5627 - mse: 0.5627 - mae: 0.5328 - val_loss: 0.5153 - val_mse: 0.5153 - val_mae: 0.5224\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.4811 - mse: 0.4811 - mae: 0.5036 - val_loss: 0.5552 - val_mse: 0.5552 - val_mae: 0.5505\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5968 - mse: 0.5968 - mae: 0.5458 - val_loss: 0.7534 - val_mse: 0.7534 - val_mae: 0.5835\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5776 - mse: 0.5776 - mae: 0.5276 - val_loss: 0.9326 - val_mse: 0.9326 - val_mae: 0.6750\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.6025 - mse: 0.6025 - mae: 0.5466 - val_loss: 0.5184 - val_mse: 0.5184 - val_mae: 0.5340\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5773 - mse: 0.5773 - mae: 0.5392 - val_loss: 0.8023 - val_mse: 0.8023 - val_mae: 0.6235\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.5657 - mse: 0.5657 - mae: 0.5384 - val_loss: 0.6097 - val_mse: 0.6097 - val_mae: 0.5635\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.5426 - mse: 0.5426 - mae: 0.5291 - val_loss: 0.8922 - val_mse: 0.8922 - val_mae: 0.7427\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.4952 - mse: 0.4952 - mae: 0.5117 - val_loss: 0.6203 - val_mse: 0.6203 - val_mae: 0.6050\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.4586 - mse: 0.4586 - mae: 0.5019 - val_loss: 0.6843 - val_mse: 0.6843 - val_mae: 0.6527\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 94s 9ms/sample - loss: 45.4523 - mse: 45.4522 - mae: 1.9749 - val_loss: 2.7239 - val_mse: 2.7239 - val_mae: 1.0112\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.8873 - mse: 0.8873 - mae: 0.7123 - val_loss: 1.0572 - val_mse: 1.0572 - val_mae: 0.7414\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.7779 - mse: 0.7779 - mae: 0.6639 - val_loss: 0.9723 - val_mse: 0.9723 - val_mae: 0.7257\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.7346 - mse: 0.7346 - mae: 0.6477 - val_loss: 1.4261 - val_mse: 1.4261 - val_mae: 0.6671\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.7840 - mse: 0.7840 - mae: 0.6615 - val_loss: 1.0920 - val_mse: 1.0920 - val_mae: 0.6816\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.7348 - mse: 0.7348 - mae: 0.6363 - val_loss: 0.6269 - val_mse: 0.6269 - val_mae: 0.5715\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.6397 - mse: 0.6397 - mae: 0.5947 - val_loss: 0.6845 - val_mse: 0.6845 - val_mae: 0.6055\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.6420 - mse: 0.6420 - mae: 0.5917 - val_loss: 0.7564 - val_mse: 0.7564 - val_mae: 0.6523\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5932 - mse: 0.5932 - mae: 0.5716 - val_loss: 0.9173 - val_mse: 0.9173 - val_mae: 0.7196\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5941 - mse: 0.5941 - mae: 0.5754 - val_loss: 1.1050 - val_mse: 1.1050 - val_mae: 0.7952\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5764 - mse: 0.5764 - mae: 0.5654 - val_loss: 3.2681 - val_mse: 3.2681 - val_mae: 0.7159\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6102 - mse: 0.6102 - mae: 0.5773 - val_loss: 0.7222 - val_mse: 0.7222 - val_mae: 0.5279\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5950 - mse: 0.5950 - mae: 0.5666 - val_loss: 1.0892 - val_mse: 1.0892 - val_mae: 0.6787\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6958 - mse: 0.6958 - mae: 0.6026 - val_loss: 0.9906 - val_mse: 0.9906 - val_mae: 0.6936\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6192 - mse: 0.6192 - mae: 0.5848 - val_loss: 0.5994 - val_mse: 0.5994 - val_mae: 0.5538\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5243 - mse: 0.5243 - mae: 0.5332 - val_loss: 1.0301 - val_mse: 1.0301 - val_mae: 0.6300\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5841 - mse: 0.5841 - mae: 0.5648 - val_loss: 0.8649 - val_mse: 0.8649 - val_mae: 0.6104\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5583 - mse: 0.5583 - mae: 0.5492 - val_loss: 1.2231 - val_mse: 1.2231 - val_mae: 0.5920\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5320 - mse: 0.5320 - mae: 0.5367 - val_loss: 1.1991 - val_mse: 1.1991 - val_mae: 0.5610\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5048 - mse: 0.5048 - mae: 0.5339 - val_loss: 2.0483 - val_mse: 2.0483 - val_mae: 0.8971\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.7454 - mse: 0.7454 - mae: 0.6253 - val_loss: 1.1550 - val_mse: 1.1550 - val_mae: 0.5961\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6142 - mse: 0.6142 - mae: 0.5654 - val_loss: 2.1636 - val_mse: 2.1636 - val_mae: 0.8756\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.6919 - mse: 0.6919 - mae: 0.5904 - val_loss: 0.7813 - val_mse: 0.7813 - val_mae: 0.6275\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.5234 - mse: 0.5234 - mae: 0.5316 - val_loss: 1.2336 - val_mse: 1.2336 - val_mae: 0.6963\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.4968 - mse: 0.4968 - mae: 0.5125 - val_loss: 1.1097 - val_mse: 1.1097 - val_mae: 0.5981\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 94s 9ms/sample - loss: 44.5027 - mse: 44.5027 - mae: 1.9751 - val_loss: 1.4400 - val_mse: 1.4400 - val_mae: 0.8932\n",
      "Epoch 2/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.9022 - mse: 0.9022 - mae: 0.7141 - val_loss: 1.3373 - val_mse: 1.3373 - val_mae: 0.8421\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.8415 - mse: 0.8415 - mae: 0.6908 - val_loss: 1.0384 - val_mse: 1.0384 - val_mae: 0.7803\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.7485 - mse: 0.7485 - mae: 0.6452 - val_loss: 0.7091 - val_mse: 0.7091 - val_mae: 0.6444\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.7631 - mse: 0.7631 - mae: 0.6430 - val_loss: 0.7881 - val_mse: 0.7881 - val_mae: 0.6553\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.8039 - mse: 0.8039 - mae: 0.6549 - val_loss: 0.6358 - val_mse: 0.6358 - val_mae: 0.5783\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.6579 - mse: 0.6579 - mae: 0.5948 - val_loss: 1.0003 - val_mse: 1.0003 - val_mae: 0.7453\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.6443 - mse: 0.6443 - mae: 0.5877 - val_loss: 0.7850 - val_mse: 0.7850 - val_mae: 0.6604\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.6957 - mse: 0.6957 - mae: 0.6102 - val_loss: 1.0689 - val_mse: 1.0689 - val_mae: 0.6556\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.6839 - mse: 0.6839 - mae: 0.5985 - val_loss: 0.6214 - val_mse: 0.6214 - val_mae: 0.5839\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.6713 - mse: 0.6713 - mae: 0.5808 - val_loss: 1.1149 - val_mse: 1.1149 - val_mae: 0.7687\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 92s 9ms/sample - loss: 0.6279 - mse: 0.6279 - mae: 0.5714 - val_loss: 0.5663 - val_mse: 0.5663 - val_mae: 0.5338\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 94s 9ms/sample - loss: 0.5881 - mse: 0.5881 - mae: 0.5446 - val_loss: 0.4989 - val_mse: 0.4989 - val_mae: 0.5066\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.5865 - mse: 0.5865 - mae: 0.5476 - val_loss: 0.4821 - val_mse: 0.4821 - val_mae: 0.5156\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.6229 - mse: 0.6229 - mae: 0.5567 - val_loss: 0.4747 - val_mse: 0.4747 - val_mae: 0.4928\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 96s 9ms/sample - loss: 0.6431 - mse: 0.6431 - mae: 0.5595 - val_loss: 0.6856 - val_mse: 0.6856 - val_mae: 0.5853\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.6375 - mse: 0.6375 - mae: 0.5645 - val_loss: 0.6316 - val_mse: 0.6316 - val_mae: 0.5317\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.6008 - mse: 0.6008 - mae: 0.5535 - val_loss: 1.5333 - val_mse: 1.5333 - val_mae: 0.8189\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.6740 - mse: 0.6740 - mae: 0.5705 - val_loss: 0.8404 - val_mse: 0.8404 - val_mae: 0.6500\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.6654 - mse: 0.6654 - mae: 0.5700 - val_loss: 0.5547 - val_mse: 0.5547 - val_mae: 0.5589\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.5698 - mse: 0.5698 - mae: 0.5286 - val_loss: 0.6866 - val_mse: 0.6866 - val_mae: 0.5874\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.6526 - mse: 0.6526 - mae: 0.5563 - val_loss: 0.5566 - val_mse: 0.5566 - val_mae: 0.5422\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.5310 - mse: 0.5310 - mae: 0.5158 - val_loss: 0.6605 - val_mse: 0.6605 - val_mae: 0.5406\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.5226 - mse: 0.5226 - mae: 0.5143 - val_loss: 1.3830 - val_mse: 1.3830 - val_mae: 0.6228\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.6649 - mse: 0.6649 - mae: 0.5588 - val_loss: 0.8647 - val_mse: 0.8647 - val_mae: 0.6635\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 97s 9ms/sample - loss: 47.6756 - mse: 47.6756 - mae: 2.0769 - val_loss: 1.0222 - val_mse: 1.0222 - val_mae: 0.7404\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.9597 - mse: 0.9597 - mae: 0.7422 - val_loss: 1.2865 - val_mse: 1.2865 - val_mae: 0.7665\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 95s 9ms/sample - loss: 0.9188 - mse: 0.9188 - mae: 0.7172 - val_loss: 0.7701 - val_mse: 0.7701 - val_mae: 0.6758\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.8548 - mse: 0.8548 - mae: 0.6863 - val_loss: 1.0842 - val_mse: 1.0842 - val_mae: 0.7225\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.7578 - mse: 0.7578 - mae: 0.6443 - val_loss: 4.1389 - val_mse: 4.1389 - val_mae: 0.9255\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.7509 - mse: 0.7509 - mae: 0.6370 - val_loss: 0.8308 - val_mse: 0.8308 - val_mae: 0.6162\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.7026 - mse: 0.7026 - mae: 0.6171 - val_loss: 0.6264 - val_mse: 0.6264 - val_mae: 0.5786\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6524 - mse: 0.6524 - mae: 0.5971 - val_loss: 0.9787 - val_mse: 0.9787 - val_mae: 0.7046\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6694 - mse: 0.6694 - mae: 0.5963 - val_loss: 0.8765 - val_mse: 0.8765 - val_mae: 0.5847\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.7383 - mse: 0.7383 - mae: 0.6169 - val_loss: 0.5694 - val_mse: 0.5694 - val_mae: 0.5503\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.7911 - mse: 0.7911 - mae: 0.6259 - val_loss: 0.8314 - val_mse: 0.8314 - val_mae: 0.6369\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6331 - mse: 0.6331 - mae: 0.5654 - val_loss: 0.6708 - val_mse: 0.6708 - val_mae: 0.6367\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.5960 - mse: 0.5960 - mae: 0.5507 - val_loss: 1.5775 - val_mse: 1.5775 - val_mae: 0.7204\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.7679 - mse: 0.7679 - mae: 0.6155 - val_loss: 2.5513 - val_mse: 2.5513 - val_mae: 0.7649\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.7078 - mse: 0.7078 - mae: 0.5904 - val_loss: 3.7679 - val_mse: 3.7679 - val_mae: 0.7590\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6098 - mse: 0.6098 - mae: 0.5543 - val_loss: 1.5724 - val_mse: 1.5724 - val_mae: 0.7935\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6687 - mse: 0.6687 - mae: 0.5683 - val_loss: 1.0359 - val_mse: 1.0359 - val_mae: 0.5656\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6630 - mse: 0.6630 - mae: 0.5675 - val_loss: 0.9719 - val_mse: 0.9719 - val_mae: 0.6740\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.5966 - mse: 0.5966 - mae: 0.5457 - val_loss: 0.6252 - val_mse: 0.6252 - val_mae: 0.5261\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 93s 9ms/sample - loss: 0.6332 - mse: 0.6332 - mae: 0.5560 - val_loss: 0.6852 - val_mse: 0.6852 - val_mae: 0.5404\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 93s 9ms/sample - loss: 47.9679 - mse: 47.9678 - mae: 1.9747 - val_loss: 1.7627 - val_mse: 1.7627 - val_mae: 1.0081\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.8226 - mse: 0.8226 - mae: 0.6876 - val_loss: 0.8428 - val_mse: 0.8428 - val_mae: 0.7142\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 93s 9ms/sample - loss: 0.8085 - mse: 0.8085 - mae: 0.6784 - val_loss: 0.6757 - val_mse: 0.6757 - val_mae: 0.5963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.7320 - mse: 0.7320 - mae: 0.6465 - val_loss: 0.8763 - val_mse: 0.8763 - val_mae: 0.6771\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 93s 9ms/sample - loss: 0.6709 - mse: 0.6709 - mae: 0.6154 - val_loss: 0.6777 - val_mse: 0.6777 - val_mae: 0.5976\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 93s 9ms/sample - loss: 0.6681 - mse: 0.6681 - mae: 0.6138 - val_loss: 0.6554 - val_mse: 0.6554 - val_mae: 0.6161\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.7008 - mse: 0.7008 - mae: 0.6304 - val_loss: 0.6983 - val_mse: 0.6983 - val_mae: 0.6063\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.6654 - mse: 0.6654 - mae: 0.6045 - val_loss: 0.6708 - val_mse: 0.6708 - val_mae: 0.6320\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.5673 - mse: 0.5673 - mae: 0.5666 - val_loss: 0.9366 - val_mse: 0.9366 - val_mae: 0.7292\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.5632 - mse: 0.5632 - mae: 0.5630 - val_loss: 0.5963 - val_mse: 0.5963 - val_mae: 0.5908\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.6314 - mse: 0.6314 - mae: 0.5923 - val_loss: 0.6562 - val_mse: 0.6562 - val_mae: 0.5611\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.6183 - mse: 0.6183 - mae: 0.5816 - val_loss: 0.8983 - val_mse: 0.8983 - val_mae: 0.6832\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.6157 - mse: 0.6157 - mae: 0.5721 - val_loss: 0.5390 - val_mse: 0.5390 - val_mae: 0.5313\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.6208 - mse: 0.6208 - mae: 0.5726 - val_loss: 0.5715 - val_mse: 0.5715 - val_mae: 0.5496\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.5794 - mse: 0.5794 - mae: 0.5612 - val_loss: 0.5498 - val_mse: 0.5498 - val_mae: 0.5389\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.5351 - mse: 0.5351 - mae: 0.5368 - val_loss: 1.1870 - val_mse: 1.1870 - val_mae: 0.8107\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.5862 - mse: 0.5862 - mae: 0.5597 - val_loss: 0.5154 - val_mse: 0.5154 - val_mae: 0.5178\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.6390 - mse: 0.6390 - mae: 0.5798 - val_loss: 1.7851 - val_mse: 1.7851 - val_mae: 0.9069\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.6929 - mse: 0.6929 - mae: 0.5923 - val_loss: 0.5328 - val_mse: 0.5328 - val_mae: 0.5397\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.7021 - mse: 0.7021 - mae: 0.5872 - val_loss: 0.6058 - val_mse: 0.6058 - val_mae: 0.5493\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.5401 - mse: 0.5401 - mae: 0.5299 - val_loss: 0.5460 - val_mse: 0.5460 - val_mae: 0.5225\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 93s 9ms/sample - loss: 0.6385 - mse: 0.6385 - mae: 0.5693 - val_loss: 0.9046 - val_mse: 0.9046 - val_mae: 0.7041\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.6608 - mse: 0.6608 - mae: 0.5685 - val_loss: 2.1582 - val_mse: 2.1582 - val_mae: 0.9831\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.6392 - mse: 0.6392 - mae: 0.5662 - val_loss: 0.7215 - val_mse: 0.7215 - val_mae: 0.6479\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.5657 - mse: 0.5657 - mae: 0.5315 - val_loss: 0.8668 - val_mse: 0.8668 - val_mae: 0.6299\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.5577 - mse: 0.5577 - mae: 0.5223 - val_loss: 1.0150 - val_mse: 1.0150 - val_mae: 0.7132\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 92s 9ms/sample - loss: 0.4901 - mse: 0.4901 - mae: 0.5033 - val_loss: 0.5197 - val_mse: 0.5197 - val_mae: 0.5248\n",
      "Avg. MAE: 0.456954\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 4s 353us/sample - loss: 1.2361 - mse: 1.2361 - mae: 0.7578 - val_loss: 0.7271 - val_mse: 0.7271 - val_mae: 0.6760\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.5633 - mse: 0.5633 - mae: 0.5642 - val_loss: 0.5062 - val_mse: 0.5062 - val_mae: 0.5306\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.4831 - mse: 0.4831 - mae: 0.5201 - val_loss: 0.5897 - val_mse: 0.5897 - val_mae: 0.5966\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 2s 223us/sample - loss: 0.4523 - mse: 0.4523 - mae: 0.5026 - val_loss: 0.5090 - val_mse: 0.5090 - val_mae: 0.5214\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 2s 222us/sample - loss: 0.4099 - mse: 0.4099 - mae: 0.4775 - val_loss: 0.4977 - val_mse: 0.4977 - val_mae: 0.5379\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.3721 - mse: 0.3721 - mae: 0.4577 - val_loss: 0.5350 - val_mse: 0.5350 - val_mae: 0.5243\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 2s 222us/sample - loss: 0.3629 - mse: 0.3629 - mae: 0.4499 - val_loss: 0.4699 - val_mse: 0.4699 - val_mae: 0.5021\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 2s 224us/sample - loss: 0.3372 - mse: 0.3372 - mae: 0.4366 - val_loss: 0.4369 - val_mse: 0.4369 - val_mae: 0.4813\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.3197 - mse: 0.3197 - mae: 0.4229 - val_loss: 0.4354 - val_mse: 0.4354 - val_mae: 0.4812\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.3010 - mse: 0.3010 - mae: 0.4140 - val_loss: 0.4400 - val_mse: 0.4400 - val_mae: 0.4765\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 2s 218us/sample - loss: 0.2964 - mse: 0.2964 - mae: 0.4071 - val_loss: 0.4453 - val_mse: 0.4453 - val_mae: 0.4812\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 2s 218us/sample - loss: 0.2841 - mse: 0.2841 - mae: 0.3973 - val_loss: 0.4824 - val_mse: 0.4824 - val_mae: 0.5121\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 2s 222us/sample - loss: 0.2675 - mse: 0.2675 - mae: 0.3886 - val_loss: 0.4849 - val_mse: 0.4849 - val_mae: 0.4997\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 2s 216us/sample - loss: 0.2675 - mse: 0.2675 - mae: 0.3863 - val_loss: 0.4984 - val_mse: 0.4984 - val_mae: 0.4988\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.2350 - mse: 0.2350 - mae: 0.3637 - val_loss: 0.4254 - val_mse: 0.4254 - val_mae: 0.4683\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 2s 217us/sample - loss: 0.2346 - mse: 0.2346 - mae: 0.3643 - val_loss: 0.4129 - val_mse: 0.4129 - val_mae: 0.4609\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.2392 - mse: 0.2392 - mae: 0.3644 - val_loss: 0.3997 - val_mse: 0.3997 - val_mae: 0.4666\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 2s 217us/sample - loss: 0.2247 - mse: 0.2247 - mae: 0.3576 - val_loss: 0.4011 - val_mse: 0.4011 - val_mae: 0.4587\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.2232 - mse: 0.2232 - mae: 0.3536 - val_loss: 0.4393 - val_mse: 0.4393 - val_mae: 0.4677\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.2051 - mse: 0.2051 - mae: 0.3415 - val_loss: 0.4128 - val_mse: 0.4128 - val_mae: 0.4629\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.2029 - mse: 0.2029 - mae: 0.3390 - val_loss: 0.3970 - val_mse: 0.3970 - val_mae: 0.4502\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.2008 - mse: 0.2008 - mae: 0.3387 - val_loss: 0.3908 - val_mse: 0.3908 - val_mae: 0.4430\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 2s 217us/sample - loss: 0.1838 - mse: 0.1838 - mae: 0.3230 - val_loss: 0.4093 - val_mse: 0.4093 - val_mae: 0.4589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.1840 - mse: 0.1840 - mae: 0.3228 - val_loss: 0.4507 - val_mse: 0.4507 - val_mae: 0.4748\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.1876 - mse: 0.1876 - mae: 0.3244 - val_loss: 0.4421 - val_mse: 0.4421 - val_mae: 0.4734\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.1780 - mse: 0.1780 - mae: 0.3166 - val_loss: 0.4048 - val_mse: 0.4048 - val_mae: 0.4541\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.1706 - mse: 0.1706 - mae: 0.3121 - val_loss: 0.5010 - val_mse: 0.5010 - val_mae: 0.4984\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 2s 220us/sample - loss: 0.1626 - mse: 0.1626 - mae: 0.3023 - val_loss: 0.4596 - val_mse: 0.4596 - val_mae: 0.4753\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 2s 218us/sample - loss: 0.1675 - mse: 0.1675 - mae: 0.3050 - val_loss: 0.3916 - val_mse: 0.3916 - val_mae: 0.4510\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 2s 222us/sample - loss: 0.1586 - mse: 0.1586 - mae: 0.2995 - val_loss: 0.4615 - val_mse: 0.4615 - val_mae: 0.4674\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 2s 219us/sample - loss: 0.1543 - mse: 0.1543 - mae: 0.2915 - val_loss: 0.4102 - val_mse: 0.4102 - val_mae: 0.4477\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 2s 221us/sample - loss: 0.1554 - mse: 0.1554 - mae: 0.2947 - val_loss: 0.4089 - val_mse: 0.4089 - val_mae: 0.4429\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 4s 420us/sample - loss: 1.3078 - mse: 1.3078 - mae: 0.7773 - val_loss: 0.8361 - val_mse: 0.8361 - val_mae: 0.7191\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 2s 231us/sample - loss: 0.5925 - mse: 0.5925 - mae: 0.5785 - val_loss: 0.5455 - val_mse: 0.5455 - val_mae: 0.5500\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 2s 233us/sample - loss: 0.4891 - mse: 0.4891 - mae: 0.5276 - val_loss: 0.6713 - val_mse: 0.6713 - val_mae: 0.5662\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.4470 - mse: 0.4470 - mae: 0.4995 - val_loss: 0.7904 - val_mse: 0.7904 - val_mae: 0.5666\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.4324 - mse: 0.4324 - mae: 0.4943 - val_loss: 0.5405 - val_mse: 0.5405 - val_mae: 0.5114\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.3987 - mse: 0.3987 - mae: 0.4731 - val_loss: 1.0091 - val_mse: 1.0091 - val_mae: 0.5433\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 2s 231us/sample - loss: 0.3575 - mse: 0.3575 - mae: 0.4483 - val_loss: 0.5070 - val_mse: 0.5070 - val_mae: 0.4910\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.3548 - mse: 0.3548 - mae: 0.4463 - val_loss: 0.7464 - val_mse: 0.7464 - val_mae: 0.5296\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.3342 - mse: 0.3342 - mae: 0.4366 - val_loss: 0.8905 - val_mse: 0.8905 - val_mae: 0.5253\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.3219 - mse: 0.3219 - mae: 0.4252 - val_loss: 0.6344 - val_mse: 0.6344 - val_mae: 0.4891\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.2927 - mse: 0.2927 - mae: 0.4064 - val_loss: 0.6024 - val_mse: 0.6024 - val_mae: 0.5066\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.2753 - mse: 0.2753 - mae: 0.3939 - val_loss: 0.5975 - val_mse: 0.5975 - val_mae: 0.5006\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.2674 - mse: 0.2674 - mae: 0.3870 - val_loss: 0.6377 - val_mse: 0.6377 - val_mae: 0.4982\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 2s 233us/sample - loss: 0.2531 - mse: 0.2531 - mae: 0.3780 - val_loss: 0.7802 - val_mse: 0.7802 - val_mae: 0.5427\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.2582 - mse: 0.2582 - mae: 0.3824 - val_loss: 0.7150 - val_mse: 0.7150 - val_mae: 0.5220\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.2495 - mse: 0.2495 - mae: 0.3759 - val_loss: 0.4779 - val_mse: 0.4779 - val_mae: 0.4601\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.2347 - mse: 0.2347 - mae: 0.3635 - val_loss: 0.4553 - val_mse: 0.4553 - val_mae: 0.4737\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 3s 237us/sample - loss: 0.2286 - mse: 0.2286 - mae: 0.3588 - val_loss: 0.7715 - val_mse: 0.7715 - val_mae: 0.4717\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.2307 - mse: 0.2307 - mae: 0.3579 - val_loss: 0.5645 - val_mse: 0.5645 - val_mae: 0.4952\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 2s 231us/sample - loss: 0.2011 - mse: 0.2011 - mae: 0.3378 - val_loss: 0.6173 - val_mse: 0.6173 - val_mae: 0.4743\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.2011 - mse: 0.2011 - mae: 0.3372 - val_loss: 0.4524 - val_mse: 0.4524 - val_mae: 0.4670\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.2007 - mse: 0.2007 - mae: 0.3348 - val_loss: 0.5582 - val_mse: 0.5582 - val_mae: 0.4627\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.2008 - mse: 0.2008 - mae: 0.3365 - val_loss: 0.4629 - val_mse: 0.4629 - val_mae: 0.4625\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 3s 236us/sample - loss: 0.1822 - mse: 0.1822 - mae: 0.3220 - val_loss: 0.5360 - val_mse: 0.5360 - val_mae: 0.4738\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1858 - mse: 0.1858 - mae: 0.3212 - val_loss: 0.4091 - val_mse: 0.4091 - val_mae: 0.4461\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 2s 232us/sample - loss: 0.1753 - mse: 0.1753 - mae: 0.3132 - val_loss: 0.4557 - val_mse: 0.4557 - val_mae: 0.4706\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.1793 - mse: 0.1793 - mae: 0.3136 - val_loss: 0.4410 - val_mse: 0.4410 - val_mae: 0.4552\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 2s 233us/sample - loss: 0.1782 - mse: 0.1782 - mae: 0.3173 - val_loss: 0.8577 - val_mse: 0.8577 - val_mae: 0.4672\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1744 - mse: 0.1744 - mae: 0.3140 - val_loss: 0.4918 - val_mse: 0.4918 - val_mae: 0.4574\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.1673 - mse: 0.1673 - mae: 0.3062 - val_loss: 0.5026 - val_mse: 0.5026 - val_mae: 0.4802\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.1562 - mse: 0.1562 - mae: 0.2949 - val_loss: 0.4617 - val_mse: 0.4617 - val_mae: 0.4653\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.1491 - mse: 0.1491 - mae: 0.2888 - val_loss: 0.4665 - val_mse: 0.4665 - val_mae: 0.4545\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 2s 232us/sample - loss: 0.1598 - mse: 0.1598 - mae: 0.2981 - val_loss: 0.4076 - val_mse: 0.4076 - val_mae: 0.4507\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.1476 - mse: 0.1476 - mae: 0.2882 - val_loss: 0.5910 - val_mse: 0.5910 - val_mae: 0.4594\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1446 - mse: 0.1446 - mae: 0.2840 - val_loss: 0.4730 - val_mse: 0.4730 - val_mae: 0.4435\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.1311 - mse: 0.1311 - mae: 0.2709 - val_loss: 0.5137 - val_mse: 0.5137 - val_mae: 0.4645\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 2s 232us/sample - loss: 0.1431 - mse: 0.1431 - mae: 0.2817 - val_loss: 0.5412 - val_mse: 0.5412 - val_mae: 0.4693\n",
      "Epoch 38/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.1354 - mse: 0.1354 - mae: 0.2763 - val_loss: 0.5067 - val_mse: 0.5067 - val_mae: 0.4582\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.1282 - mse: 0.1282 - mae: 0.2677 - val_loss: 0.4100 - val_mse: 0.4100 - val_mae: 0.4435\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 2s 233us/sample - loss: 0.1415 - mse: 0.1415 - mae: 0.2794 - val_loss: 0.4489 - val_mse: 0.4489 - val_mae: 0.4578\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.1360 - mse: 0.1360 - mae: 0.2775 - val_loss: 0.5082 - val_mse: 0.5082 - val_mae: 0.4493\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 3s 235us/sample - loss: 0.1331 - mse: 0.1331 - mae: 0.2729 - val_loss: 0.5618 - val_mse: 0.5618 - val_mae: 0.4419\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.1259 - mse: 0.1259 - mae: 0.2641 - val_loss: 0.5122 - val_mse: 0.5122 - val_mae: 0.4409\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 4s 355us/sample - loss: 1.2309 - mse: 1.2309 - mae: 0.7582 - val_loss: 1.1862 - val_mse: 1.1862 - val_mae: 0.8580\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.5840 - mse: 0.5840 - mae: 0.5754 - val_loss: 0.5804 - val_mse: 0.5804 - val_mae: 0.5794\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.4898 - mse: 0.4898 - mae: 0.5235 - val_loss: 0.5230 - val_mse: 0.5230 - val_mae: 0.5372\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.4429 - mse: 0.4429 - mae: 0.4996 - val_loss: 0.5155 - val_mse: 0.5155 - val_mae: 0.5257\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.4114 - mse: 0.4114 - mae: 0.4794 - val_loss: 0.5158 - val_mse: 0.5158 - val_mae: 0.5171\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.3858 - mse: 0.3858 - mae: 0.4675 - val_loss: 0.5185 - val_mse: 0.5185 - val_mae: 0.5238\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.3548 - mse: 0.3548 - mae: 0.4461 - val_loss: 0.4916 - val_mse: 0.4916 - val_mae: 0.5176\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.3568 - mse: 0.3568 - mae: 0.4480 - val_loss: 0.5469 - val_mse: 0.5469 - val_mae: 0.5262\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.3318 - mse: 0.3318 - mae: 0.4357 - val_loss: 0.5345 - val_mse: 0.5345 - val_mae: 0.5320\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.3180 - mse: 0.3180 - mae: 0.4231 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.4909\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 2s 231us/sample - loss: 0.2978 - mse: 0.2978 - mae: 0.4092 - val_loss: 0.4546 - val_mse: 0.4546 - val_mae: 0.4799\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.2892 - mse: 0.2892 - mae: 0.4068 - val_loss: 0.6824 - val_mse: 0.6824 - val_mae: 0.4975\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 2s 232us/sample - loss: 0.2788 - mse: 0.2788 - mae: 0.3980 - val_loss: 0.4420 - val_mse: 0.4420 - val_mae: 0.4707\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.2644 - mse: 0.2644 - mae: 0.3893 - val_loss: 0.4815 - val_mse: 0.4815 - val_mae: 0.4865\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.2498 - mse: 0.2498 - mae: 0.3773 - val_loss: 0.4463 - val_mse: 0.4463 - val_mae: 0.4633\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.2402 - mse: 0.2402 - mae: 0.3689 - val_loss: 0.4697 - val_mse: 0.4697 - val_mae: 0.4772\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 2s 231us/sample - loss: 0.2434 - mse: 0.2434 - mae: 0.3696 - val_loss: 0.6084 - val_mse: 0.6084 - val_mae: 0.5123\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.2273 - mse: 0.2273 - mae: 0.3597 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4544\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 2s 232us/sample - loss: 0.2212 - mse: 0.2212 - mae: 0.3549 - val_loss: 0.5096 - val_mse: 0.5096 - val_mae: 0.4938\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 2s 232us/sample - loss: 0.2084 - mse: 0.2084 - mae: 0.3461 - val_loss: 0.5169 - val_mse: 0.5169 - val_mae: 0.4714\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.2069 - mse: 0.2069 - mae: 0.3427 - val_loss: 0.5317 - val_mse: 0.5317 - val_mae: 0.4744\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 2s 231us/sample - loss: 0.1962 - mse: 0.1962 - mae: 0.3344 - val_loss: 0.4518 - val_mse: 0.4518 - val_mae: 0.4717\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1906 - mse: 0.1906 - mae: 0.3285 - val_loss: 0.5122 - val_mse: 0.5122 - val_mae: 0.4704\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1854 - mse: 0.1854 - mae: 0.3222 - val_loss: 0.4401 - val_mse: 0.4401 - val_mae: 0.4567\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1781 - mse: 0.1781 - mae: 0.3175 - val_loss: 0.4575 - val_mse: 0.4575 - val_mae: 0.4792\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1713 - mse: 0.1713 - mae: 0.3142 - val_loss: 0.4570 - val_mse: 0.4570 - val_mae: 0.4804\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.1780 - mse: 0.1780 - mae: 0.3152 - val_loss: 0.4919 - val_mse: 0.4919 - val_mae: 0.4716\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1735 - mse: 0.1735 - mae: 0.3134 - val_loss: 0.4333 - val_mse: 0.4333 - val_mae: 0.4517\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 4s 352us/sample - loss: 1.3192 - mse: 1.3192 - mae: 0.7658 - val_loss: 0.8514 - val_mse: 0.8514 - val_mae: 0.7380\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.5642 - mse: 0.5642 - mae: 0.5651 - val_loss: 0.6497 - val_mse: 0.6497 - val_mae: 0.5773\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.4891 - mse: 0.4891 - mae: 0.5261 - val_loss: 0.5164 - val_mse: 0.5164 - val_mae: 0.5596\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.4374 - mse: 0.4374 - mae: 0.4938 - val_loss: 0.8476 - val_mse: 0.8476 - val_mae: 0.6125\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.4125 - mse: 0.4125 - mae: 0.4837 - val_loss: 0.4906 - val_mse: 0.4906 - val_mae: 0.5172\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.3814 - mse: 0.3814 - mae: 0.4640 - val_loss: 0.4776 - val_mse: 0.4776 - val_mae: 0.4944\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.3772 - mse: 0.3772 - mae: 0.4619 - val_loss: 0.6240 - val_mse: 0.6240 - val_mae: 0.5430\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.3462 - mse: 0.3462 - mae: 0.4412 - val_loss: 0.5171 - val_mse: 0.5171 - val_mae: 0.5080\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.3439 - mse: 0.3439 - mae: 0.4404 - val_loss: 0.4302 - val_mse: 0.4302 - val_mae: 0.4837\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.3183 - mse: 0.3183 - mae: 0.4241 - val_loss: 0.4578 - val_mse: 0.4578 - val_mae: 0.4979\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.2874 - mse: 0.2874 - mae: 0.4037 - val_loss: 0.4430 - val_mse: 0.4430 - val_mae: 0.4963\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.2856 - mse: 0.2856 - mae: 0.3992 - val_loss: 0.4474 - val_mse: 0.4474 - val_mae: 0.4743\n",
      "Epoch 13/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.2611 - mse: 0.2611 - mae: 0.3851 - val_loss: 0.4579 - val_mse: 0.4579 - val_mae: 0.4936\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.2659 - mse: 0.2659 - mae: 0.3881 - val_loss: 0.4307 - val_mse: 0.4307 - val_mae: 0.4712\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.2417 - mse: 0.2417 - mae: 0.3695 - val_loss: 0.4275 - val_mse: 0.4275 - val_mae: 0.4751\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.2533 - mse: 0.2533 - mae: 0.3779 - val_loss: 0.4415 - val_mse: 0.4415 - val_mae: 0.4779\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.2381 - mse: 0.2381 - mae: 0.3674 - val_loss: 0.4176 - val_mse: 0.4176 - val_mae: 0.4672\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.2162 - mse: 0.2162 - mae: 0.3523 - val_loss: 0.4315 - val_mse: 0.4315 - val_mae: 0.4742\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 3s 237us/sample - loss: 0.2106 - mse: 0.2106 - mae: 0.3459 - val_loss: 0.4054 - val_mse: 0.4054 - val_mae: 0.4433\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1985 - mse: 0.1985 - mae: 0.3359 - val_loss: 0.4652 - val_mse: 0.4652 - val_mae: 0.4750\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.2029 - mse: 0.2029 - mae: 0.3367 - val_loss: 0.4443 - val_mse: 0.4443 - val_mae: 0.4742\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.2007 - mse: 0.2007 - mae: 0.3365 - val_loss: 0.4194 - val_mse: 0.4194 - val_mae: 0.4635\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.1873 - mse: 0.1873 - mae: 0.3250 - val_loss: 0.4083 - val_mse: 0.4083 - val_mae: 0.4501\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.1906 - mse: 0.1906 - mae: 0.3257 - val_loss: 0.4089 - val_mse: 0.4089 - val_mae: 0.4521\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1784 - mse: 0.1784 - mae: 0.3190 - val_loss: 0.4116 - val_mse: 0.4116 - val_mae: 0.4532\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.1688 - mse: 0.1688 - mae: 0.3068 - val_loss: 0.3981 - val_mse: 0.3981 - val_mae: 0.4370\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.1750 - mse: 0.1750 - mae: 0.3149 - val_loss: 0.3997 - val_mse: 0.3997 - val_mae: 0.4480\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.1702 - mse: 0.1702 - mae: 0.3107 - val_loss: 0.4234 - val_mse: 0.4234 - val_mae: 0.4616\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.1666 - mse: 0.1666 - mae: 0.3064 - val_loss: 0.4171 - val_mse: 0.4171 - val_mae: 0.4567\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.1600 - mse: 0.1600 - mae: 0.3013 - val_loss: 0.3917 - val_mse: 0.3917 - val_mae: 0.4380\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.1569 - mse: 0.1569 - mae: 0.2968 - val_loss: 0.4047 - val_mse: 0.4047 - val_mae: 0.4584\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.1567 - mse: 0.1567 - mae: 0.2953 - val_loss: 0.4071 - val_mse: 0.4071 - val_mae: 0.4575\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.1644 - mse: 0.1644 - mae: 0.3022 - val_loss: 0.3856 - val_mse: 0.3856 - val_mae: 0.4359\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.1482 - mse: 0.1482 - mae: 0.2871 - val_loss: 0.4178 - val_mse: 0.4178 - val_mae: 0.4501\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.1428 - mse: 0.1428 - mae: 0.2805 - val_loss: 0.3840 - val_mse: 0.3840 - val_mae: 0.4332\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1323 - mse: 0.1323 - mae: 0.2730 - val_loss: 0.3875 - val_mse: 0.3875 - val_mae: 0.4452\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.1279 - mse: 0.1279 - mae: 0.2680 - val_loss: 0.4130 - val_mse: 0.4130 - val_mae: 0.4448\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.1342 - mse: 0.1342 - mae: 0.2745 - val_loss: 0.3931 - val_mse: 0.3931 - val_mae: 0.4425\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1312 - mse: 0.1312 - mae: 0.2744 - val_loss: 0.4086 - val_mse: 0.4086 - val_mae: 0.4396\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 2s 233us/sample - loss: 0.1276 - mse: 0.1276 - mae: 0.2660 - val_loss: 0.3820 - val_mse: 0.3820 - val_mae: 0.4324\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.1296 - mse: 0.1296 - mae: 0.2708 - val_loss: 0.3934 - val_mse: 0.3934 - val_mae: 0.4429\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1243 - mse: 0.1243 - mae: 0.2638 - val_loss: 0.3777 - val_mse: 0.3777 - val_mae: 0.4408\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.1323 - mse: 0.1323 - mae: 0.2709 - val_loss: 0.3720 - val_mse: 0.3720 - val_mae: 0.4355\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 3s 235us/sample - loss: 0.1329 - mse: 0.1329 - mae: 0.2726 - val_loss: 0.3941 - val_mse: 0.3941 - val_mae: 0.4391\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1162 - mse: 0.1162 - mae: 0.2561 - val_loss: 0.3769 - val_mse: 0.3769 - val_mae: 0.4306\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.1095 - mse: 0.1095 - mae: 0.2477 - val_loss: 0.3999 - val_mse: 0.3999 - val_mae: 0.4402\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1199 - mse: 0.1199 - mae: 0.2561 - val_loss: 0.3648 - val_mse: 0.3648 - val_mae: 0.4251\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.1103 - mse: 0.1103 - mae: 0.2469 - val_loss: 0.3812 - val_mse: 0.3812 - val_mae: 0.4345\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.1099 - mse: 0.1099 - mae: 0.2484 - val_loss: 0.4341 - val_mse: 0.4341 - val_mae: 0.4553\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.1125 - mse: 0.1125 - mae: 0.2498 - val_loss: 0.3672 - val_mse: 0.3672 - val_mae: 0.4191\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 2s 230us/sample - loss: 0.1066 - mse: 0.1066 - mae: 0.2428 - val_loss: 0.3832 - val_mse: 0.3832 - val_mae: 0.4310\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.1043 - mse: 0.1043 - mae: 0.2394 - val_loss: 0.3675 - val_mse: 0.3675 - val_mae: 0.4210\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.1013 - mse: 0.1013 - mae: 0.2367 - val_loss: 0.3640 - val_mse: 0.3640 - val_mae: 0.4155\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 2s 229us/sample - loss: 0.1004 - mse: 0.1004 - mae: 0.2350 - val_loss: 0.3765 - val_mse: 0.3765 - val_mae: 0.4223\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1073 - mse: 0.1073 - mae: 0.2426 - val_loss: 0.3903 - val_mse: 0.3903 - val_mae: 0.4448\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.1013 - mse: 0.1013 - mae: 0.2353 - val_loss: 0.3699 - val_mse: 0.3699 - val_mae: 0.4236\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.0986 - mse: 0.0986 - mae: 0.2364 - val_loss: 0.3752 - val_mse: 0.3752 - val_mae: 0.4276\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.0935 - mse: 0.0935 - mae: 0.2293 - val_loss: 0.3738 - val_mse: 0.3738 - val_mae: 0.4201\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.0940 - mse: 0.0940 - mae: 0.2295 - val_loss: 0.3762 - val_mse: 0.3762 - val_mae: 0.4188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.0915 - mse: 0.0915 - mae: 0.2256 - val_loss: 0.3683 - val_mse: 0.3683 - val_mae: 0.4165\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.0929 - mse: 0.0929 - mae: 0.2267 - val_loss: 0.3650 - val_mse: 0.3650 - val_mae: 0.4225\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 2s 227us/sample - loss: 0.0942 - mse: 0.0942 - mae: 0.2295 - val_loss: 0.3787 - val_mse: 0.3787 - val_mae: 0.4261\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 2s 228us/sample - loss: 0.0935 - mse: 0.0935 - mae: 0.2265 - val_loss: 0.3655 - val_mse: 0.3655 - val_mae: 0.4155\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 4s 348us/sample - loss: 1.3415 - mse: 1.3415 - mae: 0.7701 - val_loss: 0.6520 - val_mse: 0.6520 - val_mae: 0.6267\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 2s 225us/sample - loss: 0.5689 - mse: 0.5689 - mae: 0.5629 - val_loss: 0.5086 - val_mse: 0.5086 - val_mae: 0.5434\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 2s 232us/sample - loss: 0.5144 - mse: 0.5144 - mae: 0.5352 - val_loss: 0.5196 - val_mse: 0.5196 - val_mae: 0.5214\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 2s 225us/sample - loss: 0.4583 - mse: 0.4583 - mae: 0.5041 - val_loss: 0.5042 - val_mse: 0.5042 - val_mae: 0.5195\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 2s 231us/sample - loss: 0.4189 - mse: 0.4189 - mae: 0.4849 - val_loss: 0.4720 - val_mse: 0.4720 - val_mae: 0.4966\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 2s 227us/sample - loss: 0.3924 - mse: 0.3924 - mae: 0.4665 - val_loss: 0.5018 - val_mse: 0.5018 - val_mae: 0.4952\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 2s 226us/sample - loss: 0.3688 - mse: 0.3688 - mae: 0.4557 - val_loss: 0.4830 - val_mse: 0.4830 - val_mae: 0.4846\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 2s 229us/sample - loss: 0.3496 - mse: 0.3496 - mae: 0.4416 - val_loss: 0.4485 - val_mse: 0.4485 - val_mae: 0.4744\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 2s 224us/sample - loss: 0.3405 - mse: 0.3405 - mae: 0.4359 - val_loss: 0.5227 - val_mse: 0.5227 - val_mae: 0.4830\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 2s 223us/sample - loss: 0.3108 - mse: 0.3108 - mae: 0.4185 - val_loss: 0.5281 - val_mse: 0.5281 - val_mae: 0.5093\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 2s 223us/sample - loss: 0.3023 - mse: 0.3023 - mae: 0.4099 - val_loss: 0.4468 - val_mse: 0.4468 - val_mae: 0.4834\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 2s 225us/sample - loss: 0.2930 - mse: 0.2930 - mae: 0.4037 - val_loss: 0.4812 - val_mse: 0.4812 - val_mae: 0.4915\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 2s 227us/sample - loss: 0.2678 - mse: 0.2678 - mae: 0.3865 - val_loss: 0.5398 - val_mse: 0.5398 - val_mae: 0.4989\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 2s 226us/sample - loss: 0.2591 - mse: 0.2591 - mae: 0.3825 - val_loss: 0.4904 - val_mse: 0.4904 - val_mae: 0.4882\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 2s 223us/sample - loss: 0.2445 - mse: 0.2445 - mae: 0.3704 - val_loss: 0.5233 - val_mse: 0.5233 - val_mae: 0.5108\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 2s 223us/sample - loss: 0.2514 - mse: 0.2514 - mae: 0.3754 - val_loss: 0.4848 - val_mse: 0.4848 - val_mae: 0.4715\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 2s 225us/sample - loss: 0.2335 - mse: 0.2335 - mae: 0.3647 - val_loss: 0.4883 - val_mse: 0.4883 - val_mae: 0.4911\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 2s 227us/sample - loss: 0.2360 - mse: 0.2360 - mae: 0.3643 - val_loss: 0.4776 - val_mse: 0.4776 - val_mae: 0.4803\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 2s 226us/sample - loss: 0.2190 - mse: 0.2190 - mae: 0.3501 - val_loss: 0.4508 - val_mse: 0.4508 - val_mae: 0.4607\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 2s 226us/sample - loss: 0.2113 - mse: 0.2113 - mae: 0.3438 - val_loss: 0.4682 - val_mse: 0.4682 - val_mae: 0.4754\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 2s 227us/sample - loss: 0.2074 - mse: 0.2074 - mae: 0.3400 - val_loss: 0.4501 - val_mse: 0.4501 - val_mae: 0.4737\n",
      "Avg. MAE: 0.396130\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 2.0245 - mse: 2.0245 - mae: 0.8178 - val_loss: 0.9771 - val_mse: 0.9771 - val_mae: 0.8025\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.5837 - mse: 0.5837 - mae: 0.5726 - val_loss: 0.5569 - val_mse: 0.5569 - val_mae: 0.5663\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.5450 - mse: 0.5450 - mae: 0.5537 - val_loss: 0.6902 - val_mse: 0.6902 - val_mae: 0.6339\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.5353 - mse: 0.5353 - mae: 0.5491 - val_loss: 0.5554 - val_mse: 0.5554 - val_mae: 0.5546\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.5114 - mse: 0.5114 - mae: 0.5389 - val_loss: 0.5840 - val_mse: 0.5840 - val_mae: 0.5878\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4925 - mse: 0.4925 - mae: 0.5295 - val_loss: 0.6280 - val_mse: 0.6280 - val_mae: 0.5709\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4627 - mse: 0.4627 - mae: 0.5131 - val_loss: 0.5315 - val_mse: 0.5315 - val_mae: 0.5369\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4441 - mse: 0.4441 - mae: 0.5046 - val_loss: 0.5526 - val_mse: 0.5526 - val_mae: 0.5559\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4270 - mse: 0.4270 - mae: 0.4927 - val_loss: 0.5130 - val_mse: 0.5130 - val_mae: 0.5359\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.4177 - mse: 0.4177 - mae: 0.4907 - val_loss: 0.5341 - val_mse: 0.5341 - val_mae: 0.5410\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.4001 - mse: 0.4001 - mae: 0.4787 - val_loss: 0.5642 - val_mse: 0.5642 - val_mae: 0.5590\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3986 - mse: 0.3986 - mae: 0.4791 - val_loss: 0.5401 - val_mse: 0.5401 - val_mae: 0.5487\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3702 - mse: 0.3702 - mae: 0.4638 - val_loss: 0.4672 - val_mse: 0.4672 - val_mae: 0.5040\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 53us/sample - loss: 0.3616 - mse: 0.3616 - mae: 0.4541 - val_loss: 0.4816 - val_mse: 0.4816 - val_mae: 0.5090\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.3536 - mse: 0.3536 - mae: 0.4520 - val_loss: 0.4601 - val_mse: 0.4601 - val_mae: 0.5045\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.3560 - mse: 0.3560 - mae: 0.4537 - val_loss: 0.5196 - val_mse: 0.5196 - val_mae: 0.5305\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3364 - mse: 0.3364 - mae: 0.4387 - val_loss: 0.4816 - val_mse: 0.4816 - val_mae: 0.5041\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.3318 - mse: 0.3318 - mae: 0.4385 - val_loss: 0.4427 - val_mse: 0.4427 - val_mae: 0.4960\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.3290 - mse: 0.3290 - mae: 0.4385 - val_loss: 0.4663 - val_mse: 0.4663 - val_mae: 0.4989\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3018 - mse: 0.3018 - mae: 0.4164 - val_loss: 0.4695 - val_mse: 0.4695 - val_mae: 0.5035\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.3035 - mse: 0.3035 - mae: 0.4167 - val_loss: 0.5233 - val_mse: 0.5233 - val_mae: 0.5278\n",
      "Epoch 22/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.3125 - mse: 0.3125 - mae: 0.4251 - val_loss: 0.4954 - val_mse: 0.4954 - val_mae: 0.5089\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2948 - mse: 0.2948 - mae: 0.4135 - val_loss: 0.4519 - val_mse: 0.4519 - val_mae: 0.4859\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2894 - mse: 0.2894 - mae: 0.4095 - val_loss: 0.4725 - val_mse: 0.4725 - val_mae: 0.5190\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2988 - mse: 0.2988 - mae: 0.4163 - val_loss: 0.4987 - val_mse: 0.4987 - val_mae: 0.5222\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2913 - mse: 0.2913 - mae: 0.4114 - val_loss: 0.4556 - val_mse: 0.4556 - val_mae: 0.4935\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2870 - mse: 0.2870 - mae: 0.4083 - val_loss: 0.4572 - val_mse: 0.4572 - val_mae: 0.4992\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2742 - mse: 0.2742 - mae: 0.3990 - val_loss: 0.4881 - val_mse: 0.4881 - val_mae: 0.5324\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 126us/sample - loss: 1.9169 - mse: 1.9169 - mae: 0.8239 - val_loss: 0.8093 - val_mse: 0.8093 - val_mae: 0.6951\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.5937 - mse: 0.5937 - mae: 0.5801 - val_loss: 0.5947 - val_mse: 0.5947 - val_mae: 0.5699\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.5740 - mse: 0.5740 - mae: 0.5717 - val_loss: 0.8170 - val_mse: 0.8170 - val_mae: 0.6133\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.5321 - mse: 0.5321 - mae: 0.5533 - val_loss: 0.6104 - val_mse: 0.6104 - val_mae: 0.5725\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.5155 - mse: 0.5155 - mae: 0.5407 - val_loss: 0.5488 - val_mse: 0.5488 - val_mae: 0.5409\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4973 - mse: 0.4973 - mae: 0.5345 - val_loss: 0.7947 - val_mse: 0.7947 - val_mae: 0.5717\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4457 - mse: 0.4457 - mae: 0.5057 - val_loss: 0.5495 - val_mse: 0.5495 - val_mae: 0.5351\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4499 - mse: 0.4499 - mae: 0.5096 - val_loss: 0.6501 - val_mse: 0.6501 - val_mae: 0.5371\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4363 - mse: 0.4363 - mae: 0.5035 - val_loss: 0.7239 - val_mse: 0.7239 - val_mae: 0.5553\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4180 - mse: 0.4180 - mae: 0.4894 - val_loss: 0.5794 - val_mse: 0.5794 - val_mae: 0.5212\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3946 - mse: 0.3946 - mae: 0.4762 - val_loss: 0.7089 - val_mse: 0.7089 - val_mae: 0.5249\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3737 - mse: 0.3737 - mae: 0.4640 - val_loss: 0.7119 - val_mse: 0.7119 - val_mae: 0.5313\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.3752 - mse: 0.3752 - mae: 0.4662 - val_loss: 0.7578 - val_mse: 0.7578 - val_mae: 0.5153\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.3563 - mse: 0.3563 - mae: 0.4531 - val_loss: 0.6072 - val_mse: 0.6072 - val_mae: 0.5166\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3538 - mse: 0.3538 - mae: 0.4521 - val_loss: 0.5647 - val_mse: 0.5647 - val_mae: 0.5050\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 2.1112 - mse: 2.1112 - mae: 0.8515 - val_loss: 0.9268 - val_mse: 0.9268 - val_mae: 0.7946\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.6350 - mse: 0.6350 - mae: 0.5975 - val_loss: 0.5666 - val_mse: 0.5666 - val_mae: 0.5768\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.5712 - mse: 0.5712 - mae: 0.5664 - val_loss: 0.5699 - val_mse: 0.5699 - val_mae: 0.5846\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.5306 - mse: 0.5306 - mae: 0.5494 - val_loss: 0.6096 - val_mse: 0.6096 - val_mae: 0.5736\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.5186 - mse: 0.5186 - mae: 0.5390 - val_loss: 0.5617 - val_mse: 0.5617 - val_mae: 0.5603\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4944 - mse: 0.4944 - mae: 0.5294 - val_loss: 0.5549 - val_mse: 0.5549 - val_mae: 0.5550\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4619 - mse: 0.4619 - mae: 0.5127 - val_loss: 0.6253 - val_mse: 0.6253 - val_mae: 0.6013\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4618 - mse: 0.4618 - mae: 0.5153 - val_loss: 0.6044 - val_mse: 0.6044 - val_mae: 0.5583\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4395 - mse: 0.4395 - mae: 0.5018 - val_loss: 0.5340 - val_mse: 0.5340 - val_mae: 0.5408\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4261 - mse: 0.4261 - mae: 0.4940 - val_loss: 0.5556 - val_mse: 0.5556 - val_mae: 0.5532\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4002 - mse: 0.4002 - mae: 0.4780 - val_loss: 0.5600 - val_mse: 0.5600 - val_mae: 0.5391\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3968 - mse: 0.3968 - mae: 0.4786 - val_loss: 0.5643 - val_mse: 0.5643 - val_mae: 0.5290\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3845 - mse: 0.3845 - mae: 0.4692 - val_loss: 0.5036 - val_mse: 0.5036 - val_mae: 0.5342\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.3595 - mse: 0.3595 - mae: 0.4540 - val_loss: 0.4925 - val_mse: 0.4925 - val_mae: 0.5087\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.3579 - mse: 0.3579 - mae: 0.4554 - val_loss: 0.5216 - val_mse: 0.5216 - val_mae: 0.5273\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3529 - mse: 0.3529 - mae: 0.4521 - val_loss: 0.4877 - val_mse: 0.4877 - val_mae: 0.5012\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3504 - mse: 0.3504 - mae: 0.4457 - val_loss: 0.5332 - val_mse: 0.5332 - val_mae: 0.5149\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3404 - mse: 0.3404 - mae: 0.4433 - val_loss: 0.4882 - val_mse: 0.4882 - val_mae: 0.5070\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.3274 - mse: 0.3274 - mae: 0.4351 - val_loss: 0.5138 - val_mse: 0.5138 - val_mae: 0.5197\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3223 - mse: 0.3223 - mae: 0.4333 - val_loss: 0.4792 - val_mse: 0.4792 - val_mae: 0.5071\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.3171 - mse: 0.3171 - mae: 0.4294 - val_loss: 0.5143 - val_mse: 0.5143 - val_mae: 0.5194\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3120 - mse: 0.3120 - mae: 0.4239 - val_loss: 0.4894 - val_mse: 0.4894 - val_mae: 0.5080\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3113 - mse: 0.3113 - mae: 0.4257 - val_loss: 0.5340 - val_mse: 0.5340 - val_mae: 0.5246\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3017 - mse: 0.3017 - mae: 0.4168 - val_loss: 0.4672 - val_mse: 0.4672 - val_mae: 0.4973\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3013 - mse: 0.3013 - mae: 0.4172 - val_loss: 0.4533 - val_mse: 0.4533 - val_mae: 0.4869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2941 - mse: 0.2941 - mae: 0.4148 - val_loss: 0.4720 - val_mse: 0.4720 - val_mae: 0.4929\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2930 - mse: 0.2930 - mae: 0.4118 - val_loss: 0.6013 - val_mse: 0.6013 - val_mae: 0.5880\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2987 - mse: 0.2987 - mae: 0.4161 - val_loss: 0.4783 - val_mse: 0.4783 - val_mae: 0.4963\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2922 - mse: 0.2922 - mae: 0.4135 - val_loss: 0.5101 - val_mse: 0.5101 - val_mae: 0.5002\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2876 - mse: 0.2876 - mae: 0.4110 - val_loss: 0.4782 - val_mse: 0.4782 - val_mae: 0.4937\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2765 - mse: 0.2765 - mae: 0.4020 - val_loss: 0.4982 - val_mse: 0.4982 - val_mae: 0.5296\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2750 - mse: 0.2750 - mae: 0.4013 - val_loss: 0.4841 - val_mse: 0.4841 - val_mae: 0.4869\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2775 - mse: 0.2775 - mae: 0.4022 - val_loss: 0.5033 - val_mse: 0.5033 - val_mae: 0.4985\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2584 - mse: 0.2584 - mae: 0.3879 - val_loss: 0.4879 - val_mse: 0.4879 - val_mae: 0.4986\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 56us/sample - loss: 0.2683 - mse: 0.2683 - mae: 0.3975 - val_loss: 0.4587 - val_mse: 0.4587 - val_mae: 0.4924\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 120us/sample - loss: 1.6816 - mse: 1.6816 - mae: 0.7957 - val_loss: 0.7234 - val_mse: 0.7234 - val_mae: 0.6672\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.6145 - mse: 0.6145 - mae: 0.5891 - val_loss: 0.6189 - val_mse: 0.6189 - val_mae: 0.6077\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.5593 - mse: 0.5593 - mae: 0.5647 - val_loss: 0.5979 - val_mse: 0.5979 - val_mae: 0.5964\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.5114 - mse: 0.5114 - mae: 0.5369 - val_loss: 0.6356 - val_mse: 0.6356 - val_mae: 0.5657\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.5134 - mse: 0.5134 - mae: 0.5417 - val_loss: 0.6565 - val_mse: 0.6565 - val_mae: 0.5718\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4891 - mse: 0.4891 - mae: 0.5289 - val_loss: 0.5510 - val_mse: 0.5510 - val_mae: 0.5338\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4707 - mse: 0.4707 - mae: 0.5230 - val_loss: 0.7247 - val_mse: 0.7247 - val_mae: 0.5805\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.4408 - mse: 0.4408 - mae: 0.5024 - val_loss: 0.7300 - val_mse: 0.7300 - val_mae: 0.5316\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4386 - mse: 0.4386 - mae: 0.5003 - val_loss: 0.6230 - val_mse: 0.6230 - val_mae: 0.5575\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4055 - mse: 0.4055 - mae: 0.4842 - val_loss: 0.6092 - val_mse: 0.6092 - val_mae: 0.5457\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3837 - mse: 0.3837 - mae: 0.4701 - val_loss: 0.5344 - val_mse: 0.5344 - val_mae: 0.5365\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3816 - mse: 0.3816 - mae: 0.4670 - val_loss: 0.5447 - val_mse: 0.5447 - val_mae: 0.5228\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3498 - mse: 0.3498 - mae: 0.4475 - val_loss: 0.6357 - val_mse: 0.6357 - val_mae: 0.5457\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3571 - mse: 0.3571 - mae: 0.4544 - val_loss: 0.5748 - val_mse: 0.5748 - val_mae: 0.5238\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3350 - mse: 0.3350 - mae: 0.4392 - val_loss: 0.5111 - val_mse: 0.5111 - val_mae: 0.5294\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.3381 - mse: 0.3381 - mae: 0.4403 - val_loss: 0.5497 - val_mse: 0.5497 - val_mae: 0.5373\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.3354 - mse: 0.3354 - mae: 0.4394 - val_loss: 0.5917 - val_mse: 0.5917 - val_mae: 0.5118\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3249 - mse: 0.3249 - mae: 0.4320 - val_loss: 0.5467 - val_mse: 0.5467 - val_mae: 0.5452\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3250 - mse: 0.3250 - mae: 0.4320 - val_loss: 0.5395 - val_mse: 0.5395 - val_mae: 0.5097\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.3126 - mse: 0.3126 - mae: 0.4255 - val_loss: 0.4975 - val_mse: 0.4975 - val_mae: 0.4908\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3139 - mse: 0.3139 - mae: 0.4244 - val_loss: 0.5531 - val_mse: 0.5531 - val_mae: 0.5009\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3012 - mse: 0.3012 - mae: 0.4169 - val_loss: 0.5405 - val_mse: 0.5405 - val_mae: 0.5120\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2948 - mse: 0.2948 - mae: 0.4112 - val_loss: 0.6144 - val_mse: 0.6144 - val_mae: 0.5083\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2856 - mse: 0.2856 - mae: 0.4048 - val_loss: 0.6269 - val_mse: 0.6269 - val_mae: 0.5064\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2873 - mse: 0.2873 - mae: 0.4072 - val_loss: 0.5128 - val_mse: 0.5128 - val_mae: 0.5065\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2745 - mse: 0.2745 - mae: 0.4005 - val_loss: 0.5557 - val_mse: 0.5557 - val_mae: 0.5039\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2911 - mse: 0.2911 - mae: 0.4113 - val_loss: 0.4822 - val_mse: 0.4822 - val_mae: 0.4987\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2831 - mse: 0.2831 - mae: 0.4084 - val_loss: 0.5388 - val_mse: 0.5388 - val_mae: 0.5029\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2867 - mse: 0.2867 - mae: 0.4105 - val_loss: 0.5230 - val_mse: 0.5230 - val_mae: 0.5059\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2705 - mse: 0.2705 - mae: 0.3981 - val_loss: 0.5098 - val_mse: 0.5098 - val_mae: 0.4966\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2711 - mse: 0.2711 - mae: 0.3979 - val_loss: 0.5480 - val_mse: 0.5480 - val_mae: 0.4873\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2718 - mse: 0.2718 - mae: 0.3985 - val_loss: 0.4941 - val_mse: 0.4941 - val_mae: 0.4863\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2787 - mse: 0.2787 - mae: 0.4053 - val_loss: 0.6059 - val_mse: 0.6059 - val_mae: 0.4869\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2553 - mse: 0.2553 - mae: 0.3842 - val_loss: 0.5444 - val_mse: 0.5444 - val_mae: 0.5016\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2592 - mse: 0.2592 - mae: 0.3866 - val_loss: 0.6208 - val_mse: 0.6208 - val_mae: 0.5905\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 55us/sample - loss: 0.2609 - mse: 0.2609 - mae: 0.3936 - val_loss: 0.5516 - val_mse: 0.5516 - val_mae: 0.4798\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 57us/sample - loss: 0.2546 - mse: 0.2546 - mae: 0.3859 - val_loss: 0.8303 - val_mse: 0.8303 - val_mae: 0.4998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 120us/sample - loss: 1.6889 - mse: 1.6889 - mae: 0.7861 - val_loss: 0.7167 - val_mse: 0.7167 - val_mae: 0.6804\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.6252 - mse: 0.6252 - mae: 0.5961 - val_loss: 0.7462 - val_mse: 0.7462 - val_mae: 0.6439\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 1s 62us/sample - loss: 0.5694 - mse: 0.5694 - mae: 0.5694 - val_loss: 0.6292 - val_mse: 0.6292 - val_mae: 0.5683\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.5298 - mse: 0.5298 - mae: 0.5484 - val_loss: 0.5894 - val_mse: 0.5894 - val_mae: 0.5561\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.5125 - mse: 0.5125 - mae: 0.5409 - val_loss: 0.7441 - val_mse: 0.7441 - val_mae: 0.5666\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.4884 - mse: 0.4884 - mae: 0.5293 - val_loss: 0.6803 - val_mse: 0.6803 - val_mae: 0.5793\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.4774 - mse: 0.4774 - mae: 0.5237 - val_loss: 0.5070 - val_mse: 0.5070 - val_mae: 0.5224\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.4614 - mse: 0.4614 - mae: 0.5156 - val_loss: 0.5182 - val_mse: 0.5182 - val_mae: 0.5203\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 1s 56us/sample - loss: 0.4336 - mse: 0.4336 - mae: 0.4981 - val_loss: 0.5168 - val_mse: 0.5168 - val_mae: 0.5120\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.4146 - mse: 0.4146 - mae: 0.4856 - val_loss: 0.5436 - val_mse: 0.5436 - val_mae: 0.5450\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 55us/sample - loss: 0.4064 - mse: 0.4064 - mae: 0.4855 - val_loss: 0.4862 - val_mse: 0.4862 - val_mae: 0.5090\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3862 - mse: 0.3862 - mae: 0.4690 - val_loss: 0.5075 - val_mse: 0.5075 - val_mae: 0.5128\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.3783 - mse: 0.3783 - mae: 0.4677 - val_loss: 0.5204 - val_mse: 0.5204 - val_mae: 0.4973\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3599 - mse: 0.3599 - mae: 0.4541 - val_loss: 0.5406 - val_mse: 0.5406 - val_mae: 0.5298\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 1s 60us/sample - loss: 0.3429 - mse: 0.3429 - mae: 0.4466 - val_loss: 0.5115 - val_mse: 0.5115 - val_mae: 0.4961\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3430 - mse: 0.3430 - mae: 0.4439 - val_loss: 0.5922 - val_mse: 0.5922 - val_mae: 0.4981\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3330 - mse: 0.3330 - mae: 0.4381 - val_loss: 0.4701 - val_mse: 0.4701 - val_mae: 0.4947\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3388 - mse: 0.3388 - mae: 0.4434 - val_loss: 0.4965 - val_mse: 0.4965 - val_mae: 0.4916\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 1s 60us/sample - loss: 0.3179 - mse: 0.3179 - mae: 0.4285 - val_loss: 0.5257 - val_mse: 0.5257 - val_mae: 0.4971\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3071 - mse: 0.3071 - mae: 0.4189 - val_loss: 0.4655 - val_mse: 0.4655 - val_mae: 0.4869\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3172 - mse: 0.3172 - mae: 0.4293 - val_loss: 0.5204 - val_mse: 0.5204 - val_mae: 0.4959\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3152 - mse: 0.3152 - mae: 0.4258 - val_loss: 0.5348 - val_mse: 0.5348 - val_mae: 0.4971\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.3111 - mse: 0.3111 - mae: 0.4231 - val_loss: 0.4563 - val_mse: 0.4563 - val_mae: 0.4928\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3192 - mse: 0.3192 - mae: 0.4318 - val_loss: 0.4918 - val_mse: 0.4918 - val_mae: 0.4904\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.2933 - mse: 0.2933 - mae: 0.4101 - val_loss: 0.4735 - val_mse: 0.4735 - val_mae: 0.4805\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.2967 - mse: 0.2967 - mae: 0.4115 - val_loss: 0.5190 - val_mse: 0.5190 - val_mae: 0.4850\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.2962 - mse: 0.2962 - mae: 0.4142 - val_loss: 0.4795 - val_mse: 0.4795 - val_mae: 0.5111\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.2854 - mse: 0.2854 - mae: 0.4044 - val_loss: 0.5157 - val_mse: 0.5157 - val_mae: 0.4914\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.2810 - mse: 0.2810 - mae: 0.4032 - val_loss: 0.6567 - val_mse: 0.6567 - val_mae: 0.4866\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.2758 - mse: 0.2758 - mae: 0.3976 - val_loss: 0.9064 - val_mse: 0.9064 - val_mae: 0.4988\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.2741 - mse: 0.2741 - mae: 0.3984 - val_loss: 0.8313 - val_mse: 0.8313 - val_mae: 0.5186\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.2804 - mse: 0.2804 - mae: 0.4018 - val_loss: 0.4690 - val_mse: 0.4690 - val_mae: 0.4795\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 1s 60us/sample - loss: 0.2764 - mse: 0.2764 - mae: 0.4016 - val_loss: 0.4782 - val_mse: 0.4782 - val_mae: 0.5084\n",
      "Avg. MAE: 0.443424\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 6s 607us/sample - loss: 1.1240 - mse: 1.1240 - mae: 0.7913 - val_loss: 0.7101 - val_mse: 0.7101 - val_mae: 0.6405\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.5991 - mse: 0.5991 - mae: 0.5801 - val_loss: 0.5707 - val_mse: 0.5707 - val_mae: 0.5623\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.5020 - mse: 0.5020 - mae: 0.5334 - val_loss: 0.5399 - val_mse: 0.5399 - val_mae: 0.5627\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.4672 - mse: 0.4672 - mae: 0.5149 - val_loss: 0.5397 - val_mse: 0.5397 - val_mae: 0.5336\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 5s 465us/sample - loss: 0.4639 - mse: 0.4639 - mae: 0.5085 - val_loss: 0.4829 - val_mse: 0.4829 - val_mae: 0.5126\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 5s 469us/sample - loss: 0.4021 - mse: 0.4021 - mae: 0.4756 - val_loss: 0.4681 - val_mse: 0.4681 - val_mae: 0.4988\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 5s 461us/sample - loss: 0.3853 - mse: 0.3853 - mae: 0.4657 - val_loss: 0.4748 - val_mse: 0.4748 - val_mae: 0.5048\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 5s 468us/sample - loss: 0.3805 - mse: 0.3805 - mae: 0.4632 - val_loss: 0.5824 - val_mse: 0.5824 - val_mae: 0.5454\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.3624 - mse: 0.3624 - mae: 0.4515 - val_loss: 0.4534 - val_mse: 0.4534 - val_mae: 0.4937\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 5s 462us/sample - loss: 0.3559 - mse: 0.3559 - mae: 0.4493 - val_loss: 0.5208 - val_mse: 0.5208 - val_mae: 0.5143\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 5s 465us/sample - loss: 0.3381 - mse: 0.3381 - mae: 0.4356 - val_loss: 0.4269 - val_mse: 0.4269 - val_mae: 0.4784\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 5s 464us/sample - loss: 0.3363 - mse: 0.3363 - mae: 0.4341 - val_loss: 0.4803 - val_mse: 0.4803 - val_mae: 0.5108\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 5s 464us/sample - loss: 0.3189 - mse: 0.3189 - mae: 0.4258 - val_loss: 0.5710 - val_mse: 0.5710 - val_mae: 0.5331\n",
      "Epoch 14/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.3157 - mse: 0.3157 - mae: 0.4194 - val_loss: 0.4972 - val_mse: 0.4972 - val_mae: 0.5056\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 5s 461us/sample - loss: 0.3049 - mse: 0.3049 - mae: 0.4150 - val_loss: 0.4709 - val_mse: 0.4709 - val_mae: 0.5018\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 5s 465us/sample - loss: 0.3099 - mse: 0.3099 - mae: 0.4177 - val_loss: 0.4547 - val_mse: 0.4547 - val_mae: 0.4978\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 5s 461us/sample - loss: 0.2955 - mse: 0.2955 - mae: 0.4081 - val_loss: 0.4906 - val_mse: 0.4906 - val_mae: 0.5037\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 5s 466us/sample - loss: 0.2878 - mse: 0.2878 - mae: 0.4051 - val_loss: 0.4475 - val_mse: 0.4475 - val_mae: 0.4812\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.2905 - mse: 0.2905 - mae: 0.4043 - val_loss: 0.4341 - val_mse: 0.4341 - val_mae: 0.4723\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 5s 462us/sample - loss: 0.2688 - mse: 0.2688 - mae: 0.3918 - val_loss: 0.4855 - val_mse: 0.4855 - val_mae: 0.4812\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 5s 471us/sample - loss: 0.2589 - mse: 0.2589 - mae: 0.3812 - val_loss: 0.4116 - val_mse: 0.4116 - val_mae: 0.4654\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 5s 461us/sample - loss: 0.2536 - mse: 0.2536 - mae: 0.3812 - val_loss: 0.4409 - val_mse: 0.4409 - val_mae: 0.4652\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.2567 - mse: 0.2567 - mae: 0.3823 - val_loss: 0.4139 - val_mse: 0.4139 - val_mae: 0.4689\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 5s 466us/sample - loss: 0.2453 - mse: 0.2453 - mae: 0.3741 - val_loss: 0.4879 - val_mse: 0.4879 - val_mae: 0.4862\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 5s 466us/sample - loss: 0.2390 - mse: 0.2390 - mae: 0.3698 - val_loss: 0.4104 - val_mse: 0.4104 - val_mae: 0.4701\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 5s 462us/sample - loss: 0.2292 - mse: 0.2292 - mae: 0.3630 - val_loss: 0.4159 - val_mse: 0.4159 - val_mae: 0.4683\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.2431 - mse: 0.2431 - mae: 0.3677 - val_loss: 0.4500 - val_mse: 0.4500 - val_mae: 0.4714\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.2277 - mse: 0.2277 - mae: 0.3590 - val_loss: 0.4681 - val_mse: 0.4681 - val_mae: 0.4836\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.2175 - mse: 0.2175 - mae: 0.3519 - val_loss: 0.3980 - val_mse: 0.3980 - val_mae: 0.4522\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 5s 472us/sample - loss: 0.2063 - mse: 0.2063 - mae: 0.3433 - val_loss: 0.4306 - val_mse: 0.4306 - val_mae: 0.4581\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 5s 464us/sample - loss: 0.1937 - mse: 0.1937 - mae: 0.3335 - val_loss: 0.4264 - val_mse: 0.4264 - val_mae: 0.4504\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 5s 462us/sample - loss: 0.1944 - mse: 0.1944 - mae: 0.3344 - val_loss: 0.4262 - val_mse: 0.4262 - val_mae: 0.4510\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 5s 470us/sample - loss: 0.1870 - mse: 0.1870 - mae: 0.3279 - val_loss: 0.3997 - val_mse: 0.3997 - val_mae: 0.4445\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 5s 461us/sample - loss: 0.1853 - mse: 0.1853 - mae: 0.3255 - val_loss: 0.4304 - val_mse: 0.4304 - val_mae: 0.4585\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 5s 476us/sample - loss: 0.1862 - mse: 0.1862 - mae: 0.3247 - val_loss: 0.4593 - val_mse: 0.4593 - val_mae: 0.4756\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 5s 464us/sample - loss: 0.1877 - mse: 0.1877 - mae: 0.3257 - val_loss: 0.4700 - val_mse: 0.4700 - val_mae: 0.4739\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 5s 467us/sample - loss: 0.1704 - mse: 0.1704 - mae: 0.3131 - val_loss: 0.4198 - val_mse: 0.4198 - val_mae: 0.4659\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 5s 462us/sample - loss: 0.1851 - mse: 0.1851 - mae: 0.3243 - val_loss: 0.4547 - val_mse: 0.4547 - val_mae: 0.4669\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 5s 462us/sample - loss: 0.1764 - mse: 0.1764 - mae: 0.3172 - val_loss: 0.4415 - val_mse: 0.4415 - val_mae: 0.4596\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 7s 663us/sample - loss: 1.1076 - mse: 1.1076 - mae: 0.7848 - val_loss: 0.7863 - val_mse: 0.7863 - val_mae: 0.6771\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 5s 468us/sample - loss: 0.5976 - mse: 0.5976 - mae: 0.5814 - val_loss: 0.5845 - val_mse: 0.5845 - val_mae: 0.5353\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 5s 472us/sample - loss: 0.5150 - mse: 0.5150 - mae: 0.5421 - val_loss: 0.8537 - val_mse: 0.8537 - val_mae: 0.5897\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 5s 469us/sample - loss: 0.4727 - mse: 0.4727 - mae: 0.5193 - val_loss: 0.6232 - val_mse: 0.6232 - val_mae: 0.5309\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 5s 499us/sample - loss: 0.4409 - mse: 0.4409 - mae: 0.5012 - val_loss: 0.6101 - val_mse: 0.6101 - val_mae: 0.5330\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 5s 469us/sample - loss: 0.4189 - mse: 0.4189 - mae: 0.4874 - val_loss: 0.7326 - val_mse: 0.7326 - val_mae: 0.5340\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 5s 467us/sample - loss: 0.3905 - mse: 0.3905 - mae: 0.4696 - val_loss: 0.5894 - val_mse: 0.5894 - val_mae: 0.5165\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 5s 467us/sample - loss: 0.3842 - mse: 0.3842 - mae: 0.4653 - val_loss: 0.6952 - val_mse: 0.6952 - val_mae: 0.5445\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 5s 467us/sample - loss: 0.3611 - mse: 0.3611 - mae: 0.4546 - val_loss: 0.9354 - val_mse: 0.9354 - val_mae: 0.5269\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 5s 466us/sample - loss: 0.3601 - mse: 0.3601 - mae: 0.4536 - val_loss: 0.6140 - val_mse: 0.6140 - val_mae: 0.5135\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 5s 470us/sample - loss: 0.3411 - mse: 0.3411 - mae: 0.4369 - val_loss: 0.7178 - val_mse: 0.7178 - val_mae: 0.5014\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 5s 468us/sample - loss: 0.3230 - mse: 0.3230 - mae: 0.4314 - val_loss: 0.8630 - val_mse: 0.8630 - val_mae: 0.5301\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 7s 612us/sample - loss: 1.0880 - mse: 1.0880 - mae: 0.7788 - val_loss: 1.0783 - val_mse: 1.0783 - val_mae: 0.7177\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 5s 473us/sample - loss: 0.6075 - mse: 0.6075 - mae: 0.5928 - val_loss: 0.7081 - val_mse: 0.7081 - val_mae: 0.6171\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 5s 466us/sample - loss: 0.5182 - mse: 0.5182 - mae: 0.5393 - val_loss: 0.6431 - val_mse: 0.6431 - val_mae: 0.5691\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 5s 466us/sample - loss: 0.4745 - mse: 0.4745 - mae: 0.5182 - val_loss: 0.5518 - val_mse: 0.5518 - val_mae: 0.5377\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 5s 475us/sample - loss: 0.4317 - mse: 0.4317 - mae: 0.4913 - val_loss: 0.5493 - val_mse: 0.5493 - val_mae: 0.5206\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 5s 465us/sample - loss: 0.4179 - mse: 0.4179 - mae: 0.4853 - val_loss: 0.5518 - val_mse: 0.5518 - val_mae: 0.5207\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 5s 464us/sample - loss: 0.3988 - mse: 0.3988 - mae: 0.4731 - val_loss: 0.5248 - val_mse: 0.5248 - val_mae: 0.5275\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 5s 466us/sample - loss: 0.3927 - mse: 0.3927 - mae: 0.4693 - val_loss: 0.6309 - val_mse: 0.6309 - val_mae: 0.5377\n",
      "Epoch 9/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.3739 - mse: 0.3739 - mae: 0.4612 - val_loss: 0.4613 - val_mse: 0.4613 - val_mae: 0.4856\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 5s 468us/sample - loss: 0.3594 - mse: 0.3594 - mae: 0.4498 - val_loss: 0.6005 - val_mse: 0.6005 - val_mae: 0.5140\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 5s 499us/sample - loss: 0.3398 - mse: 0.3398 - mae: 0.4393 - val_loss: 0.4777 - val_mse: 0.4777 - val_mae: 0.5007\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 5s 488us/sample - loss: 0.3326 - mse: 0.3326 - mae: 0.4354 - val_loss: 0.5193 - val_mse: 0.5193 - val_mae: 0.4927\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 5s 467us/sample - loss: 0.3377 - mse: 0.3377 - mae: 0.4372 - val_loss: 0.5465 - val_mse: 0.5465 - val_mae: 0.4948\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 5s 465us/sample - loss: 0.3268 - mse: 0.3268 - mae: 0.4276 - val_loss: 0.4498 - val_mse: 0.4498 - val_mae: 0.4790\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.3394 - mse: 0.3394 - mae: 0.4373 - val_loss: 0.4913 - val_mse: 0.4913 - val_mae: 0.5005\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 5s 464us/sample - loss: 0.3134 - mse: 0.3134 - mae: 0.4232 - val_loss: 0.5969 - val_mse: 0.5969 - val_mae: 0.4888\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 5s 472us/sample - loss: 0.3025 - mse: 0.3025 - mae: 0.4138 - val_loss: 0.4638 - val_mse: 0.4638 - val_mae: 0.5049\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 5s 464us/sample - loss: 0.2832 - mse: 0.2832 - mae: 0.4002 - val_loss: 0.5279 - val_mse: 0.5279 - val_mae: 0.4897\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 5s 464us/sample - loss: 0.2720 - mse: 0.2720 - mae: 0.3933 - val_loss: 0.4898 - val_mse: 0.4898 - val_mae: 0.4984\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 5s 473us/sample - loss: 0.2692 - mse: 0.2692 - mae: 0.3945 - val_loss: 0.6188 - val_mse: 0.6188 - val_mae: 0.5025\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 5s 482us/sample - loss: 0.2728 - mse: 0.2728 - mae: 0.3945 - val_loss: 1.0649 - val_mse: 1.0649 - val_mae: 0.5001\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 5s 472us/sample - loss: 0.2597 - mse: 0.2597 - mae: 0.3849 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4691\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 5s 473us/sample - loss: 0.2565 - mse: 0.2565 - mae: 0.3834 - val_loss: 0.6718 - val_mse: 0.6718 - val_mae: 0.4925\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 5s 468us/sample - loss: 0.2415 - mse: 0.2415 - mae: 0.3704 - val_loss: 0.4584 - val_mse: 0.4584 - val_mae: 0.4797\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 5s 479us/sample - loss: 0.2334 - mse: 0.2334 - mae: 0.3657 - val_loss: 0.5928 - val_mse: 0.5928 - val_mae: 0.5278\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 5s 474us/sample - loss: 0.2225 - mse: 0.2225 - mae: 0.3574 - val_loss: 0.4160 - val_mse: 0.4160 - val_mae: 0.4580\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 5s 467us/sample - loss: 0.2196 - mse: 0.2196 - mae: 0.3546 - val_loss: 0.6029 - val_mse: 0.6029 - val_mae: 0.4652\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 5s 468us/sample - loss: 0.2187 - mse: 0.2187 - mae: 0.3542 - val_loss: 0.5633 - val_mse: 0.5633 - val_mae: 0.4927\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 5s 471us/sample - loss: 0.2062 - mse: 0.2062 - mae: 0.3429 - val_loss: 0.5011 - val_mse: 0.5011 - val_mae: 0.4837\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 5s 473us/sample - loss: 0.2136 - mse: 0.2136 - mae: 0.3508 - val_loss: 0.5825 - val_mse: 0.5825 - val_mae: 0.4706\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 5s 479us/sample - loss: 0.2041 - mse: 0.2041 - mae: 0.3429 - val_loss: 0.4493 - val_mse: 0.4493 - val_mae: 0.4797\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 5s 482us/sample - loss: 0.1991 - mse: 0.1991 - mae: 0.3373 - val_loss: 0.5087 - val_mse: 0.5087 - val_mae: 0.4651\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 5s 479us/sample - loss: 0.1975 - mse: 0.1975 - mae: 0.3362 - val_loss: 0.5160 - val_mse: 0.5160 - val_mae: 0.4689\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 5s 480us/sample - loss: 0.1815 - mse: 0.1815 - mae: 0.3246 - val_loss: 0.4604 - val_mse: 0.4604 - val_mae: 0.4687\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 5s 482us/sample - loss: 0.1908 - mse: 0.1908 - mae: 0.3278 - val_loss: 0.4948 - val_mse: 0.4948 - val_mae: 0.4639\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 5s 484us/sample - loss: 0.1796 - mse: 0.1796 - mae: 0.3223 - val_loss: 0.5742 - val_mse: 0.5742 - val_mae: 0.4558\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 7s 626us/sample - loss: 1.0998 - mse: 1.0998 - mae: 0.7795 - val_loss: 0.5843 - val_mse: 0.5843 - val_mae: 0.5846\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 5s 480us/sample - loss: 0.6103 - mse: 0.6103 - mae: 0.5914 - val_loss: 0.5853 - val_mse: 0.5853 - val_mae: 0.5683\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 5s 476us/sample - loss: 0.5086 - mse: 0.5086 - mae: 0.5386 - val_loss: 0.6171 - val_mse: 0.6171 - val_mae: 0.6076\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 5s 477us/sample - loss: 0.4609 - mse: 0.4609 - mae: 0.5081 - val_loss: 0.5971 - val_mse: 0.5971 - val_mae: 0.5455\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 5s 480us/sample - loss: 0.4348 - mse: 0.4348 - mae: 0.4955 - val_loss: 0.5549 - val_mse: 0.5549 - val_mae: 0.5229\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 5s 474us/sample - loss: 0.4070 - mse: 0.4070 - mae: 0.4811 - val_loss: 0.4569 - val_mse: 0.4569 - val_mae: 0.4996\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 5s 472us/sample - loss: 0.3955 - mse: 0.3955 - mae: 0.4715 - val_loss: 0.4991 - val_mse: 0.4991 - val_mae: 0.5269\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 5s 472us/sample - loss: 0.3846 - mse: 0.3846 - mae: 0.4657 - val_loss: 0.5560 - val_mse: 0.5560 - val_mae: 0.5195\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 5s 465us/sample - loss: 0.3717 - mse: 0.3717 - mae: 0.4590 - val_loss: 0.4759 - val_mse: 0.4759 - val_mae: 0.5049\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 5s 474us/sample - loss: 0.3498 - mse: 0.3498 - mae: 0.4478 - val_loss: 0.4858 - val_mse: 0.4858 - val_mae: 0.4998\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 5s 475us/sample - loss: 0.3419 - mse: 0.3419 - mae: 0.4405 - val_loss: 0.5198 - val_mse: 0.5198 - val_mae: 0.5345\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 5s 492us/sample - loss: 0.3397 - mse: 0.3397 - mae: 0.4382 - val_loss: 0.4786 - val_mse: 0.4786 - val_mae: 0.4831\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 5s 501us/sample - loss: 0.3178 - mse: 0.3178 - mae: 0.4246 - val_loss: 0.4763 - val_mse: 0.4763 - val_mae: 0.4912\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 5s 493us/sample - loss: 0.3155 - mse: 0.3155 - mae: 0.4234 - val_loss: 0.5339 - val_mse: 0.5339 - val_mae: 0.5253\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 5s 490us/sample - loss: 0.3272 - mse: 0.3272 - mae: 0.4310 - val_loss: 0.4680 - val_mse: 0.4680 - val_mae: 0.4843\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 5s 495us/sample - loss: 0.3049 - mse: 0.3049 - mae: 0.4165 - val_loss: 0.5122 - val_mse: 0.5122 - val_mae: 0.5259\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 8s 706us/sample - loss: 1.1395 - mse: 1.1395 - mae: 0.7924 - val_loss: 0.7050 - val_mse: 0.7050 - val_mae: 0.6429\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 5s 492us/sample - loss: 0.6106 - mse: 0.6106 - mae: 0.5900 - val_loss: 0.7268 - val_mse: 0.7268 - val_mae: 0.5860\n",
      "Epoch 3/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 5s 490us/sample - loss: 0.5154 - mse: 0.5154 - mae: 0.5412 - val_loss: 0.5908 - val_mse: 0.5908 - val_mae: 0.5723\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 5s 482us/sample - loss: 0.4676 - mse: 0.4676 - mae: 0.5148 - val_loss: 0.6477 - val_mse: 0.6477 - val_mae: 0.5412\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 5s 486us/sample - loss: 0.4336 - mse: 0.4336 - mae: 0.4950 - val_loss: 0.5596 - val_mse: 0.5596 - val_mae: 0.5025\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 5s 492us/sample - loss: 0.4040 - mse: 0.4040 - mae: 0.4783 - val_loss: 0.6494 - val_mse: 0.6494 - val_mae: 0.5056\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 5s 484us/sample - loss: 0.3953 - mse: 0.3953 - mae: 0.4758 - val_loss: 0.6718 - val_mse: 0.6718 - val_mae: 0.5449\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 5s 481us/sample - loss: 0.3762 - mse: 0.3762 - mae: 0.4588 - val_loss: 0.4869 - val_mse: 0.4869 - val_mae: 0.4973\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 5s 489us/sample - loss: 0.3655 - mse: 0.3655 - mae: 0.4573 - val_loss: 0.7832 - val_mse: 0.7832 - val_mae: 0.5343\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 5s 498us/sample - loss: 0.3503 - mse: 0.3503 - mae: 0.4449 - val_loss: 0.4724 - val_mse: 0.4724 - val_mae: 0.4909\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 5s 510us/sample - loss: 0.3410 - mse: 0.3410 - mae: 0.4383 - val_loss: 0.4926 - val_mse: 0.4926 - val_mae: 0.5093\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 6s 521us/sample - loss: 0.3353 - mse: 0.3353 - mae: 0.4352 - val_loss: 0.6920 - val_mse: 0.6920 - val_mae: 0.4835\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 5s 488us/sample - loss: 0.3220 - mse: 0.3220 - mae: 0.4248 - val_loss: 0.6789 - val_mse: 0.6789 - val_mae: 0.4818\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 5s 507us/sample - loss: 0.3064 - mse: 0.3064 - mae: 0.4176 - val_loss: 0.8563 - val_mse: 0.8563 - val_mae: 0.5204\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 5s 496us/sample - loss: 0.3077 - mse: 0.3077 - mae: 0.4192 - val_loss: 0.7454 - val_mse: 0.7454 - val_mae: 0.5148\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 5s 505us/sample - loss: 0.3042 - mse: 0.3042 - mae: 0.4137 - val_loss: 1.0643 - val_mse: 1.0643 - val_mae: 0.5247\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 5s 495us/sample - loss: 0.2887 - mse: 0.2887 - mae: 0.4032 - val_loss: 0.6390 - val_mse: 0.6390 - val_mae: 0.5046\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 5s 491us/sample - loss: 0.2847 - mse: 0.2847 - mae: 0.4051 - val_loss: 0.4785 - val_mse: 0.4785 - val_mae: 0.4923\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 5s 496us/sample - loss: 0.2741 - mse: 0.2741 - mae: 0.3943 - val_loss: 0.6023 - val_mse: 0.6023 - val_mae: 0.4863\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 5s 501us/sample - loss: 0.2606 - mse: 0.2606 - mae: 0.3847 - val_loss: 0.5752 - val_mse: 0.5752 - val_mae: 0.4654\n",
      "Avg. MAE: 0.429448\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 206us/sample - loss: 0.8830 - mse: 0.8830 - mae: 0.6999 - val_loss: 0.7809 - val_mse: 0.7809 - val_mae: 0.7046\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 75us/sample - loss: 0.5447 - mse: 0.5447 - mae: 0.5515 - val_loss: 0.5473 - val_mse: 0.5473 - val_mae: 0.5713\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 73us/sample - loss: 0.4750 - mse: 0.4750 - mae: 0.5163 - val_loss: 0.5140 - val_mse: 0.5140 - val_mae: 0.5464\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 73us/sample - loss: 0.4451 - mse: 0.4451 - mae: 0.4993 - val_loss: 0.5168 - val_mse: 0.5168 - val_mae: 0.5260\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 74us/sample - loss: 0.4120 - mse: 0.4120 - mae: 0.4791 - val_loss: 0.4733 - val_mse: 0.4733 - val_mae: 0.5070\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.3743 - mse: 0.3743 - mae: 0.4590 - val_loss: 0.4470 - val_mse: 0.4470 - val_mae: 0.4883\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 72us/sample - loss: 0.3530 - mse: 0.3530 - mae: 0.4428 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.4823\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 72us/sample - loss: 0.3441 - mse: 0.3441 - mae: 0.4374 - val_loss: 0.4707 - val_mse: 0.4707 - val_mae: 0.4975\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 70us/sample - loss: 0.3323 - mse: 0.3323 - mae: 0.4299 - val_loss: 0.4567 - val_mse: 0.4567 - val_mae: 0.4943\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 71us/sample - loss: 0.3146 - mse: 0.3146 - mae: 0.4211 - val_loss: 0.4602 - val_mse: 0.4602 - val_mae: 0.4850\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.2978 - mse: 0.2978 - mae: 0.4056 - val_loss: 0.4477 - val_mse: 0.4477 - val_mae: 0.4854\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.2975 - mse: 0.2975 - mae: 0.4061 - val_loss: 0.4889 - val_mse: 0.4889 - val_mae: 0.5076\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 75us/sample - loss: 0.2815 - mse: 0.2815 - mae: 0.3987 - val_loss: 0.4868 - val_mse: 0.4868 - val_mae: 0.5117\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.2785 - mse: 0.2785 - mae: 0.3920 - val_loss: 0.4574 - val_mse: 0.4574 - val_mae: 0.4834\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2627 - mse: 0.2627 - mae: 0.3844 - val_loss: 0.4591 - val_mse: 0.4591 - val_mae: 0.4870\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 72us/sample - loss: 0.2608 - mse: 0.2608 - mae: 0.3845 - val_loss: 0.4573 - val_mse: 0.4573 - val_mae: 0.4761\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.2526 - mse: 0.2526 - mae: 0.3770 - val_loss: 0.4137 - val_mse: 0.4137 - val_mae: 0.4657\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 75us/sample - loss: 0.2469 - mse: 0.2469 - mae: 0.3723 - val_loss: 0.4407 - val_mse: 0.4407 - val_mae: 0.4748\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 73us/sample - loss: 0.2487 - mse: 0.2487 - mae: 0.3748 - val_loss: 0.4611 - val_mse: 0.4611 - val_mae: 0.4882\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.2301 - mse: 0.2301 - mae: 0.3611 - val_loss: 0.4102 - val_mse: 0.4102 - val_mae: 0.4651\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 74us/sample - loss: 0.2274 - mse: 0.2274 - mae: 0.3585 - val_loss: 0.4183 - val_mse: 0.4183 - val_mae: 0.4690\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 64us/sample - loss: 0.2250 - mse: 0.2250 - mae: 0.3573 - val_loss: 0.4294 - val_mse: 0.4294 - val_mae: 0.4697\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.2129 - mse: 0.2129 - mae: 0.3493 - val_loss: 0.4063 - val_mse: 0.4063 - val_mae: 0.4537\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 72us/sample - loss: 0.2068 - mse: 0.2068 - mae: 0.3439 - val_loss: 0.4683 - val_mse: 0.4683 - val_mae: 0.4945\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.2198 - mse: 0.2198 - mae: 0.3509 - val_loss: 0.4130 - val_mse: 0.4130 - val_mae: 0.4637\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 70us/sample - loss: 0.2046 - mse: 0.2046 - mae: 0.3414 - val_loss: 0.4335 - val_mse: 0.4335 - val_mae: 0.4778\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 73us/sample - loss: 0.2004 - mse: 0.2004 - mae: 0.3392 - val_loss: 0.4013 - val_mse: 0.4013 - val_mae: 0.4617\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1931 - mse: 0.1931 - mae: 0.3319 - val_loss: 0.4210 - val_mse: 0.4210 - val_mae: 0.4620\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.1864 - mse: 0.1864 - mae: 0.3263 - val_loss: 0.3769 - val_mse: 0.3769 - val_mae: 0.4458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1854 - mse: 0.1854 - mae: 0.3275 - val_loss: 0.4353 - val_mse: 0.4353 - val_mae: 0.4657\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1801 - mse: 0.1801 - mae: 0.3200 - val_loss: 0.4152 - val_mse: 0.4152 - val_mae: 0.4595\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.1872 - mse: 0.1872 - mae: 0.3266 - val_loss: 0.4126 - val_mse: 0.4126 - val_mae: 0.4661\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1769 - mse: 0.1769 - mae: 0.3200 - val_loss: 0.4076 - val_mse: 0.4076 - val_mae: 0.4519\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.1717 - mse: 0.1717 - mae: 0.3152 - val_loss: 0.3968 - val_mse: 0.3968 - val_mae: 0.4528\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.1682 - mse: 0.1682 - mae: 0.3098 - val_loss: 0.4165 - val_mse: 0.4165 - val_mae: 0.4541\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1659 - mse: 0.1659 - mae: 0.3069 - val_loss: 0.4053 - val_mse: 0.4053 - val_mae: 0.4536\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 64us/sample - loss: 0.1629 - mse: 0.1629 - mae: 0.3062 - val_loss: 0.4037 - val_mse: 0.4037 - val_mae: 0.4520\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - ETA: 0s - loss: 0.1695 - mse: 0.1695 - mae: 0.309 - 1s 66us/sample - loss: 0.1698 - mse: 0.1698 - mae: 0.3096 - val_loss: 0.4169 - val_mse: 0.4169 - val_mae: 0.4557\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.1656 - mse: 0.1656 - mae: 0.3083 - val_loss: 0.4073 - val_mse: 0.4073 - val_mae: 0.4554\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 191us/sample - loss: 0.8788 - mse: 0.8788 - mae: 0.7008 - val_loss: 0.8332 - val_mse: 0.8332 - val_mae: 0.6811\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.5528 - mse: 0.5528 - mae: 0.5586 - val_loss: 0.5724 - val_mse: 0.5724 - val_mae: 0.5409\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.4750 - mse: 0.4750 - mae: 0.5185 - val_loss: 0.7633 - val_mse: 0.7633 - val_mae: 0.5514\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.4349 - mse: 0.4349 - mae: 0.4947 - val_loss: 0.5176 - val_mse: 0.5176 - val_mae: 0.5171\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.4184 - mse: 0.4184 - mae: 0.4853 - val_loss: 0.5366 - val_mse: 0.5366 - val_mae: 0.5261\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.3857 - mse: 0.3857 - mae: 0.4683 - val_loss: 0.6216 - val_mse: 0.6216 - val_mae: 0.5120\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.3554 - mse: 0.3554 - mae: 0.4491 - val_loss: 0.5168 - val_mse: 0.5168 - val_mae: 0.4884\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.3534 - mse: 0.3534 - mae: 0.4465 - val_loss: 0.5814 - val_mse: 0.5814 - val_mae: 0.4890\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.3278 - mse: 0.3278 - mae: 0.4318 - val_loss: 0.8143 - val_mse: 0.8143 - val_mae: 0.5108\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.3215 - mse: 0.3215 - mae: 0.4253 - val_loss: 0.4505 - val_mse: 0.4505 - val_mae: 0.4798\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.2957 - mse: 0.2957 - mae: 0.4086 - val_loss: 0.5322 - val_mse: 0.5322 - val_mae: 0.4833\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2810 - mse: 0.2810 - mae: 0.4009 - val_loss: 0.6030 - val_mse: 0.6030 - val_mae: 0.5032\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.2818 - mse: 0.2818 - mae: 0.3988 - val_loss: 0.5795 - val_mse: 0.5795 - val_mae: 0.4866\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.2779 - mse: 0.2779 - mae: 0.3973 - val_loss: 0.5185 - val_mse: 0.5185 - val_mae: 0.4861\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.2659 - mse: 0.2659 - mae: 0.3891 - val_loss: 0.4589 - val_mse: 0.4589 - val_mae: 0.4779\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 64us/sample - loss: 0.2608 - mse: 0.2608 - mae: 0.3845 - val_loss: 0.4709 - val_mse: 0.4709 - val_mae: 0.4668\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 64us/sample - loss: 0.2457 - mse: 0.2457 - mae: 0.3732 - val_loss: 0.4568 - val_mse: 0.4568 - val_mae: 0.4729\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2455 - mse: 0.2455 - mae: 0.3742 - val_loss: 0.4564 - val_mse: 0.4564 - val_mae: 0.4780\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.2495 - mse: 0.2495 - mae: 0.3732 - val_loss: 0.4807 - val_mse: 0.4807 - val_mae: 0.4772\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2215 - mse: 0.2215 - mae: 0.3538 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.4749\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 194us/sample - loss: 0.8476 - mse: 0.8476 - mae: 0.6890 - val_loss: 0.7623 - val_mse: 0.7623 - val_mae: 0.6913\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.5513 - mse: 0.5513 - mae: 0.5543 - val_loss: 0.5563 - val_mse: 0.5563 - val_mae: 0.5623\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.4759 - mse: 0.4759 - mae: 0.5171 - val_loss: 0.5090 - val_mse: 0.5090 - val_mae: 0.5279\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.4378 - mse: 0.4378 - mae: 0.4958 - val_loss: 0.5135 - val_mse: 0.5135 - val_mae: 0.5158\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.4042 - mse: 0.4042 - mae: 0.4739 - val_loss: 0.4864 - val_mse: 0.4864 - val_mae: 0.5081\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.3881 - mse: 0.3881 - mae: 0.4636 - val_loss: 0.4364 - val_mse: 0.4364 - val_mae: 0.4826\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.3576 - mse: 0.3576 - mae: 0.4484 - val_loss: 0.4621 - val_mse: 0.4621 - val_mae: 0.4877\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 64us/sample - loss: 0.3561 - mse: 0.3561 - mae: 0.4480 - val_loss: 0.4745 - val_mse: 0.4745 - val_mae: 0.4943\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 64us/sample - loss: 0.3354 - mse: 0.3354 - mae: 0.4338 - val_loss: 0.4470 - val_mse: 0.4470 - val_mae: 0.4734\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.3185 - mse: 0.3185 - mae: 0.4207 - val_loss: 0.4984 - val_mse: 0.4984 - val_mae: 0.4859\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.3066 - mse: 0.3066 - mae: 0.4148 - val_loss: 0.4350 - val_mse: 0.4350 - val_mae: 0.4707\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2960 - mse: 0.2960 - mae: 0.4088 - val_loss: 0.5607 - val_mse: 0.5607 - val_mae: 0.4924\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2857 - mse: 0.2857 - mae: 0.4027 - val_loss: 0.4342 - val_mse: 0.4342 - val_mae: 0.4690\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.2701 - mse: 0.2701 - mae: 0.3895 - val_loss: 0.4362 - val_mse: 0.4362 - val_mae: 0.4676\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2677 - mse: 0.2677 - mae: 0.3907 - val_loss: 0.4217 - val_mse: 0.4217 - val_mae: 0.4608\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.2646 - mse: 0.2646 - mae: 0.3888 - val_loss: 0.4579 - val_mse: 0.4579 - val_mae: 0.4798\n",
      "Epoch 17/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.2614 - mse: 0.2614 - mae: 0.3837 - val_loss: 0.4804 - val_mse: 0.4804 - val_mae: 0.4863\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 64us/sample - loss: 0.2437 - mse: 0.2437 - mae: 0.3695 - val_loss: 0.5728 - val_mse: 0.5728 - val_mae: 0.4855\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2367 - mse: 0.2367 - mae: 0.3666 - val_loss: 0.4838 - val_mse: 0.4838 - val_mae: 0.4739\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2359 - mse: 0.2359 - mae: 0.3672 - val_loss: 0.4513 - val_mse: 0.4513 - val_mae: 0.4760\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2267 - mse: 0.2267 - mae: 0.3602 - val_loss: 0.5011 - val_mse: 0.5011 - val_mae: 0.4711\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 64us/sample - loss: 0.2194 - mse: 0.2194 - mae: 0.3522 - val_loss: 0.4531 - val_mse: 0.4531 - val_mae: 0.4659\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.2196 - mse: 0.2196 - mae: 0.3538 - val_loss: 0.4989 - val_mse: 0.4989 - val_mae: 0.4612\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 64us/sample - loss: 0.2112 - mse: 0.2112 - mae: 0.3456 - val_loss: 0.4295 - val_mse: 0.4295 - val_mae: 0.4557\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.2048 - mse: 0.2048 - mae: 0.3400 - val_loss: 0.4602 - val_mse: 0.4602 - val_mae: 0.4789\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 252us/sample - loss: 0.8664 - mse: 0.8664 - mae: 0.6951 - val_loss: 0.7659 - val_mse: 0.7659 - val_mae: 0.6827\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.5470 - mse: 0.5470 - mae: 0.5526 - val_loss: 0.5575 - val_mse: 0.5575 - val_mae: 0.5723\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.4596 - mse: 0.4596 - mae: 0.5095 - val_loss: 0.5820 - val_mse: 0.5820 - val_mae: 0.5707\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.4318 - mse: 0.4318 - mae: 0.4935 - val_loss: 0.5190 - val_mse: 0.5190 - val_mae: 0.5255\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.4069 - mse: 0.4069 - mae: 0.4786 - val_loss: 0.5613 - val_mse: 0.5613 - val_mae: 0.5175\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.3753 - mse: 0.3753 - mae: 0.4600 - val_loss: 0.4776 - val_mse: 0.4776 - val_mae: 0.4896\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.3600 - mse: 0.3600 - mae: 0.4495 - val_loss: 0.4506 - val_mse: 0.4506 - val_mae: 0.4851\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.3438 - mse: 0.3438 - mae: 0.4382 - val_loss: 0.4882 - val_mse: 0.4882 - val_mae: 0.4979\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.3318 - mse: 0.3318 - mae: 0.4307 - val_loss: 0.4558 - val_mse: 0.4558 - val_mae: 0.4874\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.3181 - mse: 0.3181 - mae: 0.4234 - val_loss: 0.4524 - val_mse: 0.4524 - val_mae: 0.4803\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2995 - mse: 0.2995 - mae: 0.4131 - val_loss: 0.4358 - val_mse: 0.4358 - val_mae: 0.4880\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.2907 - mse: 0.2907 - mae: 0.4052 - val_loss: 0.4903 - val_mse: 0.4903 - val_mae: 0.4928\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2720 - mse: 0.2720 - mae: 0.3908 - val_loss: 0.4247 - val_mse: 0.4247 - val_mae: 0.4690\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 69us/sample - loss: 0.2727 - mse: 0.2727 - mae: 0.3921 - val_loss: 0.4579 - val_mse: 0.4579 - val_mae: 0.4827\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2647 - mse: 0.2647 - mae: 0.3877 - val_loss: 0.4359 - val_mse: 0.4359 - val_mae: 0.4651\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2577 - mse: 0.2577 - mae: 0.3823 - val_loss: 0.4475 - val_mse: 0.4475 - val_mae: 0.4768\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.2525 - mse: 0.2525 - mae: 0.3784 - val_loss: 0.4323 - val_mse: 0.4323 - val_mae: 0.4748\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.2388 - mse: 0.2388 - mae: 0.3689 - val_loss: 0.4167 - val_mse: 0.4167 - val_mae: 0.4611\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2415 - mse: 0.2415 - mae: 0.3716 - val_loss: 0.4292 - val_mse: 0.4292 - val_mae: 0.4652\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.2335 - mse: 0.2335 - mae: 0.3645 - val_loss: 0.4573 - val_mse: 0.4573 - val_mae: 0.4816\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 69us/sample - loss: 0.2206 - mse: 0.2206 - mae: 0.3538 - val_loss: 0.4456 - val_mse: 0.4456 - val_mae: 0.4651\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.2274 - mse: 0.2274 - mae: 0.3582 - val_loss: 0.4438 - val_mse: 0.4438 - val_mae: 0.4661\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.2148 - mse: 0.2148 - mae: 0.3494 - val_loss: 0.4350 - val_mse: 0.4350 - val_mae: 0.4606\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2173 - mse: 0.2173 - mae: 0.3493 - val_loss: 0.4234 - val_mse: 0.4234 - val_mae: 0.4545\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.2058 - mse: 0.2058 - mae: 0.3432 - val_loss: 0.4336 - val_mse: 0.4336 - val_mae: 0.4626\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1998 - mse: 0.1998 - mae: 0.3358 - val_loss: 0.4453 - val_mse: 0.4453 - val_mae: 0.4692\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.2078 - mse: 0.2078 - mae: 0.3451 - val_loss: 0.4148 - val_mse: 0.4148 - val_mae: 0.4562\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.1993 - mse: 0.1993 - mae: 0.3386 - val_loss: 0.4215 - val_mse: 0.4215 - val_mae: 0.4630\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.1893 - mse: 0.1893 - mae: 0.3300 - val_loss: 0.4292 - val_mse: 0.4292 - val_mae: 0.4603\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 70us/sample - loss: 0.1892 - mse: 0.1892 - mae: 0.3274 - val_loss: 0.4411 - val_mse: 0.4411 - val_mae: 0.4697\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.1861 - mse: 0.1861 - mae: 0.3248 - val_loss: 0.4104 - val_mse: 0.4104 - val_mae: 0.4583\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.1788 - mse: 0.1788 - mae: 0.3208 - val_loss: 0.4000 - val_mse: 0.4000 - val_mae: 0.4471\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 65us/sample - loss: 0.1837 - mse: 0.1837 - mae: 0.3250 - val_loss: 0.4099 - val_mse: 0.4099 - val_mae: 0.4480\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1727 - mse: 0.1727 - mae: 0.3136 - val_loss: 0.4290 - val_mse: 0.4290 - val_mae: 0.4615\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1714 - mse: 0.1714 - mae: 0.3110 - val_loss: 0.4178 - val_mse: 0.4178 - val_mae: 0.4527\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.1693 - mse: 0.1693 - mae: 0.3109 - val_loss: 0.3886 - val_mse: 0.3886 - val_mae: 0.4479\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1644 - mse: 0.1644 - mae: 0.3039 - val_loss: 0.4017 - val_mse: 0.4017 - val_mae: 0.4519\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.1658 - mse: 0.1658 - mae: 0.3086 - val_loss: 0.3930 - val_mse: 0.3930 - val_mae: 0.4432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.1599 - mse: 0.1599 - mae: 0.3044 - val_loss: 0.4138 - val_mse: 0.4138 - val_mae: 0.4531\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 66us/sample - loss: 0.1598 - mse: 0.1598 - mae: 0.3017 - val_loss: 0.3985 - val_mse: 0.3985 - val_mae: 0.4480\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1654 - mse: 0.1654 - mae: 0.3075 - val_loss: 0.4048 - val_mse: 0.4048 - val_mae: 0.4540\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.1600 - mse: 0.1600 - mae: 0.3033 - val_loss: 0.3982 - val_mse: 0.3982 - val_mae: 0.4548\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1586 - mse: 0.1586 - mae: 0.3029 - val_loss: 0.3968 - val_mse: 0.3968 - val_mae: 0.4499\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1521 - mse: 0.1521 - mae: 0.2976 - val_loss: 0.4012 - val_mse: 0.4012 - val_mae: 0.4471\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 67us/sample - loss: 0.1475 - mse: 0.1475 - mae: 0.2919 - val_loss: 0.4061 - val_mse: 0.4061 - val_mae: 0.4447\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 68us/sample - loss: 0.1528 - mse: 0.1528 - mae: 0.2953 - val_loss: 0.4000 - val_mse: 0.4000 - val_mae: 0.4474\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 196us/sample - loss: 0.8626 - mse: 0.8626 - mae: 0.6933 - val_loss: 0.7197 - val_mse: 0.7197 - val_mae: 0.6605\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 1s 66us/sample - loss: 0.5560 - mse: 0.5560 - mae: 0.5605 - val_loss: 0.6015 - val_mse: 0.6015 - val_mae: 0.5665\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 1s 66us/sample - loss: 0.4775 - mse: 0.4775 - mae: 0.5164 - val_loss: 0.4656 - val_mse: 0.4656 - val_mae: 0.4977\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 66us/sample - loss: 0.4324 - mse: 0.4324 - mae: 0.4921 - val_loss: 0.5428 - val_mse: 0.5428 - val_mae: 0.5208\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 1s 66us/sample - loss: 0.4133 - mse: 0.4133 - mae: 0.4780 - val_loss: 0.4911 - val_mse: 0.4911 - val_mae: 0.4837\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 1s 66us/sample - loss: 0.3846 - mse: 0.3846 - mae: 0.4633 - val_loss: 0.4832 - val_mse: 0.4832 - val_mae: 0.4858\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 1s 68us/sample - loss: 0.3671 - mse: 0.3671 - mae: 0.4537 - val_loss: 0.5134 - val_mse: 0.5134 - val_mae: 0.4969\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 67us/sample - loss: 0.3437 - mse: 0.3437 - mae: 0.4377 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4813\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 1s 66us/sample - loss: 0.3311 - mse: 0.3311 - mae: 0.4301 - val_loss: 0.4720 - val_mse: 0.4720 - val_mae: 0.4754\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 67us/sample - loss: 0.3206 - mse: 0.3206 - mae: 0.4237 - val_loss: 0.4875 - val_mse: 0.4875 - val_mae: 0.4999\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 67us/sample - loss: 0.3049 - mse: 0.3049 - mae: 0.4148 - val_loss: 0.4672 - val_mse: 0.4672 - val_mae: 0.4692\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 67us/sample - loss: 0.2944 - mse: 0.2944 - mae: 0.4071 - val_loss: 0.4567 - val_mse: 0.4567 - val_mae: 0.4830\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 1s 68us/sample - loss: 0.2867 - mse: 0.2867 - mae: 0.4002 - val_loss: 0.4613 - val_mse: 0.4613 - val_mae: 0.4644\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 1s 68us/sample - loss: 0.2789 - mse: 0.2789 - mae: 0.3951 - val_loss: 0.4384 - val_mse: 0.4384 - val_mae: 0.4726\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 1s 67us/sample - loss: 0.2680 - mse: 0.2680 - mae: 0.3894 - val_loss: 0.4749 - val_mse: 0.4749 - val_mae: 0.4738\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 1s 65us/sample - loss: 0.2689 - mse: 0.2689 - mae: 0.3874 - val_loss: 0.4913 - val_mse: 0.4913 - val_mae: 0.4645\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 1s 64us/sample - loss: 0.2561 - mse: 0.2561 - mae: 0.3778 - val_loss: 0.4428 - val_mse: 0.4428 - val_mae: 0.4679\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 1s 67us/sample - loss: 0.2547 - mse: 0.2547 - mae: 0.3781 - val_loss: 0.4653 - val_mse: 0.4653 - val_mae: 0.4940\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 1s 68us/sample - loss: 0.2457 - mse: 0.2457 - mae: 0.3721 - val_loss: 0.4726 - val_mse: 0.4726 - val_mae: 0.4695\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 1s 67us/sample - loss: 0.2364 - mse: 0.2364 - mae: 0.3669 - val_loss: 0.4690 - val_mse: 0.4690 - val_mae: 0.4625\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 1s 68us/sample - loss: 0.2263 - mse: 0.2263 - mae: 0.3606 - val_loss: 0.4712 - val_mse: 0.4712 - val_mae: 0.4709\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 1s 71us/sample - loss: 0.2257 - mse: 0.2257 - mae: 0.3555 - val_loss: 0.4300 - val_mse: 0.4300 - val_mae: 0.4515\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 1s 71us/sample - loss: 0.2174 - mse: 0.2174 - mae: 0.3503 - val_loss: 0.4297 - val_mse: 0.4297 - val_mae: 0.4675\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 1s 66us/sample - loss: 0.2222 - mse: 0.2222 - mae: 0.3540 - val_loss: 0.4695 - val_mse: 0.4695 - val_mae: 0.4734\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 1s 67us/sample - loss: 0.2160 - mse: 0.2160 - mae: 0.3481 - val_loss: 0.4596 - val_mse: 0.4596 - val_mae: 0.4611\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 1s 66us/sample - loss: 0.2081 - mse: 0.2081 - mae: 0.3423 - val_loss: 0.4888 - val_mse: 0.4888 - val_mae: 0.4644\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 1s 66us/sample - loss: 0.2101 - mse: 0.2101 - mae: 0.3459 - val_loss: 0.4173 - val_mse: 0.4173 - val_mae: 0.4584\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 1s 68us/sample - loss: 0.1996 - mse: 0.1996 - mae: 0.3371 - val_loss: 0.4038 - val_mse: 0.4038 - val_mae: 0.4461\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 1s 68us/sample - loss: 0.1915 - mse: 0.1915 - mae: 0.3311 - val_loss: 0.4110 - val_mse: 0.4110 - val_mae: 0.4468\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 1s 65us/sample - loss: 0.1905 - mse: 0.1905 - mae: 0.3303 - val_loss: 0.4931 - val_mse: 0.4931 - val_mae: 0.4624\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 1s 66us/sample - loss: 0.1836 - mse: 0.1836 - mae: 0.3228 - val_loss: 0.4522 - val_mse: 0.4522 - val_mae: 0.4517\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 1s 68us/sample - loss: 0.1883 - mse: 0.1883 - mae: 0.3274 - val_loss: 0.4369 - val_mse: 0.4369 - val_mae: 0.4513\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 1s 68us/sample - loss: 0.1840 - mse: 0.1840 - mae: 0.3247 - val_loss: 0.4506 - val_mse: 0.4506 - val_mae: 0.4590\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 1s 67us/sample - loss: 0.1788 - mse: 0.1788 - mae: 0.3211 - val_loss: 0.4650 - val_mse: 0.4650 - val_mae: 0.4586\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 1s 66us/sample - loss: 0.1701 - mse: 0.1701 - mae: 0.3124 - val_loss: 0.4522 - val_mse: 0.4522 - val_mae: 0.4504\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 1s 71us/sample - loss: 0.1694 - mse: 0.1694 - mae: 0.3135 - val_loss: 0.4724 - val_mse: 0.4724 - val_mae: 0.4510\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 1s 65us/sample - loss: 0.1728 - mse: 0.1728 - mae: 0.3138 - val_loss: 0.4400 - val_mse: 0.4400 - val_mae: 0.4403\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 1s 67us/sample - loss: 0.1662 - mse: 0.1662 - mae: 0.3079 - val_loss: 0.4214 - val_mse: 0.4214 - val_mae: 0.4487\n",
      "Avg. MAE: 0.402016\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.8317 - mse: 0.8317 - mae: 0.6709 - val_loss: 0.7503 - val_mse: 0.7503 - val_mae: 0.6231\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 109us/sample - loss: 0.5913 - mse: 0.5913 - mae: 0.5723 - val_loss: 0.5616 - val_mse: 0.5616 - val_mae: 0.5464\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 112us/sample - loss: 0.5296 - mse: 0.5296 - mae: 0.5423 - val_loss: 0.5605 - val_mse: 0.5605 - val_mae: 0.5616\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 110us/sample - loss: 0.5197 - mse: 0.5197 - mae: 0.5366 - val_loss: 0.5547 - val_mse: 0.5547 - val_mae: 0.5378\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 119us/sample - loss: 0.4991 - mse: 0.4991 - mae: 0.5229 - val_loss: 0.5282 - val_mse: 0.5282 - val_mae: 0.5349\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 112us/sample - loss: 0.4619 - mse: 0.4619 - mae: 0.5047 - val_loss: 0.4732 - val_mse: 0.4732 - val_mae: 0.5091\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 108us/sample - loss: 0.4476 - mse: 0.4476 - mae: 0.4979 - val_loss: 0.4652 - val_mse: 0.4652 - val_mae: 0.5012\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 110us/sample - loss: 0.4263 - mse: 0.4263 - mae: 0.4840 - val_loss: 0.4971 - val_mse: 0.4971 - val_mae: 0.5191\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 112us/sample - loss: 0.4135 - mse: 0.4135 - mae: 0.4746 - val_loss: 0.4970 - val_mse: 0.4970 - val_mae: 0.5206\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 107us/sample - loss: 0.4047 - mse: 0.4047 - mae: 0.4747 - val_loss: 0.4700 - val_mse: 0.4700 - val_mae: 0.4957\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 112us/sample - loss: 0.3863 - mse: 0.3863 - mae: 0.4598 - val_loss: 0.4516 - val_mse: 0.4516 - val_mae: 0.4965\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 110us/sample - loss: 0.3854 - mse: 0.3854 - mae: 0.4607 - val_loss: 0.5313 - val_mse: 0.5313 - val_mae: 0.5205\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 109us/sample - loss: 0.3688 - mse: 0.3688 - mae: 0.4528 - val_loss: 0.5261 - val_mse: 0.5261 - val_mae: 0.5107\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 112us/sample - loss: 0.3658 - mse: 0.3658 - mae: 0.4504 - val_loss: 0.4582 - val_mse: 0.4582 - val_mae: 0.4931\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 109us/sample - loss: 0.3449 - mse: 0.3449 - mae: 0.4400 - val_loss: 0.5166 - val_mse: 0.5166 - val_mae: 0.4963\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 109us/sample - loss: 0.3530 - mse: 0.3530 - mae: 0.4432 - val_loss: 0.4766 - val_mse: 0.4766 - val_mae: 0.4938\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 111us/sample - loss: 0.3444 - mse: 0.3444 - mae: 0.4411 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4883\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 110us/sample - loss: 0.3339 - mse: 0.3339 - mae: 0.4332 - val_loss: 0.4482 - val_mse: 0.4482 - val_mae: 0.4724\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 109us/sample - loss: 0.3275 - mse: 0.3275 - mae: 0.4284 - val_loss: 0.4490 - val_mse: 0.4490 - val_mae: 0.4869\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 110us/sample - loss: 0.3281 - mse: 0.3281 - mae: 0.4295 - val_loss: 0.4391 - val_mse: 0.4391 - val_mae: 0.4782\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 110us/sample - loss: 0.3084 - mse: 0.3084 - mae: 0.4159 - val_loss: 0.4203 - val_mse: 0.4203 - val_mae: 0.4704\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 110us/sample - loss: 0.3011 - mse: 0.3011 - mae: 0.4131 - val_loss: 0.4539 - val_mse: 0.4539 - val_mae: 0.4986\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 105us/sample - loss: 0.3007 - mse: 0.3007 - mae: 0.4138 - val_loss: 0.4034 - val_mse: 0.4034 - val_mae: 0.4565\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.3012 - mse: 0.3012 - mae: 0.4110 - val_loss: 0.4932 - val_mse: 0.4932 - val_mae: 0.4933\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.2973 - mse: 0.2973 - mae: 0.4086 - val_loss: 0.4303 - val_mse: 0.4303 - val_mae: 0.4714\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.2898 - mse: 0.2898 - mae: 0.4044 - val_loss: 0.5112 - val_mse: 0.5112 - val_mae: 0.5211\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.2832 - mse: 0.2832 - mae: 0.4001 - val_loss: 0.4401 - val_mse: 0.4401 - val_mae: 0.4842\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2767 - mse: 0.2767 - mae: 0.3964 - val_loss: 0.4759 - val_mse: 0.4759 - val_mae: 0.5020\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.2690 - mse: 0.2690 - mae: 0.3884 - val_loss: 0.4144 - val_mse: 0.4144 - val_mae: 0.4577\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 105us/sample - loss: 0.2661 - mse: 0.2661 - mae: 0.3887 - val_loss: 0.5010 - val_mse: 0.5010 - val_mae: 0.4904\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.2540 - mse: 0.2540 - mae: 0.3783 - val_loss: 0.4307 - val_mse: 0.4307 - val_mae: 0.4617\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.2552 - mse: 0.2552 - mae: 0.3821 - val_loss: 0.4213 - val_mse: 0.4213 - val_mae: 0.4627\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.2497 - mse: 0.2497 - mae: 0.3772 - val_loss: 0.4065 - val_mse: 0.4065 - val_mae: 0.4549\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.8246 - mse: 0.8246 - mae: 0.6776 - val_loss: 0.6508 - val_mse: 0.6508 - val_mae: 0.6008\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.6134 - mse: 0.6134 - mae: 0.5851 - val_loss: 0.5848 - val_mse: 0.5848 - val_mae: 0.5468\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.5466 - mse: 0.5466 - mae: 0.5524 - val_loss: 0.7941 - val_mse: 0.7941 - val_mae: 0.5763\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.5121 - mse: 0.5121 - mae: 0.5344 - val_loss: 0.5347 - val_mse: 0.5347 - val_mae: 0.5219\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.4961 - mse: 0.4961 - mae: 0.5241 - val_loss: 0.5712 - val_mse: 0.5712 - val_mae: 0.5455\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.4616 - mse: 0.4616 - mae: 0.5061 - val_loss: 0.8624 - val_mse: 0.8624 - val_mae: 0.5540\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.4401 - mse: 0.4401 - mae: 0.4949 - val_loss: 0.4924 - val_mse: 0.4924 - val_mae: 0.4972\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.4326 - mse: 0.4326 - mae: 0.4899 - val_loss: 0.5978 - val_mse: 0.5978 - val_mae: 0.5200\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.4137 - mse: 0.4137 - mae: 0.4822 - val_loss: 0.7591 - val_mse: 0.7591 - val_mae: 0.5055\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.4030 - mse: 0.4030 - mae: 0.4742 - val_loss: 0.5172 - val_mse: 0.5172 - val_mae: 0.4975\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.3865 - mse: 0.3865 - mae: 0.4621 - val_loss: 0.5138 - val_mse: 0.5138 - val_mae: 0.5025\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.3748 - mse: 0.3748 - mae: 0.4607 - val_loss: 0.5363 - val_mse: 0.5363 - val_mae: 0.5040\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.3852 - mse: 0.3852 - mae: 0.4663 - val_loss: 0.4898 - val_mse: 0.4898 - val_mae: 0.4849\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.3595 - mse: 0.3595 - mae: 0.4498 - val_loss: 0.5270 - val_mse: 0.5270 - val_mae: 0.4992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 110us/sample - loss: 0.3732 - mse: 0.3732 - mae: 0.4565 - val_loss: 0.4809 - val_mse: 0.4809 - val_mae: 0.4907\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 112us/sample - loss: 0.3568 - mse: 0.3568 - mae: 0.4469 - val_loss: 0.5269 - val_mse: 0.5269 - val_mae: 0.5027\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3497 - mse: 0.3497 - mae: 0.4436 - val_loss: 0.4706 - val_mse: 0.4706 - val_mae: 0.4915\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3441 - mse: 0.3441 - mae: 0.4403 - val_loss: 0.4705 - val_mse: 0.4705 - val_mae: 0.4899\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.3355 - mse: 0.3355 - mae: 0.4331 - val_loss: 0.4908 - val_mse: 0.4908 - val_mae: 0.4982\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.3149 - mse: 0.3149 - mae: 0.4209 - val_loss: 0.4675 - val_mse: 0.4675 - val_mae: 0.4820\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.3114 - mse: 0.3114 - mae: 0.4206 - val_loss: 0.5263 - val_mse: 0.5263 - val_mae: 0.4851\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.3090 - mse: 0.3090 - mae: 0.4164 - val_loss: 0.4566 - val_mse: 0.4566 - val_mae: 0.4801\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.3111 - mse: 0.3111 - mae: 0.4194 - val_loss: 0.4655 - val_mse: 0.4655 - val_mae: 0.4854\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3167 - mse: 0.3167 - mae: 0.4224 - val_loss: 0.5678 - val_mse: 0.5678 - val_mae: 0.4997\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.3031 - mse: 0.3031 - mae: 0.4128 - val_loss: 0.4626 - val_mse: 0.4626 - val_mae: 0.4728\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2891 - mse: 0.2891 - mae: 0.4031 - val_loss: 0.4819 - val_mse: 0.4819 - val_mae: 0.4894\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.2852 - mse: 0.2852 - mae: 0.4032 - val_loss: 0.4510 - val_mse: 0.4510 - val_mae: 0.4738\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2813 - mse: 0.2813 - mae: 0.3986 - val_loss: 0.5560 - val_mse: 0.5560 - val_mae: 0.4883\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.2888 - mse: 0.2888 - mae: 0.4020 - val_loss: 0.4840 - val_mse: 0.4840 - val_mae: 0.4818\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2808 - mse: 0.2808 - mae: 0.3972 - val_loss: 0.4774 - val_mse: 0.4774 - val_mae: 0.4631\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2608 - mse: 0.2608 - mae: 0.3835 - val_loss: 0.4244 - val_mse: 0.4244 - val_mae: 0.4577\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2626 - mse: 0.2626 - mae: 0.3831 - val_loss: 0.4671 - val_mse: 0.4671 - val_mae: 0.4822\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2677 - mse: 0.2677 - mae: 0.3901 - val_loss: 0.4317 - val_mse: 0.4317 - val_mae: 0.4644\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2546 - mse: 0.2546 - mae: 0.3808 - val_loss: 0.4475 - val_mse: 0.4475 - val_mae: 0.4570\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 105us/sample - loss: 0.2489 - mse: 0.2489 - mae: 0.3768 - val_loss: 0.4584 - val_mse: 0.4584 - val_mae: 0.4521\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2450 - mse: 0.2450 - mae: 0.3761 - val_loss: 0.4315 - val_mse: 0.4315 - val_mae: 0.4622\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2588 - mse: 0.2588 - mae: 0.3825 - val_loss: 0.4886 - val_mse: 0.4886 - val_mae: 0.4723\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2525 - mse: 0.2525 - mae: 0.3784 - val_loss: 0.5470 - val_mse: 0.5470 - val_mae: 0.4849\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 107us/sample - loss: 0.2542 - mse: 0.2542 - mae: 0.3805 - val_loss: 0.4240 - val_mse: 0.4240 - val_mae: 0.4546\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2428 - mse: 0.2428 - mae: 0.3730 - val_loss: 0.4823 - val_mse: 0.4823 - val_mae: 0.4640\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2472 - mse: 0.2472 - mae: 0.3760 - val_loss: 0.5766 - val_mse: 0.5766 - val_mae: 0.4698\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.2602 - mse: 0.2602 - mae: 0.3852 - val_loss: 0.4506 - val_mse: 0.4506 - val_mae: 0.4716\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2556 - mse: 0.2556 - mae: 0.3806 - val_loss: 0.4522 - val_mse: 0.4522 - val_mae: 0.4709\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2418 - mse: 0.2418 - mae: 0.3705 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.4504\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2299 - mse: 0.2299 - mae: 0.3635 - val_loss: 0.4688 - val_mse: 0.4688 - val_mae: 0.4701\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.2279 - mse: 0.2279 - mae: 0.3601 - val_loss: 0.4451 - val_mse: 0.4451 - val_mae: 0.4556\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2234 - mse: 0.2234 - mae: 0.3591 - val_loss: 0.4451 - val_mse: 0.4451 - val_mae: 0.4719\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2215 - mse: 0.2215 - mae: 0.3570 - val_loss: 0.4905 - val_mse: 0.4905 - val_mae: 0.4605\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2149 - mse: 0.2149 - mae: 0.3502 - val_loss: 0.4907 - val_mse: 0.4907 - val_mae: 0.4816\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2074 - mse: 0.2074 - mae: 0.3454 - val_loss: 0.4724 - val_mse: 0.4724 - val_mae: 0.4628\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2214 - mse: 0.2214 - mae: 0.3557 - val_loss: 0.4598 - val_mse: 0.4598 - val_mae: 0.4582\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.2137 - mse: 0.2137 - mae: 0.3504 - val_loss: 0.4586 - val_mse: 0.4586 - val_mae: 0.4596\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2213 - mse: 0.2213 - mae: 0.3555 - val_loss: 0.4501 - val_mse: 0.4501 - val_mae: 0.4661\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.2142 - mse: 0.2142 - mae: 0.3495 - val_loss: 0.4557 - val_mse: 0.4557 - val_mae: 0.4612\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 225us/sample - loss: 0.8351 - mse: 0.8351 - mae: 0.6750 - val_loss: 0.8404 - val_mse: 0.8404 - val_mae: 0.6693\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 100us/sample - loss: 0.6186 - mse: 0.6186 - mae: 0.5864 - val_loss: 0.6769 - val_mse: 0.6769 - val_mae: 0.6102\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.5451 - mse: 0.5451 - mae: 0.5451 - val_loss: 0.5473 - val_mse: 0.5473 - val_mae: 0.5370\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.5275 - mse: 0.5275 - mae: 0.5402 - val_loss: 0.5378 - val_mse: 0.5378 - val_mae: 0.5282\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.4827 - mse: 0.4827 - mae: 0.5163 - val_loss: 0.4751 - val_mse: 0.4751 - val_mae: 0.5080\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.4721 - mse: 0.4721 - mae: 0.5105 - val_loss: 0.4929 - val_mse: 0.4929 - val_mae: 0.5142\n",
      "Epoch 7/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.4373 - mse: 0.4373 - mae: 0.4926 - val_loss: 0.5300 - val_mse: 0.5300 - val_mae: 0.5158\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.4367 - mse: 0.4367 - mae: 0.4910 - val_loss: 0.5872 - val_mse: 0.5872 - val_mae: 0.5241\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.4192 - mse: 0.4192 - mae: 0.4832 - val_loss: 0.5003 - val_mse: 0.5003 - val_mae: 0.4968\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.4093 - mse: 0.4093 - mae: 0.4782 - val_loss: 0.5138 - val_mse: 0.5138 - val_mae: 0.5223\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.3953 - mse: 0.3953 - mae: 0.4694 - val_loss: 0.4423 - val_mse: 0.4423 - val_mae: 0.4849\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.3897 - mse: 0.3897 - mae: 0.4646 - val_loss: 0.4840 - val_mse: 0.4840 - val_mae: 0.5010\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.3779 - mse: 0.3779 - mae: 0.4593 - val_loss: 0.4583 - val_mse: 0.4583 - val_mae: 0.5028\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.3721 - mse: 0.3721 - mae: 0.4559 - val_loss: 0.5336 - val_mse: 0.5336 - val_mae: 0.5171\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 107us/sample - loss: 0.3722 - mse: 0.3722 - mae: 0.4541 - val_loss: 0.4549 - val_mse: 0.4549 - val_mae: 0.4785\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.3524 - mse: 0.3524 - mae: 0.4463 - val_loss: 0.5056 - val_mse: 0.5056 - val_mae: 0.4909\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.3454 - mse: 0.3454 - mae: 0.4397 - val_loss: 0.4661 - val_mse: 0.4661 - val_mae: 0.4878\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.3302 - mse: 0.3302 - mae: 0.4299 - val_loss: 0.5024 - val_mse: 0.5024 - val_mae: 0.5020\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.3314 - mse: 0.3314 - mae: 0.4302 - val_loss: 0.4767 - val_mse: 0.4767 - val_mae: 0.4857\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.3260 - mse: 0.3260 - mae: 0.4252 - val_loss: 0.4640 - val_mse: 0.4640 - val_mae: 0.4910\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 101us/sample - loss: 0.3200 - mse: 0.3200 - mae: 0.4258 - val_loss: 0.4908 - val_mse: 0.4908 - val_mae: 0.4860\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 226us/sample - loss: 0.8222 - mse: 0.8222 - mae: 0.6778 - val_loss: 0.6152 - val_mse: 0.6152 - val_mae: 0.5905\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.6061 - mse: 0.6061 - mae: 0.5788 - val_loss: 0.6160 - val_mse: 0.6160 - val_mae: 0.5718\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.5373 - mse: 0.5373 - mae: 0.5461 - val_loss: 0.5320 - val_mse: 0.5320 - val_mae: 0.5512\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.5061 - mse: 0.5061 - mae: 0.5267 - val_loss: 0.5415 - val_mse: 0.5415 - val_mae: 0.5333\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 105us/sample - loss: 0.4894 - mse: 0.4894 - mae: 0.5186 - val_loss: 0.5251 - val_mse: 0.5251 - val_mae: 0.5340\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.4670 - mse: 0.4670 - mae: 0.5055 - val_loss: 0.5154 - val_mse: 0.5154 - val_mae: 0.5163\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.4458 - mse: 0.4458 - mae: 0.4970 - val_loss: 0.4732 - val_mse: 0.4732 - val_mae: 0.5034\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.4348 - mse: 0.4348 - mae: 0.4898 - val_loss: 0.5674 - val_mse: 0.5674 - val_mae: 0.5311\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.4273 - mse: 0.4273 - mae: 0.4830 - val_loss: 0.4696 - val_mse: 0.4696 - val_mae: 0.4978\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 105us/sample - loss: 0.4037 - mse: 0.4037 - mae: 0.4742 - val_loss: 0.4843 - val_mse: 0.4843 - val_mae: 0.4987\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3953 - mse: 0.3953 - mae: 0.4680 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.5030\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3742 - mse: 0.3742 - mae: 0.4550 - val_loss: 0.5396 - val_mse: 0.5396 - val_mae: 0.4967\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3659 - mse: 0.3659 - mae: 0.4510 - val_loss: 0.5129 - val_mse: 0.5129 - val_mae: 0.5023\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3617 - mse: 0.3617 - mae: 0.4492 - val_loss: 0.5172 - val_mse: 0.5172 - val_mae: 0.4904\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 103us/sample - loss: 0.3576 - mse: 0.3576 - mae: 0.4461 - val_loss: 0.4540 - val_mse: 0.4540 - val_mae: 0.4761\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3541 - mse: 0.3541 - mae: 0.4456 - val_loss: 0.6168 - val_mse: 0.6168 - val_mae: 0.5496\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3459 - mse: 0.3459 - mae: 0.4416 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.4852\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3257 - mse: 0.3257 - mae: 0.4264 - val_loss: 0.4726 - val_mse: 0.4726 - val_mae: 0.4883\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3280 - mse: 0.3280 - mae: 0.4298 - val_loss: 0.5273 - val_mse: 0.5273 - val_mae: 0.4863\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3241 - mse: 0.3241 - mae: 0.4293 - val_loss: 0.6248 - val_mse: 0.6248 - val_mae: 0.4945\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3129 - mse: 0.3129 - mae: 0.4196 - val_loss: 0.5742 - val_mse: 0.5742 - val_mae: 0.4874\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.3082 - mse: 0.3082 - mae: 0.4148 - val_loss: 0.5385 - val_mse: 0.5385 - val_mae: 0.4768\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 104us/sample - loss: 0.2987 - mse: 0.2987 - mae: 0.4098 - val_loss: 0.6208 - val_mse: 0.6208 - val_mae: 0.4799\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 102us/sample - loss: 0.2982 - mse: 0.2982 - mae: 0.4094 - val_loss: 0.4991 - val_mse: 0.4991 - val_mae: 0.4645\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 105us/sample - loss: 0.2875 - mse: 0.2875 - mae: 0.4041 - val_loss: 0.5110 - val_mse: 0.5110 - val_mae: 0.4807\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 227us/sample - loss: 0.8147 - mse: 0.8147 - mae: 0.6668 - val_loss: 0.6180 - val_mse: 0.6180 - val_mae: 0.5929\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 1s 104us/sample - loss: 0.6124 - mse: 0.6124 - mae: 0.5829 - val_loss: 0.6340 - val_mse: 0.6340 - val_mae: 0.5691\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 1s 103us/sample - loss: 0.5519 - mse: 0.5519 - mae: 0.5552 - val_loss: 0.5338 - val_mse: 0.5338 - val_mae: 0.5250\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 103us/sample - loss: 0.5177 - mse: 0.5177 - mae: 0.5349 - val_loss: 0.5293 - val_mse: 0.5293 - val_mae: 0.5124\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 1s 103us/sample - loss: 0.4836 - mse: 0.4836 - mae: 0.5162 - val_loss: 0.5591 - val_mse: 0.5591 - val_mae: 0.5182\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 1s 104us/sample - loss: 0.4696 - mse: 0.4696 - mae: 0.5108 - val_loss: 0.5534 - val_mse: 0.5534 - val_mae: 0.5057\n",
      "Epoch 7/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 1s 103us/sample - loss: 0.4526 - mse: 0.4526 - mae: 0.5001 - val_loss: 0.5337 - val_mse: 0.5337 - val_mae: 0.5154\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 103us/sample - loss: 0.4274 - mse: 0.4274 - mae: 0.4871 - val_loss: 0.4829 - val_mse: 0.4829 - val_mae: 0.4999\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 1s 101us/sample - loss: 0.4199 - mse: 0.4199 - mae: 0.4842 - val_loss: 0.6347 - val_mse: 0.6347 - val_mae: 0.4896\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 104us/sample - loss: 0.4019 - mse: 0.4019 - mae: 0.4732 - val_loss: 0.5390 - val_mse: 0.5390 - val_mae: 0.5132\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 103us/sample - loss: 0.3853 - mse: 0.3853 - mae: 0.4648 - val_loss: 0.4936 - val_mse: 0.4936 - val_mae: 0.4953\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 103us/sample - loss: 0.3878 - mse: 0.3878 - mae: 0.4645 - val_loss: 0.5164 - val_mse: 0.5164 - val_mae: 0.4964\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 1s 105us/sample - loss: 0.3667 - mse: 0.3667 - mae: 0.4516 - val_loss: 0.5443 - val_mse: 0.5443 - val_mae: 0.4906\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 1s 102us/sample - loss: 0.3613 - mse: 0.3613 - mae: 0.4480 - val_loss: 0.5105 - val_mse: 0.5105 - val_mae: 0.5097\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 1s 104us/sample - loss: 0.3625 - mse: 0.3625 - mae: 0.4470 - val_loss: 0.5937 - val_mse: 0.5937 - val_mae: 0.4909\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 1s 103us/sample - loss: 0.3418 - mse: 0.3418 - mae: 0.4377 - val_loss: 0.5896 - val_mse: 0.5896 - val_mae: 0.4829\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 1s 103us/sample - loss: 0.3454 - mse: 0.3454 - mae: 0.4369 - val_loss: 0.5709 - val_mse: 0.5709 - val_mae: 0.5015\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 1s 104us/sample - loss: 0.3356 - mse: 0.3356 - mae: 0.4356 - val_loss: 0.4867 - val_mse: 0.4867 - val_mae: 0.4915\n",
      "Avg. MAE: 0.417433\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.9293 - mse: 0.9293 - mae: 0.6838 - val_loss: 0.7492 - val_mse: 0.7492 - val_mae: 0.6918\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.5615 - mse: 0.5615 - mae: 0.5608 - val_loss: 0.5812 - val_mse: 0.5812 - val_mae: 0.5709\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - ETA: 0s - loss: 0.5251 - mse: 0.5251 - mae: 0.541 - 0s 34us/sample - loss: 0.5244 - mse: 0.5244 - mae: 0.5422 - val_loss: 0.5674 - val_mse: 0.5674 - val_mae: 0.5613\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.5082 - mse: 0.5082 - mae: 0.5361 - val_loss: 0.5450 - val_mse: 0.5450 - val_mae: 0.5414\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4688 - mse: 0.4688 - mae: 0.5121 - val_loss: 0.5607 - val_mse: 0.5607 - val_mae: 0.5692\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.4415 - mse: 0.4415 - mae: 0.4993 - val_loss: 0.5222 - val_mse: 0.5222 - val_mae: 0.5328\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4252 - mse: 0.4252 - mae: 0.4904 - val_loss: 0.5141 - val_mse: 0.5141 - val_mae: 0.5198\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4179 - mse: 0.4179 - mae: 0.4834 - val_loss: 0.5205 - val_mse: 0.5205 - val_mae: 0.5401\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4035 - mse: 0.4035 - mae: 0.4765 - val_loss: 0.4992 - val_mse: 0.4992 - val_mae: 0.5374\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3881 - mse: 0.3881 - mae: 0.4705 - val_loss: 0.4533 - val_mse: 0.4533 - val_mae: 0.5040\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 36us/sample - loss: 0.3782 - mse: 0.3782 - mae: 0.4628 - val_loss: 0.4778 - val_mse: 0.4778 - val_mae: 0.5240\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.3762 - mse: 0.3762 - mae: 0.4635 - val_loss: 0.5162 - val_mse: 0.5162 - val_mae: 0.5151\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 36us/sample - loss: 0.3623 - mse: 0.3623 - mae: 0.4567 - val_loss: 0.5142 - val_mse: 0.5142 - val_mae: 0.5267\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.3616 - mse: 0.3616 - mae: 0.4521 - val_loss: 0.4892 - val_mse: 0.4892 - val_mae: 0.5142\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 38us/sample - loss: 0.3485 - mse: 0.3485 - mae: 0.4437 - val_loss: 0.5208 - val_mse: 0.5208 - val_mae: 0.5213\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3544 - mse: 0.3544 - mae: 0.4505 - val_loss: 0.4992 - val_mse: 0.4992 - val_mae: 0.5064\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3413 - mse: 0.3413 - mae: 0.4398 - val_loss: 0.4664 - val_mse: 0.4664 - val_mae: 0.5087\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 36us/sample - loss: 0.3404 - mse: 0.3404 - mae: 0.4417 - val_loss: 0.4818 - val_mse: 0.4818 - val_mae: 0.5106\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3333 - mse: 0.3333 - mae: 0.4386 - val_loss: 0.5097 - val_mse: 0.5097 - val_mae: 0.5092\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3167 - mse: 0.3167 - mae: 0.4275 - val_loss: 0.4465 - val_mse: 0.4465 - val_mae: 0.4964\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.3215 - mse: 0.3215 - mae: 0.4300 - val_loss: 0.5563 - val_mse: 0.5563 - val_mae: 0.5334\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3230 - mse: 0.3230 - mae: 0.4315 - val_loss: 0.4824 - val_mse: 0.4824 - val_mae: 0.5108\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.3150 - mse: 0.3150 - mae: 0.4281 - val_loss: 0.4943 - val_mse: 0.4943 - val_mae: 0.4942\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3106 - mse: 0.3106 - mae: 0.4206 - val_loss: 0.4690 - val_mse: 0.4690 - val_mae: 0.5049\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3151 - mse: 0.3151 - mae: 0.4266 - val_loss: 0.4944 - val_mse: 0.4944 - val_mae: 0.5042\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.3085 - mse: 0.3085 - mae: 0.4227 - val_loss: 0.5189 - val_mse: 0.5189 - val_mae: 0.5043\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 36us/sample - loss: 0.2984 - mse: 0.2984 - mae: 0.4166 - val_loss: 0.5599 - val_mse: 0.5599 - val_mae: 0.5104\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.2919 - mse: 0.2919 - mae: 0.4106 - val_loss: 1.0651 - val_mse: 1.0651 - val_mae: 0.5556\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.2947 - mse: 0.2947 - mae: 0.4141 - val_loss: 0.5858 - val_mse: 0.5858 - val_mae: 0.4973\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.2899 - mse: 0.2899 - mae: 0.4106 - val_loss: 1.2065 - val_mse: 1.2065 - val_mae: 0.5377\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 96us/sample - loss: 0.9050 - mse: 0.9050 - mae: 0.6868 - val_loss: 0.7940 - val_mse: 0.7940 - val_mae: 0.6838\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.5780 - mse: 0.5780 - mae: 0.5691 - val_loss: 0.6098 - val_mse: 0.6098 - val_mae: 0.5628\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.5222 - mse: 0.5222 - mae: 0.5450 - val_loss: 0.7204 - val_mse: 0.7204 - val_mae: 0.5736\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.5020 - mse: 0.5020 - mae: 0.5323 - val_loss: 0.5593 - val_mse: 0.5593 - val_mae: 0.5429\n",
      "Epoch 5/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4869 - mse: 0.4869 - mae: 0.5244 - val_loss: 0.5374 - val_mse: 0.5374 - val_mae: 0.5249\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4475 - mse: 0.4475 - mae: 0.5038 - val_loss: 0.6354 - val_mse: 0.6354 - val_mae: 0.5307\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4205 - mse: 0.4205 - mae: 0.4874 - val_loss: 0.5750 - val_mse: 0.5750 - val_mae: 0.5412\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.4213 - mse: 0.4213 - mae: 0.4874 - val_loss: 0.6521 - val_mse: 0.6521 - val_mae: 0.5594\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.4043 - mse: 0.4043 - mae: 0.4814 - val_loss: 0.7048 - val_mse: 0.7048 - val_mae: 0.5404\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3877 - mse: 0.3877 - mae: 0.4684 - val_loss: 0.5022 - val_mse: 0.5022 - val_mae: 0.5080\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3743 - mse: 0.3743 - mae: 0.4612 - val_loss: 0.6066 - val_mse: 0.6066 - val_mae: 0.5157\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.3664 - mse: 0.3664 - mae: 0.4583 - val_loss: 0.6136 - val_mse: 0.6136 - val_mae: 0.5146\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.3694 - mse: 0.3694 - mae: 0.4608 - val_loss: 0.5852 - val_mse: 0.5852 - val_mae: 0.5138\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.3603 - mse: 0.3603 - mae: 0.4552 - val_loss: 0.5980 - val_mse: 0.5980 - val_mae: 0.5190\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3658 - mse: 0.3658 - mae: 0.4593 - val_loss: 0.5469 - val_mse: 0.5469 - val_mae: 0.5071\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3529 - mse: 0.3529 - mae: 0.4475 - val_loss: 0.5398 - val_mse: 0.5398 - val_mae: 0.5046\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3400 - mse: 0.3400 - mae: 0.4430 - val_loss: 0.5401 - val_mse: 0.5401 - val_mae: 0.5113\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.3406 - mse: 0.3406 - mae: 0.4415 - val_loss: 0.5935 - val_mse: 0.5935 - val_mae: 0.5100\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3383 - mse: 0.3383 - mae: 0.4383 - val_loss: 0.5377 - val_mse: 0.5377 - val_mae: 0.5184\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3108 - mse: 0.3108 - mae: 0.4208 - val_loss: 0.5445 - val_mse: 0.5445 - val_mae: 0.5284\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.8898 - mse: 0.8898 - mae: 0.6796 - val_loss: 0.8027 - val_mse: 0.8027 - val_mae: 0.7269\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.6015 - mse: 0.6015 - mae: 0.5767 - val_loss: 0.5774 - val_mse: 0.5774 - val_mae: 0.5927\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.5321 - mse: 0.5321 - mae: 0.5447 - val_loss: 0.5779 - val_mse: 0.5779 - val_mae: 0.5726\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.5031 - mse: 0.5031 - mae: 0.5327 - val_loss: 0.5399 - val_mse: 0.5399 - val_mae: 0.5390\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4708 - mse: 0.4708 - mae: 0.5140 - val_loss: 0.5002 - val_mse: 0.5002 - val_mae: 0.5216\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4504 - mse: 0.4504 - mae: 0.5052 - val_loss: 0.5250 - val_mse: 0.5250 - val_mae: 0.5464\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4377 - mse: 0.4377 - mae: 0.4985 - val_loss: 0.5618 - val_mse: 0.5618 - val_mae: 0.5345\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4262 - mse: 0.4262 - mae: 0.4934 - val_loss: 0.5046 - val_mse: 0.5046 - val_mae: 0.5128\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4101 - mse: 0.4101 - mae: 0.4817 - val_loss: 0.5050 - val_mse: 0.5050 - val_mae: 0.5202\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3994 - mse: 0.3994 - mae: 0.4774 - val_loss: 0.5216 - val_mse: 0.5216 - val_mae: 0.5094\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3864 - mse: 0.3864 - mae: 0.4689 - val_loss: 0.4964 - val_mse: 0.4964 - val_mae: 0.5169\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3790 - mse: 0.3790 - mae: 0.4656 - val_loss: 0.5912 - val_mse: 0.5912 - val_mae: 0.5353\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.3733 - mse: 0.3733 - mae: 0.4627 - val_loss: 0.5126 - val_mse: 0.5126 - val_mae: 0.5197\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3627 - mse: 0.3627 - mae: 0.4542 - val_loss: 0.5416 - val_mse: 0.5416 - val_mae: 0.5206\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3536 - mse: 0.3536 - mae: 0.4499 - val_loss: 0.4853 - val_mse: 0.4853 - val_mae: 0.5105\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3574 - mse: 0.3574 - mae: 0.4525 - val_loss: 0.5784 - val_mse: 0.5784 - val_mae: 0.5347\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3424 - mse: 0.3424 - mae: 0.4392 - val_loss: 0.5309 - val_mse: 0.5309 - val_mae: 0.5092\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.3310 - mse: 0.3310 - mae: 0.4348 - val_loss: 0.5036 - val_mse: 0.5036 - val_mae: 0.5065\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3373 - mse: 0.3373 - mae: 0.4385 - val_loss: 0.5534 - val_mse: 0.5534 - val_mae: 0.5202\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3230 - mse: 0.3230 - mae: 0.4304 - val_loss: 0.4973 - val_mse: 0.4973 - val_mae: 0.4932\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3232 - mse: 0.3232 - mae: 0.4328 - val_loss: 0.5473 - val_mse: 0.5473 - val_mae: 0.5166\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.3082 - mse: 0.3082 - mae: 0.4191 - val_loss: 0.5216 - val_mse: 0.5216 - val_mae: 0.5003\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.3195 - mse: 0.3195 - mae: 0.4293 - val_loss: 0.5669 - val_mse: 0.5669 - val_mae: 0.5009\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3026 - mse: 0.3026 - mae: 0.4172 - val_loss: 0.5317 - val_mse: 0.5317 - val_mae: 0.5217\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.2999 - mse: 0.2999 - mae: 0.4150 - val_loss: 0.5057 - val_mse: 0.5057 - val_mae: 0.4978\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.8660 - mse: 0.8660 - mae: 0.6699 - val_loss: 0.7220 - val_mse: 0.7220 - val_mae: 0.6611\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.5773 - mse: 0.5773 - mae: 0.5694 - val_loss: 0.5862 - val_mse: 0.5862 - val_mae: 0.5871\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.5132 - mse: 0.5132 - mae: 0.5370 - val_loss: 0.6288 - val_mse: 0.6288 - val_mae: 0.5820\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4956 - mse: 0.4956 - mae: 0.5265 - val_loss: 0.5338 - val_mse: 0.5338 - val_mae: 0.5326\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.4755 - mse: 0.4755 - mae: 0.5152 - val_loss: 0.5699 - val_mse: 0.5699 - val_mae: 0.5382\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4415 - mse: 0.4415 - mae: 0.4990 - val_loss: 0.5316 - val_mse: 0.5316 - val_mae: 0.5244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.4334 - mse: 0.4334 - mae: 0.4954 - val_loss: 0.5994 - val_mse: 0.5994 - val_mae: 0.5370\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.4116 - mse: 0.4116 - mae: 0.4821 - val_loss: 0.6533 - val_mse: 0.6533 - val_mae: 0.5379\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.4102 - mse: 0.4102 - mae: 0.4800 - val_loss: 0.4958 - val_mse: 0.4958 - val_mae: 0.5001\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3937 - mse: 0.3937 - mae: 0.4728 - val_loss: 0.5723 - val_mse: 0.5723 - val_mae: 0.5191\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3825 - mse: 0.3825 - mae: 0.4650 - val_loss: 0.6323 - val_mse: 0.6323 - val_mae: 0.5378\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 33us/sample - loss: 0.3765 - mse: 0.3765 - mae: 0.4606 - val_loss: 0.5184 - val_mse: 0.5184 - val_mae: 0.5170\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.3638 - mse: 0.3638 - mae: 0.4516 - val_loss: 0.5526 - val_mse: 0.5526 - val_mae: 0.5175\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.3582 - mse: 0.3582 - mae: 0.4507 - val_loss: 0.5304 - val_mse: 0.5304 - val_mae: 0.5048\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3468 - mse: 0.3468 - mae: 0.4445 - val_loss: 0.5334 - val_mse: 0.5334 - val_mae: 0.5063\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3383 - mse: 0.3383 - mae: 0.4385 - val_loss: 0.5733 - val_mse: 0.5733 - val_mae: 0.5319\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3403 - mse: 0.3403 - mae: 0.4420 - val_loss: 0.7067 - val_mse: 0.7067 - val_mae: 0.5069\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3296 - mse: 0.3296 - mae: 0.4352 - val_loss: 0.5719 - val_mse: 0.5719 - val_mae: 0.5147\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 34us/sample - loss: 0.3306 - mse: 0.3306 - mae: 0.4371 - val_loss: 0.6216 - val_mse: 0.6216 - val_mae: 0.4941\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 98us/sample - loss: 0.8855 - mse: 0.8855 - mae: 0.6774 - val_loss: 0.6825 - val_mse: 0.6825 - val_mae: 0.6622\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.5742 - mse: 0.5742 - mae: 0.5685 - val_loss: 0.5423 - val_mse: 0.5423 - val_mae: 0.5545\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 35us/sample - loss: 0.5245 - mse: 0.5245 - mae: 0.5468 - val_loss: 0.5505 - val_mse: 0.5505 - val_mae: 0.5383\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 33us/sample - loss: 0.4933 - mse: 0.4933 - mae: 0.5280 - val_loss: 0.5800 - val_mse: 0.5800 - val_mae: 0.5424\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 36us/sample - loss: 0.4755 - mse: 0.4755 - mae: 0.5160 - val_loss: 0.4835 - val_mse: 0.4835 - val_mae: 0.5112\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 33us/sample - loss: 0.4494 - mse: 0.4494 - mae: 0.5023 - val_loss: 0.5071 - val_mse: 0.5071 - val_mae: 0.5134\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 35us/sample - loss: 0.4368 - mse: 0.4368 - mae: 0.4989 - val_loss: 0.4961 - val_mse: 0.4961 - val_mae: 0.5221\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 38us/sample - loss: 0.4163 - mse: 0.4163 - mae: 0.4870 - val_loss: 0.4845 - val_mse: 0.4845 - val_mae: 0.5082\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 36us/sample - loss: 0.4035 - mse: 0.4035 - mae: 0.4803 - val_loss: 0.4812 - val_mse: 0.4812 - val_mae: 0.5050\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 37us/sample - loss: 0.3894 - mse: 0.3894 - mae: 0.4709 - val_loss: 0.4957 - val_mse: 0.4957 - val_mae: 0.5179\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 34us/sample - loss: 0.3817 - mse: 0.3817 - mae: 0.4670 - val_loss: 0.5155 - val_mse: 0.5155 - val_mae: 0.5345\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 34us/sample - loss: 0.3795 - mse: 0.3795 - mae: 0.4629 - val_loss: 0.4588 - val_mse: 0.4588 - val_mae: 0.4995\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 34us/sample - loss: 0.3688 - mse: 0.3688 - mae: 0.4615 - val_loss: 0.4656 - val_mse: 0.4656 - val_mae: 0.4909\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 35us/sample - loss: 0.3533 - mse: 0.3533 - mae: 0.4466 - val_loss: 0.4995 - val_mse: 0.4995 - val_mae: 0.5098\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 34us/sample - loss: 0.3474 - mse: 0.3474 - mae: 0.4469 - val_loss: 0.4777 - val_mse: 0.4777 - val_mae: 0.4909\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 36us/sample - loss: 0.3517 - mse: 0.3517 - mae: 0.4484 - val_loss: 0.5251 - val_mse: 0.5251 - val_mae: 0.5228\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 34us/sample - loss: 0.3503 - mse: 0.3503 - mae: 0.4477 - val_loss: 0.4684 - val_mse: 0.4684 - val_mae: 0.4989\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 35us/sample - loss: 0.3440 - mse: 0.3440 - mae: 0.4460 - val_loss: 0.4918 - val_mse: 0.4918 - val_mae: 0.5179\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 33us/sample - loss: 0.3267 - mse: 0.3267 - mae: 0.4316 - val_loss: 0.4854 - val_mse: 0.4854 - val_mae: 0.4918\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 34us/sample - loss: 0.3136 - mse: 0.3136 - mae: 0.4246 - val_loss: 0.4563 - val_mse: 0.4563 - val_mae: 0.4864\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 34us/sample - loss: 0.3129 - mse: 0.3129 - mae: 0.4262 - val_loss: 0.4871 - val_mse: 0.4871 - val_mae: 0.4954\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 34us/sample - loss: 0.3162 - mse: 0.3162 - mae: 0.4268 - val_loss: 0.4278 - val_mse: 0.4278 - val_mae: 0.4765\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 35us/sample - loss: 0.3126 - mse: 0.3126 - mae: 0.4254 - val_loss: 0.4451 - val_mse: 0.4451 - val_mae: 0.4800\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 34us/sample - loss: 0.3207 - mse: 0.3207 - mae: 0.4332 - val_loss: 0.4710 - val_mse: 0.4710 - val_mae: 0.4890\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 35us/sample - loss: 0.3131 - mse: 0.3131 - mae: 0.4234 - val_loss: 0.5358 - val_mse: 0.5358 - val_mae: 0.5063\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 33us/sample - loss: 0.3008 - mse: 0.3008 - mae: 0.4168 - val_loss: 0.4390 - val_mse: 0.4390 - val_mae: 0.4779\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 35us/sample - loss: 0.3050 - mse: 0.3050 - mae: 0.4221 - val_loss: 0.4827 - val_mse: 0.4827 - val_mae: 0.5194\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 35us/sample - loss: 0.2978 - mse: 0.2978 - mae: 0.4139 - val_loss: 0.4465 - val_mse: 0.4465 - val_mae: 0.4813\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 34us/sample - loss: 0.2943 - mse: 0.2943 - mae: 0.4127 - val_loss: 0.4555 - val_mse: 0.4555 - val_mae: 0.4867\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 35us/sample - loss: 0.2887 - mse: 0.2887 - mae: 0.4073 - val_loss: 0.4559 - val_mse: 0.4559 - val_mae: 0.4835\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 35us/sample - loss: 0.2792 - mse: 0.2792 - mae: 0.4027 - val_loss: 0.4799 - val_mse: 0.4799 - val_mae: 0.5077\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 34us/sample - loss: 0.2876 - mse: 0.2876 - mae: 0.4089 - val_loss: 0.4505 - val_mse: 0.4505 - val_mae: 0.4815\n",
      "Avg. MAE: 0.439255\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 30s 3ms/sample - loss: 14.1154 - mse: 14.1154 - mae: 1.2901 - val_loss: 2.6789 - val_mse: 2.6789 - val_mae: 1.0880\n",
      "Epoch 2/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.7813 - mse: 0.7813 - mae: 0.6609 - val_loss: 0.6757 - val_mse: 0.6757 - val_mae: 0.6133\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6970 - mse: 0.6970 - mae: 0.6247 - val_loss: 0.7321 - val_mse: 0.7321 - val_mae: 0.6559\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.7178 - mse: 0.7178 - mae: 0.6370 - val_loss: 2.4481 - val_mse: 2.4481 - val_mae: 0.9602\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.7664 - mse: 0.7664 - mae: 0.6247 - val_loss: 0.6918 - val_mse: 0.6918 - val_mae: 0.6227\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6320 - mse: 0.6320 - mae: 0.5804 - val_loss: 0.8629 - val_mse: 0.8629 - val_mae: 0.6209\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6326 - mse: 0.6326 - mae: 0.5773 - val_loss: 0.7526 - val_mse: 0.7526 - val_mae: 0.6207\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.7126 - mse: 0.7127 - mae: 0.5986 - val_loss: 0.4969 - val_mse: 0.4969 - val_mae: 0.5430\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5969 - mse: 0.5969 - mae: 0.5677 - val_loss: 0.5680 - val_mse: 0.5680 - val_mae: 0.5870\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6548 - mse: 0.6548 - mae: 0.5852 - val_loss: 0.6763 - val_mse: 0.6763 - val_mae: 0.6438\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5941 - mse: 0.5941 - mae: 0.5462 - val_loss: 0.5504 - val_mse: 0.5504 - val_mae: 0.5455\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5090 - mse: 0.5090 - mae: 0.5238 - val_loss: 0.8632 - val_mse: 0.8632 - val_mae: 0.6569\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5049 - mse: 0.5049 - mae: 0.5220 - val_loss: 0.6993 - val_mse: 0.6993 - val_mae: 0.5802\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 30s 3ms/sample - loss: 0.6914 - mse: 0.6914 - mae: 0.5659 - val_loss: 0.6032 - val_mse: 0.6032 - val_mae: 0.5539\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6626 - mse: 0.6626 - mae: 0.5644 - val_loss: 0.9308 - val_mse: 0.9308 - val_mae: 0.6792\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5459 - mse: 0.5459 - mae: 0.5388 - val_loss: 0.7473 - val_mse: 0.7473 - val_mae: 0.6102\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5838 - mse: 0.5838 - mae: 0.5369 - val_loss: 0.5023 - val_mse: 0.5023 - val_mae: 0.5215\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4489 - mse: 0.4489 - mae: 0.4918 - val_loss: 0.5098 - val_mse: 0.5098 - val_mae: 0.5123\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 30s 3ms/sample - loss: 18.1273 - mse: 18.1273 - mae: 1.4106 - val_loss: 1.3526 - val_mse: 1.3526 - val_mae: 0.7817\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.8451 - mse: 0.8451 - mae: 0.6905 - val_loss: 0.9173 - val_mse: 0.9173 - val_mae: 0.7483\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.7527 - mse: 0.7527 - mae: 0.6524 - val_loss: 0.8468 - val_mse: 0.8468 - val_mae: 0.6550\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.7112 - mse: 0.7112 - mae: 0.6301 - val_loss: 0.8170 - val_mse: 0.8170 - val_mae: 0.6967\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.7391 - mse: 0.7391 - mae: 0.6376 - val_loss: 0.7206 - val_mse: 0.7206 - val_mae: 0.6430\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6324 - mse: 0.6324 - mae: 0.5931 - val_loss: 0.8779 - val_mse: 0.8779 - val_mae: 0.6323\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5584 - mse: 0.5584 - mae: 0.5581 - val_loss: 0.7013 - val_mse: 0.7013 - val_mae: 0.6062\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6277 - mse: 0.6277 - mae: 0.5781 - val_loss: 0.6927 - val_mse: 0.6927 - val_mae: 0.5707\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6468 - mse: 0.6468 - mae: 0.5872 - val_loss: 0.6477 - val_mse: 0.6477 - val_mae: 0.5731\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6084 - mse: 0.6084 - mae: 0.5607 - val_loss: 2.1930 - val_mse: 2.1930 - val_mae: 0.6953\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6637 - mse: 0.6637 - mae: 0.5796 - val_loss: 1.7024 - val_mse: 1.7024 - val_mae: 0.6237\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5230 - mse: 0.5230 - mae: 0.5260 - val_loss: 0.9120 - val_mse: 0.9120 - val_mae: 0.5843\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5406 - mse: 0.5406 - mae: 0.5364 - val_loss: 1.5114 - val_mse: 1.5114 - val_mae: 0.6330\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4969 - mse: 0.4969 - mae: 0.5088 - val_loss: 1.0362 - val_mse: 1.0362 - val_mae: 0.5682\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5487 - mse: 0.5487 - mae: 0.5370 - val_loss: 0.9892 - val_mse: 0.9892 - val_mae: 0.6463\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5152 - mse: 0.5152 - mae: 0.5154 - val_loss: 1.7601 - val_mse: 1.7601 - val_mae: 0.6645\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5971 - mse: 0.5971 - mae: 0.5509 - val_loss: 0.4904 - val_mse: 0.4904 - val_mae: 0.4894\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5068 - mse: 0.5068 - mae: 0.5155 - val_loss: 0.4699 - val_mse: 0.4699 - val_mae: 0.4919\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4330 - mse: 0.4330 - mae: 0.4863 - val_loss: 0.8156 - val_mse: 0.8156 - val_mae: 0.6713\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4240 - mse: 0.4240 - mae: 0.4794 - val_loss: 2.1283 - val_mse: 2.1283 - val_mae: 0.6481\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3613 - mse: 0.3613 - mae: 0.4456 - val_loss: 0.5313 - val_mse: 0.5313 - val_mae: 0.5168\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3989 - mse: 0.3989 - mae: 0.4639 - val_loss: 1.2247 - val_mse: 1.2247 - val_mae: 0.6841\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4140 - mse: 0.4140 - mae: 0.4740 - val_loss: 1.3406 - val_mse: 1.3406 - val_mae: 0.7390\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3909 - mse: 0.3909 - mae: 0.4626 - val_loss: 1.0628 - val_mse: 1.0628 - val_mae: 0.5185\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3614 - mse: 0.3614 - mae: 0.4483 - val_loss: 0.6880 - val_mse: 0.6880 - val_mae: 0.5279\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3760 - mse: 0.3760 - mae: 0.4543 - val_loss: 0.4884 - val_mse: 0.4884 - val_mae: 0.4962\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3676 - mse: 0.3676 - mae: 0.4524 - val_loss: 0.4893 - val_mse: 0.4893 - val_mae: 0.4869\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3510 - mse: 0.3510 - mae: 0.4413 - val_loss: 0.9396 - val_mse: 0.9396 - val_mae: 0.4998\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 30s 3ms/sample - loss: 19.5215 - mse: 19.5215 - mae: 1.4185 - val_loss: 2.6661 - val_mse: 2.6661 - val_mae: 0.9343\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.7753 - mse: 0.7753 - mae: 0.6604 - val_loss: 0.7296 - val_mse: 0.7296 - val_mae: 0.6698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.7044 - mse: 0.7044 - mae: 0.6276 - val_loss: 0.6529 - val_mse: 0.6529 - val_mae: 0.6128\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.7509 - mse: 0.7509 - mae: 0.6389 - val_loss: 1.1090 - val_mse: 1.1090 - val_mae: 0.7030\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6796 - mse: 0.6796 - mae: 0.6119 - val_loss: 0.8117 - val_mse: 0.8117 - val_mae: 0.6224\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6182 - mse: 0.6182 - mae: 0.5859 - val_loss: 1.6619 - val_mse: 1.6619 - val_mae: 0.6717\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5869 - mse: 0.5869 - mae: 0.5614 - val_loss: 0.6807 - val_mse: 0.6807 - val_mae: 0.5557\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5725 - mse: 0.5725 - mae: 0.5568 - val_loss: 0.7532 - val_mse: 0.7532 - val_mae: 0.5653\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6816 - mse: 0.6816 - mae: 0.5857 - val_loss: 0.6856 - val_mse: 0.6856 - val_mae: 0.5699\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6623 - mse: 0.6623 - mae: 0.5869 - val_loss: 1.0106 - val_mse: 1.0106 - val_mae: 0.6104\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6014 - mse: 0.6014 - mae: 0.5576 - val_loss: 0.6611 - val_mse: 0.6611 - val_mae: 0.5599\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5398 - mse: 0.5398 - mae: 0.5358 - val_loss: 0.5814 - val_mse: 0.5814 - val_mae: 0.5583\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5551 - mse: 0.5551 - mae: 0.5323 - val_loss: 0.9061 - val_mse: 0.9061 - val_mae: 0.6792\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5091 - mse: 0.5091 - mae: 0.5229 - val_loss: 1.0494 - val_mse: 1.0494 - val_mae: 0.5817\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5466 - mse: 0.5466 - mae: 0.5262 - val_loss: 1.0629 - val_mse: 1.0629 - val_mae: 0.6318\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5673 - mse: 0.5673 - mae: 0.5327 - val_loss: 0.6553 - val_mse: 0.6553 - val_mae: 0.5671\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4829 - mse: 0.4829 - mae: 0.5102 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.4999\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4537 - mse: 0.4537 - mae: 0.4912 - val_loss: 0.4729 - val_mse: 0.4729 - val_mae: 0.4933\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4238 - mse: 0.4238 - mae: 0.4765 - val_loss: 0.5069 - val_mse: 0.5069 - val_mae: 0.5054\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3953 - mse: 0.3953 - mae: 0.4652 - val_loss: 0.8380 - val_mse: 0.8380 - val_mae: 0.5558\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4219 - mse: 0.4219 - mae: 0.4825 - val_loss: 0.5922 - val_mse: 0.5922 - val_mae: 0.4942\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5476 - mse: 0.5476 - mae: 0.5395 - val_loss: 0.5262 - val_mse: 0.5262 - val_mae: 0.5177\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4279 - mse: 0.4279 - mae: 0.4839 - val_loss: 0.5739 - val_mse: 0.5739 - val_mae: 0.5470\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3976 - mse: 0.3976 - mae: 0.4685 - val_loss: 0.5839 - val_mse: 0.5839 - val_mae: 0.5592\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3707 - mse: 0.3707 - mae: 0.4523 - val_loss: 0.6363 - val_mse: 0.6363 - val_mae: 0.6064\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 28s 3ms/sample - loss: 0.3836 - mse: 0.3836 - mae: 0.4628 - val_loss: 0.4981 - val_mse: 0.4981 - val_mae: 0.4991\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3582 - mse: 0.3582 - mae: 0.4488 - val_loss: 0.5164 - val_mse: 0.5164 - val_mae: 0.4763\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 31s 3ms/sample - loss: 17.0954 - mse: 17.0954 - mae: 1.3682 - val_loss: 1.2639 - val_mse: 1.2639 - val_mae: 0.9132\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.7778 - mse: 0.7778 - mae: 0.6588 - val_loss: 0.7608 - val_mse: 0.7608 - val_mae: 0.6723\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.7117 - mse: 0.7117 - mae: 0.6388 - val_loss: 0.7500 - val_mse: 0.7500 - val_mae: 0.6599\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6891 - mse: 0.6891 - mae: 0.6223 - val_loss: 0.9293 - val_mse: 0.9293 - val_mae: 0.7133\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6796 - mse: 0.6796 - mae: 0.6178 - val_loss: 0.7703 - val_mse: 0.7703 - val_mae: 0.6164\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6908 - mse: 0.6908 - mae: 0.6200 - val_loss: 1.1241 - val_mse: 1.1241 - val_mae: 0.7408\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6053 - mse: 0.6053 - mae: 0.5812 - val_loss: 0.8461 - val_mse: 0.8461 - val_mae: 0.6555\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6558 - mse: 0.6558 - mae: 0.6039 - val_loss: 0.8029 - val_mse: 0.8029 - val_mae: 0.6855\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5745 - mse: 0.5745 - mae: 0.5606 - val_loss: 0.6824 - val_mse: 0.6824 - val_mae: 0.5901\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6042 - mse: 0.6042 - mae: 0.5794 - val_loss: 0.7061 - val_mse: 0.7061 - val_mae: 0.5981\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6105 - mse: 0.6105 - mae: 0.5782 - val_loss: 0.7826 - val_mse: 0.7826 - val_mae: 0.5508\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5810 - mse: 0.5810 - mae: 0.5653 - val_loss: 0.9224 - val_mse: 0.9224 - val_mae: 0.6007\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5020 - mse: 0.5020 - mae: 0.5301 - val_loss: 1.1964 - val_mse: 1.1964 - val_mae: 0.6754\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.6030 - mse: 0.6030 - mae: 0.5667 - val_loss: 0.6256 - val_mse: 0.6256 - val_mae: 0.5738\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5030 - mse: 0.5030 - mae: 0.5222 - val_loss: 0.5123 - val_mse: 0.5123 - val_mae: 0.5188\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5089 - mse: 0.5089 - mae: 0.5293 - val_loss: 0.8804 - val_mse: 0.8804 - val_mae: 0.7337\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5360 - mse: 0.5360 - mae: 0.5436 - val_loss: 0.6235 - val_mse: 0.6235 - val_mae: 0.5469\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4159 - mse: 0.4159 - mae: 0.4771 - val_loss: 0.6933 - val_mse: 0.6933 - val_mae: 0.5535\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4829 - mse: 0.4829 - mae: 0.5071 - val_loss: 1.7897 - val_mse: 1.7897 - val_mae: 0.6710\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4585 - mse: 0.4585 - mae: 0.5053 - val_loss: 1.4581 - val_mse: 1.4581 - val_mae: 0.5913\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.5158 - mse: 0.5158 - mae: 0.5290 - val_loss: 0.5096 - val_mse: 0.5096 - val_mae: 0.5145\n",
      "Epoch 22/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4525 - mse: 0.4525 - mae: 0.4923 - val_loss: 0.6056 - val_mse: 0.6056 - val_mae: 0.5500\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4259 - mse: 0.4259 - mae: 0.4856 - val_loss: 1.1409 - val_mse: 1.1409 - val_mae: 0.6591\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.4108 - mse: 0.4108 - mae: 0.4723 - val_loss: 0.6221 - val_mse: 0.6221 - val_mae: 0.4906\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3472 - mse: 0.3472 - mae: 0.4398 - val_loss: 0.8787 - val_mse: 0.8787 - val_mae: 0.5680\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3618 - mse: 0.3618 - mae: 0.4465 - val_loss: 0.5186 - val_mse: 0.5186 - val_mae: 0.4822\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 30s 3ms/sample - loss: 0.3339 - mse: 0.3339 - mae: 0.4363 - val_loss: 0.5602 - val_mse: 0.5602 - val_mae: 0.5243\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.3363 - mse: 0.3363 - mae: 0.4320 - val_loss: 0.6363 - val_mse: 0.6363 - val_mae: 0.5151\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 30s 3ms/sample - loss: 0.3951 - mse: 0.3951 - mae: 0.4678 - val_loss: 0.4936 - val_mse: 0.4936 - val_mae: 0.5298\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 30s 3ms/sample - loss: 0.3181 - mse: 0.3181 - mae: 0.4229 - val_loss: 0.5569 - val_mse: 0.5569 - val_mae: 0.5662\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 30s 3ms/sample - loss: 0.2805 - mse: 0.2805 - mae: 0.3989 - val_loss: 0.4309 - val_mse: 0.4309 - val_mae: 0.4655\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 30s 3ms/sample - loss: 0.3043 - mse: 0.3043 - mae: 0.4160 - val_loss: 0.4940 - val_mse: 0.4940 - val_mae: 0.4875\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 30s 3ms/sample - loss: 0.3097 - mse: 0.3097 - mae: 0.4203 - val_loss: 0.5626 - val_mse: 0.5626 - val_mae: 0.5053\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 30s 3ms/sample - loss: 0.2676 - mse: 0.2676 - mae: 0.3854 - val_loss: 0.6155 - val_mse: 0.6155 - val_mae: 0.5264\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.2734 - mse: 0.2734 - mae: 0.3904 - val_loss: 0.6165 - val_mse: 0.6165 - val_mae: 0.5070\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.2675 - mse: 0.2675 - mae: 0.3919 - val_loss: 0.5850 - val_mse: 0.5850 - val_mae: 0.4979\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.2358 - mse: 0.2358 - mae: 0.3654 - val_loss: 0.5065 - val_mse: 0.5065 - val_mae: 0.4808\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.2241 - mse: 0.2241 - mae: 0.3563 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4786\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.2287 - mse: 0.2287 - mae: 0.3626 - val_loss: 0.5034 - val_mse: 0.5034 - val_mae: 0.4593\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.2277 - mse: 0.2277 - mae: 0.3590 - val_loss: 0.4547 - val_mse: 0.4547 - val_mae: 0.4564\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 29s 3ms/sample - loss: 0.2196 - mse: 0.2196 - mae: 0.3507 - val_loss: 0.5327 - val_mse: 0.5327 - val_mae: 0.4905\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 30s 3ms/sample - loss: 19.7446 - mse: 19.7446 - mae: 1.5073 - val_loss: 0.7753 - val_mse: 0.7753 - val_mae: 0.6598\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.8446 - mse: 0.8446 - mae: 0.6874 - val_loss: 0.6924 - val_mse: 0.6924 - val_mae: 0.6166\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.7991 - mse: 0.7991 - mae: 0.6657 - val_loss: 0.7000 - val_mse: 0.7000 - val_mae: 0.6256\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.6792 - mse: 0.6792 - mae: 0.6121 - val_loss: 0.6581 - val_mse: 0.6581 - val_mae: 0.6026\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.7282 - mse: 0.7282 - mae: 0.6244 - val_loss: 0.5931 - val_mse: 0.5931 - val_mae: 0.5689\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.5830 - mse: 0.5830 - mae: 0.5695 - val_loss: 0.6353 - val_mse: 0.6353 - val_mae: 0.5703\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.5934 - mse: 0.5934 - mae: 0.5750 - val_loss: 0.5032 - val_mse: 0.5032 - val_mae: 0.5108\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.6404 - mse: 0.6404 - mae: 0.5762 - val_loss: 0.7100 - val_mse: 0.7100 - val_mae: 0.5806\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.5780 - mse: 0.5780 - mae: 0.5523 - val_loss: 0.6144 - val_mse: 0.6144 - val_mae: 0.5635\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.5324 - mse: 0.5324 - mae: 0.5351 - val_loss: 0.5439 - val_mse: 0.5439 - val_mae: 0.5548\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.5950 - mse: 0.5950 - mae: 0.5537 - val_loss: 0.4769 - val_mse: 0.4769 - val_mae: 0.5242\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.5883 - mse: 0.5883 - mae: 0.5478 - val_loss: 0.5724 - val_mse: 0.5724 - val_mae: 0.5431\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.5560 - mse: 0.5560 - mae: 0.5353 - val_loss: 0.5138 - val_mse: 0.5138 - val_mae: 0.5084\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.6314 - mse: 0.6314 - mae: 0.5570 - val_loss: 0.5733 - val_mse: 0.5733 - val_mae: 0.5358\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.4679 - mse: 0.4679 - mae: 0.4920 - val_loss: 0.7980 - val_mse: 0.7980 - val_mae: 0.5866\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.4831 - mse: 0.4831 - mae: 0.5036 - val_loss: 0.5148 - val_mse: 0.5148 - val_mae: 0.5377\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.4794 - mse: 0.4794 - mae: 0.5141 - val_loss: 0.7642 - val_mse: 0.7642 - val_mae: 0.6814\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.4562 - mse: 0.4562 - mae: 0.4953 - val_loss: 0.5784 - val_mse: 0.5784 - val_mae: 0.5326\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.3999 - mse: 0.3999 - mae: 0.4621 - val_loss: 0.5914 - val_mse: 0.5914 - val_mae: 0.5705\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.5030 - mse: 0.5030 - mae: 0.4962 - val_loss: 0.7002 - val_mse: 0.7002 - val_mae: 0.5950\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 29s 3ms/sample - loss: 0.4399 - mse: 0.4399 - mae: 0.4823 - val_loss: 0.4873 - val_mse: 0.4873 - val_mae: 0.4950\n",
      "Avg. MAE: 0.445043\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 4s 348us/sample - loss: 21.3208 - mse: 21.3208 - mae: 2.5706 - val_loss: 6.3209 - val_mse: 6.3209 - val_mae: 1.9808\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.9084 - mse: 0.9084 - mae: 0.7136 - val_loss: 1.0187 - val_mse: 1.0187 - val_mae: 0.7896\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.6163 - mse: 0.6163 - mae: 0.5871 - val_loss: 1.0438 - val_mse: 1.0438 - val_mae: 0.8254\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.5570 - mse: 0.5570 - mae: 0.5564 - val_loss: 0.9169 - val_mse: 0.9169 - val_mae: 0.7729\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.5213 - mse: 0.5213 - mae: 0.5357 - val_loss: 0.8389 - val_mse: 0.8389 - val_mae: 0.7084\n",
      "Epoch 6/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.4886 - mse: 0.4886 - mae: 0.5199 - val_loss: 0.8103 - val_mse: 0.8103 - val_mae: 0.7165\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.4618 - mse: 0.4618 - mae: 0.5057 - val_loss: 0.7751 - val_mse: 0.7751 - val_mae: 0.7037\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.4361 - mse: 0.4361 - mae: 0.4901 - val_loss: 0.6997 - val_mse: 0.6997 - val_mae: 0.6624\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.4067 - mse: 0.4067 - mae: 0.4735 - val_loss: 0.6578 - val_mse: 0.6578 - val_mae: 0.6507\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.3838 - mse: 0.3838 - mae: 0.4603 - val_loss: 0.5935 - val_mse: 0.5935 - val_mae: 0.6104\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.3581 - mse: 0.3581 - mae: 0.4435 - val_loss: 0.5887 - val_mse: 0.5887 - val_mae: 0.6140\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 3s 238us/sample - loss: 0.3532 - mse: 0.3532 - mae: 0.4422 - val_loss: 0.5372 - val_mse: 0.5372 - val_mae: 0.5743\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.3181 - mse: 0.3181 - mae: 0.4219 - val_loss: 0.4894 - val_mse: 0.4894 - val_mae: 0.5474\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.2942 - mse: 0.2942 - mae: 0.4034 - val_loss: 0.4889 - val_mse: 0.4889 - val_mae: 0.5424\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.2799 - mse: 0.2799 - mae: 0.3955 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.5100\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.2636 - mse: 0.2636 - mae: 0.3819 - val_loss: 0.4284 - val_mse: 0.4284 - val_mae: 0.4996\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 3s 246us/sample - loss: 0.2441 - mse: 0.2441 - mae: 0.3707 - val_loss: 0.4414 - val_mse: 0.4414 - val_mae: 0.5103\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.2290 - mse: 0.2290 - mae: 0.3582 - val_loss: 0.4180 - val_mse: 0.4180 - val_mae: 0.4820\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.2362 - mse: 0.2362 - mae: 0.3643 - val_loss: 0.4419 - val_mse: 0.4419 - val_mae: 0.5086\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.2137 - mse: 0.2137 - mae: 0.3471 - val_loss: 0.4395 - val_mse: 0.4395 - val_mae: 0.4997\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.2038 - mse: 0.2038 - mae: 0.3395 - val_loss: 0.4346 - val_mse: 0.4346 - val_mae: 0.4950\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1915 - mse: 0.1915 - mae: 0.3272 - val_loss: 0.4048 - val_mse: 0.4048 - val_mae: 0.4722\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 3s 249us/sample - loss: 0.1798 - mse: 0.1798 - mae: 0.3173 - val_loss: 0.3941 - val_mse: 0.3941 - val_mae: 0.4602\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1683 - mse: 0.1683 - mae: 0.3087 - val_loss: 0.4102 - val_mse: 0.4102 - val_mae: 0.4870\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1636 - mse: 0.1636 - mae: 0.3023 - val_loss: 0.3994 - val_mse: 0.3994 - val_mae: 0.4748\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1571 - mse: 0.1571 - mae: 0.2972 - val_loss: 0.4072 - val_mse: 0.4072 - val_mae: 0.4722\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1487 - mse: 0.1487 - mae: 0.2884 - val_loss: 0.3850 - val_mse: 0.3850 - val_mae: 0.4630\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1401 - mse: 0.1401 - mae: 0.2823 - val_loss: 0.3969 - val_mse: 0.3969 - val_mae: 0.4594\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1319 - mse: 0.1319 - mae: 0.2724 - val_loss: 0.3817 - val_mse: 0.3817 - val_mae: 0.4550\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1412 - mse: 0.1412 - mae: 0.2809 - val_loss: 0.4868 - val_mse: 0.4868 - val_mae: 0.4888\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1303 - mse: 0.1303 - mae: 0.2717 - val_loss: 0.3973 - val_mse: 0.3973 - val_mae: 0.4567\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1300 - mse: 0.1300 - mae: 0.2712 - val_loss: 0.4209 - val_mse: 0.4209 - val_mae: 0.4795\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1241 - mse: 0.1241 - mae: 0.2632 - val_loss: 0.4385 - val_mse: 0.4385 - val_mae: 0.4826\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1264 - mse: 0.1264 - mae: 0.2640 - val_loss: 0.3813 - val_mse: 0.3813 - val_mae: 0.4455\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 3s 247us/sample - loss: 0.1078 - mse: 0.1078 - mae: 0.2463 - val_loss: 0.3738 - val_mse: 0.3738 - val_mae: 0.4443\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 3s 246us/sample - loss: 0.1082 - mse: 0.1082 - mae: 0.2471 - val_loss: 0.3838 - val_mse: 0.3838 - val_mae: 0.4559\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1107 - mse: 0.1107 - mae: 0.2496 - val_loss: 0.3788 - val_mse: 0.3788 - val_mae: 0.4484\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1098 - mse: 0.1098 - mae: 0.2464 - val_loss: 0.4130 - val_mse: 0.4130 - val_mae: 0.4662\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1109 - mse: 0.1109 - mae: 0.2494 - val_loss: 0.4021 - val_mse: 0.4021 - val_mae: 0.4672\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1020 - mse: 0.1020 - mae: 0.2409 - val_loss: 0.5196 - val_mse: 0.5196 - val_mae: 0.5215\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1318 - mse: 0.1318 - mae: 0.2718 - val_loss: 0.4063 - val_mse: 0.4063 - val_mae: 0.4691\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.0986 - mse: 0.0986 - mae: 0.2368 - val_loss: 0.3717 - val_mse: 0.3717 - val_mae: 0.4454\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0986 - mse: 0.0986 - mae: 0.2344 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4792\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0960 - mse: 0.0960 - mae: 0.2324 - val_loss: 0.3908 - val_mse: 0.3908 - val_mae: 0.4466\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.0856 - mse: 0.0856 - mae: 0.2186 - val_loss: 0.3781 - val_mse: 0.3781 - val_mae: 0.4417\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0896 - mse: 0.0896 - mae: 0.2243 - val_loss: 0.3809 - val_mse: 0.3809 - val_mae: 0.4453\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 3s 246us/sample - loss: 0.0993 - mse: 0.0993 - mae: 0.2379 - val_loss: 0.3833 - val_mse: 0.3833 - val_mae: 0.4532\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.0844 - mse: 0.0844 - mae: 0.2181 - val_loss: 0.3851 - val_mse: 0.3851 - val_mae: 0.4529\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2240 - val_loss: 0.4209 - val_mse: 0.4209 - val_mae: 0.4625\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0860 - mse: 0.0860 - mae: 0.2200 - val_loss: 0.4105 - val_mse: 0.4105 - val_mae: 0.4661\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 3s 254us/sample - loss: 0.0834 - mse: 0.0834 - mae: 0.2177 - val_loss: 0.4048 - val_mse: 0.4048 - val_mae: 0.4640\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 3s 265us/sample - loss: 0.0884 - mse: 0.0884 - mae: 0.2236 - val_loss: 0.4212 - val_mse: 0.4212 - val_mae: 0.4711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 4s 345us/sample - loss: 21.3937 - mse: 21.3937 - mae: 2.4678 - val_loss: 23.5822 - val_mse: 23.5822 - val_mae: 4.2492\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.9243 - mse: 0.9243 - mae: 0.7177 - val_loss: 5.5110 - val_mse: 5.5110 - val_mae: 2.0983\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.6001 - mse: 0.6001 - mae: 0.5794 - val_loss: 1.4251 - val_mse: 1.4251 - val_mae: 0.8950\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.5122 - mse: 0.5122 - mae: 0.5328 - val_loss: 1.5373 - val_mse: 1.5373 - val_mae: 0.9368\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.4772 - mse: 0.4772 - mae: 0.5151 - val_loss: 1.1043 - val_mse: 1.1043 - val_mae: 0.7556\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.4442 - mse: 0.4442 - mae: 0.4995 - val_loss: 1.1122 - val_mse: 1.1122 - val_mae: 0.7585\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 3s 238us/sample - loss: 0.4097 - mse: 0.4097 - mae: 0.4768 - val_loss: 1.0428 - val_mse: 1.0428 - val_mae: 0.7505\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.3887 - mse: 0.3887 - mae: 0.4657 - val_loss: 0.9055 - val_mse: 0.9055 - val_mae: 0.6947\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.3581 - mse: 0.3581 - mae: 0.4459 - val_loss: 0.7543 - val_mse: 0.7543 - val_mae: 0.6354\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.3309 - mse: 0.3309 - mae: 0.4294 - val_loss: 0.7595 - val_mse: 0.7595 - val_mae: 0.6456\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 3s 245us/sample - loss: 0.3088 - mse: 0.3088 - mae: 0.4143 - val_loss: 0.7089 - val_mse: 0.7089 - val_mae: 0.6226\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.2909 - mse: 0.2909 - mae: 0.4043 - val_loss: 0.6066 - val_mse: 0.6066 - val_mae: 0.5751\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.2748 - mse: 0.2748 - mae: 0.3924 - val_loss: 0.5658 - val_mse: 0.5658 - val_mae: 0.5487\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 3s 238us/sample - loss: 0.2620 - mse: 0.2620 - mae: 0.3840 - val_loss: 0.6416 - val_mse: 0.6416 - val_mae: 0.5963\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.2447 - mse: 0.2447 - mae: 0.3722 - val_loss: 0.5577 - val_mse: 0.5577 - val_mae: 0.5452\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.2279 - mse: 0.2279 - mae: 0.3565 - val_loss: 0.5248 - val_mse: 0.5248 - val_mae: 0.5320\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.2232 - mse: 0.2232 - mae: 0.3541 - val_loss: 0.4754 - val_mse: 0.4754 - val_mae: 0.4975\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 3s 245us/sample - loss: 0.2140 - mse: 0.2140 - mae: 0.3460 - val_loss: 0.4704 - val_mse: 0.4704 - val_mae: 0.4950\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.2032 - mse: 0.2032 - mae: 0.3363 - val_loss: 0.4763 - val_mse: 0.4763 - val_mae: 0.5071\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1871 - mse: 0.1871 - mae: 0.3253 - val_loss: 0.4492 - val_mse: 0.4492 - val_mae: 0.4903\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1790 - mse: 0.1790 - mae: 0.3182 - val_loss: 0.4245 - val_mse: 0.4245 - val_mae: 0.4665\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1613 - mse: 0.1613 - mae: 0.2992 - val_loss: 0.4282 - val_mse: 0.4282 - val_mae: 0.4714\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1580 - mse: 0.1580 - mae: 0.2987 - val_loss: 0.4435 - val_mse: 0.4435 - val_mae: 0.4794\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1498 - mse: 0.1498 - mae: 0.2917 - val_loss: 0.4515 - val_mse: 0.4515 - val_mae: 0.4885\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1432 - mse: 0.1432 - mae: 0.2848 - val_loss: 0.4390 - val_mse: 0.4390 - val_mae: 0.4707\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1490 - mse: 0.1490 - mae: 0.2921 - val_loss: 0.4159 - val_mse: 0.4159 - val_mae: 0.4583\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1406 - mse: 0.1406 - mae: 0.2830 - val_loss: 0.4156 - val_mse: 0.4156 - val_mae: 0.4615\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1321 - mse: 0.1321 - mae: 0.2720 - val_loss: 0.4288 - val_mse: 0.4288 - val_mae: 0.4610\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1309 - mse: 0.1309 - mae: 0.2742 - val_loss: 0.4142 - val_mse: 0.4142 - val_mae: 0.4565\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1258 - mse: 0.1258 - mae: 0.2680 - val_loss: 0.4184 - val_mse: 0.4184 - val_mae: 0.4577\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1222 - mse: 0.1222 - mae: 0.2627 - val_loss: 0.4384 - val_mse: 0.4384 - val_mae: 0.4621\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1244 - mse: 0.1244 - mae: 0.2639 - val_loss: 0.4170 - val_mse: 0.4170 - val_mae: 0.4555\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1164 - mse: 0.1164 - mae: 0.2583 - val_loss: 0.4758 - val_mse: 0.4758 - val_mae: 0.5009\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1164 - mse: 0.1164 - mae: 0.2584 - val_loss: 0.4114 - val_mse: 0.4114 - val_mae: 0.4541\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1124 - mse: 0.1124 - mae: 0.2502 - val_loss: 0.4081 - val_mse: 0.4081 - val_mae: 0.4471\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1355 - mse: 0.1355 - mae: 0.2809 - val_loss: 0.4093 - val_mse: 0.4093 - val_mae: 0.4492\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1078 - mse: 0.1078 - mae: 0.2442 - val_loss: 0.4252 - val_mse: 0.4252 - val_mae: 0.4530\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0982 - mse: 0.0982 - mae: 0.2329 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4484\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1002 - mse: 0.1002 - mae: 0.2344 - val_loss: 0.4378 - val_mse: 0.4378 - val_mae: 0.4699\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1024 - mse: 0.1024 - mae: 0.2379 - val_loss: 0.4218 - val_mse: 0.4218 - val_mae: 0.4576\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.0982 - mse: 0.0982 - mae: 0.2381 - val_loss: 0.4054 - val_mse: 0.4054 - val_mae: 0.4419\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.0987 - mse: 0.0987 - mae: 0.2377 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4645\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0878 - mse: 0.0878 - mae: 0.2196 - val_loss: 0.4375 - val_mse: 0.4375 - val_mae: 0.4669\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0823 - mse: 0.0823 - mae: 0.2165 - val_loss: 0.4301 - val_mse: 0.4301 - val_mae: 0.4556\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0937 - mse: 0.0937 - mae: 0.2280 - val_loss: 0.4246 - val_mse: 0.4246 - val_mae: 0.4566\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 3s 237us/sample - loss: 0.0940 - mse: 0.0940 - mae: 0.2307 - val_loss: 0.4161 - val_mse: 0.4161 - val_mae: 0.4510\n",
      "Epoch 47/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0759 - mse: 0.0759 - mae: 0.2069 - val_loss: 0.4114 - val_mse: 0.4114 - val_mae: 0.4476\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0805 - mse: 0.0805 - mae: 0.2124 - val_loss: 0.4105 - val_mse: 0.4105 - val_mae: 0.4456\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.0884 - mse: 0.0884 - mae: 0.2225 - val_loss: 0.3975 - val_mse: 0.3975 - val_mae: 0.4433\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.0923 - mse: 0.0923 - mae: 0.2269 - val_loss: 0.4368 - val_mse: 0.4368 - val_mae: 0.4556\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.0878 - mse: 0.0878 - mae: 0.2225 - val_loss: 0.4342 - val_mse: 0.4342 - val_mae: 0.4524\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.0778 - mse: 0.0778 - mae: 0.2094 - val_loss: 0.4086 - val_mse: 0.4086 - val_mae: 0.4459\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0722 - mse: 0.0722 - mae: 0.1998 - val_loss: 0.4219 - val_mse: 0.4219 - val_mae: 0.4506\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 3s 237us/sample - loss: 0.0847 - mse: 0.0847 - mae: 0.2183 - val_loss: 0.4340 - val_mse: 0.4340 - val_mae: 0.4520\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0829 - mse: 0.0829 - mae: 0.2143 - val_loss: 0.4122 - val_mse: 0.4122 - val_mae: 0.4452\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0763 - mse: 0.0763 - mae: 0.2056 - val_loss: 0.4180 - val_mse: 0.4180 - val_mae: 0.4422\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.0709 - mse: 0.0709 - mae: 0.1995 - val_loss: 0.4396 - val_mse: 0.4396 - val_mae: 0.4714\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.0793 - mse: 0.0793 - mae: 0.2054 - val_loss: 0.4127 - val_mse: 0.4127 - val_mae: 0.4438\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.0739 - mse: 0.0739 - mae: 0.2007 - val_loss: 0.4219 - val_mse: 0.4219 - val_mae: 0.4577\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 4s 344us/sample - loss: 20.7552 - mse: 20.7552 - mae: 2.5586 - val_loss: 13.6320 - val_mse: 13.6320 - val_mae: 2.9453\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.9526 - mse: 0.9526 - mae: 0.7245 - val_loss: 2.1527 - val_mse: 2.1527 - val_mae: 1.0803\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.6019 - mse: 0.6019 - mae: 0.5798 - val_loss: 1.4758 - val_mse: 1.4758 - val_mae: 0.9436\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.5363 - mse: 0.5363 - mae: 0.5452 - val_loss: 0.8931 - val_mse: 0.8931 - val_mae: 0.6920\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.4993 - mse: 0.4993 - mae: 0.5251 - val_loss: 0.7896 - val_mse: 0.7896 - val_mae: 0.6840\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.4622 - mse: 0.4622 - mae: 0.5063 - val_loss: 0.7864 - val_mse: 0.7864 - val_mae: 0.6829\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.4325 - mse: 0.4325 - mae: 0.4900 - val_loss: 0.7482 - val_mse: 0.7482 - val_mae: 0.6705\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.4080 - mse: 0.4080 - mae: 0.4759 - val_loss: 0.6781 - val_mse: 0.6781 - val_mae: 0.6360\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.3789 - mse: 0.3789 - mae: 0.4575 - val_loss: 0.6557 - val_mse: 0.6557 - val_mae: 0.6319\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.3583 - mse: 0.3583 - mae: 0.4461 - val_loss: 0.5743 - val_mse: 0.5743 - val_mae: 0.5907\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 3s 238us/sample - loss: 0.3346 - mse: 0.3346 - mae: 0.4309 - val_loss: 0.5794 - val_mse: 0.5794 - val_mae: 0.5895\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.3205 - mse: 0.3205 - mae: 0.4224 - val_loss: 0.5288 - val_mse: 0.5288 - val_mae: 0.5515\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.2919 - mse: 0.2919 - mae: 0.4019 - val_loss: 0.5063 - val_mse: 0.5063 - val_mae: 0.5431\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 3s 238us/sample - loss: 0.2830 - mse: 0.2830 - mae: 0.3966 - val_loss: 0.5093 - val_mse: 0.5093 - val_mae: 0.5332\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.2648 - mse: 0.2648 - mae: 0.3870 - val_loss: 0.4646 - val_mse: 0.4646 - val_mae: 0.5099\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.2640 - mse: 0.2640 - mae: 0.3865 - val_loss: 0.5252 - val_mse: 0.5252 - val_mae: 0.5510\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.2540 - mse: 0.2540 - mae: 0.3788 - val_loss: 0.4318 - val_mse: 0.4318 - val_mae: 0.4846\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.2205 - mse: 0.2205 - mae: 0.3527 - val_loss: 0.4708 - val_mse: 0.4708 - val_mae: 0.5086\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.2140 - mse: 0.2140 - mae: 0.3460 - val_loss: 0.4249 - val_mse: 0.4249 - val_mae: 0.4797\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1986 - mse: 0.1986 - mae: 0.3324 - val_loss: 0.4871 - val_mse: 0.4871 - val_mae: 0.5182\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.1955 - mse: 0.1955 - mae: 0.3326 - val_loss: 0.4246 - val_mse: 0.4246 - val_mae: 0.4719\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1816 - mse: 0.1816 - mae: 0.3200 - val_loss: 0.4297 - val_mse: 0.4297 - val_mae: 0.4790\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1742 - mse: 0.1742 - mae: 0.3128 - val_loss: 0.4258 - val_mse: 0.4258 - val_mae: 0.4718\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1872 - mse: 0.1872 - mae: 0.3271 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4628\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1668 - mse: 0.1668 - mae: 0.3092 - val_loss: 0.4044 - val_mse: 0.4044 - val_mae: 0.4621\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 3s 244us/sample - loss: 0.1491 - mse: 0.1491 - mae: 0.2918 - val_loss: 0.4183 - val_mse: 0.4183 - val_mae: 0.4639\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1390 - mse: 0.1390 - mae: 0.2819 - val_loss: 0.4120 - val_mse: 0.4120 - val_mae: 0.4546\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 3s 238us/sample - loss: 0.1383 - mse: 0.1383 - mae: 0.2793 - val_loss: 0.4399 - val_mse: 0.4399 - val_mae: 0.4702\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 3s 245us/sample - loss: 0.1324 - mse: 0.1324 - mae: 0.2731 - val_loss: 0.3983 - val_mse: 0.3983 - val_mae: 0.4522\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1361 - mse: 0.1361 - mae: 0.2786 - val_loss: 0.4203 - val_mse: 0.4203 - val_mae: 0.4601\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1309 - mse: 0.1309 - mae: 0.2728 - val_loss: 0.4250 - val_mse: 0.4250 - val_mae: 0.4700\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1351 - mse: 0.1351 - mae: 0.2760 - val_loss: 0.3929 - val_mse: 0.3929 - val_mae: 0.4451\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1220 - mse: 0.1220 - mae: 0.2616 - val_loss: 0.3890 - val_mse: 0.3890 - val_mae: 0.4387\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1104 - mse: 0.1104 - mae: 0.2500 - val_loss: 0.4490 - val_mse: 0.4490 - val_mae: 0.4817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1185 - mse: 0.1185 - mae: 0.2614 - val_loss: 0.3940 - val_mse: 0.3940 - val_mae: 0.4468\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1144 - mse: 0.1144 - mae: 0.2559 - val_loss: 0.3867 - val_mse: 0.3867 - val_mae: 0.4396\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1147 - mse: 0.1147 - mae: 0.2580 - val_loss: 0.4026 - val_mse: 0.4026 - val_mae: 0.4549\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 3s 238us/sample - loss: 0.1061 - mse: 0.1061 - mae: 0.2442 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4564\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1174 - mse: 0.1174 - mae: 0.2572 - val_loss: 0.4101 - val_mse: 0.4101 - val_mae: 0.4569\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 3s 238us/sample - loss: 0.1003 - mse: 0.1003 - mae: 0.2385 - val_loss: 0.4151 - val_mse: 0.4151 - val_mae: 0.4607\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1023 - mse: 0.1023 - mae: 0.2429 - val_loss: 0.4057 - val_mse: 0.4057 - val_mae: 0.4506\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1087 - mse: 0.1087 - mae: 0.2483 - val_loss: 0.3815 - val_mse: 0.3815 - val_mae: 0.4364\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.0882 - mse: 0.0882 - mae: 0.2233 - val_loss: 0.4176 - val_mse: 0.4176 - val_mae: 0.4627\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0879 - mse: 0.0879 - mae: 0.2251 - val_loss: 0.4002 - val_mse: 0.4002 - val_mae: 0.4522\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 3s 244us/sample - loss: 0.0929 - mse: 0.0929 - mae: 0.2309 - val_loss: 0.3995 - val_mse: 0.3995 - val_mae: 0.4486\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.0908 - mse: 0.0908 - mae: 0.2267 - val_loss: 0.4026 - val_mse: 0.4026 - val_mae: 0.4501\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0935 - mse: 0.0935 - mae: 0.2311 - val_loss: 0.3821 - val_mse: 0.3821 - val_mae: 0.4410\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0827 - mse: 0.0827 - mae: 0.2190 - val_loss: 0.3810 - val_mse: 0.3810 - val_mae: 0.4310\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 3s 245us/sample - loss: 0.0941 - mse: 0.0941 - mae: 0.2329 - val_loss: 0.3970 - val_mse: 0.3970 - val_mae: 0.4499\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0872 - mse: 0.0872 - mae: 0.2236 - val_loss: 0.3832 - val_mse: 0.3832 - val_mae: 0.4407\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 3s 238us/sample - loss: 0.0865 - mse: 0.0865 - mae: 0.2225 - val_loss: 0.3925 - val_mse: 0.3925 - val_mae: 0.4476\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 3s 238us/sample - loss: 0.0879 - mse: 0.0879 - mae: 0.2246 - val_loss: 0.4042 - val_mse: 0.4042 - val_mae: 0.4511\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 3s 246us/sample - loss: 0.0836 - mse: 0.0836 - mae: 0.2165 - val_loss: 0.3800 - val_mse: 0.3800 - val_mae: 0.4300\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0771 - mse: 0.0771 - mae: 0.2101 - val_loss: 0.3881 - val_mse: 0.3881 - val_mae: 0.4390\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0766 - mse: 0.0766 - mae: 0.2113 - val_loss: 0.4033 - val_mse: 0.4033 - val_mae: 0.4477\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0731 - mse: 0.0731 - mae: 0.2051 - val_loss: 0.3802 - val_mse: 0.3802 - val_mae: 0.4327\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0687 - mse: 0.0687 - mae: 0.1999 - val_loss: 0.3984 - val_mse: 0.3984 - val_mae: 0.4431\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0760 - mse: 0.0760 - mae: 0.2075 - val_loss: 0.3752 - val_mse: 0.3752 - val_mae: 0.4289\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.0633 - mse: 0.0633 - mae: 0.1885 - val_loss: 0.3690 - val_mse: 0.3690 - val_mae: 0.4213\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.0655 - mse: 0.0655 - mae: 0.1906 - val_loss: 0.4297 - val_mse: 0.4297 - val_mae: 0.4629\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0656 - mse: 0.0656 - mae: 0.1908 - val_loss: 0.3733 - val_mse: 0.3733 - val_mae: 0.4256\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.0630 - mse: 0.0630 - mae: 0.1891 - val_loss: 0.3783 - val_mse: 0.3783 - val_mae: 0.4343\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0594 - mse: 0.0594 - mae: 0.1860 - val_loss: 0.3818 - val_mse: 0.3818 - val_mae: 0.4291\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 3s 238us/sample - loss: 0.0606 - mse: 0.0606 - mae: 0.1862 - val_loss: 0.3836 - val_mse: 0.3836 - val_mae: 0.4364\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0646 - mse: 0.0646 - mae: 0.1940 - val_loss: 0.3742 - val_mse: 0.3742 - val_mae: 0.4258\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 3s 244us/sample - loss: 0.0669 - mse: 0.0669 - mae: 0.1940 - val_loss: 0.3677 - val_mse: 0.3677 - val_mae: 0.4285\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 3s 238us/sample - loss: 0.0638 - mse: 0.0638 - mae: 0.1928 - val_loss: 0.3917 - val_mse: 0.3917 - val_mae: 0.4431\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0564 - mse: 0.0564 - mae: 0.1792 - val_loss: 0.3608 - val_mse: 0.3608 - val_mae: 0.4239\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.0638 - mse: 0.0638 - mae: 0.1922 - val_loss: 0.3812 - val_mse: 0.3812 - val_mae: 0.4297\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.0624 - mse: 0.0624 - mae: 0.1861 - val_loss: 0.3850 - val_mse: 0.3850 - val_mae: 0.4341\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0560 - mse: 0.0560 - mae: 0.1790 - val_loss: 0.3722 - val_mse: 0.3722 - val_mae: 0.4229\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0667 - mse: 0.0667 - mae: 0.1937 - val_loss: 0.3689 - val_mse: 0.3689 - val_mae: 0.4226\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0558 - mse: 0.0558 - mae: 0.1770 - val_loss: 0.3741 - val_mse: 0.3741 - val_mae: 0.4253\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.0685 - mse: 0.0685 - mae: 0.1929 - val_loss: 0.3927 - val_mse: 0.3927 - val_mae: 0.4390\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0698 - mse: 0.0698 - mae: 0.1987 - val_loss: 0.3989 - val_mse: 0.3989 - val_mae: 0.4484\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0646 - mse: 0.0646 - mae: 0.1928 - val_loss: 0.3682 - val_mse: 0.3682 - val_mae: 0.4207\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 3s 247us/sample - loss: 0.0678 - mse: 0.0678 - mae: 0.1939 - val_loss: 0.3722 - val_mse: 0.3722 - val_mae: 0.4255\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.0642 - mse: 0.0642 - mae: 0.1899 - val_loss: 0.3741 - val_mse: 0.3741 - val_mae: 0.4233\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 4s 409us/sample - loss: 21.3979 - mse: 21.3979 - mae: 2.5859 - val_loss: 25.0561 - val_mse: 25.0561 - val_mae: 4.4703\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.9367 - mse: 0.9367 - mae: 0.7211 - val_loss: 3.4245 - val_mse: 3.4245 - val_mae: 1.5412\n",
      "Epoch 3/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.5969 - mse: 0.5969 - mae: 0.5786 - val_loss: 1.1514 - val_mse: 1.1514 - val_mae: 0.8125\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.5371 - mse: 0.5371 - mae: 0.5477 - val_loss: 1.1933 - val_mse: 1.1933 - val_mae: 0.8019\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.4905 - mse: 0.4905 - mae: 0.5220 - val_loss: 0.9107 - val_mse: 0.9107 - val_mae: 0.6925\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.4658 - mse: 0.4658 - mae: 0.5072 - val_loss: 0.8616 - val_mse: 0.8616 - val_mae: 0.6742\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.4338 - mse: 0.4338 - mae: 0.4887 - val_loss: 0.7326 - val_mse: 0.7326 - val_mae: 0.6483\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.4027 - mse: 0.4027 - mae: 0.4716 - val_loss: 0.6821 - val_mse: 0.6821 - val_mae: 0.6261\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.3752 - mse: 0.3752 - mae: 0.4550 - val_loss: 0.6049 - val_mse: 0.6049 - val_mae: 0.5955\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.3542 - mse: 0.3542 - mae: 0.4421 - val_loss: 0.5584 - val_mse: 0.5584 - val_mae: 0.5722\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 3s 244us/sample - loss: 0.3329 - mse: 0.3329 - mae: 0.4291 - val_loss: 0.5826 - val_mse: 0.5826 - val_mae: 0.5785\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 3s 246us/sample - loss: 0.3155 - mse: 0.3155 - mae: 0.4184 - val_loss: 0.5479 - val_mse: 0.5479 - val_mae: 0.5562\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.2917 - mse: 0.2917 - mae: 0.4009 - val_loss: 0.5138 - val_mse: 0.5138 - val_mae: 0.5296\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.2824 - mse: 0.2824 - mae: 0.3957 - val_loss: 0.4965 - val_mse: 0.4965 - val_mae: 0.5198\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.2567 - mse: 0.2567 - mae: 0.3762 - val_loss: 0.4907 - val_mse: 0.4907 - val_mae: 0.5228\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.2535 - mse: 0.2535 - mae: 0.3748 - val_loss: 0.4881 - val_mse: 0.4881 - val_mae: 0.5128\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.2494 - mse: 0.2494 - mae: 0.3692 - val_loss: 0.4506 - val_mse: 0.4506 - val_mae: 0.4919\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.2308 - mse: 0.2308 - mae: 0.3584 - val_loss: 0.5319 - val_mse: 0.5319 - val_mae: 0.5309\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 3s 243us/sample - loss: 0.2251 - mse: 0.2251 - mae: 0.3525 - val_loss: 0.5159 - val_mse: 0.5159 - val_mae: 0.5308\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.2088 - mse: 0.2088 - mae: 0.3403 - val_loss: 0.4537 - val_mse: 0.4537 - val_mae: 0.4963\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 3s 247us/sample - loss: 0.1897 - mse: 0.1897 - mae: 0.3262 - val_loss: 0.4310 - val_mse: 0.4310 - val_mae: 0.4740\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 3s 245us/sample - loss: 0.1994 - mse: 0.1994 - mae: 0.3350 - val_loss: 0.4374 - val_mse: 0.4374 - val_mae: 0.4830\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1955 - mse: 0.1955 - mae: 0.3338 - val_loss: 0.4475 - val_mse: 0.4475 - val_mae: 0.4901\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1802 - mse: 0.1802 - mae: 0.3167 - val_loss: 0.4096 - val_mse: 0.4096 - val_mae: 0.4672\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1612 - mse: 0.1612 - mae: 0.2993 - val_loss: 0.4295 - val_mse: 0.4295 - val_mae: 0.4841\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1538 - mse: 0.1538 - mae: 0.2917 - val_loss: 0.4171 - val_mse: 0.4171 - val_mae: 0.4680\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1536 - mse: 0.1536 - mae: 0.2948 - val_loss: 0.3904 - val_mse: 0.3904 - val_mae: 0.4516\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1421 - mse: 0.1421 - mae: 0.2833 - val_loss: 0.4077 - val_mse: 0.4077 - val_mae: 0.4604\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1388 - mse: 0.1388 - mae: 0.2814 - val_loss: 0.3877 - val_mse: 0.3877 - val_mae: 0.4464\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1296 - mse: 0.1296 - mae: 0.2688 - val_loss: 0.3800 - val_mse: 0.3800 - val_mae: 0.4468\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1287 - mse: 0.1287 - mae: 0.2686 - val_loss: 0.4132 - val_mse: 0.4132 - val_mae: 0.4576\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1355 - mse: 0.1355 - mae: 0.2759 - val_loss: 0.4154 - val_mse: 0.4154 - val_mae: 0.4681\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1311 - mse: 0.1311 - mae: 0.2693 - val_loss: 0.3914 - val_mse: 0.3914 - val_mae: 0.4545\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1230 - mse: 0.1230 - mae: 0.2619 - val_loss: 0.4030 - val_mse: 0.4030 - val_mae: 0.4594\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 3s 246us/sample - loss: 0.1182 - mse: 0.1182 - mae: 0.2594 - val_loss: 0.3884 - val_mse: 0.3884 - val_mae: 0.4463\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 3s 241us/sample - loss: 0.1186 - mse: 0.1186 - mae: 0.2588 - val_loss: 0.4158 - val_mse: 0.4158 - val_mae: 0.4710\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 3s 242us/sample - loss: 0.1164 - mse: 0.1164 - mae: 0.2554 - val_loss: 0.4020 - val_mse: 0.4020 - val_mae: 0.4651\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1190 - mse: 0.1190 - mae: 0.2626 - val_loss: 0.4043 - val_mse: 0.4043 - val_mae: 0.4599\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.1190 - mse: 0.1190 - mae: 0.2582 - val_loss: 0.4082 - val_mse: 0.4082 - val_mae: 0.4628\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 3s 239us/sample - loss: 0.1010 - mse: 0.1010 - mae: 0.2369 - val_loss: 0.3841 - val_mse: 0.3841 - val_mae: 0.4459\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 4s 346us/sample - loss: 16.9994 - mse: 16.9994 - mae: 2.3842 - val_loss: 27.0110 - val_mse: 27.0110 - val_mae: 4.4090\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.9055 - mse: 0.9055 - mae: 0.7084 - val_loss: 1.4475 - val_mse: 1.4475 - val_mae: 0.9196\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.5906 - mse: 0.5906 - mae: 0.5750 - val_loss: 0.8406 - val_mse: 0.8406 - val_mae: 0.6970\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 3s 246us/sample - loss: 0.5212 - mse: 0.5212 - mae: 0.5383 - val_loss: 0.7460 - val_mse: 0.7460 - val_mae: 0.6586\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 3s 243us/sample - loss: 0.4750 - mse: 0.4750 - mae: 0.5152 - val_loss: 0.7586 - val_mse: 0.7586 - val_mae: 0.6552\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 3s 243us/sample - loss: 0.4396 - mse: 0.4396 - mae: 0.4956 - val_loss: 0.7126 - val_mse: 0.7126 - val_mae: 0.6423\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 3s 239us/sample - loss: 0.4151 - mse: 0.4151 - mae: 0.4795 - val_loss: 0.6899 - val_mse: 0.6899 - val_mae: 0.6318\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.3842 - mse: 0.3842 - mae: 0.4631 - val_loss: 0.6130 - val_mse: 0.6130 - val_mae: 0.5978\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.3604 - mse: 0.3604 - mae: 0.4483 - val_loss: 0.5695 - val_mse: 0.5695 - val_mae: 0.5690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.3351 - mse: 0.3351 - mae: 0.4325 - val_loss: 0.5358 - val_mse: 0.5358 - val_mae: 0.5525\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.3111 - mse: 0.3111 - mae: 0.4154 - val_loss: 0.5281 - val_mse: 0.5281 - val_mae: 0.5445\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.2969 - mse: 0.2969 - mae: 0.4063 - val_loss: 0.4857 - val_mse: 0.4857 - val_mae: 0.5239\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 3s 239us/sample - loss: 0.2879 - mse: 0.2879 - mae: 0.4006 - val_loss: 0.4969 - val_mse: 0.4969 - val_mae: 0.5195\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.2688 - mse: 0.2688 - mae: 0.3890 - val_loss: 0.4959 - val_mse: 0.4959 - val_mae: 0.5016\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.2601 - mse: 0.2601 - mae: 0.3809 - val_loss: 0.4709 - val_mse: 0.4709 - val_mae: 0.5031\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.2266 - mse: 0.2266 - mae: 0.3549 - val_loss: 0.4697 - val_mse: 0.4697 - val_mae: 0.4941\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.2157 - mse: 0.2157 - mae: 0.3468 - val_loss: 0.4708 - val_mse: 0.4708 - val_mae: 0.4914\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 3s 246us/sample - loss: 0.2071 - mse: 0.2071 - mae: 0.3394 - val_loss: 0.4871 - val_mse: 0.4871 - val_mae: 0.5041\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.2117 - mse: 0.2117 - mae: 0.3459 - val_loss: 0.4255 - val_mse: 0.4255 - val_mae: 0.4678\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.1901 - mse: 0.1901 - mae: 0.3259 - val_loss: 0.4260 - val_mse: 0.4260 - val_mae: 0.4682\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.1782 - mse: 0.1782 - mae: 0.3129 - val_loss: 0.3936 - val_mse: 0.3936 - val_mae: 0.4509\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.1789 - mse: 0.1789 - mae: 0.3163 - val_loss: 0.4215 - val_mse: 0.4215 - val_mae: 0.4663\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.1685 - mse: 0.1685 - mae: 0.3061 - val_loss: 0.4531 - val_mse: 0.4531 - val_mae: 0.4894\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 3s 246us/sample - loss: 0.1657 - mse: 0.1657 - mae: 0.3045 - val_loss: 0.4391 - val_mse: 0.4391 - val_mae: 0.4812\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 3s 239us/sample - loss: 0.1536 - mse: 0.1536 - mae: 0.2934 - val_loss: 0.4033 - val_mse: 0.4033 - val_mae: 0.4467\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.1378 - mse: 0.1378 - mae: 0.2794 - val_loss: 0.4102 - val_mse: 0.4102 - val_mae: 0.4508\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.1448 - mse: 0.1448 - mae: 0.2848 - val_loss: 0.3989 - val_mse: 0.3989 - val_mae: 0.4424\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 3s 246us/sample - loss: 0.1393 - mse: 0.1393 - mae: 0.2800 - val_loss: 0.3880 - val_mse: 0.3880 - val_mae: 0.4436\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.1307 - mse: 0.1307 - mae: 0.2720 - val_loss: 0.4206 - val_mse: 0.4206 - val_mae: 0.4616\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.1180 - mse: 0.1180 - mae: 0.2553 - val_loss: 0.4039 - val_mse: 0.4039 - val_mae: 0.4553\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.1191 - mse: 0.1191 - mae: 0.2584 - val_loss: 0.4020 - val_mse: 0.4020 - val_mae: 0.4496\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.1130 - mse: 0.1130 - mae: 0.2538 - val_loss: 0.4334 - val_mse: 0.4334 - val_mae: 0.4641\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.1217 - mse: 0.1217 - mae: 0.2628 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.4643\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.1253 - mse: 0.1253 - mae: 0.2642 - val_loss: 0.4180 - val_mse: 0.4180 - val_mae: 0.4637\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.1254 - mse: 0.1254 - mae: 0.2642 - val_loss: 0.5125 - val_mse: 0.5125 - val_mae: 0.5186\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.1255 - mse: 0.1255 - mae: 0.2685 - val_loss: 0.3852 - val_mse: 0.3852 - val_mae: 0.4380\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 3s 247us/sample - loss: 0.1002 - mse: 0.1002 - mae: 0.2377 - val_loss: 0.4432 - val_mse: 0.4432 - val_mae: 0.4658\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 3s 252us/sample - loss: 0.0996 - mse: 0.0996 - mae: 0.2388 - val_loss: 0.4085 - val_mse: 0.4085 - val_mae: 0.4545\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 3s 250us/sample - loss: 0.1053 - mse: 0.1053 - mae: 0.2474 - val_loss: 0.3913 - val_mse: 0.3913 - val_mae: 0.4395\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.0987 - mse: 0.0987 - mae: 0.2376 - val_loss: 0.3922 - val_mse: 0.3922 - val_mae: 0.4345\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0950 - mse: 0.0950 - mae: 0.2333 - val_loss: 0.4094 - val_mse: 0.4094 - val_mae: 0.4539\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 3s 238us/sample - loss: 0.1000 - mse: 0.1000 - mae: 0.2376 - val_loss: 0.4142 - val_mse: 0.4142 - val_mae: 0.4659\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.1004 - mse: 0.1004 - mae: 0.2392 - val_loss: 0.3974 - val_mse: 0.3974 - val_mae: 0.4503\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0936 - mse: 0.0936 - mae: 0.2344 - val_loss: 0.4180 - val_mse: 0.4180 - val_mae: 0.4543\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0910 - mse: 0.0910 - mae: 0.2255 - val_loss: 0.3748 - val_mse: 0.3748 - val_mae: 0.4271\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 3s 239us/sample - loss: 0.0831 - mse: 0.0831 - mae: 0.2173 - val_loss: 0.4125 - val_mse: 0.4125 - val_mae: 0.4537\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0884 - mse: 0.0884 - mae: 0.2228 - val_loss: 0.4316 - val_mse: 0.4316 - val_mae: 0.4776\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 3s 239us/sample - loss: 0.0786 - mse: 0.0786 - mae: 0.2098 - val_loss: 0.3992 - val_mse: 0.3992 - val_mae: 0.4376\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0750 - mse: 0.0750 - mae: 0.2064 - val_loss: 0.3954 - val_mse: 0.3954 - val_mae: 0.4494\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0858 - mse: 0.0858 - mae: 0.2214 - val_loss: 0.3833 - val_mse: 0.3833 - val_mae: 0.4358\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0862 - mse: 0.0862 - mae: 0.2235 - val_loss: 0.3745 - val_mse: 0.3745 - val_mae: 0.4212\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 3s 246us/sample - loss: 0.0795 - mse: 0.0795 - mae: 0.2116 - val_loss: 0.4003 - val_mse: 0.4003 - val_mae: 0.4429\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.0677 - mse: 0.0677 - mae: 0.1949 - val_loss: 0.4001 - val_mse: 0.4001 - val_mae: 0.4384\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0759 - mse: 0.0759 - mae: 0.2095 - val_loss: 0.3913 - val_mse: 0.3913 - val_mae: 0.4381\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.0723 - mse: 0.0723 - mae: 0.2055 - val_loss: 0.3833 - val_mse: 0.3833 - val_mae: 0.4295\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0738 - mse: 0.0738 - mae: 0.2056 - val_loss: 0.4088 - val_mse: 0.4088 - val_mae: 0.4536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0825 - mse: 0.0825 - mae: 0.2170 - val_loss: 0.4087 - val_mse: 0.4087 - val_mae: 0.4524\n",
      "Epoch 58/3000\n",
      "10664/10664 [==============================] - 3s 239us/sample - loss: 0.0800 - mse: 0.0800 - mae: 0.2107 - val_loss: 0.4022 - val_mse: 0.4022 - val_mae: 0.4517\n",
      "Epoch 59/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0826 - mse: 0.0826 - mae: 0.2190 - val_loss: 0.3720 - val_mse: 0.3720 - val_mae: 0.4231\n",
      "Epoch 60/3000\n",
      "10664/10664 [==============================] - 3s 238us/sample - loss: 0.0664 - mse: 0.0664 - mae: 0.1918 - val_loss: 0.3961 - val_mse: 0.3961 - val_mae: 0.4425\n",
      "Epoch 61/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0655 - mse: 0.0655 - mae: 0.1904 - val_loss: 0.3690 - val_mse: 0.3690 - val_mae: 0.4187\n",
      "Epoch 62/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0636 - mse: 0.0636 - mae: 0.1881 - val_loss: 0.3760 - val_mse: 0.3760 - val_mae: 0.4268\n",
      "Epoch 63/3000\n",
      "10664/10664 [==============================] - 3s 244us/sample - loss: 0.0575 - mse: 0.0575 - mae: 0.1803 - val_loss: 0.3614 - val_mse: 0.3614 - val_mae: 0.4181\n",
      "Epoch 64/3000\n",
      "10664/10664 [==============================] - 3s 244us/sample - loss: 0.0546 - mse: 0.0546 - mae: 0.1761 - val_loss: 0.3722 - val_mse: 0.3722 - val_mae: 0.4214\n",
      "Epoch 65/3000\n",
      "10664/10664 [==============================] - 3s 243us/sample - loss: 0.0600 - mse: 0.0600 - mae: 0.1842 - val_loss: 0.3788 - val_mse: 0.3788 - val_mae: 0.4324\n",
      "Epoch 66/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0610 - mse: 0.0610 - mae: 0.1837 - val_loss: 0.3839 - val_mse: 0.3839 - val_mae: 0.4284\n",
      "Epoch 67/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0593 - mse: 0.0593 - mae: 0.1814 - val_loss: 0.3985 - val_mse: 0.3985 - val_mae: 0.4349\n",
      "Epoch 68/3000\n",
      "10664/10664 [==============================] - 3s 239us/sample - loss: 0.0565 - mse: 0.0565 - mae: 0.1775 - val_loss: 0.3703 - val_mse: 0.3703 - val_mae: 0.4217\n",
      "Epoch 69/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0614 - mse: 0.0614 - mae: 0.1880 - val_loss: 0.3682 - val_mse: 0.3682 - val_mae: 0.4205\n",
      "Epoch 70/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.0590 - mse: 0.0590 - mae: 0.1843 - val_loss: 0.3935 - val_mse: 0.3935 - val_mae: 0.4269\n",
      "Epoch 71/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0567 - mse: 0.0567 - mae: 0.1795 - val_loss: 0.3535 - val_mse: 0.3535 - val_mae: 0.4095\n",
      "Epoch 72/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0596 - mse: 0.0596 - mae: 0.1799 - val_loss: 0.3788 - val_mse: 0.3788 - val_mae: 0.4267\n",
      "Epoch 73/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0574 - mse: 0.0574 - mae: 0.1801 - val_loss: 0.3869 - val_mse: 0.3869 - val_mae: 0.4303\n",
      "Epoch 74/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0660 - mse: 0.0660 - mae: 0.1944 - val_loss: 0.3713 - val_mse: 0.3713 - val_mae: 0.4288\n",
      "Epoch 75/3000\n",
      "10664/10664 [==============================] - 3s 244us/sample - loss: 0.0622 - mse: 0.0622 - mae: 0.1874 - val_loss: 0.3756 - val_mse: 0.3756 - val_mae: 0.4332\n",
      "Epoch 76/3000\n",
      "10664/10664 [==============================] - 3s 244us/sample - loss: 0.0664 - mse: 0.0664 - mae: 0.1911 - val_loss: 0.3597 - val_mse: 0.3597 - val_mae: 0.4124\n",
      "Epoch 77/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0535 - mse: 0.0535 - mae: 0.1727 - val_loss: 0.3488 - val_mse: 0.3488 - val_mae: 0.4070\n",
      "Epoch 78/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.0523 - mse: 0.0523 - mae: 0.1709 - val_loss: 0.3582 - val_mse: 0.3582 - val_mae: 0.4120\n",
      "Epoch 79/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0519 - mse: 0.0519 - mae: 0.1712 - val_loss: 0.3604 - val_mse: 0.3604 - val_mae: 0.4122\n",
      "Epoch 80/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0594 - mse: 0.0594 - mae: 0.1825 - val_loss: 0.3690 - val_mse: 0.3690 - val_mae: 0.4189\n",
      "Epoch 81/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0658 - mse: 0.0658 - mae: 0.1936 - val_loss: 0.3692 - val_mse: 0.3692 - val_mae: 0.4222\n",
      "Epoch 82/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0687 - mse: 0.0687 - mae: 0.1967 - val_loss: 0.3805 - val_mse: 0.3805 - val_mae: 0.4385\n",
      "Epoch 83/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.0510 - mse: 0.0510 - mae: 0.1681 - val_loss: 0.3557 - val_mse: 0.3557 - val_mae: 0.4108\n",
      "Epoch 84/3000\n",
      "10664/10664 [==============================] - 3s 239us/sample - loss: 0.0504 - mse: 0.0504 - mae: 0.1683 - val_loss: 0.3613 - val_mse: 0.3613 - val_mae: 0.4169\n",
      "Epoch 85/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0461 - mse: 0.0461 - mae: 0.1608 - val_loss: 0.3412 - val_mse: 0.3412 - val_mae: 0.4040\n",
      "Epoch 86/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.0539 - mse: 0.0539 - mae: 0.1734 - val_loss: 0.3651 - val_mse: 0.3651 - val_mae: 0.4182\n",
      "Epoch 87/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.0525 - mse: 0.0525 - mae: 0.1736 - val_loss: 0.3690 - val_mse: 0.3690 - val_mae: 0.4287\n",
      "Epoch 88/3000\n",
      "10664/10664 [==============================] - 3s 243us/sample - loss: 0.0522 - mse: 0.0522 - mae: 0.1710 - val_loss: 0.3476 - val_mse: 0.3476 - val_mae: 0.4161\n",
      "Epoch 89/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0519 - mse: 0.0519 - mae: 0.1721 - val_loss: 0.3775 - val_mse: 0.3775 - val_mae: 0.4303\n",
      "Epoch 90/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0435 - mse: 0.0435 - mae: 0.1559 - val_loss: 0.3526 - val_mse: 0.3526 - val_mae: 0.4076\n",
      "Epoch 91/3000\n",
      "10664/10664 [==============================] - 3s 240us/sample - loss: 0.0513 - mse: 0.0513 - mae: 0.1693 - val_loss: 0.3964 - val_mse: 0.3964 - val_mae: 0.4510\n",
      "Epoch 92/3000\n",
      "10664/10664 [==============================] - 3s 242us/sample - loss: 0.0473 - mse: 0.0473 - mae: 0.1632 - val_loss: 0.3586 - val_mse: 0.3586 - val_mae: 0.4110\n",
      "Epoch 93/3000\n",
      "10664/10664 [==============================] - 3s 243us/sample - loss: 0.0409 - mse: 0.0409 - mae: 0.1506 - val_loss: 0.3501 - val_mse: 0.3501 - val_mae: 0.4038\n",
      "Epoch 94/3000\n",
      "10664/10664 [==============================] - 3s 239us/sample - loss: 0.0394 - mse: 0.0394 - mae: 0.1476 - val_loss: 0.3546 - val_mse: 0.3546 - val_mae: 0.4095\n",
      "Epoch 95/3000\n",
      "10664/10664 [==============================] - 3s 241us/sample - loss: 0.0415 - mse: 0.0415 - mae: 0.1535 - val_loss: 0.3534 - val_mse: 0.3534 - val_mae: 0.4071\n",
      "Avg. MAE: 0.381420\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 113us/sample - loss: 23.5141 - mse: 23.5141 - mae: 2.7309 - val_loss: 7.2755 - val_mse: 7.2755 - val_mae: 2.0732\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 1.4497 - mse: 1.4497 - mae: 0.9040 - val_loss: 1.4709 - val_mse: 1.4709 - val_mae: 0.9565\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.7276 - mse: 0.7276 - mae: 0.6408 - val_loss: 1.2881 - val_mse: 1.2881 - val_mae: 0.9300\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.5864 - mse: 0.5864 - mae: 0.5717 - val_loss: 0.9030 - val_mse: 0.9030 - val_mae: 0.7671\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.5448 - mse: 0.5448 - mae: 0.5485 - val_loss: 0.8830 - val_mse: 0.8830 - val_mae: 0.7702\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.5102 - mse: 0.5102 - mae: 0.5314 - val_loss: 0.8338 - val_mse: 0.8338 - val_mae: 0.7488\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4988 - mse: 0.4988 - mae: 0.5278 - val_loss: 0.7656 - val_mse: 0.7656 - val_mae: 0.7175\n",
      "Epoch 8/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4721 - mse: 0.4721 - mae: 0.5104 - val_loss: 0.6844 - val_mse: 0.6844 - val_mae: 0.6708\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.4669 - mse: 0.4669 - mae: 0.5088 - val_loss: 0.7602 - val_mse: 0.7602 - val_mae: 0.7053\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4407 - mse: 0.4407 - mae: 0.4965 - val_loss: 0.6165 - val_mse: 0.6165 - val_mae: 0.6272\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.4214 - mse: 0.4214 - mae: 0.4816 - val_loss: 0.5915 - val_mse: 0.5915 - val_mae: 0.6159\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.4090 - mse: 0.4090 - mae: 0.4756 - val_loss: 0.6400 - val_mse: 0.6400 - val_mae: 0.6465\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3929 - mse: 0.3929 - mae: 0.4674 - val_loss: 0.5407 - val_mse: 0.5407 - val_mae: 0.5803\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3774 - mse: 0.3774 - mae: 0.4556 - val_loss: 0.5171 - val_mse: 0.5171 - val_mae: 0.5610\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 54us/sample - loss: 0.3678 - mse: 0.3678 - mae: 0.4529 - val_loss: 0.5261 - val_mse: 0.5261 - val_mae: 0.5666\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.3578 - mse: 0.3578 - mae: 0.4464 - val_loss: 0.5051 - val_mse: 0.5051 - val_mae: 0.5541\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.3407 - mse: 0.3407 - mae: 0.4382 - val_loss: 0.4491 - val_mse: 0.4491 - val_mae: 0.5120\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3348 - mse: 0.3348 - mae: 0.4312 - val_loss: 0.4523 - val_mse: 0.4523 - val_mae: 0.5058\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.3521 - mse: 0.3521 - mae: 0.4478 - val_loss: 0.5602 - val_mse: 0.5602 - val_mae: 0.6001\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3652 - mse: 0.3652 - mae: 0.4548 - val_loss: 0.4790 - val_mse: 0.4790 - val_mae: 0.5282\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.3145 - mse: 0.3145 - mae: 0.4218 - val_loss: 0.4416 - val_mse: 0.4416 - val_mae: 0.4974\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3047 - mse: 0.3047 - mae: 0.4148 - val_loss: 0.4271 - val_mse: 0.4271 - val_mae: 0.4912\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2824 - mse: 0.2824 - mae: 0.3993 - val_loss: 0.4398 - val_mse: 0.4398 - val_mae: 0.4881\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2832 - mse: 0.2832 - mae: 0.3989 - val_loss: 0.4488 - val_mse: 0.4488 - val_mae: 0.5098\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.2900 - mse: 0.2900 - mae: 0.4045 - val_loss: 0.4228 - val_mse: 0.4228 - val_mae: 0.4970\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2815 - mse: 0.2815 - mae: 0.3964 - val_loss: 0.4466 - val_mse: 0.4466 - val_mae: 0.4965\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2691 - mse: 0.2691 - mae: 0.3886 - val_loss: 0.4146 - val_mse: 0.4146 - val_mae: 0.4796\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2728 - mse: 0.2728 - mae: 0.3900 - val_loss: 0.4908 - val_mse: 0.4908 - val_mae: 0.5515\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2563 - mse: 0.2563 - mae: 0.3810 - val_loss: 0.4100 - val_mse: 0.4100 - val_mae: 0.4828\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2451 - mse: 0.2451 - mae: 0.3712 - val_loss: 0.4449 - val_mse: 0.4449 - val_mae: 0.4947\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2355 - mse: 0.2355 - mae: 0.3648 - val_loss: 0.4250 - val_mse: 0.4250 - val_mae: 0.4778\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.2458 - mse: 0.2458 - mae: 0.3703 - val_loss: 0.4565 - val_mse: 0.4565 - val_mae: 0.4941\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2524 - mse: 0.2524 - mae: 0.3766 - val_loss: 0.4750 - val_mse: 0.4750 - val_mae: 0.5093\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2241 - mse: 0.2241 - mae: 0.3574 - val_loss: 0.4145 - val_mse: 0.4145 - val_mae: 0.4818\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2558 - mse: 0.2558 - mae: 0.3771 - val_loss: 0.4353 - val_mse: 0.4353 - val_mae: 0.4945\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.2454 - mse: 0.2454 - mae: 0.3713 - val_loss: 0.4196 - val_mse: 0.4196 - val_mae: 0.4849\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2341 - mse: 0.2341 - mae: 0.3634 - val_loss: 0.4280 - val_mse: 0.4280 - val_mae: 0.4807\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2318 - mse: 0.2318 - mae: 0.3624 - val_loss: 0.4039 - val_mse: 0.4039 - val_mae: 0.4679\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.2292 - mse: 0.2292 - mae: 0.3584 - val_loss: 0.4601 - val_mse: 0.4601 - val_mae: 0.5064\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2491 - mse: 0.2491 - mae: 0.3760 - val_loss: 0.4691 - val_mse: 0.4691 - val_mae: 0.5103\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.2223 - mse: 0.2223 - mae: 0.3550 - val_loss: 0.4409 - val_mse: 0.4409 - val_mae: 0.4920\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2267 - mse: 0.2267 - mae: 0.3568 - val_loss: 0.4134 - val_mse: 0.4134 - val_mae: 0.4858\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2089 - mse: 0.2089 - mae: 0.3401 - val_loss: 0.4169 - val_mse: 0.4169 - val_mae: 0.4696\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.1905 - mse: 0.1905 - mae: 0.3280 - val_loss: 0.4224 - val_mse: 0.4224 - val_mae: 0.4933\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.1948 - mse: 0.1948 - mae: 0.3294 - val_loss: 0.4037 - val_mse: 0.4037 - val_mae: 0.4703\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.1915 - mse: 0.1915 - mae: 0.3256 - val_loss: 0.4230 - val_mse: 0.4230 - val_mae: 0.4652\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 53us/sample - loss: 0.1838 - mse: 0.1838 - mae: 0.3185 - val_loss: 0.4128 - val_mse: 0.4128 - val_mae: 0.4666\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.1956 - mse: 0.1956 - mae: 0.3240 - val_loss: 0.4325 - val_mse: 0.4325 - val_mae: 0.4736\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2255 - mse: 0.2255 - mae: 0.3439 - val_loss: 0.4504 - val_mse: 0.4504 - val_mae: 0.4861\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.2275 - mse: 0.2275 - mae: 0.3474 - val_loss: 0.4821 - val_mse: 0.4821 - val_mae: 0.4974\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.2127 - mse: 0.2127 - mae: 0.3397 - val_loss: 0.4067 - val_mse: 0.4067 - val_mae: 0.4711\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2029 - mse: 0.2029 - mae: 0.3383 - val_loss: 0.4271 - val_mse: 0.4271 - val_mae: 0.4776\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1867 - mse: 0.1867 - mae: 0.3270 - val_loss: 0.3854 - val_mse: 0.3854 - val_mae: 0.4551\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1773 - mse: 0.1773 - mae: 0.3194 - val_loss: 0.4035 - val_mse: 0.4035 - val_mae: 0.4639\n",
      "Epoch 55/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.1684 - mse: 0.1684 - mae: 0.3105 - val_loss: 0.4065 - val_mse: 0.4065 - val_mae: 0.4671\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1652 - mse: 0.1652 - mae: 0.3068 - val_loss: 0.4279 - val_mse: 0.4279 - val_mae: 0.4799\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1760 - mse: 0.1760 - mae: 0.3144 - val_loss: 0.4069 - val_mse: 0.4069 - val_mae: 0.4697\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1911 - mse: 0.1911 - mae: 0.3295 - val_loss: 0.4257 - val_mse: 0.4257 - val_mae: 0.4907\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1691 - mse: 0.1691 - mae: 0.3098 - val_loss: 0.4501 - val_mse: 0.4501 - val_mae: 0.4885\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1650 - mse: 0.1650 - mae: 0.3040 - val_loss: 0.4339 - val_mse: 0.4339 - val_mae: 0.4776\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1696 - mse: 0.1696 - mae: 0.3076 - val_loss: 0.4098 - val_mse: 0.4098 - val_mae: 0.4641\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1745 - mse: 0.1745 - mae: 0.3128 - val_loss: 0.4552 - val_mse: 0.4552 - val_mae: 0.5171\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1922 - mse: 0.1922 - mae: 0.3263 - val_loss: 0.4606 - val_mse: 0.4606 - val_mae: 0.5025\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 114us/sample - loss: 19.3754 - mse: 19.3754 - mae: 2.4178 - val_loss: 55.0535 - val_mse: 55.0535 - val_mae: 6.7641\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 1.2591 - mse: 1.2591 - mae: 0.8321 - val_loss: 10.0271 - val_mse: 10.0271 - val_mae: 2.8461\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.6940 - mse: 0.6940 - mae: 0.6220 - val_loss: 2.6402 - val_mse: 2.6402 - val_mae: 1.4150\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.5852 - mse: 0.5852 - mae: 0.5729 - val_loss: 1.7916 - val_mse: 1.7916 - val_mae: 1.1730\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.5452 - mse: 0.5452 - mae: 0.5528 - val_loss: 1.3748 - val_mse: 1.3748 - val_mae: 1.0035\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.5174 - mse: 0.5174 - mae: 0.5386 - val_loss: 1.2903 - val_mse: 1.2903 - val_mae: 0.9318\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.4983 - mse: 0.4983 - mae: 0.5275 - val_loss: 1.0644 - val_mse: 1.0644 - val_mae: 0.8732\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.4794 - mse: 0.4794 - mae: 0.5175 - val_loss: 0.7719 - val_mse: 0.7719 - val_mae: 0.7095\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.4559 - mse: 0.4559 - mae: 0.5050 - val_loss: 0.8405 - val_mse: 0.8405 - val_mae: 0.7481\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.4394 - mse: 0.4394 - mae: 0.4959 - val_loss: 0.6996 - val_mse: 0.6996 - val_mae: 0.6661\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4333 - mse: 0.4333 - mae: 0.4988 - val_loss: 0.6974 - val_mse: 0.6974 - val_mae: 0.6568\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3986 - mse: 0.3986 - mae: 0.4722 - val_loss: 0.6775 - val_mse: 0.6775 - val_mae: 0.6351\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.3797 - mse: 0.3797 - mae: 0.4613 - val_loss: 0.6414 - val_mse: 0.6414 - val_mae: 0.6295\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3838 - mse: 0.3838 - mae: 0.4662 - val_loss: 0.6091 - val_mse: 0.6091 - val_mae: 0.5887\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3630 - mse: 0.3630 - mae: 0.4516 - val_loss: 0.5044 - val_mse: 0.5044 - val_mae: 0.5367\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3388 - mse: 0.3388 - mae: 0.4358 - val_loss: 0.5294 - val_mse: 0.5294 - val_mae: 0.5423\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3246 - mse: 0.3246 - mae: 0.4260 - val_loss: 0.5278 - val_mse: 0.5278 - val_mae: 0.5457\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3233 - mse: 0.3233 - mae: 0.4279 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.5168\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3104 - mse: 0.3104 - mae: 0.4204 - val_loss: 0.4809 - val_mse: 0.4809 - val_mae: 0.5089\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3091 - mse: 0.3091 - mae: 0.4187 - val_loss: 0.5517 - val_mse: 0.5517 - val_mae: 0.5495\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3078 - mse: 0.3078 - mae: 0.4183 - val_loss: 0.5594 - val_mse: 0.5594 - val_mae: 0.5253\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.2881 - mse: 0.2881 - mae: 0.4033 - val_loss: 0.5053 - val_mse: 0.5053 - val_mae: 0.5348\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - ETA: 0s - loss: 0.2899 - mse: 0.2899 - mae: 0.406 - 1s 48us/sample - loss: 0.2890 - mse: 0.2890 - mae: 0.4064 - val_loss: 0.4688 - val_mse: 0.4688 - val_mae: 0.4962\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2838 - mse: 0.2838 - mae: 0.4016 - val_loss: 0.5037 - val_mse: 0.5037 - val_mae: 0.4957\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.2808 - mse: 0.2808 - mae: 0.4001 - val_loss: 0.4574 - val_mse: 0.4574 - val_mae: 0.4987\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2721 - mse: 0.2721 - mae: 0.3929 - val_loss: 0.4969 - val_mse: 0.4969 - val_mae: 0.5092\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2733 - mse: 0.2733 - mae: 0.3932 - val_loss: 0.4481 - val_mse: 0.4481 - val_mae: 0.4887\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2739 - mse: 0.2739 - mae: 0.3940 - val_loss: 0.5569 - val_mse: 0.5569 - val_mae: 0.5196\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.2787 - mse: 0.2787 - mae: 0.3986 - val_loss: 0.5457 - val_mse: 0.5457 - val_mae: 0.5150\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.2607 - mse: 0.2607 - mae: 0.3846 - val_loss: 0.4384 - val_mse: 0.4384 - val_mae: 0.4822\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2461 - mse: 0.2461 - mae: 0.3746 - val_loss: 0.5078 - val_mse: 0.5078 - val_mae: 0.5196\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.2566 - mse: 0.2566 - mae: 0.3815 - val_loss: 0.4873 - val_mse: 0.4873 - val_mae: 0.4911\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.2395 - mse: 0.2395 - mae: 0.3692 - val_loss: 0.5274 - val_mse: 0.5274 - val_mae: 0.4865\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2470 - mse: 0.2470 - mae: 0.3755 - val_loss: 0.5384 - val_mse: 0.5384 - val_mae: 0.4897\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2569 - mse: 0.2569 - mae: 0.3829 - val_loss: 0.5024 - val_mse: 0.5024 - val_mae: 0.5005\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2438 - mse: 0.2438 - mae: 0.3689 - val_loss: 0.4448 - val_mse: 0.4448 - val_mae: 0.4834\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2565 - mse: 0.2565 - mae: 0.3831 - val_loss: 0.7771 - val_mse: 0.7771 - val_mae: 0.5349\n",
      "Epoch 38/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3167 - mse: 0.3167 - mae: 0.4103 - val_loss: 0.5362 - val_mse: 0.5362 - val_mae: 0.5245\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2650 - mse: 0.2650 - mae: 0.3901 - val_loss: 0.5352 - val_mse: 0.5352 - val_mae: 0.4930\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2224 - mse: 0.2224 - mae: 0.3573 - val_loss: 0.4633 - val_mse: 0.4633 - val_mae: 0.4843\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 119us/sample - loss: 27.2758 - mse: 27.2758 - mae: 2.7815 - val_loss: 28.3443 - val_mse: 28.3443 - val_mae: 4.6295\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 53us/sample - loss: 1.5409 - mse: 1.5409 - mae: 0.9048 - val_loss: 2.6269 - val_mse: 2.6269 - val_mae: 1.0141\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.7233 - mse: 0.7233 - mae: 0.6326 - val_loss: 2.1354 - val_mse: 2.1354 - val_mae: 1.2407\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.6184 - mse: 0.6184 - mae: 0.5854 - val_loss: 1.1444 - val_mse: 1.1444 - val_mae: 0.8877\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.5752 - mse: 0.5752 - mae: 0.5634 - val_loss: 1.0220 - val_mse: 1.0220 - val_mae: 0.8430\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.5421 - mse: 0.5421 - mae: 0.5470 - val_loss: 0.8697 - val_mse: 0.8697 - val_mae: 0.7686\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.5252 - mse: 0.5252 - mae: 0.5393 - val_loss: 0.8205 - val_mse: 0.8205 - val_mae: 0.7435\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.5090 - mse: 0.5090 - mae: 0.5289 - val_loss: 0.7661 - val_mse: 0.7661 - val_mae: 0.7147\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4837 - mse: 0.4837 - mae: 0.5168 - val_loss: 0.8178 - val_mse: 0.8178 - val_mae: 0.7519\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4636 - mse: 0.4636 - mae: 0.5069 - val_loss: 0.6564 - val_mse: 0.6564 - val_mae: 0.6476\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4489 - mse: 0.4489 - mae: 0.4992 - val_loss: 0.6913 - val_mse: 0.6913 - val_mae: 0.6764\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4334 - mse: 0.4334 - mae: 0.4912 - val_loss: 0.6774 - val_mse: 0.6774 - val_mae: 0.6559\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.4136 - mse: 0.4136 - mae: 0.4787 - val_loss: 0.5892 - val_mse: 0.5892 - val_mae: 0.6131\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3983 - mse: 0.3983 - mae: 0.4708 - val_loss: 0.5864 - val_mse: 0.5864 - val_mae: 0.6125\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3823 - mse: 0.3823 - mae: 0.4621 - val_loss: 0.5185 - val_mse: 0.5185 - val_mae: 0.5515\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3812 - mse: 0.3812 - mae: 0.4620 - val_loss: 0.4853 - val_mse: 0.4853 - val_mae: 0.5203\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3603 - mse: 0.3603 - mae: 0.4466 - val_loss: 0.5254 - val_mse: 0.5254 - val_mae: 0.5725\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3519 - mse: 0.3519 - mae: 0.4410 - val_loss: 0.4664 - val_mse: 0.4664 - val_mae: 0.5129\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3478 - mse: 0.3478 - mae: 0.4386 - val_loss: 0.5048 - val_mse: 0.5048 - val_mae: 0.5441\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.3290 - mse: 0.3290 - mae: 0.4282 - val_loss: 0.4857 - val_mse: 0.4857 - val_mae: 0.5345\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.3168 - mse: 0.3168 - mae: 0.4210 - val_loss: 0.4463 - val_mse: 0.4463 - val_mae: 0.4923\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.3107 - mse: 0.3107 - mae: 0.4172 - val_loss: 0.4620 - val_mse: 0.4620 - val_mae: 0.4979\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 51us/sample - loss: 0.3136 - mse: 0.3136 - mae: 0.4195 - val_loss: 0.4419 - val_mse: 0.4419 - val_mae: 0.4899\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3033 - mse: 0.3033 - mae: 0.4099 - val_loss: 0.4596 - val_mse: 0.4596 - val_mae: 0.4967\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2886 - mse: 0.2886 - mae: 0.4019 - val_loss: 0.5009 - val_mse: 0.5009 - val_mae: 0.5437\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2918 - mse: 0.2918 - mae: 0.4086 - val_loss: 0.4625 - val_mse: 0.4625 - val_mae: 0.4901\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2834 - mse: 0.2834 - mae: 0.3979 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4871\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2940 - mse: 0.2940 - mae: 0.4050 - val_loss: 0.4698 - val_mse: 0.4698 - val_mae: 0.4969\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2803 - mse: 0.2803 - mae: 0.3968 - val_loss: 0.4638 - val_mse: 0.4638 - val_mae: 0.5088\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2886 - mse: 0.2886 - mae: 0.4082 - val_loss: 0.4861 - val_mse: 0.4861 - val_mae: 0.4967\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.2968 - mse: 0.2968 - mae: 0.4097 - val_loss: 0.4654 - val_mse: 0.4654 - val_mae: 0.5014\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2866 - mse: 0.2866 - mae: 0.4031 - val_loss: 0.4557 - val_mse: 0.4557 - val_mae: 0.4913\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2695 - mse: 0.2695 - mae: 0.3876 - val_loss: 0.4439 - val_mse: 0.4439 - val_mae: 0.4841\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 111us/sample - loss: 22.2099 - mse: 22.2099 - mae: 2.5658 - val_loss: 92.6778 - val_mse: 92.6777 - val_mae: 9.0432\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 1.4196 - mse: 1.4196 - mae: 0.8689 - val_loss: 9.3902 - val_mse: 9.3902 - val_mae: 2.8447\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.7249 - mse: 0.7249 - mae: 0.6368 - val_loss: 2.5001 - val_mse: 2.5001 - val_mae: 1.4051\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.5985 - mse: 0.5985 - mae: 0.5800 - val_loss: 1.8916 - val_mse: 1.8916 - val_mae: 1.2094\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.5590 - mse: 0.5590 - mae: 0.5596 - val_loss: 1.1961 - val_mse: 1.1961 - val_mae: 0.9387\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.5383 - mse: 0.5383 - mae: 0.5489 - val_loss: 0.9734 - val_mse: 0.9734 - val_mae: 0.8322\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.5093 - mse: 0.5093 - mae: 0.5335 - val_loss: 1.0422 - val_mse: 1.0422 - val_mae: 0.8696\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.4872 - mse: 0.4872 - mae: 0.5193 - val_loss: 0.9100 - val_mse: 0.9100 - val_mae: 0.8005\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4693 - mse: 0.4693 - mae: 0.5131 - val_loss: 0.8184 - val_mse: 0.8184 - val_mae: 0.7577\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4514 - mse: 0.4514 - mae: 0.5018 - val_loss: 0.8320 - val_mse: 0.8320 - val_mae: 0.7668\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.4323 - mse: 0.4323 - mae: 0.4918 - val_loss: 0.6337 - val_mse: 0.6337 - val_mae: 0.6378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.4178 - mse: 0.4178 - mae: 0.4835 - val_loss: 0.6211 - val_mse: 0.6211 - val_mae: 0.6196\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.4133 - mse: 0.4133 - mae: 0.4823 - val_loss: 0.6059 - val_mse: 0.6059 - val_mae: 0.6170\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3988 - mse: 0.3988 - mae: 0.4717 - val_loss: 0.5822 - val_mse: 0.5822 - val_mae: 0.6077\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3718 - mse: 0.3718 - mae: 0.4553 - val_loss: 0.5740 - val_mse: 0.5740 - val_mae: 0.5842\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3702 - mse: 0.3702 - mae: 0.4554 - val_loss: 0.5079 - val_mse: 0.5079 - val_mae: 0.5468\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3675 - mse: 0.3675 - mae: 0.4528 - val_loss: 0.5063 - val_mse: 0.5063 - val_mae: 0.5491\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.3606 - mse: 0.3606 - mae: 0.4516 - val_loss: 0.5479 - val_mse: 0.5479 - val_mae: 0.5880\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.3468 - mse: 0.3468 - mae: 0.4403 - val_loss: 0.4905 - val_mse: 0.4905 - val_mae: 0.5191\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3283 - mse: 0.3283 - mae: 0.4295 - val_loss: 0.4589 - val_mse: 0.4589 - val_mae: 0.5035\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.3279 - mse: 0.3279 - mae: 0.4277 - val_loss: 0.4601 - val_mse: 0.4601 - val_mae: 0.5104\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3256 - mse: 0.3256 - mae: 0.4243 - val_loss: 0.4614 - val_mse: 0.4614 - val_mae: 0.5048\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3056 - mse: 0.3056 - mae: 0.4137 - val_loss: 0.4822 - val_mse: 0.4822 - val_mae: 0.5219\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2985 - mse: 0.2985 - mae: 0.4102 - val_loss: 0.4429 - val_mse: 0.4429 - val_mae: 0.4992\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.2896 - mse: 0.2896 - mae: 0.4037 - val_loss: 0.4593 - val_mse: 0.4593 - val_mae: 0.5105\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.3047 - mse: 0.3047 - mae: 0.4165 - val_loss: 0.4300 - val_mse: 0.4300 - val_mae: 0.4829\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2958 - mse: 0.2958 - mae: 0.4118 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.4910\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2667 - mse: 0.2667 - mae: 0.3891 - val_loss: 0.4482 - val_mse: 0.4482 - val_mae: 0.5019\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2777 - mse: 0.2777 - mae: 0.3962 - val_loss: 0.4727 - val_mse: 0.4727 - val_mae: 0.5217\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.2730 - mse: 0.2730 - mae: 0.3949 - val_loss: 0.4549 - val_mse: 0.4549 - val_mae: 0.5077\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2670 - mse: 0.2670 - mae: 0.3894 - val_loss: 0.4510 - val_mse: 0.4510 - val_mae: 0.5039\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2715 - mse: 0.2715 - mae: 0.3913 - val_loss: 0.4659 - val_mse: 0.4659 - val_mae: 0.5044\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2706 - mse: 0.2706 - mae: 0.3925 - val_loss: 0.4477 - val_mse: 0.4477 - val_mae: 0.4925\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2692 - mse: 0.2692 - mae: 0.3933 - val_loss: 0.4432 - val_mse: 0.4432 - val_mae: 0.4824\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2847 - mse: 0.2847 - mae: 0.3975 - val_loss: 0.4408 - val_mse: 0.4408 - val_mae: 0.4792\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2485 - mse: 0.2485 - mae: 0.3700 - val_loss: 0.4233 - val_mse: 0.4233 - val_mae: 0.4789\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.2440 - mse: 0.2440 - mae: 0.3695 - val_loss: 0.4130 - val_mse: 0.4130 - val_mae: 0.4698\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2546 - mse: 0.2546 - mae: 0.3764 - val_loss: 0.4689 - val_mse: 0.4689 - val_mae: 0.5172\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2284 - mse: 0.2284 - mae: 0.3577 - val_loss: 0.4299 - val_mse: 0.4299 - val_mae: 0.4811\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2156 - mse: 0.2156 - mae: 0.3491 - val_loss: 0.4482 - val_mse: 0.4482 - val_mae: 0.4828\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2192 - mse: 0.2192 - mae: 0.3493 - val_loss: 0.4333 - val_mse: 0.4333 - val_mae: 0.4781\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2400 - mse: 0.2400 - mae: 0.3611 - val_loss: 0.5141 - val_mse: 0.5141 - val_mae: 0.5476\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2361 - mse: 0.2361 - mae: 0.3640 - val_loss: 0.4498 - val_mse: 0.4498 - val_mae: 0.4972\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2127 - mse: 0.2127 - mae: 0.3468 - val_loss: 0.4535 - val_mse: 0.4535 - val_mae: 0.4799\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1945 - mse: 0.1945 - mae: 0.3304 - val_loss: 0.4085 - val_mse: 0.4085 - val_mae: 0.4725\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1892 - mse: 0.1892 - mae: 0.3255 - val_loss: 0.4660 - val_mse: 0.4660 - val_mae: 0.4985\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2103 - mse: 0.2103 - mae: 0.3453 - val_loss: 0.4494 - val_mse: 0.4494 - val_mae: 0.4864\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1902 - mse: 0.1902 - mae: 0.3289 - val_loss: 0.4375 - val_mse: 0.4375 - val_mae: 0.4970\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.2011 - mse: 0.2011 - mae: 0.3365 - val_loss: 0.4764 - val_mse: 0.4764 - val_mae: 0.5175\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1998 - mse: 0.1998 - mae: 0.3349 - val_loss: 0.4227 - val_mse: 0.4227 - val_mae: 0.4691\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 48us/sample - loss: 0.1866 - mse: 0.1866 - mae: 0.3249 - val_loss: 0.4089 - val_mse: 0.4089 - val_mae: 0.4742\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 50us/sample - loss: 0.1814 - mse: 0.1814 - mae: 0.3213 - val_loss: 0.4299 - val_mse: 0.4299 - val_mae: 0.4738\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.1822 - mse: 0.1822 - mae: 0.3227 - val_loss: 0.4575 - val_mse: 0.4575 - val_mae: 0.4902\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 47us/sample - loss: 0.2120 - mse: 0.2120 - mae: 0.3440 - val_loss: 0.4517 - val_mse: 0.4517 - val_mae: 0.4898\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 1s 49us/sample - loss: 0.2103 - mse: 0.2103 - mae: 0.3434 - val_loss: 0.4566 - val_mse: 0.4566 - val_mae: 0.4913\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 110us/sample - loss: 29.5105 - mse: 29.5105 - mae: 2.8987 - val_loss: 71.2295 - val_mse: 71.2295 - val_mae: 7.8084\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 1.7663 - mse: 1.7663 - mae: 0.9820 - val_loss: 3.0240 - val_mse: 3.0240 - val_mae: 1.5092\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.7770 - mse: 0.7770 - mae: 0.6620 - val_loss: 3.3374 - val_mse: 3.3374 - val_mae: 1.6315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.6215 - mse: 0.6215 - mae: 0.5893 - val_loss: 1.4276 - val_mse: 1.4276 - val_mae: 1.0263\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.5761 - mse: 0.5761 - mae: 0.5663 - val_loss: 1.0264 - val_mse: 1.0264 - val_mae: 0.8542\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.5539 - mse: 0.5539 - mae: 0.5573 - val_loss: 0.9931 - val_mse: 0.9931 - val_mae: 0.8324\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.5501 - mse: 0.5501 - mae: 0.5546 - val_loss: 0.8611 - val_mse: 0.8611 - val_mae: 0.7655\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.5145 - mse: 0.5145 - mae: 0.5375 - val_loss: 0.8314 - val_mse: 0.8314 - val_mae: 0.7465\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.4929 - mse: 0.4929 - mae: 0.5241 - val_loss: 0.7119 - val_mse: 0.7119 - val_mae: 0.6892\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.4787 - mse: 0.4787 - mae: 0.5183 - val_loss: 0.7177 - val_mse: 0.7177 - val_mae: 0.6937\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.4482 - mse: 0.4482 - mae: 0.4988 - val_loss: 0.6606 - val_mse: 0.6606 - val_mae: 0.6608\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.4409 - mse: 0.4409 - mae: 0.4970 - val_loss: 0.6030 - val_mse: 0.6030 - val_mae: 0.6167\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.4249 - mse: 0.4249 - mae: 0.4857 - val_loss: 0.5479 - val_mse: 0.5479 - val_mae: 0.5784\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.4187 - mse: 0.4187 - mae: 0.4858 - val_loss: 0.5475 - val_mse: 0.5475 - val_mae: 0.5828\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.4096 - mse: 0.4096 - mae: 0.4779 - val_loss: 0.4952 - val_mse: 0.4952 - val_mae: 0.5302\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.3851 - mse: 0.3851 - mae: 0.4640 - val_loss: 0.4960 - val_mse: 0.4960 - val_mae: 0.5341\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.3708 - mse: 0.3708 - mae: 0.4527 - val_loss: 0.4942 - val_mse: 0.4942 - val_mae: 0.5258\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 47us/sample - loss: 0.3676 - mse: 0.3676 - mae: 0.4541 - val_loss: 0.5145 - val_mse: 0.5145 - val_mae: 0.5499\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 47us/sample - loss: 0.3532 - mse: 0.3532 - mae: 0.4445 - val_loss: 0.4738 - val_mse: 0.4738 - val_mae: 0.5195\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 1s 51us/sample - loss: 0.3373 - mse: 0.3373 - mae: 0.4332 - val_loss: 0.4822 - val_mse: 0.4822 - val_mae: 0.5081\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 1s 50us/sample - loss: 0.3378 - mse: 0.3378 - mae: 0.4352 - val_loss: 0.4742 - val_mse: 0.4742 - val_mae: 0.5054\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.3385 - mse: 0.3385 - mae: 0.4358 - val_loss: 0.4767 - val_mse: 0.4767 - val_mae: 0.5286\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.3261 - mse: 0.3261 - mae: 0.4276 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.5230\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 1s 51us/sample - loss: 0.3189 - mse: 0.3189 - mae: 0.4186 - val_loss: 0.5200 - val_mse: 0.5200 - val_mae: 0.5707\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.3215 - mse: 0.3215 - mae: 0.4210 - val_loss: 0.4538 - val_mse: 0.4538 - val_mae: 0.4984\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.2932 - mse: 0.2932 - mae: 0.4042 - val_loss: 0.4537 - val_mse: 0.4537 - val_mae: 0.4970\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.3103 - mse: 0.3103 - mae: 0.4173 - val_loss: 0.4642 - val_mse: 0.4642 - val_mae: 0.4924\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2988 - mse: 0.2988 - mae: 0.4083 - val_loss: 0.4601 - val_mse: 0.4601 - val_mae: 0.5000\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2899 - mse: 0.2899 - mae: 0.4036 - val_loss: 0.4440 - val_mse: 0.4440 - val_mae: 0.4893\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2819 - mse: 0.2819 - mae: 0.3971 - val_loss: 0.4296 - val_mse: 0.4296 - val_mae: 0.4798\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 1s 47us/sample - loss: 0.2742 - mse: 0.2742 - mae: 0.3902 - val_loss: 0.4507 - val_mse: 0.4507 - val_mae: 0.5001\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2740 - mse: 0.2740 - mae: 0.3918 - val_loss: 0.4163 - val_mse: 0.4163 - val_mae: 0.4700\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 47us/sample - loss: 0.2583 - mse: 0.2583 - mae: 0.3830 - val_loss: 0.4394 - val_mse: 0.4394 - val_mae: 0.4956\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.2464 - mse: 0.2464 - mae: 0.3699 - val_loss: 0.4374 - val_mse: 0.4374 - val_mae: 0.4707\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2545 - mse: 0.2545 - mae: 0.3754 - val_loss: 0.4862 - val_mse: 0.4862 - val_mae: 0.5192\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2584 - mse: 0.2584 - mae: 0.3814 - val_loss: 0.4436 - val_mse: 0.4436 - val_mae: 0.4803\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2463 - mse: 0.2463 - mae: 0.3750 - val_loss: 0.4393 - val_mse: 0.4393 - val_mae: 0.4764\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2250 - mse: 0.2250 - mae: 0.3566 - val_loss: 0.4342 - val_mse: 0.4342 - val_mae: 0.4685\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2358 - mse: 0.2358 - mae: 0.3663 - val_loss: 0.4375 - val_mse: 0.4375 - val_mae: 0.4741\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2290 - mse: 0.2290 - mae: 0.3586 - val_loss: 0.4174 - val_mse: 0.4174 - val_mae: 0.4533\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.2293 - mse: 0.2293 - mae: 0.3574 - val_loss: 0.4079 - val_mse: 0.4079 - val_mae: 0.4546\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 0s 47us/sample - loss: 0.2177 - mse: 0.2177 - mae: 0.3517 - val_loss: 0.4385 - val_mse: 0.4385 - val_mae: 0.4700\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 0s 47us/sample - loss: 0.2187 - mse: 0.2187 - mae: 0.3508 - val_loss: 0.4452 - val_mse: 0.4452 - val_mae: 0.4887\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2252 - mse: 0.2252 - mae: 0.3528 - val_loss: 0.4867 - val_mse: 0.4867 - val_mae: 0.4985\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2273 - mse: 0.2273 - mae: 0.3507 - val_loss: 0.4616 - val_mse: 0.4616 - val_mae: 0.4910\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 1s 51us/sample - loss: 0.2328 - mse: 0.2328 - mae: 0.3520 - val_loss: 0.4191 - val_mse: 0.4191 - val_mae: 0.4670\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 1s 53us/sample - loss: 0.2150 - mse: 0.2150 - mae: 0.3443 - val_loss: 0.4351 - val_mse: 0.4351 - val_mae: 0.4701\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2285 - mse: 0.2285 - mae: 0.3479 - val_loss: 0.5075 - val_mse: 0.5075 - val_mae: 0.5127\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 1s 48us/sample - loss: 0.2229 - mse: 0.2229 - mae: 0.3521 - val_loss: 0.4352 - val_mse: 0.4352 - val_mae: 0.4726\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.2050 - mse: 0.2050 - mae: 0.3387 - val_loss: 0.4339 - val_mse: 0.4339 - val_mae: 0.4727\n",
      "Epoch 51/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 1s 49us/sample - loss: 0.2090 - mse: 0.2090 - mae: 0.3439 - val_loss: 0.4770 - val_mse: 0.4770 - val_mae: 0.5041\n",
      "Avg. MAE: 0.415049\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 7s 639us/sample - loss: 1.6613 - mse: 1.6613 - mae: 0.9601 - val_loss: 1.0415 - val_mse: 1.0415 - val_mae: 0.8073\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.8271 - mse: 0.8271 - mae: 0.6347 - val_loss: 1.0118 - val_mse: 1.0118 - val_mae: 0.7540\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.5222 - mse: 0.5222 - mae: 0.5023 - val_loss: 0.9356 - val_mse: 0.9356 - val_mae: 0.7340\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.4305 - mse: 0.4305 - mae: 0.4434 - val_loss: 0.9384 - val_mse: 0.9384 - val_mae: 0.7407\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.3254 - mse: 0.3254 - mae: 0.4024 - val_loss: 0.9238 - val_mse: 0.9238 - val_mae: 0.7306\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 5s 440us/sample - loss: 0.2549 - mse: 0.2549 - mae: 0.3581 - val_loss: 0.9004 - val_mse: 0.9004 - val_mae: 0.7241\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.2269 - mse: 0.2269 - mae: 0.3352 - val_loss: 0.8505 - val_mse: 0.8505 - val_mae: 0.7062\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.1875 - mse: 0.1875 - mae: 0.3134 - val_loss: 0.8006 - val_mse: 0.8006 - val_mae: 0.6779\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.1834 - mse: 0.1834 - mae: 0.3121 - val_loss: 0.7509 - val_mse: 0.7509 - val_mae: 0.6630\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.1709 - mse: 0.1709 - mae: 0.3009 - val_loss: 0.7080 - val_mse: 0.7080 - val_mae: 0.6438\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.1584 - mse: 0.1584 - mae: 0.2893 - val_loss: 0.6822 - val_mse: 0.6822 - val_mae: 0.6266\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 5s 438us/sample - loss: 0.1535 - mse: 0.1535 - mae: 0.2802 - val_loss: 0.6186 - val_mse: 0.6186 - val_mae: 0.6056\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 5s 438us/sample - loss: 0.1462 - mse: 0.1462 - mae: 0.2716 - val_loss: 0.5912 - val_mse: 0.5912 - val_mae: 0.5911\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.1383 - mse: 0.1383 - mae: 0.2668 - val_loss: 0.5566 - val_mse: 0.5566 - val_mae: 0.5733\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.1326 - mse: 0.1326 - mae: 0.2649 - val_loss: 0.5419 - val_mse: 0.5419 - val_mae: 0.5618\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.1187 - mse: 0.1187 - mae: 0.2546 - val_loss: 0.5145 - val_mse: 0.5145 - val_mae: 0.5432\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.1215 - mse: 0.1215 - mae: 0.2540 - val_loss: 0.5166 - val_mse: 0.5166 - val_mae: 0.5427\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 5s 436us/sample - loss: 0.1136 - mse: 0.1136 - mae: 0.2450 - val_loss: 0.4972 - val_mse: 0.4972 - val_mae: 0.5327\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.1070 - mse: 0.1070 - mae: 0.2406 - val_loss: 0.4926 - val_mse: 0.4926 - val_mae: 0.5308\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.1055 - mse: 0.1055 - mae: 0.2341 - val_loss: 0.4938 - val_mse: 0.4938 - val_mae: 0.5250\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.1072 - mse: 0.1072 - mae: 0.2387 - val_loss: 0.5213 - val_mse: 0.5213 - val_mae: 0.5261\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.1124 - mse: 0.1124 - mae: 0.2378 - val_loss: 0.4829 - val_mse: 0.4829 - val_mae: 0.5124\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 5s 434us/sample - loss: 0.1070 - mse: 0.1070 - mae: 0.2321 - val_loss: 0.4823 - val_mse: 0.4823 - val_mae: 0.5167\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.1293 - mse: 0.1293 - mae: 0.2429 - val_loss: 0.4879 - val_mse: 0.4879 - val_mae: 0.5148\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.1082 - mse: 0.1082 - mae: 0.2374 - val_loss: 0.4719 - val_mse: 0.4719 - val_mae: 0.5054\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 5s 438us/sample - loss: 0.1034 - mse: 0.1034 - mae: 0.2332 - val_loss: 0.4653 - val_mse: 0.4653 - val_mae: 0.5048\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.1000 - mse: 0.1000 - mae: 0.2305 - val_loss: 0.4907 - val_mse: 0.4907 - val_mae: 0.5143\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0941 - mse: 0.0941 - mae: 0.2230 - val_loss: 0.4626 - val_mse: 0.4626 - val_mae: 0.4984\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0886 - mse: 0.0886 - mae: 0.2191 - val_loss: 0.4617 - val_mse: 0.4617 - val_mae: 0.5056\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 5s 434us/sample - loss: 0.0882 - mse: 0.0882 - mae: 0.2176 - val_loss: 0.4807 - val_mse: 0.4807 - val_mae: 0.4998\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0854 - mse: 0.0854 - mae: 0.2131 - val_loss: 0.4581 - val_mse: 0.4581 - val_mae: 0.4919\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 5s 439us/sample - loss: 0.0810 - mse: 0.0810 - mae: 0.2075 - val_loss: 0.4403 - val_mse: 0.4403 - val_mae: 0.4841\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0820 - mse: 0.0820 - mae: 0.2116 - val_loss: 0.4746 - val_mse: 0.4746 - val_mae: 0.4986\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0743 - mse: 0.0743 - mae: 0.2015 - val_loss: 0.4395 - val_mse: 0.4395 - val_mae: 0.4809\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0741 - mse: 0.0741 - mae: 0.2026 - val_loss: 0.4450 - val_mse: 0.4450 - val_mae: 0.4847\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 5s 434us/sample - loss: 0.0696 - mse: 0.0696 - mae: 0.1975 - val_loss: 0.4331 - val_mse: 0.4331 - val_mae: 0.4813\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0696 - mse: 0.0696 - mae: 0.1968 - val_loss: 0.4305 - val_mse: 0.4305 - val_mae: 0.4757\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0710 - mse: 0.0710 - mae: 0.1980 - val_loss: 0.4413 - val_mse: 0.4413 - val_mae: 0.4810\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 5s 439us/sample - loss: 0.0677 - mse: 0.0677 - mae: 0.1925 - val_loss: 0.4214 - val_mse: 0.4214 - val_mae: 0.4714\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0628 - mse: 0.0628 - mae: 0.1859 - val_loss: 0.4343 - val_mse: 0.4343 - val_mae: 0.4782\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0675 - mse: 0.0675 - mae: 0.1929 - val_loss: 0.4281 - val_mse: 0.4281 - val_mae: 0.4768\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0652 - mse: 0.0652 - mae: 0.1873 - val_loss: 0.4190 - val_mse: 0.4190 - val_mae: 0.4723\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.0654 - mse: 0.0654 - mae: 0.1889 - val_loss: 0.4524 - val_mse: 0.4524 - val_mae: 0.4852\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0658 - mse: 0.0658 - mae: 0.1874 - val_loss: 0.4289 - val_mse: 0.4289 - val_mae: 0.4725\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0641 - mse: 0.0641 - mae: 0.1885 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4700\n",
      "Epoch 46/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0635 - mse: 0.0635 - mae: 0.1869 - val_loss: 0.4215 - val_mse: 0.4215 - val_mae: 0.4698\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0614 - mse: 0.0614 - mae: 0.1842 - val_loss: 0.4258 - val_mse: 0.4258 - val_mae: 0.4694\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0590 - mse: 0.0590 - mae: 0.1779 - val_loss: 0.4439 - val_mse: 0.4439 - val_mae: 0.4752\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0627 - mse: 0.0627 - mae: 0.1831 - val_loss: 0.4406 - val_mse: 0.4406 - val_mae: 0.4768\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0581 - mse: 0.0581 - mae: 0.1783 - val_loss: 0.4248 - val_mse: 0.4248 - val_mae: 0.4706\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 5s 434us/sample - loss: 0.0573 - mse: 0.0573 - mae: 0.1763 - val_loss: 0.4036 - val_mse: 0.4036 - val_mae: 0.4568\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 5s 439us/sample - loss: 0.0561 - mse: 0.0561 - mae: 0.1753 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.4674\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0592 - mse: 0.0592 - mae: 0.1796 - val_loss: 0.4002 - val_mse: 0.4002 - val_mae: 0.4566\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0537 - mse: 0.0537 - mae: 0.1713 - val_loss: 0.4134 - val_mse: 0.4134 - val_mae: 0.4672\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0540 - mse: 0.0540 - mae: 0.1733 - val_loss: 0.4026 - val_mse: 0.4026 - val_mae: 0.4577\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.0534 - mse: 0.0534 - mae: 0.1741 - val_loss: 0.4095 - val_mse: 0.4095 - val_mae: 0.4626\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0532 - mse: 0.0532 - mae: 0.1721 - val_loss: 0.4040 - val_mse: 0.4040 - val_mae: 0.4571\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 5s 437us/sample - loss: 0.0495 - mse: 0.0495 - mae: 0.1658 - val_loss: 0.3962 - val_mse: 0.3962 - val_mae: 0.4559\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0485 - mse: 0.0485 - mae: 0.1657 - val_loss: 0.4020 - val_mse: 0.4020 - val_mae: 0.4540\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.0502 - mse: 0.0502 - mae: 0.1669 - val_loss: 0.4076 - val_mse: 0.4076 - val_mae: 0.4606\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 5s 438us/sample - loss: 0.0515 - mse: 0.0515 - mae: 0.1703 - val_loss: 0.3913 - val_mse: 0.3913 - val_mae: 0.4496\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0502 - mse: 0.0502 - mae: 0.1639 - val_loss: 0.4049 - val_mse: 0.4049 - val_mae: 0.4557\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0460 - mse: 0.0460 - mae: 0.1590 - val_loss: 0.3903 - val_mse: 0.3903 - val_mae: 0.4478\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0491 - mse: 0.0491 - mae: 0.1651 - val_loss: 0.3943 - val_mse: 0.3943 - val_mae: 0.4506\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 5s 437us/sample - loss: 0.0524 - mse: 0.0524 - mae: 0.1681 - val_loss: 0.3906 - val_mse: 0.3906 - val_mae: 0.4479\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0513 - mse: 0.0513 - mae: 0.1670 - val_loss: 0.3979 - val_mse: 0.3979 - val_mae: 0.4548\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0480 - mse: 0.0480 - mae: 0.1622 - val_loss: 0.4001 - val_mse: 0.4001 - val_mae: 0.4539\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0440 - mse: 0.0440 - mae: 0.1572 - val_loss: 0.3944 - val_mse: 0.3944 - val_mae: 0.4493\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 5s 436us/sample - loss: 0.0455 - mse: 0.0455 - mae: 0.1592 - val_loss: 0.3994 - val_mse: 0.3994 - val_mae: 0.4496\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 5s 451us/sample - loss: 0.0443 - mse: 0.0443 - mae: 0.1546 - val_loss: 0.3876 - val_mse: 0.3876 - val_mae: 0.4498\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 5s 438us/sample - loss: 0.0470 - mse: 0.0470 - mae: 0.1605 - val_loss: 0.3961 - val_mse: 0.3961 - val_mae: 0.4493\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0452 - mse: 0.0452 - mae: 0.1581 - val_loss: 0.3789 - val_mse: 0.3789 - val_mae: 0.4433\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0448 - mse: 0.0448 - mae: 0.1568 - val_loss: 0.4250 - val_mse: 0.4250 - val_mae: 0.4599\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0462 - mse: 0.0462 - mae: 0.1595 - val_loss: 0.4052 - val_mse: 0.4052 - val_mae: 0.4523\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0491 - mse: 0.0491 - mae: 0.1641 - val_loss: 0.3804 - val_mse: 0.3804 - val_mae: 0.4444\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0496 - mse: 0.0496 - mae: 0.1647 - val_loss: 0.3886 - val_mse: 0.3886 - val_mae: 0.4456\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.0468 - mse: 0.0468 - mae: 0.1629 - val_loss: 0.3811 - val_mse: 0.3811 - val_mae: 0.4444\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 5s 435us/sample - loss: 0.0423 - mse: 0.0423 - mae: 0.1541 - val_loss: 0.3782 - val_mse: 0.3782 - val_mae: 0.4399\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 5s 439us/sample - loss: 0.0405 - mse: 0.0405 - mae: 0.1517 - val_loss: 0.3804 - val_mse: 0.3804 - val_mae: 0.4360\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 5s 428us/sample - loss: 0.0419 - mse: 0.0419 - mae: 0.1528 - val_loss: 0.3898 - val_mse: 0.3898 - val_mae: 0.4429\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0412 - mse: 0.0412 - mae: 0.1515 - val_loss: 0.3804 - val_mse: 0.3804 - val_mae: 0.4401\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0414 - mse: 0.0414 - mae: 0.1497 - val_loss: 0.3837 - val_mse: 0.3837 - val_mae: 0.4394\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 5s 435us/sample - loss: 0.0403 - mse: 0.0403 - mae: 0.1501 - val_loss: 0.3731 - val_mse: 0.3731 - val_mae: 0.4363\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 5s 439us/sample - loss: 0.0399 - mse: 0.0399 - mae: 0.1474 - val_loss: 0.3717 - val_mse: 0.3717 - val_mae: 0.4353\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0416 - mse: 0.0416 - mae: 0.1499 - val_loss: 0.3755 - val_mse: 0.3755 - val_mae: 0.4378\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 5s 437us/sample - loss: 0.0388 - mse: 0.0388 - mae: 0.1471 - val_loss: 0.3755 - val_mse: 0.3755 - val_mae: 0.4403\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0418 - mse: 0.0418 - mae: 0.1508 - val_loss: 0.3853 - val_mse: 0.3853 - val_mae: 0.4434\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0446 - mse: 0.0446 - mae: 0.1574 - val_loss: 0.3765 - val_mse: 0.3765 - val_mae: 0.4364\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.0404 - mse: 0.0404 - mae: 0.1498 - val_loss: 0.3724 - val_mse: 0.3724 - val_mae: 0.4390\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0416 - mse: 0.0416 - mae: 0.1490 - val_loss: 0.3705 - val_mse: 0.3705 - val_mae: 0.4367\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0410 - mse: 0.0410 - mae: 0.1508 - val_loss: 0.3935 - val_mse: 0.3935 - val_mae: 0.4489\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 5s 438us/sample - loss: 0.0434 - mse: 0.0434 - mae: 0.1556 - val_loss: 0.3655 - val_mse: 0.3655 - val_mae: 0.4335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 5s 428us/sample - loss: 0.0422 - mse: 0.0422 - mae: 0.1511 - val_loss: 0.3900 - val_mse: 0.3900 - val_mae: 0.4431\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0436 - mse: 0.0436 - mae: 0.1532 - val_loss: 0.3675 - val_mse: 0.3675 - val_mae: 0.4311\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0385 - mse: 0.0385 - mae: 0.1467 - val_loss: 0.3777 - val_mse: 0.3777 - val_mae: 0.4364\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0392 - mse: 0.0392 - mae: 0.1455 - val_loss: 0.3665 - val_mse: 0.3665 - val_mae: 0.4335\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0388 - mse: 0.0388 - mae: 0.1472 - val_loss: 0.3768 - val_mse: 0.3768 - val_mae: 0.4352\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0383 - mse: 0.0383 - mae: 0.1467 - val_loss: 0.3640 - val_mse: 0.3640 - val_mae: 0.4294\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0330 - mse: 0.0330 - mae: 0.1342 - val_loss: 0.3753 - val_mse: 0.3753 - val_mae: 0.4337\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0329 - mse: 0.0329 - mae: 0.1338 - val_loss: 0.3801 - val_mse: 0.3801 - val_mae: 0.4320\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0340 - mse: 0.0340 - mae: 0.1369 - val_loss: 0.3669 - val_mse: 0.3669 - val_mae: 0.4312\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 5s 434us/sample - loss: 0.0363 - mse: 0.0363 - mae: 0.1413 - val_loss: 0.3669 - val_mse: 0.3669 - val_mae: 0.4295\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.0352 - mse: 0.0352 - mae: 0.1361 - val_loss: 0.3886 - val_mse: 0.3886 - val_mae: 0.4387\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0395 - mse: 0.0395 - mae: 0.1452 - val_loss: 0.3704 - val_mse: 0.3704 - val_mae: 0.4340\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 5s 438us/sample - loss: 0.0397 - mse: 0.0397 - mae: 0.1428 - val_loss: 0.3739 - val_mse: 0.3739 - val_mae: 0.4331\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0373 - mse: 0.0373 - mae: 0.1419 - val_loss: 0.3711 - val_mse: 0.3711 - val_mae: 0.4337\n",
      "Epoch 107/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0372 - mse: 0.0372 - mae: 0.1433 - val_loss: 0.3678 - val_mse: 0.3678 - val_mae: 0.4280\n",
      "Epoch 108/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0344 - mse: 0.0344 - mae: 0.1360 - val_loss: 0.3711 - val_mse: 0.3711 - val_mae: 0.4330\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 6s 585us/sample - loss: 1.6753 - mse: 1.6753 - mae: 0.9552 - val_loss: 1.0983 - val_mse: 1.0983 - val_mae: 0.8353\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.8257 - mse: 0.8257 - mae: 0.6301 - val_loss: 1.0084 - val_mse: 1.0084 - val_mae: 0.7689\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.5175 - mse: 0.5175 - mae: 0.5021 - val_loss: 0.9763 - val_mse: 0.9763 - val_mae: 0.7358\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.4137 - mse: 0.4137 - mae: 0.4510 - val_loss: 0.9717 - val_mse: 0.9717 - val_mae: 0.7364\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.3316 - mse: 0.3316 - mae: 0.4019 - val_loss: 0.9781 - val_mse: 0.9781 - val_mae: 0.7408\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.2684 - mse: 0.2684 - mae: 0.3660 - val_loss: 0.9302 - val_mse: 0.9302 - val_mae: 0.7243\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.2457 - mse: 0.2457 - mae: 0.3456 - val_loss: 0.8846 - val_mse: 0.8846 - val_mae: 0.7059\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.2113 - mse: 0.2113 - mae: 0.3258 - val_loss: 0.8428 - val_mse: 0.8428 - val_mae: 0.6961\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.1857 - mse: 0.1857 - mae: 0.3089 - val_loss: 0.8378 - val_mse: 0.8378 - val_mae: 0.6762\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 5s 438us/sample - loss: 0.1776 - mse: 0.1776 - mae: 0.2977 - val_loss: 0.7273 - val_mse: 0.7273 - val_mae: 0.6362\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.1705 - mse: 0.1705 - mae: 0.2901 - val_loss: 0.7340 - val_mse: 0.7340 - val_mae: 0.6191\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.1662 - mse: 0.1662 - mae: 0.2852 - val_loss: 0.6346 - val_mse: 0.6346 - val_mae: 0.5979\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 5s 434us/sample - loss: 0.1599 - mse: 0.1599 - mae: 0.2792 - val_loss: 0.6777 - val_mse: 0.6777 - val_mae: 0.5918\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.1552 - mse: 0.1552 - mae: 0.2744 - val_loss: 0.5784 - val_mse: 0.5784 - val_mae: 0.5746\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.1334 - mse: 0.1334 - mae: 0.2631 - val_loss: 0.5594 - val_mse: 0.5594 - val_mae: 0.5598\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.1259 - mse: 0.1259 - mae: 0.2579 - val_loss: 0.5824 - val_mse: 0.5824 - val_mae: 0.5487\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.1182 - mse: 0.1182 - mae: 0.2517 - val_loss: 0.5422 - val_mse: 0.5422 - val_mae: 0.5360\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.1112 - mse: 0.1112 - mae: 0.2395 - val_loss: 0.5478 - val_mse: 0.5478 - val_mae: 0.5272\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.1179 - mse: 0.1179 - mae: 0.2451 - val_loss: 0.5794 - val_mse: 0.5794 - val_mae: 0.5289\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.1088 - mse: 0.1088 - mae: 0.2367 - val_loss: 0.5004 - val_mse: 0.5004 - val_mae: 0.5210\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.1010 - mse: 0.1010 - mae: 0.2313 - val_loss: 0.5762 - val_mse: 0.5762 - val_mae: 0.5201\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.1020 - mse: 0.1020 - mae: 0.2356 - val_loss: 0.5086 - val_mse: 0.5086 - val_mae: 0.5044\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 5s 438us/sample - loss: 0.0987 - mse: 0.0987 - mae: 0.2300 - val_loss: 0.5931 - val_mse: 0.5931 - val_mae: 0.5068\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.1025 - mse: 0.1025 - mae: 0.2342 - val_loss: 0.5465 - val_mse: 0.5465 - val_mae: 0.5186\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.1027 - mse: 0.1027 - mae: 0.2299 - val_loss: 0.4934 - val_mse: 0.4934 - val_mae: 0.5008\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0980 - mse: 0.0980 - mae: 0.2262 - val_loss: 0.5009 - val_mse: 0.5009 - val_mae: 0.4996\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 5s 435us/sample - loss: 0.0860 - mse: 0.0860 - mae: 0.2145 - val_loss: 0.5107 - val_mse: 0.5107 - val_mae: 0.4935\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0798 - mse: 0.0798 - mae: 0.2076 - val_loss: 0.5361 - val_mse: 0.5361 - val_mae: 0.4949\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0805 - mse: 0.0805 - mae: 0.2089 - val_loss: 0.4652 - val_mse: 0.4652 - val_mae: 0.4883\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0723 - mse: 0.0723 - mae: 0.1995 - val_loss: 0.4896 - val_mse: 0.4896 - val_mae: 0.4855\n",
      "Epoch 31/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 5s 428us/sample - loss: 0.0723 - mse: 0.0723 - mae: 0.2002 - val_loss: 0.4944 - val_mse: 0.4944 - val_mae: 0.4933\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0733 - mse: 0.0733 - mae: 0.2004 - val_loss: 0.5167 - val_mse: 0.5167 - val_mae: 0.4879\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0715 - mse: 0.0715 - mae: 0.1981 - val_loss: 0.4616 - val_mse: 0.4616 - val_mae: 0.4827\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0729 - mse: 0.0729 - mae: 0.1992 - val_loss: 0.5515 - val_mse: 0.5515 - val_mae: 0.4819\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0756 - mse: 0.0756 - mae: 0.2027 - val_loss: 0.4582 - val_mse: 0.4582 - val_mae: 0.4780\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 6s 580us/sample - loss: 0.0726 - mse: 0.0726 - mae: 0.1983 - val_loss: 0.5077 - val_mse: 0.5077 - val_mae: 0.4841\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 5s 489us/sample - loss: 0.0699 - mse: 0.0699 - mae: 0.1958 - val_loss: 0.4568 - val_mse: 0.4568 - val_mae: 0.4751\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 5s 468us/sample - loss: 0.0721 - mse: 0.0721 - mae: 0.2006 - val_loss: 0.4791 - val_mse: 0.4791 - val_mae: 0.4793\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 5s 458us/sample - loss: 0.0665 - mse: 0.0665 - mae: 0.1906 - val_loss: 0.4909 - val_mse: 0.4909 - val_mae: 0.4835\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 5s 451us/sample - loss: 0.0675 - mse: 0.0675 - mae: 0.1948 - val_loss: 0.4648 - val_mse: 0.4648 - val_mae: 0.4786\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 5s 449us/sample - loss: 0.0661 - mse: 0.0661 - mae: 0.1921 - val_loss: 0.4807 - val_mse: 0.4807 - val_mae: 0.4807\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 5s 494us/sample - loss: 0.0591 - mse: 0.0591 - mae: 0.1826 - val_loss: 0.4792 - val_mse: 0.4792 - val_mae: 0.4746\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 5s 507us/sample - loss: 0.0604 - mse: 0.0604 - mae: 0.1814 - val_loss: 0.4664 - val_mse: 0.4664 - val_mae: 0.4764\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 5s 465us/sample - loss: 0.0594 - mse: 0.0594 - mae: 0.1822 - val_loss: 0.4661 - val_mse: 0.4661 - val_mae: 0.4763\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 6s 517us/sample - loss: 0.0603 - mse: 0.0603 - mae: 0.1816 - val_loss: 0.5247 - val_mse: 0.5247 - val_mae: 0.4767\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 5s 493us/sample - loss: 0.0650 - mse: 0.0650 - mae: 0.1899 - val_loss: 0.4672 - val_mse: 0.4672 - val_mae: 0.4732\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 5s 446us/sample - loss: 0.0633 - mse: 0.0633 - mae: 0.1872 - val_loss: 0.4816 - val_mse: 0.4816 - val_mae: 0.4757\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 7s 612us/sample - loss: 1.6014 - mse: 1.6014 - mae: 0.9373 - val_loss: 1.1326 - val_mse: 1.1326 - val_mae: 0.8684\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 5s 494us/sample - loss: 0.8094 - mse: 0.8094 - mae: 0.6202 - val_loss: 1.0244 - val_mse: 1.0244 - val_mae: 0.7945\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 5s 502us/sample - loss: 0.5329 - mse: 0.5329 - mae: 0.5090 - val_loss: 0.9811 - val_mse: 0.9811 - val_mae: 0.7547\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 6s 551us/sample - loss: 0.4243 - mse: 0.4243 - mae: 0.4521 - val_loss: 0.9933 - val_mse: 0.9933 - val_mae: 0.7551\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.3272 - mse: 0.3272 - mae: 0.3977 - val_loss: 0.9943 - val_mse: 0.9943 - val_mae: 0.7646\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 5s 437us/sample - loss: 0.2944 - mse: 0.2944 - mae: 0.3710 - val_loss: 0.9587 - val_mse: 0.9587 - val_mae: 0.7479\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.2681 - mse: 0.2681 - mae: 0.3598 - val_loss: 0.9370 - val_mse: 0.9370 - val_mae: 0.7308\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.2369 - mse: 0.2369 - mae: 0.3399 - val_loss: 0.8478 - val_mse: 0.8478 - val_mae: 0.7065\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.2001 - mse: 0.2001 - mae: 0.3186 - val_loss: 0.7756 - val_mse: 0.7756 - val_mae: 0.6685\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.1824 - mse: 0.1824 - mae: 0.3057 - val_loss: 0.7402 - val_mse: 0.7402 - val_mae: 0.6695\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.1617 - mse: 0.1617 - mae: 0.2884 - val_loss: 0.6918 - val_mse: 0.6918 - val_mae: 0.6337\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.1438 - mse: 0.1438 - mae: 0.2734 - val_loss: 0.6379 - val_mse: 0.6379 - val_mae: 0.6147\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 5s 438us/sample - loss: 0.1341 - mse: 0.1341 - mae: 0.2622 - val_loss: 0.6198 - val_mse: 0.6198 - val_mae: 0.5998\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 5s 435us/sample - loss: 0.1244 - mse: 0.1244 - mae: 0.2588 - val_loss: 0.5917 - val_mse: 0.5917 - val_mae: 0.5830\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.1133 - mse: 0.1133 - mae: 0.2501 - val_loss: 0.5555 - val_mse: 0.5555 - val_mae: 0.5642\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 5s 455us/sample - loss: 0.1139 - mse: 0.1139 - mae: 0.2490 - val_loss: 0.5563 - val_mse: 0.5563 - val_mae: 0.5656\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 5s 474us/sample - loss: 0.1108 - mse: 0.1108 - mae: 0.2449 - val_loss: 0.5303 - val_mse: 0.5303 - val_mae: 0.5360\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 5s 476us/sample - loss: 0.1055 - mse: 0.1055 - mae: 0.2385 - val_loss: 0.5187 - val_mse: 0.5187 - val_mae: 0.5264\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 5s 448us/sample - loss: 0.0998 - mse: 0.0998 - mae: 0.2335 - val_loss: 0.5077 - val_mse: 0.5077 - val_mae: 0.5162\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0948 - mse: 0.0948 - mae: 0.2306 - val_loss: 0.5076 - val_mse: 0.5076 - val_mae: 0.5167\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 5s 434us/sample - loss: 0.1022 - mse: 0.1022 - mae: 0.2346 - val_loss: 0.4990 - val_mse: 0.4990 - val_mae: 0.5090\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 5s 438us/sample - loss: 0.1051 - mse: 0.1051 - mae: 0.2373 - val_loss: 0.4971 - val_mse: 0.4971 - val_mae: 0.5032\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 5s 441us/sample - loss: 0.0993 - mse: 0.0993 - mae: 0.2276 - val_loss: 0.5297 - val_mse: 0.5297 - val_mae: 0.5072\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 5s 469us/sample - loss: 0.0933 - mse: 0.0933 - mae: 0.2237 - val_loss: 0.4837 - val_mse: 0.4837 - val_mae: 0.4968\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 5s 446us/sample - loss: 0.0888 - mse: 0.0888 - mae: 0.2174 - val_loss: 0.4888 - val_mse: 0.4888 - val_mae: 0.4950\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 5s 462us/sample - loss: 0.0928 - mse: 0.0928 - mae: 0.2205 - val_loss: 0.4904 - val_mse: 0.4904 - val_mae: 0.5027\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 5s 479us/sample - loss: 0.0939 - mse: 0.0939 - mae: 0.2182 - val_loss: 0.5253 - val_mse: 0.5253 - val_mae: 0.4928\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 5s 468us/sample - loss: 0.0956 - mse: 0.0956 - mae: 0.2213 - val_loss: 0.4951 - val_mse: 0.4951 - val_mae: 0.4904\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 6s 587us/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2131 - val_loss: 0.4861 - val_mse: 0.4861 - val_mae: 0.4924\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 5s 500us/sample - loss: 0.0881 - mse: 0.0881 - mae: 0.2076 - val_loss: 0.4805 - val_mse: 0.4805 - val_mae: 0.4887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 5s 461us/sample - loss: 0.0832 - mse: 0.0832 - mae: 0.2031 - val_loss: 0.4739 - val_mse: 0.4739 - val_mae: 0.4891\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 5s 474us/sample - loss: 0.0921 - mse: 0.0921 - mae: 0.2196 - val_loss: 0.4837 - val_mse: 0.4837 - val_mae: 0.4879\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 6s 600us/sample - loss: 0.1138 - mse: 0.1138 - mae: 0.2272 - val_loss: 0.4708 - val_mse: 0.4708 - val_mae: 0.4842\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 5s 468us/sample - loss: 0.0994 - mse: 0.0994 - mae: 0.2214 - val_loss: 0.4736 - val_mse: 0.4736 - val_mae: 0.4877\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 5s 473us/sample - loss: 0.0782 - mse: 0.0782 - mae: 0.2093 - val_loss: 0.4842 - val_mse: 0.4842 - val_mae: 0.4879\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 7s 618us/sample - loss: 0.0712 - mse: 0.0712 - mae: 0.1987 - val_loss: 0.4662 - val_mse: 0.4662 - val_mae: 0.4777\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 5s 499us/sample - loss: 0.0697 - mse: 0.0697 - mae: 0.1966 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.4750\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 5s 467us/sample - loss: 0.0667 - mse: 0.0667 - mae: 0.1913 - val_loss: 0.4607 - val_mse: 0.4607 - val_mae: 0.4775\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 5s 471us/sample - loss: 0.0705 - mse: 0.0705 - mae: 0.1952 - val_loss: 0.4710 - val_mse: 0.4710 - val_mae: 0.4751\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 7s 617us/sample - loss: 0.0640 - mse: 0.0640 - mae: 0.1898 - val_loss: 0.4835 - val_mse: 0.4835 - val_mae: 0.4769\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 5s 464us/sample - loss: 0.0600 - mse: 0.0600 - mae: 0.1844 - val_loss: 0.4408 - val_mse: 0.4408 - val_mae: 0.4710\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 5s 476us/sample - loss: 0.0563 - mse: 0.0563 - mae: 0.1795 - val_loss: 0.4402 - val_mse: 0.4402 - val_mae: 0.4688\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 6s 588us/sample - loss: 0.0558 - mse: 0.0558 - mae: 0.1782 - val_loss: 0.4423 - val_mse: 0.4423 - val_mae: 0.4651\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 5s 505us/sample - loss: 0.0526 - mse: 0.0526 - mae: 0.1746 - val_loss: 0.4490 - val_mse: 0.4490 - val_mae: 0.4659\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 5s 459us/sample - loss: 0.0553 - mse: 0.0553 - mae: 0.1777 - val_loss: 0.4463 - val_mse: 0.4463 - val_mae: 0.4665\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0583 - mse: 0.0583 - mae: 0.1813 - val_loss: 0.4366 - val_mse: 0.4366 - val_mae: 0.4664\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 5s 462us/sample - loss: 0.0525 - mse: 0.0525 - mae: 0.1737 - val_loss: 0.4361 - val_mse: 0.4361 - val_mae: 0.4584\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 5s 465us/sample - loss: 0.0572 - mse: 0.0572 - mae: 0.1797 - val_loss: 0.4332 - val_mse: 0.4332 - val_mae: 0.4628\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 5s 481us/sample - loss: 0.0534 - mse: 0.0534 - mae: 0.1743 - val_loss: 0.4415 - val_mse: 0.4415 - val_mae: 0.4628\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 5s 444us/sample - loss: 0.0596 - mse: 0.0596 - mae: 0.1839 - val_loss: 0.4448 - val_mse: 0.4448 - val_mae: 0.4647\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 5s 459us/sample - loss: 0.0537 - mse: 0.0537 - mae: 0.1747 - val_loss: 0.4278 - val_mse: 0.4278 - val_mae: 0.4572\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 5s 458us/sample - loss: 0.0518 - mse: 0.0518 - mae: 0.1736 - val_loss: 0.4439 - val_mse: 0.4439 - val_mae: 0.4657\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 5s 493us/sample - loss: 0.0499 - mse: 0.0499 - mae: 0.1688 - val_loss: 0.4271 - val_mse: 0.4271 - val_mae: 0.4549\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 5s 447us/sample - loss: 0.0530 - mse: 0.0530 - mae: 0.1726 - val_loss: 0.4547 - val_mse: 0.4547 - val_mae: 0.4677\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 5s 485us/sample - loss: 0.0552 - mse: 0.0552 - mae: 0.1732 - val_loss: 0.4288 - val_mse: 0.4288 - val_mae: 0.4619\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 5s 478us/sample - loss: 0.0557 - mse: 0.0557 - mae: 0.1785 - val_loss: 0.4508 - val_mse: 0.4508 - val_mae: 0.4659\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 5s 458us/sample - loss: 0.0494 - mse: 0.0494 - mae: 0.1671 - val_loss: 0.4279 - val_mse: 0.4279 - val_mae: 0.4569\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 5s 442us/sample - loss: 0.0452 - mse: 0.0452 - mae: 0.1606 - val_loss: 0.4192 - val_mse: 0.4192 - val_mae: 0.4496\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0469 - mse: 0.0469 - mae: 0.1639 - val_loss: 0.4188 - val_mse: 0.4188 - val_mae: 0.4501\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 5s 453us/sample - loss: 0.0465 - mse: 0.0465 - mae: 0.1633 - val_loss: 0.4201 - val_mse: 0.4201 - val_mae: 0.4519\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 5s 446us/sample - loss: 0.0483 - mse: 0.0483 - mae: 0.1661 - val_loss: 0.4070 - val_mse: 0.4070 - val_mae: 0.4467\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 5s 442us/sample - loss: 0.0500 - mse: 0.0500 - mae: 0.1642 - val_loss: 0.4302 - val_mse: 0.4302 - val_mae: 0.4617\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 5s 468us/sample - loss: 0.0533 - mse: 0.0533 - mae: 0.1677 - val_loss: 0.4474 - val_mse: 0.4474 - val_mae: 0.4576\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 5s 456us/sample - loss: 0.0530 - mse: 0.0530 - mae: 0.1731 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4491\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0444 - mse: 0.0444 - mae: 0.1609 - val_loss: 0.4089 - val_mse: 0.4089 - val_mae: 0.4477\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 5s 495us/sample - loss: 0.0439 - mse: 0.0439 - mae: 0.1575 - val_loss: 0.4074 - val_mse: 0.4074 - val_mae: 0.4467\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 5s 441us/sample - loss: 0.0445 - mse: 0.0445 - mae: 0.1610 - val_loss: 0.4147 - val_mse: 0.4147 - val_mae: 0.4488\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 5s 462us/sample - loss: 0.0467 - mse: 0.0467 - mae: 0.1629 - val_loss: 0.4459 - val_mse: 0.4459 - val_mae: 0.4529\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 5s 471us/sample - loss: 0.0492 - mse: 0.0492 - mae: 0.1658 - val_loss: 0.4122 - val_mse: 0.4122 - val_mae: 0.4499\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 5s 466us/sample - loss: 0.0469 - mse: 0.0469 - mae: 0.1598 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.4523\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0470 - mse: 0.0470 - mae: 0.1602 - val_loss: 0.4078 - val_mse: 0.4078 - val_mae: 0.4469\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 6s 589us/sample - loss: 1.6753 - mse: 1.6753 - mae: 0.9644 - val_loss: 1.0713 - val_mse: 1.0713 - val_mae: 0.8262\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 5s 478us/sample - loss: 0.8192 - mse: 0.8192 - mae: 0.6367 - val_loss: 1.0205 - val_mse: 1.0205 - val_mae: 0.8110\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 6s 517us/sample - loss: 0.5609 - mse: 0.5609 - mae: 0.5190 - val_loss: 0.9884 - val_mse: 0.9884 - val_mae: 0.7865\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 5s 500us/sample - loss: 0.4122 - mse: 0.4122 - mae: 0.4476 - val_loss: 0.9643 - val_mse: 0.9643 - val_mae: 0.7634\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 6s 573us/sample - loss: 0.3011 - mse: 0.3011 - mae: 0.3908 - val_loss: 0.9695 - val_mse: 0.9695 - val_mae: 0.7579\n",
      "Epoch 6/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 6s 566us/sample - loss: 0.2631 - mse: 0.2631 - mae: 0.3631 - val_loss: 0.9362 - val_mse: 0.9362 - val_mae: 0.7399\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 7s 651us/sample - loss: 0.2373 - mse: 0.2373 - mae: 0.3393 - val_loss: 0.9018 - val_mse: 0.9018 - val_mae: 0.7358\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 7s 649us/sample - loss: 0.2197 - mse: 0.2197 - mae: 0.3266 - val_loss: 0.8546 - val_mse: 0.8546 - val_mae: 0.7069\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 6s 610us/sample - loss: 0.2047 - mse: 0.2047 - mae: 0.3181 - val_loss: 0.7844 - val_mse: 0.7844 - val_mae: 0.6687\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 7s 665us/sample - loss: 0.1710 - mse: 0.1710 - mae: 0.3008 - val_loss: 0.7172 - val_mse: 0.7172 - val_mae: 0.6460\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 8s 706us/sample - loss: 0.1642 - mse: 0.1642 - mae: 0.2894 - val_loss: 0.6669 - val_mse: 0.6669 - val_mae: 0.6211\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 7s 638us/sample - loss: 0.1513 - mse: 0.1513 - mae: 0.2805 - val_loss: 0.6323 - val_mse: 0.6323 - val_mae: 0.5992\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 6s 556us/sample - loss: 0.1395 - mse: 0.1395 - mae: 0.2687 - val_loss: 0.5978 - val_mse: 0.5978 - val_mae: 0.5860\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 6s 557us/sample - loss: 0.1374 - mse: 0.1374 - mae: 0.2701 - val_loss: 0.5347 - val_mse: 0.5347 - val_mae: 0.5487\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 5s 505us/sample - loss: 0.1573 - mse: 0.1573 - mae: 0.2759 - val_loss: 0.5490 - val_mse: 0.5490 - val_mae: 0.5517\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 5s 489us/sample - loss: 0.1449 - mse: 0.1449 - mae: 0.2698 - val_loss: 0.5167 - val_mse: 0.5167 - val_mae: 0.5399\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 5s 481us/sample - loss: 0.1362 - mse: 0.1362 - mae: 0.2626 - val_loss: 0.5203 - val_mse: 0.5203 - val_mae: 0.5419\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 5s 475us/sample - loss: 0.1204 - mse: 0.1204 - mae: 0.2472 - val_loss: 0.5045 - val_mse: 0.5045 - val_mae: 0.5348\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 5s 461us/sample - loss: 0.1111 - mse: 0.1111 - mae: 0.2425 - val_loss: 0.4857 - val_mse: 0.4857 - val_mae: 0.5170\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 5s 488us/sample - loss: 0.1119 - mse: 0.1119 - mae: 0.2395 - val_loss: 0.4759 - val_mse: 0.4759 - val_mae: 0.5046\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 6s 532us/sample - loss: 0.1035 - mse: 0.1035 - mae: 0.2346 - val_loss: 0.4748 - val_mse: 0.4748 - val_mae: 0.5057\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 5s 482us/sample - loss: 0.1002 - mse: 0.1002 - mae: 0.2369 - val_loss: 0.4572 - val_mse: 0.4572 - val_mae: 0.4970\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 5s 480us/sample - loss: 0.0911 - mse: 0.0911 - mae: 0.2232 - val_loss: 0.4627 - val_mse: 0.4627 - val_mae: 0.4946\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 5s 499us/sample - loss: 0.0917 - mse: 0.0917 - mae: 0.2231 - val_loss: 0.4715 - val_mse: 0.4715 - val_mae: 0.4976\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 5s 483us/sample - loss: 0.0918 - mse: 0.0918 - mae: 0.2214 - val_loss: 0.4542 - val_mse: 0.4542 - val_mae: 0.4886\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 5s 492us/sample - loss: 0.0856 - mse: 0.0856 - mae: 0.2183 - val_loss: 0.4592 - val_mse: 0.4592 - val_mae: 0.4906\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 5s 470us/sample - loss: 0.0856 - mse: 0.0856 - mae: 0.2159 - val_loss: 0.4625 - val_mse: 0.4625 - val_mae: 0.4882\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 5s 465us/sample - loss: 0.0843 - mse: 0.0843 - mae: 0.2148 - val_loss: 0.4609 - val_mse: 0.4609 - val_mae: 0.4882\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 5s 456us/sample - loss: 0.0797 - mse: 0.0797 - mae: 0.2112 - val_loss: 0.4544 - val_mse: 0.4544 - val_mae: 0.4792\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 5s 456us/sample - loss: 0.0784 - mse: 0.0784 - mae: 0.2068 - val_loss: 0.4560 - val_mse: 0.4560 - val_mae: 0.4788\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 5s 463us/sample - loss: 0.0745 - mse: 0.0745 - mae: 0.2039 - val_loss: 0.4600 - val_mse: 0.4600 - val_mae: 0.4814\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 5s 461us/sample - loss: 0.0743 - mse: 0.0743 - mae: 0.2034 - val_loss: 0.4502 - val_mse: 0.4502 - val_mae: 0.4776\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 5s 466us/sample - loss: 0.0743 - mse: 0.0743 - mae: 0.2062 - val_loss: 0.4688 - val_mse: 0.4688 - val_mae: 0.4811\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 5s 468us/sample - loss: 0.0729 - mse: 0.0729 - mae: 0.2029 - val_loss: 0.4610 - val_mse: 0.4610 - val_mae: 0.4826\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 5s 453us/sample - loss: 0.0734 - mse: 0.0734 - mae: 0.2025 - val_loss: 0.4522 - val_mse: 0.4522 - val_mae: 0.4769\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 5s 460us/sample - loss: 0.0705 - mse: 0.0705 - mae: 0.1997 - val_loss: 0.4616 - val_mse: 0.4616 - val_mae: 0.4805\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 5s 466us/sample - loss: 0.0686 - mse: 0.0686 - mae: 0.1967 - val_loss: 0.4498 - val_mse: 0.4498 - val_mae: 0.4725\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 5s 455us/sample - loss: 0.0657 - mse: 0.0657 - mae: 0.1909 - val_loss: 0.4443 - val_mse: 0.4443 - val_mae: 0.4676\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 5s 457us/sample - loss: 0.0703 - mse: 0.0703 - mae: 0.1961 - val_loss: 0.4511 - val_mse: 0.4511 - val_mae: 0.4760\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 5s 456us/sample - loss: 0.0697 - mse: 0.0697 - mae: 0.1962 - val_loss: 0.4423 - val_mse: 0.4423 - val_mae: 0.4732\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 5s 454us/sample - loss: 0.0708 - mse: 0.0708 - mae: 0.1946 - val_loss: 0.4436 - val_mse: 0.4436 - val_mae: 0.4705\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 5s 455us/sample - loss: 0.0641 - mse: 0.0641 - mae: 0.1890 - val_loss: 0.4469 - val_mse: 0.4469 - val_mae: 0.4702\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 5s 460us/sample - loss: 0.0646 - mse: 0.0646 - mae: 0.1879 - val_loss: 0.4335 - val_mse: 0.4335 - val_mae: 0.4714\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 5s 455us/sample - loss: 0.0641 - mse: 0.0641 - mae: 0.1879 - val_loss: 0.4449 - val_mse: 0.4449 - val_mae: 0.4654\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 5s 456us/sample - loss: 0.0595 - mse: 0.0595 - mae: 0.1818 - val_loss: 0.4416 - val_mse: 0.4416 - val_mae: 0.4655\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 5s 471us/sample - loss: 0.0610 - mse: 0.0610 - mae: 0.1842 - val_loss: 0.4332 - val_mse: 0.4332 - val_mae: 0.4679\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 7s 621us/sample - loss: 0.0590 - mse: 0.0590 - mae: 0.1806 - val_loss: 0.4490 - val_mse: 0.4490 - val_mae: 0.4738\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 6s 534us/sample - loss: 0.0582 - mse: 0.0582 - mae: 0.1793 - val_loss: 0.4286 - val_mse: 0.4286 - val_mae: 0.4643\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 6s 550us/sample - loss: 0.0599 - mse: 0.0599 - mae: 0.1833 - val_loss: 0.4415 - val_mse: 0.4415 - val_mae: 0.4689\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 6s 533us/sample - loss: 0.0600 - mse: 0.0600 - mae: 0.1822 - val_loss: 0.4357 - val_mse: 0.4357 - val_mae: 0.4633\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 5s 513us/sample - loss: 0.0570 - mse: 0.0570 - mae: 0.1768 - val_loss: 0.4452 - val_mse: 0.4452 - val_mae: 0.4603\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 6s 589us/sample - loss: 0.0563 - mse: 0.0563 - mae: 0.1758 - val_loss: 0.4235 - val_mse: 0.4235 - val_mae: 0.4599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 5s 480us/sample - loss: 0.0566 - mse: 0.0566 - mae: 0.1777 - val_loss: 0.4358 - val_mse: 0.4358 - val_mae: 0.4625\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 5s 462us/sample - loss: 0.0537 - mse: 0.0537 - mae: 0.1725 - val_loss: 0.4086 - val_mse: 0.4086 - val_mae: 0.4518\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 5s 462us/sample - loss: 0.0519 - mse: 0.0519 - mae: 0.1695 - val_loss: 0.4247 - val_mse: 0.4247 - val_mae: 0.4551\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 5s 440us/sample - loss: 0.0517 - mse: 0.0517 - mae: 0.1688 - val_loss: 0.4128 - val_mse: 0.4128 - val_mae: 0.4555\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 5s 435us/sample - loss: 0.0524 - mse: 0.0524 - mae: 0.1709 - val_loss: 0.4175 - val_mse: 0.4175 - val_mae: 0.4529\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 5s 434us/sample - loss: 0.0528 - mse: 0.0528 - mae: 0.1712 - val_loss: 0.4162 - val_mse: 0.4162 - val_mae: 0.4520\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 5s 440us/sample - loss: 0.0517 - mse: 0.0517 - mae: 0.1671 - val_loss: 0.3989 - val_mse: 0.3989 - val_mae: 0.4475\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 5s 446us/sample - loss: 0.0556 - mse: 0.0556 - mae: 0.1766 - val_loss: 0.4064 - val_mse: 0.4064 - val_mae: 0.4571\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 5s 437us/sample - loss: 0.0543 - mse: 0.0543 - mae: 0.1719 - val_loss: 0.4078 - val_mse: 0.4078 - val_mae: 0.4545\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0536 - mse: 0.0536 - mae: 0.1728 - val_loss: 0.4143 - val_mse: 0.4143 - val_mae: 0.4520\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 5s 444us/sample - loss: 0.0487 - mse: 0.0487 - mae: 0.1657 - val_loss: 0.3860 - val_mse: 0.3860 - val_mae: 0.4432\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 5s 436us/sample - loss: 0.0468 - mse: 0.0468 - mae: 0.1614 - val_loss: 0.3877 - val_mse: 0.3877 - val_mae: 0.4437\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0477 - mse: 0.0477 - mae: 0.1609 - val_loss: 0.4185 - val_mse: 0.4185 - val_mae: 0.4578\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0513 - mse: 0.0513 - mae: 0.1686 - val_loss: 0.3967 - val_mse: 0.3967 - val_mae: 0.4507\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0508 - mse: 0.0508 - mae: 0.1629 - val_loss: 0.3980 - val_mse: 0.3980 - val_mae: 0.4406\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0529 - mse: 0.0529 - mae: 0.1684 - val_loss: 0.3980 - val_mse: 0.3980 - val_mae: 0.4460\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 5s 429us/sample - loss: 0.0494 - mse: 0.0494 - mae: 0.1658 - val_loss: 0.3949 - val_mse: 0.3949 - val_mae: 0.4427\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 5s 431us/sample - loss: 0.0462 - mse: 0.0462 - mae: 0.1614 - val_loss: 0.3946 - val_mse: 0.3946 - val_mae: 0.4425\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0451 - mse: 0.0451 - mae: 0.1573 - val_loss: 0.3974 - val_mse: 0.3974 - val_mae: 0.4397\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 5s 434us/sample - loss: 0.0438 - mse: 0.0438 - mae: 0.1552 - val_loss: 0.3832 - val_mse: 0.3832 - val_mae: 0.4360\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 5s 456us/sample - loss: 0.0431 - mse: 0.0431 - mae: 0.1537 - val_loss: 0.3908 - val_mse: 0.3908 - val_mae: 0.4428\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0455 - mse: 0.0455 - mae: 0.1579 - val_loss: 0.3900 - val_mse: 0.3900 - val_mae: 0.4416\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 5s 433us/sample - loss: 0.0453 - mse: 0.0453 - mae: 0.1565 - val_loss: 0.3846 - val_mse: 0.3846 - val_mae: 0.4355\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 5s 434us/sample - loss: 0.0455 - mse: 0.0455 - mae: 0.1580 - val_loss: 0.3906 - val_mse: 0.3906 - val_mae: 0.4440\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0469 - mse: 0.0469 - mae: 0.1615 - val_loss: 0.3887 - val_mse: 0.3887 - val_mae: 0.4372\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0453 - mse: 0.0453 - mae: 0.1591 - val_loss: 0.3891 - val_mse: 0.3891 - val_mae: 0.4452\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0424 - mse: 0.0424 - mae: 0.1545 - val_loss: 0.3850 - val_mse: 0.3850 - val_mae: 0.4340\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0396 - mse: 0.0396 - mae: 0.1483 - val_loss: 0.3763 - val_mse: 0.3763 - val_mae: 0.4334\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 5s 430us/sample - loss: 0.0393 - mse: 0.0393 - mae: 0.1479 - val_loss: 0.3855 - val_mse: 0.3855 - val_mae: 0.4366\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0429 - mse: 0.0429 - mae: 0.1526 - val_loss: 0.3788 - val_mse: 0.3788 - val_mae: 0.4312\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 5s 436us/sample - loss: 0.0405 - mse: 0.0405 - mae: 0.1487 - val_loss: 0.3938 - val_mse: 0.3938 - val_mae: 0.4397\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0418 - mse: 0.0418 - mae: 0.1534 - val_loss: 0.3874 - val_mse: 0.3874 - val_mae: 0.4363\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 5s 432us/sample - loss: 0.0418 - mse: 0.0418 - mae: 0.1511 - val_loss: 0.3905 - val_mse: 0.3905 - val_mae: 0.4385\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 5s 438us/sample - loss: 0.0465 - mse: 0.0465 - mae: 0.1579 - val_loss: 0.3793 - val_mse: 0.3793 - val_mae: 0.4327\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 5s 453us/sample - loss: 0.0423 - mse: 0.0423 - mae: 0.1523 - val_loss: 0.3875 - val_mse: 0.3875 - val_mae: 0.4335\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 5s 439us/sample - loss: 0.0410 - mse: 0.0410 - mae: 0.1507 - val_loss: 0.4051 - val_mse: 0.4051 - val_mae: 0.4445\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 5s 435us/sample - loss: 0.0441 - mse: 0.0441 - mae: 0.1577 - val_loss: 0.3792 - val_mse: 0.3792 - val_mae: 0.4314\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 5s 434us/sample - loss: 0.0401 - mse: 0.0401 - mae: 0.1481 - val_loss: 0.3858 - val_mse: 0.3858 - val_mae: 0.4330\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 7s 645us/sample - loss: 1.6818 - mse: 1.6818 - mae: 0.9660 - val_loss: 1.0922 - val_mse: 1.0922 - val_mae: 0.7725\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 5s 435us/sample - loss: 0.8669 - mse: 0.8669 - mae: 0.6460 - val_loss: 1.0211 - val_mse: 1.0211 - val_mae: 0.7765\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 5s 434us/sample - loss: 0.5293 - mse: 0.5293 - mae: 0.5059 - val_loss: 0.9888 - val_mse: 0.9888 - val_mae: 0.7636\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 5s 452us/sample - loss: 0.3805 - mse: 0.3805 - mae: 0.4349 - val_loss: 1.0029 - val_mse: 1.0029 - val_mae: 0.7652\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 5s 444us/sample - loss: 0.3291 - mse: 0.3291 - mae: 0.3982 - val_loss: 0.9799 - val_mse: 0.9799 - val_mae: 0.7614\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 5s 438us/sample - loss: 0.2703 - mse: 0.2703 - mae: 0.3598 - val_loss: 0.9517 - val_mse: 0.9517 - val_mae: 0.7483\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 5s 436us/sample - loss: 0.2215 - mse: 0.2215 - mae: 0.3344 - val_loss: 0.9290 - val_mse: 0.9290 - val_mae: 0.7418\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 5s 452us/sample - loss: 0.2111 - mse: 0.2111 - mae: 0.3237 - val_loss: 0.8600 - val_mse: 0.8600 - val_mae: 0.7109\n",
      "Epoch 9/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 5s 432us/sample - loss: 0.1890 - mse: 0.1890 - mae: 0.3117 - val_loss: 0.8423 - val_mse: 0.8423 - val_mae: 0.7119\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 5s 433us/sample - loss: 0.1742 - mse: 0.1742 - mae: 0.2979 - val_loss: 0.7698 - val_mse: 0.7698 - val_mae: 0.6794\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.1573 - mse: 0.1573 - mae: 0.2836 - val_loss: 0.7377 - val_mse: 0.7377 - val_mae: 0.6698\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 5s 432us/sample - loss: 0.1405 - mse: 0.1405 - mae: 0.2756 - val_loss: 0.6768 - val_mse: 0.6768 - val_mae: 0.6400\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.1334 - mse: 0.1334 - mae: 0.2599 - val_loss: 0.6660 - val_mse: 0.6660 - val_mae: 0.6362\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 5s 434us/sample - loss: 0.1369 - mse: 0.1369 - mae: 0.2617 - val_loss: 0.5951 - val_mse: 0.5951 - val_mae: 0.5933\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 5s 433us/sample - loss: 0.1286 - mse: 0.1286 - mae: 0.2578 - val_loss: 0.5587 - val_mse: 0.5587 - val_mae: 0.5721\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 5s 435us/sample - loss: 0.1139 - mse: 0.1139 - mae: 0.2502 - val_loss: 0.5205 - val_mse: 0.5205 - val_mae: 0.5472\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.1119 - mse: 0.1119 - mae: 0.2457 - val_loss: 0.5643 - val_mse: 0.5643 - val_mae: 0.5582\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 5s 434us/sample - loss: 0.1169 - mse: 0.1169 - mae: 0.2467 - val_loss: 0.5007 - val_mse: 0.5007 - val_mae: 0.5295\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.1086 - mse: 0.1086 - mae: 0.2415 - val_loss: 0.5071 - val_mse: 0.5071 - val_mae: 0.5299\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.1051 - mse: 0.1051 - mae: 0.2355 - val_loss: 0.5059 - val_mse: 0.5059 - val_mae: 0.5209\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.1000 - mse: 0.1000 - mae: 0.2325 - val_loss: 0.4697 - val_mse: 0.4697 - val_mae: 0.4936\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 5s 440us/sample - loss: 0.1007 - mse: 0.1007 - mae: 0.2283 - val_loss: 0.4539 - val_mse: 0.4539 - val_mae: 0.4952\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 5s 433us/sample - loss: 0.0943 - mse: 0.0943 - mae: 0.2284 - val_loss: 0.4532 - val_mse: 0.4532 - val_mae: 0.4874\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 5s 433us/sample - loss: 0.0899 - mse: 0.0899 - mae: 0.2218 - val_loss: 0.4503 - val_mse: 0.4503 - val_mae: 0.4938\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 5s 446us/sample - loss: 0.0846 - mse: 0.0846 - mae: 0.2142 - val_loss: 0.4532 - val_mse: 0.4532 - val_mae: 0.4886\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 5s 439us/sample - loss: 0.0833 - mse: 0.0833 - mae: 0.2138 - val_loss: 0.4383 - val_mse: 0.4383 - val_mae: 0.4740\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 5s 433us/sample - loss: 0.0909 - mse: 0.0909 - mae: 0.2196 - val_loss: 0.4631 - val_mse: 0.4631 - val_mae: 0.4911\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.0908 - mse: 0.0908 - mae: 0.2193 - val_loss: 0.4318 - val_mse: 0.4318 - val_mae: 0.4722\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 5s 432us/sample - loss: 0.0881 - mse: 0.0881 - mae: 0.2175 - val_loss: 0.4332 - val_mse: 0.4332 - val_mae: 0.4670\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 5s 432us/sample - loss: 0.0890 - mse: 0.0890 - mae: 0.2154 - val_loss: 0.4474 - val_mse: 0.4474 - val_mae: 0.4676\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 5s 436us/sample - loss: 0.0842 - mse: 0.0842 - mae: 0.2120 - val_loss: 0.4317 - val_mse: 0.4317 - val_mae: 0.4667\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.0797 - mse: 0.0797 - mae: 0.2080 - val_loss: 0.4634 - val_mse: 0.4634 - val_mae: 0.4885\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 5s 434us/sample - loss: 0.0824 - mse: 0.0824 - mae: 0.2135 - val_loss: 0.4345 - val_mse: 0.4345 - val_mae: 0.4625\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 5s 438us/sample - loss: 0.0750 - mse: 0.0750 - mae: 0.2037 - val_loss: 0.4274 - val_mse: 0.4274 - val_mae: 0.4590\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 5s 438us/sample - loss: 0.0708 - mse: 0.0708 - mae: 0.1982 - val_loss: 0.4281 - val_mse: 0.4281 - val_mae: 0.4635\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 5s 432us/sample - loss: 0.0702 - mse: 0.0702 - mae: 0.1978 - val_loss: 0.4281 - val_mse: 0.4281 - val_mae: 0.4613\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 5s 433us/sample - loss: 0.0733 - mse: 0.0733 - mae: 0.2022 - val_loss: 0.4234 - val_mse: 0.4234 - val_mae: 0.4617\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 5s 432us/sample - loss: 0.0691 - mse: 0.0691 - mae: 0.1976 - val_loss: 0.4371 - val_mse: 0.4371 - val_mae: 0.4649\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 5s 429us/sample - loss: 0.0671 - mse: 0.0671 - mae: 0.1939 - val_loss: 0.4220 - val_mse: 0.4220 - val_mae: 0.4594\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 5s 432us/sample - loss: 0.0662 - mse: 0.0662 - mae: 0.1928 - val_loss: 0.4109 - val_mse: 0.4109 - val_mae: 0.4535\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 5s 429us/sample - loss: 0.0631 - mse: 0.0631 - mae: 0.1888 - val_loss: 0.4275 - val_mse: 0.4275 - val_mae: 0.4547\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 5s 445us/sample - loss: 0.0654 - mse: 0.0654 - mae: 0.1895 - val_loss: 0.4304 - val_mse: 0.4304 - val_mae: 0.4619\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 5s 433us/sample - loss: 0.0624 - mse: 0.0624 - mae: 0.1870 - val_loss: 0.4189 - val_mse: 0.4189 - val_mae: 0.4564\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.0639 - mse: 0.0639 - mae: 0.1880 - val_loss: 0.4098 - val_mse: 0.4098 - val_mae: 0.4489\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 5s 432us/sample - loss: 0.0582 - mse: 0.0582 - mae: 0.1793 - val_loss: 0.4042 - val_mse: 0.4042 - val_mae: 0.4502\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 5s 435us/sample - loss: 0.0594 - mse: 0.0594 - mae: 0.1826 - val_loss: 0.3949 - val_mse: 0.3949 - val_mae: 0.4431\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.0580 - mse: 0.0580 - mae: 0.1787 - val_loss: 0.4027 - val_mse: 0.4027 - val_mae: 0.4497\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 5s 437us/sample - loss: 0.0592 - mse: 0.0592 - mae: 0.1815 - val_loss: 0.4155 - val_mse: 0.4155 - val_mae: 0.4515\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.0572 - mse: 0.0572 - mae: 0.1797 - val_loss: 0.3996 - val_mse: 0.3996 - val_mae: 0.4414\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 5s 429us/sample - loss: 0.0559 - mse: 0.0559 - mae: 0.1759 - val_loss: 0.4074 - val_mse: 0.4074 - val_mae: 0.4446\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.0539 - mse: 0.0539 - mae: 0.1744 - val_loss: 0.4146 - val_mse: 0.4146 - val_mae: 0.4484\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.0557 - mse: 0.0557 - mae: 0.1765 - val_loss: 0.4126 - val_mse: 0.4126 - val_mae: 0.4507\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 5s 430us/sample - loss: 0.0510 - mse: 0.0510 - mae: 0.1696 - val_loss: 0.3984 - val_mse: 0.3984 - val_mae: 0.4385\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 5s 433us/sample - loss: 0.0548 - mse: 0.0548 - mae: 0.1744 - val_loss: 0.4082 - val_mse: 0.4082 - val_mae: 0.4505\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.0557 - mse: 0.0557 - mae: 0.1746 - val_loss: 0.3952 - val_mse: 0.3952 - val_mae: 0.4396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 5s 431us/sample - loss: 0.0494 - mse: 0.0494 - mae: 0.1654 - val_loss: 0.4087 - val_mse: 0.4087 - val_mae: 0.4457\n",
      "Avg. MAE: 0.392699\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 250us/sample - loss: 2.7876 - mse: 2.7876 - mae: 1.0387 - val_loss: 5.7848 - val_mse: 5.7848 - val_mae: 1.9744\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.4933 - mse: 0.4933 - mae: 0.5258 - val_loss: 1.0500 - val_mse: 1.0500 - val_mae: 0.7808\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 126us/sample - loss: 0.3951 - mse: 0.3951 - mae: 0.4658 - val_loss: 0.9753 - val_mse: 0.9753 - val_mae: 0.7972\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.3675 - mse: 0.3675 - mae: 0.4532 - val_loss: 0.8203 - val_mse: 0.8203 - val_mae: 0.7379\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 126us/sample - loss: 0.3027 - mse: 0.3027 - mae: 0.4118 - val_loss: 0.6511 - val_mse: 0.6511 - val_mae: 0.6496\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 125us/sample - loss: 0.2700 - mse: 0.2700 - mae: 0.3917 - val_loss: 0.5632 - val_mse: 0.5632 - val_mae: 0.6019\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.2525 - mse: 0.2525 - mae: 0.3755 - val_loss: 0.5143 - val_mse: 0.5143 - val_mae: 0.5611\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 125us/sample - loss: 0.2314 - mse: 0.2314 - mae: 0.3600 - val_loss: 0.4657 - val_mse: 0.4657 - val_mae: 0.5301\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 129us/sample - loss: 0.2157 - mse: 0.2157 - mae: 0.3478 - val_loss: 0.4032 - val_mse: 0.4032 - val_mae: 0.4755\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1840 - mse: 0.1840 - mae: 0.3246 - val_loss: 0.4380 - val_mse: 0.4380 - val_mae: 0.5006\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.1795 - mse: 0.1795 - mae: 0.3175 - val_loss: 0.4014 - val_mse: 0.4014 - val_mae: 0.4696\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.1719 - mse: 0.1719 - mae: 0.3092 - val_loss: 0.4022 - val_mse: 0.4022 - val_mae: 0.4738\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.1787 - mse: 0.1787 - mae: 0.3181 - val_loss: 0.4170 - val_mse: 0.4170 - val_mae: 0.4712\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.1475 - mse: 0.1475 - mae: 0.2906 - val_loss: 0.3891 - val_mse: 0.3891 - val_mae: 0.4598\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 129us/sample - loss: 0.1330 - mse: 0.1330 - mae: 0.2731 - val_loss: 0.3973 - val_mse: 0.3973 - val_mae: 0.4585\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.1375 - mse: 0.1375 - mae: 0.2793 - val_loss: 0.3606 - val_mse: 0.3606 - val_mae: 0.4361\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 125us/sample - loss: 0.1181 - mse: 0.1181 - mae: 0.2580 - val_loss: 0.3828 - val_mse: 0.3828 - val_mae: 0.4592\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.1261 - mse: 0.1261 - mae: 0.2659 - val_loss: 0.3702 - val_mse: 0.3702 - val_mae: 0.4327\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 125us/sample - loss: 0.1147 - mse: 0.1147 - mae: 0.2554 - val_loss: 0.3668 - val_mse: 0.3668 - val_mae: 0.4384\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1076 - mse: 0.1076 - mae: 0.2453 - val_loss: 0.3818 - val_mse: 0.3818 - val_mae: 0.4453\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.1067 - mse: 0.1067 - mae: 0.2433 - val_loss: 0.3725 - val_mse: 0.3725 - val_mae: 0.4401\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 125us/sample - loss: 0.1158 - mse: 0.1158 - mae: 0.2534 - val_loss: 0.3731 - val_mse: 0.3731 - val_mae: 0.4390\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 125us/sample - loss: 0.1035 - mse: 0.1035 - mae: 0.2399 - val_loss: 0.3659 - val_mse: 0.3659 - val_mae: 0.4346\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0975 - mse: 0.0975 - mae: 0.2331 - val_loss: 0.4241 - val_mse: 0.4241 - val_mae: 0.4783\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.0955 - mse: 0.0955 - mae: 0.2306 - val_loss: 0.3772 - val_mse: 0.3772 - val_mae: 0.4435\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0835 - mse: 0.0835 - mae: 0.2181 - val_loss: 0.3659 - val_mse: 0.3659 - val_mae: 0.4280\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 247us/sample - loss: 2.4024 - mse: 2.4024 - mae: 1.0003 - val_loss: 1.2721 - val_mse: 1.2721 - val_mae: 0.8789\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.4896 - mse: 0.4896 - mae: 0.5262 - val_loss: 1.2497 - val_mse: 1.2497 - val_mae: 0.8449\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.3960 - mse: 0.3960 - mae: 0.4721 - val_loss: 1.1277 - val_mse: 1.1277 - val_mae: 0.7971\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.3472 - mse: 0.3472 - mae: 0.4443 - val_loss: 0.8029 - val_mse: 0.8029 - val_mae: 0.7071\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.3178 - mse: 0.3178 - mae: 0.4234 - val_loss: 0.7434 - val_mse: 0.7434 - val_mae: 0.6529\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.2926 - mse: 0.2926 - mae: 0.4076 - val_loss: 0.6453 - val_mse: 0.6453 - val_mae: 0.6229\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 127us/sample - loss: 0.2550 - mse: 0.2550 - mae: 0.3808 - val_loss: 0.4882 - val_mse: 0.4882 - val_mae: 0.5064\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.2398 - mse: 0.2398 - mae: 0.3691 - val_loss: 0.5416 - val_mse: 0.5416 - val_mae: 0.4965\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.2107 - mse: 0.2107 - mae: 0.3464 - val_loss: 0.5692 - val_mse: 0.5692 - val_mae: 0.5264\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 125us/sample - loss: 0.2123 - mse: 0.2123 - mae: 0.3472 - val_loss: 0.4362 - val_mse: 0.4362 - val_mae: 0.4738\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.1923 - mse: 0.1923 - mae: 0.3290 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4738\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1653 - mse: 0.1653 - mae: 0.3044 - val_loss: 0.4300 - val_mse: 0.4300 - val_mae: 0.4626\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1556 - mse: 0.1556 - mae: 0.2968 - val_loss: 0.4656 - val_mse: 0.4656 - val_mae: 0.4702\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1585 - mse: 0.1585 - mae: 0.3018 - val_loss: 0.4562 - val_mse: 0.4562 - val_mae: 0.4740\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.1692 - mse: 0.1692 - mae: 0.3095 - val_loss: 0.4787 - val_mse: 0.4787 - val_mae: 0.4818\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.1498 - mse: 0.1498 - mae: 0.2894 - val_loss: 0.4154 - val_mse: 0.4154 - val_mae: 0.4488\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.1328 - mse: 0.1328 - mae: 0.2751 - val_loss: 0.4137 - val_mse: 0.4137 - val_mae: 0.4442\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1274 - mse: 0.1274 - mae: 0.2675 - val_loss: 0.3917 - val_mse: 0.3917 - val_mae: 0.4382\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.1210 - mse: 0.1210 - mae: 0.2611 - val_loss: 0.4546 - val_mse: 0.4546 - val_mae: 0.4607\n",
      "Epoch 20/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1141 - mse: 0.1141 - mae: 0.2555 - val_loss: 0.4580 - val_mse: 0.4580 - val_mae: 0.4603\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.1095 - mse: 0.1095 - mae: 0.2492 - val_loss: 0.4084 - val_mse: 0.4084 - val_mae: 0.4486\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.1053 - mse: 0.1053 - mae: 0.2424 - val_loss: 0.4318 - val_mse: 0.4318 - val_mae: 0.4594\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1043 - mse: 0.1043 - mae: 0.2437 - val_loss: 0.4353 - val_mse: 0.4353 - val_mae: 0.4571\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0999 - mse: 0.0999 - mae: 0.2379 - val_loss: 0.4086 - val_mse: 0.4086 - val_mae: 0.4490\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0987 - mse: 0.0987 - mae: 0.2342 - val_loss: 0.3954 - val_mse: 0.3954 - val_mae: 0.4262\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.0945 - mse: 0.0945 - mae: 0.2287 - val_loss: 0.3966 - val_mse: 0.3966 - val_mae: 0.4384\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0912 - mse: 0.0912 - mae: 0.2264 - val_loss: 0.3949 - val_mse: 0.3949 - val_mae: 0.4416\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.0881 - mse: 0.0881 - mae: 0.2209 - val_loss: 0.4126 - val_mse: 0.4126 - val_mae: 0.4451\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 250us/sample - loss: 2.5343 - mse: 2.5343 - mae: 1.0048 - val_loss: 6.7042 - val_mse: 6.7042 - val_mae: 2.3023\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.5079 - mse: 0.5079 - mae: 0.5325 - val_loss: 1.0816 - val_mse: 1.0816 - val_mae: 0.8409\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 126us/sample - loss: 0.3926 - mse: 0.3926 - mae: 0.4691 - val_loss: 1.0417 - val_mse: 1.0417 - val_mae: 0.8253\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.3722 - mse: 0.3722 - mae: 0.4576 - val_loss: 0.8702 - val_mse: 0.8702 - val_mae: 0.7481\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.3231 - mse: 0.3231 - mae: 0.4265 - val_loss: 0.6394 - val_mse: 0.6394 - val_mae: 0.6304\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.2925 - mse: 0.2925 - mae: 0.4032 - val_loss: 0.5592 - val_mse: 0.5592 - val_mae: 0.5890\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 120us/sample - loss: 0.2478 - mse: 0.2478 - mae: 0.3727 - val_loss: 0.4771 - val_mse: 0.4771 - val_mae: 0.5231\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.2493 - mse: 0.2493 - mae: 0.3741 - val_loss: 0.4661 - val_mse: 0.4661 - val_mae: 0.4828\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 120us/sample - loss: 0.2247 - mse: 0.2247 - mae: 0.3524 - val_loss: 0.4875 - val_mse: 0.4875 - val_mae: 0.5293\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1949 - mse: 0.1949 - mae: 0.3306 - val_loss: 0.4348 - val_mse: 0.4348 - val_mae: 0.4685\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.1857 - mse: 0.1857 - mae: 0.3221 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4648\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1743 - mse: 0.1743 - mae: 0.3146 - val_loss: 0.4059 - val_mse: 0.4059 - val_mae: 0.4569\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.1573 - mse: 0.1573 - mae: 0.2991 - val_loss: 0.3988 - val_mse: 0.3988 - val_mae: 0.4508\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1425 - mse: 0.1425 - mae: 0.2844 - val_loss: 0.3932 - val_mse: 0.3932 - val_mae: 0.4530\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.1369 - mse: 0.1369 - mae: 0.2810 - val_loss: 0.4167 - val_mse: 0.4167 - val_mae: 0.4607\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.1430 - mse: 0.1430 - mae: 0.2867 - val_loss: 0.3857 - val_mse: 0.3857 - val_mae: 0.4439\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1320 - mse: 0.1320 - mae: 0.2717 - val_loss: 0.3989 - val_mse: 0.3989 - val_mae: 0.4474\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.1257 - mse: 0.1257 - mae: 0.2680 - val_loss: 0.3910 - val_mse: 0.3910 - val_mae: 0.4463\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.1166 - mse: 0.1166 - mae: 0.2574 - val_loss: 0.4090 - val_mse: 0.4090 - val_mae: 0.4500\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1150 - mse: 0.1150 - mae: 0.2554 - val_loss: 0.4059 - val_mse: 0.4059 - val_mae: 0.4468\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1129 - mse: 0.1129 - mae: 0.2549 - val_loss: 0.3991 - val_mse: 0.3991 - val_mae: 0.4356\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0959 - mse: 0.0959 - mae: 0.2342 - val_loss: 0.3707 - val_mse: 0.3707 - val_mae: 0.4361\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.0977 - mse: 0.0977 - mae: 0.2371 - val_loss: 0.4137 - val_mse: 0.4137 - val_mae: 0.4486\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.1101 - mse: 0.1101 - mae: 0.2486 - val_loss: 0.3644 - val_mse: 0.3644 - val_mae: 0.4327\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0995 - mse: 0.0995 - mae: 0.2376 - val_loss: 0.3824 - val_mse: 0.3824 - val_mae: 0.4465\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0903 - mse: 0.0903 - mae: 0.2264 - val_loss: 0.4300 - val_mse: 0.4300 - val_mae: 0.4741\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0940 - mse: 0.0940 - mae: 0.2311 - val_loss: 0.3702 - val_mse: 0.3702 - val_mae: 0.4248\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0883 - mse: 0.0883 - mae: 0.2239 - val_loss: 0.4052 - val_mse: 0.4052 - val_mae: 0.4561\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0871 - mse: 0.0871 - mae: 0.2224 - val_loss: 0.3762 - val_mse: 0.3762 - val_mae: 0.4359\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0856 - mse: 0.0856 - mae: 0.2195 - val_loss: 0.4109 - val_mse: 0.4109 - val_mae: 0.4479\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0867 - mse: 0.0867 - mae: 0.2203 - val_loss: 0.3952 - val_mse: 0.3952 - val_mae: 0.4550\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0806 - mse: 0.0806 - mae: 0.2124 - val_loss: 0.3974 - val_mse: 0.3974 - val_mae: 0.4414\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0772 - mse: 0.0772 - mae: 0.2089 - val_loss: 0.3845 - val_mse: 0.3845 - val_mae: 0.4334\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0766 - mse: 0.0766 - mae: 0.2065 - val_loss: 0.3648 - val_mse: 0.3648 - val_mae: 0.4227\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 245us/sample - loss: 2.4140 - mse: 2.4140 - mae: 0.9901 - val_loss: 3.0694 - val_mse: 3.0694 - val_mae: 1.5006\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.5036 - mse: 0.5036 - mae: 0.5273 - val_loss: 0.9419 - val_mse: 0.9419 - val_mae: 0.7880\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.4137 - mse: 0.4137 - mae: 0.4822 - val_loss: 0.8556 - val_mse: 0.8556 - val_mae: 0.7515\n",
      "Epoch 4/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.3644 - mse: 0.3644 - mae: 0.4538 - val_loss: 0.7937 - val_mse: 0.7937 - val_mae: 0.7104\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.3212 - mse: 0.3212 - mae: 0.4234 - val_loss: 0.5655 - val_mse: 0.5655 - val_mae: 0.5879\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.2774 - mse: 0.2774 - mae: 0.3966 - val_loss: 0.5532 - val_mse: 0.5532 - val_mae: 0.5739\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 127us/sample - loss: 0.2625 - mse: 0.2625 - mae: 0.3842 - val_loss: 0.5314 - val_mse: 0.5314 - val_mae: 0.5619\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.2207 - mse: 0.2207 - mae: 0.3531 - val_loss: 0.4268 - val_mse: 0.4268 - val_mae: 0.4904\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.2101 - mse: 0.2101 - mae: 0.3460 - val_loss: 0.4002 - val_mse: 0.4002 - val_mae: 0.4621\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.1938 - mse: 0.1938 - mae: 0.3332 - val_loss: 0.4495 - val_mse: 0.4495 - val_mae: 0.5029\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.1703 - mse: 0.1703 - mae: 0.3114 - val_loss: 0.3973 - val_mse: 0.3973 - val_mae: 0.4599\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1702 - mse: 0.1702 - mae: 0.3109 - val_loss: 0.4329 - val_mse: 0.4329 - val_mae: 0.4735\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.1725 - mse: 0.1725 - mae: 0.3113 - val_loss: 0.3975 - val_mse: 0.3975 - val_mae: 0.4563\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 127us/sample - loss: 0.1573 - mse: 0.1573 - mae: 0.2985 - val_loss: 0.3979 - val_mse: 0.3979 - val_mae: 0.4555\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1408 - mse: 0.1408 - mae: 0.2824 - val_loss: 0.4008 - val_mse: 0.4008 - val_mae: 0.4605\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1282 - mse: 0.1282 - mae: 0.2661 - val_loss: 0.3787 - val_mse: 0.3787 - val_mae: 0.4369\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.1366 - mse: 0.1366 - mae: 0.2740 - val_loss: 0.3929 - val_mse: 0.3929 - val_mae: 0.4496\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.1273 - mse: 0.1273 - mae: 0.2682 - val_loss: 0.4141 - val_mse: 0.4141 - val_mae: 0.4657\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1137 - mse: 0.1137 - mae: 0.2542 - val_loss: 0.3866 - val_mse: 0.3866 - val_mae: 0.4445\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1154 - mse: 0.1154 - mae: 0.2522 - val_loss: 0.3822 - val_mse: 0.3822 - val_mae: 0.4418\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1074 - mse: 0.1074 - mae: 0.2428 - val_loss: 0.3818 - val_mse: 0.3818 - val_mae: 0.4386\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.1068 - mse: 0.1068 - mae: 0.2439 - val_loss: 0.3855 - val_mse: 0.3855 - val_mae: 0.4407\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0973 - mse: 0.0973 - mae: 0.2323 - val_loss: 0.3936 - val_mse: 0.3936 - val_mae: 0.4441\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.1007 - mse: 0.1007 - mae: 0.2386 - val_loss: 0.3765 - val_mse: 0.3765 - val_mae: 0.4332\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0944 - mse: 0.0944 - mae: 0.2290 - val_loss: 0.3750 - val_mse: 0.3750 - val_mae: 0.4345\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0878 - mse: 0.0878 - mae: 0.2222 - val_loss: 0.3568 - val_mse: 0.3568 - val_mae: 0.4197\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0897 - mse: 0.0897 - mae: 0.2250 - val_loss: 0.3656 - val_mse: 0.3656 - val_mae: 0.4308\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0918 - mse: 0.0918 - mae: 0.2279 - val_loss: 0.3618 - val_mse: 0.3618 - val_mae: 0.4218\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0902 - mse: 0.0902 - mae: 0.2233 - val_loss: 0.3813 - val_mse: 0.3813 - val_mae: 0.4342\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0783 - mse: 0.0783 - mae: 0.2088 - val_loss: 0.3649 - val_mse: 0.3649 - val_mae: 0.4305\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0841 - mse: 0.0841 - mae: 0.2157 - val_loss: 0.3685 - val_mse: 0.3685 - val_mae: 0.4276\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.0832 - mse: 0.0832 - mae: 0.2151 - val_loss: 0.3542 - val_mse: 0.3542 - val_mae: 0.4171\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.0787 - mse: 0.0787 - mae: 0.2099 - val_loss: 0.3557 - val_mse: 0.3557 - val_mae: 0.4181\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0767 - mse: 0.0767 - mae: 0.2050 - val_loss: 0.3823 - val_mse: 0.3823 - val_mae: 0.4331\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0780 - mse: 0.0780 - mae: 0.2087 - val_loss: 0.3828 - val_mse: 0.3828 - val_mae: 0.4386\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0710 - mse: 0.0710 - mae: 0.1977 - val_loss: 0.3568 - val_mse: 0.3568 - val_mae: 0.4182\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0684 - mse: 0.0684 - mae: 0.1927 - val_loss: 0.3637 - val_mse: 0.3637 - val_mae: 0.4228\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.0688 - mse: 0.0688 - mae: 0.1951 - val_loss: 0.3746 - val_mse: 0.3746 - val_mae: 0.4297\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0750 - mse: 0.0750 - mae: 0.2065 - val_loss: 0.3537 - val_mse: 0.3537 - val_mae: 0.4153\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.0676 - mse: 0.0676 - mae: 0.1930 - val_loss: 0.3632 - val_mse: 0.3632 - val_mae: 0.4216\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.0635 - mse: 0.0635 - mae: 0.1881 - val_loss: 0.3658 - val_mse: 0.3658 - val_mae: 0.4257\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0647 - mse: 0.0647 - mae: 0.1892 - val_loss: 0.3679 - val_mse: 0.3679 - val_mae: 0.4268\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.0664 - mse: 0.0664 - mae: 0.1904 - val_loss: 0.3520 - val_mse: 0.3520 - val_mae: 0.4147\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0595 - mse: 0.0595 - mae: 0.1805 - val_loss: 0.3572 - val_mse: 0.3572 - val_mae: 0.4142\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0613 - mse: 0.0613 - mae: 0.1811 - val_loss: 0.3618 - val_mse: 0.3618 - val_mae: 0.4278\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.0598 - mse: 0.0598 - mae: 0.1813 - val_loss: 0.3556 - val_mse: 0.3556 - val_mae: 0.4115\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0542 - mse: 0.0542 - mae: 0.1731 - val_loss: 0.3514 - val_mse: 0.3514 - val_mae: 0.4127\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0576 - mse: 0.0576 - mae: 0.1761 - val_loss: 0.3527 - val_mse: 0.3527 - val_mae: 0.4129\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0608 - mse: 0.0608 - mae: 0.1845 - val_loss: 0.3660 - val_mse: 0.3660 - val_mae: 0.4269\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0618 - mse: 0.0618 - mae: 0.1832 - val_loss: 0.3672 - val_mse: 0.3672 - val_mae: 0.4226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0631 - mse: 0.0631 - mae: 0.1867 - val_loss: 0.3578 - val_mse: 0.3578 - val_mae: 0.4212\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0544 - mse: 0.0544 - mae: 0.1736 - val_loss: 0.3541 - val_mse: 0.3541 - val_mae: 0.4192\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.0569 - mse: 0.0569 - mae: 0.1787 - val_loss: 0.3486 - val_mse: 0.3486 - val_mae: 0.4073\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0576 - mse: 0.0576 - mae: 0.1762 - val_loss: 0.3849 - val_mse: 0.3849 - val_mae: 0.4365\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.0562 - mse: 0.0562 - mae: 0.1765 - val_loss: 0.3430 - val_mse: 0.3430 - val_mae: 0.4080\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.0544 - mse: 0.0544 - mae: 0.1706 - val_loss: 0.3432 - val_mse: 0.3432 - val_mae: 0.4092\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0561 - mse: 0.0561 - mae: 0.1759 - val_loss: 0.3571 - val_mse: 0.3571 - val_mae: 0.4221\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0523 - mse: 0.0523 - mae: 0.1697 - val_loss: 0.3532 - val_mse: 0.3532 - val_mae: 0.4150\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.0514 - mse: 0.0514 - mae: 0.1666 - val_loss: 0.3445 - val_mse: 0.3445 - val_mae: 0.4093\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 1s 125us/sample - loss: 0.0521 - mse: 0.0521 - mae: 0.1692 - val_loss: 0.3482 - val_mse: 0.3482 - val_mae: 0.4109\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 1s 126us/sample - loss: 0.0559 - mse: 0.0559 - mae: 0.1728 - val_loss: 0.3609 - val_mse: 0.3609 - val_mae: 0.4152\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0573 - mse: 0.0573 - mae: 0.1752 - val_loss: 0.3411 - val_mse: 0.3411 - val_mae: 0.4025\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0551 - mse: 0.0551 - mae: 0.1745 - val_loss: 0.3673 - val_mse: 0.3673 - val_mae: 0.4288\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0559 - mse: 0.0559 - mae: 0.1754 - val_loss: 0.3363 - val_mse: 0.3363 - val_mae: 0.4024\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 1s 122us/sample - loss: 0.0472 - mse: 0.0472 - mae: 0.1589 - val_loss: 0.3619 - val_mse: 0.3619 - val_mae: 0.4154\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 1s 131us/sample - loss: 0.0484 - mse: 0.0484 - mae: 0.1629 - val_loss: 0.3410 - val_mse: 0.3410 - val_mae: 0.4020\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 1s 128us/sample - loss: 0.0478 - mse: 0.0478 - mae: 0.1622 - val_loss: 0.3407 - val_mse: 0.3407 - val_mae: 0.4048\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.0472 - mse: 0.0472 - mae: 0.1627 - val_loss: 0.3533 - val_mse: 0.3533 - val_mae: 0.4086\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 1s 125us/sample - loss: 0.0493 - mse: 0.0493 - mae: 0.1658 - val_loss: 0.3568 - val_mse: 0.3568 - val_mae: 0.4137\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0498 - mse: 0.0498 - mae: 0.1666 - val_loss: 0.3475 - val_mse: 0.3475 - val_mae: 0.4033\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 1s 121us/sample - loss: 0.0459 - mse: 0.0459 - mae: 0.1585 - val_loss: 0.3537 - val_mse: 0.3537 - val_mae: 0.4103\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0503 - mse: 0.0503 - mae: 0.1634 - val_loss: 0.3528 - val_mse: 0.3528 - val_mae: 0.4107\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 1s 123us/sample - loss: 0.0564 - mse: 0.0564 - mae: 0.1742 - val_loss: 0.3447 - val_mse: 0.3447 - val_mae: 0.4096\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 1s 124us/sample - loss: 0.0534 - mse: 0.0534 - mae: 0.1699 - val_loss: 0.3448 - val_mse: 0.3448 - val_mae: 0.4126\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 3s 318us/sample - loss: 2.3729 - mse: 2.3729 - mae: 0.9772 - val_loss: 5.1080 - val_mse: 5.1080 - val_mae: 1.8066\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.5031 - mse: 0.5031 - mae: 0.5320 - val_loss: 0.9076 - val_mse: 0.9076 - val_mae: 0.7384\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.4005 - mse: 0.4005 - mae: 0.4738 - val_loss: 1.0590 - val_mse: 1.0590 - val_mae: 0.7932\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.3534 - mse: 0.3534 - mae: 0.4443 - val_loss: 0.7863 - val_mse: 0.7863 - val_mae: 0.7069\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.3219 - mse: 0.3219 - mae: 0.4249 - val_loss: 0.5870 - val_mse: 0.5870 - val_mae: 0.5933\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.2984 - mse: 0.2984 - mae: 0.4069 - val_loss: 0.6348 - val_mse: 0.6348 - val_mae: 0.6083\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 1s 129us/sample - loss: 0.2593 - mse: 0.2593 - mae: 0.3849 - val_loss: 0.5359 - val_mse: 0.5359 - val_mae: 0.5464\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.2343 - mse: 0.2343 - mae: 0.3631 - val_loss: 0.4613 - val_mse: 0.4613 - val_mae: 0.4884\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.2195 - mse: 0.2195 - mae: 0.3494 - val_loss: 0.4555 - val_mse: 0.4555 - val_mae: 0.4824\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.2037 - mse: 0.2037 - mae: 0.3395 - val_loss: 0.4497 - val_mse: 0.4497 - val_mae: 0.4748\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.2056 - mse: 0.2056 - mae: 0.3406 - val_loss: 0.4600 - val_mse: 0.4600 - val_mae: 0.4880\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.2012 - mse: 0.2012 - mae: 0.3339 - val_loss: 0.4448 - val_mse: 0.4448 - val_mae: 0.4654\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.1763 - mse: 0.1763 - mae: 0.3135 - val_loss: 0.4579 - val_mse: 0.4579 - val_mae: 0.4681\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.1569 - mse: 0.1569 - mae: 0.2983 - val_loss: 0.4114 - val_mse: 0.4114 - val_mae: 0.4519\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.1404 - mse: 0.1404 - mae: 0.2829 - val_loss: 0.3963 - val_mse: 0.3963 - val_mae: 0.4354\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.1300 - mse: 0.1300 - mae: 0.2665 - val_loss: 0.4006 - val_mse: 0.4006 - val_mae: 0.4432\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.1239 - mse: 0.1239 - mae: 0.2639 - val_loss: 0.4195 - val_mse: 0.4195 - val_mae: 0.4517\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.1200 - mse: 0.1200 - mae: 0.2622 - val_loss: 0.4217 - val_mse: 0.4217 - val_mae: 0.4624\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.1160 - mse: 0.1160 - mae: 0.2570 - val_loss: 0.4429 - val_mse: 0.4429 - val_mae: 0.4647\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.1122 - mse: 0.1122 - mae: 0.2536 - val_loss: 0.3767 - val_mse: 0.3767 - val_mae: 0.4260\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.1112 - mse: 0.1112 - mae: 0.2500 - val_loss: 0.4022 - val_mse: 0.4022 - val_mae: 0.4368\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 1s 131us/sample - loss: 0.1086 - mse: 0.1086 - mae: 0.2462 - val_loss: 0.4094 - val_mse: 0.4094 - val_mae: 0.4481\n",
      "Epoch 23/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.1073 - mse: 0.1073 - mae: 0.2454 - val_loss: 0.4541 - val_mse: 0.4541 - val_mae: 0.4707\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 1s 127us/sample - loss: 0.1039 - mse: 0.1039 - mae: 0.2397 - val_loss: 0.3859 - val_mse: 0.3859 - val_mae: 0.4270\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.1049 - mse: 0.1049 - mae: 0.2389 - val_loss: 0.4251 - val_mse: 0.4251 - val_mae: 0.4454\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.1040 - mse: 0.1040 - mae: 0.2378 - val_loss: 0.3868 - val_mse: 0.3868 - val_mae: 0.4319\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 1s 127us/sample - loss: 0.0917 - mse: 0.0917 - mae: 0.2262 - val_loss: 0.3750 - val_mse: 0.3750 - val_mae: 0.4193\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.0854 - mse: 0.0854 - mae: 0.2187 - val_loss: 0.3728 - val_mse: 0.3728 - val_mae: 0.4133\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 1s 127us/sample - loss: 0.0879 - mse: 0.0879 - mae: 0.2235 - val_loss: 0.3680 - val_mse: 0.3680 - val_mae: 0.4261\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 1s 128us/sample - loss: 0.0834 - mse: 0.0834 - mae: 0.2135 - val_loss: 0.3761 - val_mse: 0.3761 - val_mae: 0.4279\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0883 - mse: 0.0883 - mae: 0.2213 - val_loss: 0.3794 - val_mse: 0.3794 - val_mae: 0.4243\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0789 - mse: 0.0789 - mae: 0.2094 - val_loss: 0.3756 - val_mse: 0.3756 - val_mae: 0.4152\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 1s 123us/sample - loss: 0.0812 - mse: 0.0812 - mae: 0.2135 - val_loss: 0.3752 - val_mse: 0.3752 - val_mae: 0.4219\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.0766 - mse: 0.0766 - mae: 0.2071 - val_loss: 0.3835 - val_mse: 0.3835 - val_mae: 0.4289\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0787 - mse: 0.0787 - mae: 0.2079 - val_loss: 0.3728 - val_mse: 0.3728 - val_mae: 0.4127\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0708 - mse: 0.0708 - mae: 0.1985 - val_loss: 0.3895 - val_mse: 0.3895 - val_mae: 0.4274\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 1s 127us/sample - loss: 0.0750 - mse: 0.0750 - mae: 0.2057 - val_loss: 0.3703 - val_mse: 0.3703 - val_mae: 0.4155\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.0714 - mse: 0.0714 - mae: 0.1997 - val_loss: 0.3620 - val_mse: 0.3620 - val_mae: 0.4085\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0712 - mse: 0.0712 - mae: 0.1990 - val_loss: 0.3670 - val_mse: 0.3670 - val_mae: 0.4167\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.0677 - mse: 0.0677 - mae: 0.1935 - val_loss: 0.3736 - val_mse: 0.3736 - val_mae: 0.4200\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0645 - mse: 0.0645 - mae: 0.1905 - val_loss: 0.3748 - val_mse: 0.3748 - val_mae: 0.4198\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 1s 127us/sample - loss: 0.0694 - mse: 0.0694 - mae: 0.1978 - val_loss: 0.3781 - val_mse: 0.3781 - val_mae: 0.4339\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.0678 - mse: 0.0678 - mae: 0.1931 - val_loss: 0.3564 - val_mse: 0.3564 - val_mae: 0.4103\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.0602 - mse: 0.0602 - mae: 0.1836 - val_loss: 0.3602 - val_mse: 0.3602 - val_mae: 0.4050\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.0574 - mse: 0.0574 - mae: 0.1785 - val_loss: 0.3588 - val_mse: 0.3588 - val_mae: 0.4056\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.0601 - mse: 0.0601 - mae: 0.1839 - val_loss: 0.3616 - val_mse: 0.3616 - val_mae: 0.4117\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0593 - mse: 0.0593 - mae: 0.1792 - val_loss: 0.3554 - val_mse: 0.3554 - val_mae: 0.4048\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0587 - mse: 0.0587 - mae: 0.1806 - val_loss: 0.3675 - val_mse: 0.3675 - val_mae: 0.4171\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0589 - mse: 0.0589 - mae: 0.1816 - val_loss: 0.3536 - val_mse: 0.3536 - val_mae: 0.4025\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0600 - mse: 0.0600 - mae: 0.1823 - val_loss: 0.3663 - val_mse: 0.3663 - val_mae: 0.4130\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 1s 127us/sample - loss: 0.0583 - mse: 0.0583 - mae: 0.1827 - val_loss: 0.3589 - val_mse: 0.3589 - val_mae: 0.4128\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.0576 - mse: 0.0576 - mae: 0.1782 - val_loss: 0.3603 - val_mse: 0.3603 - val_mae: 0.3986\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.0537 - mse: 0.0537 - mae: 0.1718 - val_loss: 0.3597 - val_mse: 0.3597 - val_mae: 0.4135\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.0660 - mse: 0.0660 - mae: 0.1891 - val_loss: 0.3601 - val_mse: 0.3601 - val_mae: 0.4164\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.0603 - mse: 0.0603 - mae: 0.1840 - val_loss: 0.4162 - val_mse: 0.4162 - val_mae: 0.4317\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.0574 - mse: 0.0574 - mae: 0.1769 - val_loss: 0.3608 - val_mse: 0.3608 - val_mae: 0.4074\n",
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.0537 - mse: 0.0537 - mae: 0.1719 - val_loss: 0.3445 - val_mse: 0.3445 - val_mae: 0.3978\n",
      "Epoch 58/3000\n",
      "10664/10664 [==============================] - 1s 127us/sample - loss: 0.0542 - mse: 0.0542 - mae: 0.1719 - val_loss: 0.3416 - val_mse: 0.3416 - val_mae: 0.4021\n",
      "Epoch 59/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.0569 - mse: 0.0569 - mae: 0.1775 - val_loss: 0.3521 - val_mse: 0.3521 - val_mae: 0.4035\n",
      "Epoch 60/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.0547 - mse: 0.0547 - mae: 0.1738 - val_loss: 0.3605 - val_mse: 0.3605 - val_mae: 0.4055\n",
      "Epoch 61/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0539 - mse: 0.0539 - mae: 0.1704 - val_loss: 0.3492 - val_mse: 0.3492 - val_mae: 0.4058\n",
      "Epoch 62/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.0539 - mse: 0.0539 - mae: 0.1737 - val_loss: 0.3471 - val_mse: 0.3471 - val_mae: 0.4079\n",
      "Epoch 63/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0463 - mse: 0.0463 - mae: 0.1615 - val_loss: 0.3438 - val_mse: 0.3438 - val_mae: 0.3983\n",
      "Epoch 64/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.0461 - mse: 0.0461 - mae: 0.1604 - val_loss: 0.3534 - val_mse: 0.3534 - val_mae: 0.4040\n",
      "Epoch 65/3000\n",
      "10664/10664 [==============================] - 1s 124us/sample - loss: 0.0470 - mse: 0.0470 - mae: 0.1589 - val_loss: 0.3660 - val_mse: 0.3660 - val_mae: 0.4095\n",
      "Epoch 66/3000\n",
      "10664/10664 [==============================] - 1s 126us/sample - loss: 0.0458 - mse: 0.0458 - mae: 0.1589 - val_loss: 0.3587 - val_mse: 0.3587 - val_mae: 0.4040\n",
      "Epoch 67/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0491 - mse: 0.0491 - mae: 0.1632 - val_loss: 0.3424 - val_mse: 0.3424 - val_mae: 0.3972\n",
      "Epoch 68/3000\n",
      "10664/10664 [==============================] - 1s 125us/sample - loss: 0.0502 - mse: 0.0502 - mae: 0.1640 - val_loss: 0.3503 - val_mse: 0.3503 - val_mae: 0.3974\n",
      "Avg. MAE: 0.372267\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 2s 146us/sample - loss: 3.2753 - mse: 3.2753 - mae: 1.1318 - val_loss: 1.4558 - val_mse: 1.4558 - val_mae: 0.9867\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.5436 - mse: 0.5436 - mae: 0.5502 - val_loss: 1.3750 - val_mse: 1.3750 - val_mae: 0.9911\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.4356 - mse: 0.4356 - mae: 0.4891 - val_loss: 1.1701 - val_mse: 1.1701 - val_mae: 0.9058\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.4011 - mse: 0.4011 - mae: 0.4741 - val_loss: 0.8149 - val_mse: 0.8149 - val_mae: 0.7444\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.3662 - mse: 0.3662 - mae: 0.4527 - val_loss: 0.6617 - val_mse: 0.6617 - val_mae: 0.6575\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.3350 - mse: 0.3350 - mae: 0.4364 - val_loss: 0.5768 - val_mse: 0.5768 - val_mae: 0.6063\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.3088 - mse: 0.3088 - mae: 0.4190 - val_loss: 0.4845 - val_mse: 0.4845 - val_mae: 0.5436\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2925 - mse: 0.2925 - mae: 0.4014 - val_loss: 0.4612 - val_mse: 0.4612 - val_mae: 0.5262\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.2724 - mse: 0.2724 - mae: 0.3936 - val_loss: 0.4563 - val_mse: 0.4563 - val_mae: 0.5216\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 70us/sample - loss: 0.2635 - mse: 0.2635 - mae: 0.3868 - val_loss: 0.4415 - val_mse: 0.4415 - val_mae: 0.5030\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.2420 - mse: 0.2420 - mae: 0.3692 - val_loss: 0.4431 - val_mse: 0.4431 - val_mae: 0.4898\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.2369 - mse: 0.2369 - mae: 0.3649 - val_loss: 0.4371 - val_mse: 0.4371 - val_mae: 0.4986\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.2342 - mse: 0.2342 - mae: 0.3666 - val_loss: 0.4766 - val_mse: 0.4766 - val_mae: 0.4993\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2164 - mse: 0.2164 - mae: 0.3489 - val_loss: 0.4178 - val_mse: 0.4178 - val_mae: 0.4893\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.2072 - mse: 0.2072 - mae: 0.3423 - val_loss: 0.4133 - val_mse: 0.4133 - val_mae: 0.4707\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2034 - mse: 0.2034 - mae: 0.3405 - val_loss: 0.4357 - val_mse: 0.4357 - val_mae: 0.4777\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.2063 - mse: 0.2063 - mae: 0.3399 - val_loss: 0.3938 - val_mse: 0.3938 - val_mae: 0.4626\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1879 - mse: 0.1879 - mae: 0.3260 - val_loss: 0.4105 - val_mse: 0.4105 - val_mae: 0.4672\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1713 - mse: 0.1713 - mae: 0.3129 - val_loss: 0.4013 - val_mse: 0.4013 - val_mae: 0.4576\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1601 - mse: 0.1601 - mae: 0.3005 - val_loss: 0.4334 - val_mse: 0.4334 - val_mae: 0.4773\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1590 - mse: 0.1590 - mae: 0.3006 - val_loss: 0.4115 - val_mse: 0.4115 - val_mae: 0.4616\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1619 - mse: 0.1619 - mae: 0.3023 - val_loss: 0.4090 - val_mse: 0.4090 - val_mae: 0.4634\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1502 - mse: 0.1502 - mae: 0.2915 - val_loss: 0.3948 - val_mse: 0.3948 - val_mae: 0.4582\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1452 - mse: 0.1452 - mae: 0.2867 - val_loss: 0.4430 - val_mse: 0.4430 - val_mae: 0.4989\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1455 - mse: 0.1455 - mae: 0.2884 - val_loss: 0.3780 - val_mse: 0.3780 - val_mae: 0.4479\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1357 - mse: 0.1357 - mae: 0.2782 - val_loss: 0.4146 - val_mse: 0.4146 - val_mae: 0.4666\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1357 - mse: 0.1357 - mae: 0.2761 - val_loss: 0.3940 - val_mse: 0.3940 - val_mae: 0.4536\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1387 - mse: 0.1387 - mae: 0.2782 - val_loss: 0.4126 - val_mse: 0.4126 - val_mae: 0.4626\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1275 - mse: 0.1275 - mae: 0.2677 - val_loss: 0.4063 - val_mse: 0.4063 - val_mae: 0.4577\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1282 - mse: 0.1282 - mae: 0.2716 - val_loss: 0.4049 - val_mse: 0.4049 - val_mae: 0.4553\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1197 - mse: 0.1197 - mae: 0.2608 - val_loss: 0.4007 - val_mse: 0.4007 - val_mae: 0.4597\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1259 - mse: 0.1259 - mae: 0.2653 - val_loss: 0.3920 - val_mse: 0.3920 - val_mae: 0.4578\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1147 - mse: 0.1147 - mae: 0.2547 - val_loss: 0.3793 - val_mse: 0.3793 - val_mae: 0.4467\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1098 - mse: 0.1098 - mae: 0.2501 - val_loss: 0.3666 - val_mse: 0.3666 - val_mae: 0.4332\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1054 - mse: 0.1054 - mae: 0.2433 - val_loss: 0.3917 - val_mse: 0.3917 - val_mae: 0.4463\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1008 - mse: 0.1008 - mae: 0.2393 - val_loss: 0.3804 - val_mse: 0.3804 - val_mae: 0.4421\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1077 - mse: 0.1077 - mae: 0.2482 - val_loss: 0.3680 - val_mse: 0.3680 - val_mae: 0.4465\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1221 - mse: 0.1221 - mae: 0.2627 - val_loss: 0.4129 - val_mse: 0.4129 - val_mae: 0.4659\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1082 - mse: 0.1082 - mae: 0.2480 - val_loss: 0.3871 - val_mse: 0.3871 - val_mae: 0.4453\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1047 - mse: 0.1047 - mae: 0.2428 - val_loss: 0.3743 - val_mse: 0.3743 - val_mae: 0.4350\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0927 - mse: 0.0927 - mae: 0.2284 - val_loss: 0.3641 - val_mse: 0.3641 - val_mae: 0.4347\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.0886 - mse: 0.0886 - mae: 0.2239 - val_loss: 0.3726 - val_mse: 0.3726 - val_mae: 0.4403\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0891 - mse: 0.0891 - mae: 0.2241 - val_loss: 0.3722 - val_mse: 0.3722 - val_mae: 0.4382\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.0922 - mse: 0.0922 - mae: 0.2294 - val_loss: 0.3828 - val_mse: 0.3828 - val_mae: 0.4486\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0899 - mse: 0.0899 - mae: 0.2263 - val_loss: 0.3827 - val_mse: 0.3827 - val_mae: 0.4395\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0838 - mse: 0.0838 - mae: 0.2179 - val_loss: 0.3945 - val_mse: 0.3945 - val_mae: 0.4496\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0837 - mse: 0.0837 - mae: 0.2170 - val_loss: 0.3942 - val_mse: 0.3942 - val_mae: 0.4512\n",
      "Epoch 48/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0857 - mse: 0.0857 - mae: 0.2203 - val_loss: 0.3750 - val_mse: 0.3750 - val_mae: 0.4365\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0925 - mse: 0.0925 - mae: 0.2284 - val_loss: 0.3808 - val_mse: 0.3808 - val_mae: 0.4425\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0900 - mse: 0.0900 - mae: 0.2270 - val_loss: 0.3842 - val_mse: 0.3842 - val_mae: 0.4413\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0822 - mse: 0.0822 - mae: 0.2166 - val_loss: 0.3673 - val_mse: 0.3673 - val_mae: 0.4329\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 144us/sample - loss: 2.9996 - mse: 2.9996 - mae: 1.0983 - val_loss: 1.6272 - val_mse: 1.6272 - val_mae: 0.9341\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.5390 - mse: 0.5390 - mae: 0.5503 - val_loss: 1.1393 - val_mse: 1.1393 - val_mae: 0.8641\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.4267 - mse: 0.4267 - mae: 0.4912 - val_loss: 1.1730 - val_mse: 1.1730 - val_mae: 0.8946\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3921 - mse: 0.3921 - mae: 0.4692 - val_loss: 0.8803 - val_mse: 0.8803 - val_mae: 0.7748\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.3527 - mse: 0.3527 - mae: 0.4459 - val_loss: 0.7156 - val_mse: 0.7156 - val_mae: 0.6877\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.3243 - mse: 0.3243 - mae: 0.4292 - val_loss: 0.5996 - val_mse: 0.5996 - val_mae: 0.6081\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3101 - mse: 0.3101 - mae: 0.4192 - val_loss: 0.5668 - val_mse: 0.5668 - val_mae: 0.5822\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3019 - mse: 0.3019 - mae: 0.4138 - val_loss: 0.5369 - val_mse: 0.5369 - val_mae: 0.5316\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.2692 - mse: 0.2692 - mae: 0.3882 - val_loss: 0.5464 - val_mse: 0.5464 - val_mae: 0.5580\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2722 - mse: 0.2722 - mae: 0.3961 - val_loss: 0.4938 - val_mse: 0.4938 - val_mae: 0.5207\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2503 - mse: 0.2503 - mae: 0.3785 - val_loss: 0.4539 - val_mse: 0.4539 - val_mae: 0.4911\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2331 - mse: 0.2331 - mae: 0.3622 - val_loss: 0.4546 - val_mse: 0.4546 - val_mae: 0.4928\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2271 - mse: 0.2271 - mae: 0.3562 - val_loss: 0.4657 - val_mse: 0.4657 - val_mae: 0.4989\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2214 - mse: 0.2214 - mae: 0.3510 - val_loss: 0.4255 - val_mse: 0.4255 - val_mae: 0.4626\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2152 - mse: 0.2152 - mae: 0.3501 - val_loss: 0.4810 - val_mse: 0.4810 - val_mae: 0.4636\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1999 - mse: 0.1999 - mae: 0.3342 - val_loss: 0.5053 - val_mse: 0.5053 - val_mae: 0.4959\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2259 - mse: 0.2259 - mae: 0.3548 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.4921\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1979 - mse: 0.1979 - mae: 0.3304 - val_loss: 0.4294 - val_mse: 0.4294 - val_mae: 0.4666\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1865 - mse: 0.1865 - mae: 0.3235 - val_loss: 0.4649 - val_mse: 0.4649 - val_mae: 0.4743\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1668 - mse: 0.1668 - mae: 0.3078 - val_loss: 0.4689 - val_mse: 0.4689 - val_mae: 0.4729\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1715 - mse: 0.1715 - mae: 0.3122 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4573\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1674 - mse: 0.1674 - mae: 0.3080 - val_loss: 0.4559 - val_mse: 0.4559 - val_mae: 0.4918\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1597 - mse: 0.1597 - mae: 0.2997 - val_loss: 0.4317 - val_mse: 0.4317 - val_mae: 0.4708\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1515 - mse: 0.1515 - mae: 0.2948 - val_loss: 0.4278 - val_mse: 0.4278 - val_mae: 0.4721\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1420 - mse: 0.1420 - mae: 0.2859 - val_loss: 0.4227 - val_mse: 0.4227 - val_mae: 0.4526\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1408 - mse: 0.1408 - mae: 0.2826 - val_loss: 0.4117 - val_mse: 0.4117 - val_mae: 0.4545\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1408 - mse: 0.1408 - mae: 0.2824 - val_loss: 0.4049 - val_mse: 0.4049 - val_mae: 0.4548\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1269 - mse: 0.1269 - mae: 0.2654 - val_loss: 0.4666 - val_mse: 0.4666 - val_mae: 0.4660\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1237 - mse: 0.1237 - mae: 0.2654 - val_loss: 0.4215 - val_mse: 0.4215 - val_mae: 0.4591\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1354 - mse: 0.1354 - mae: 0.2769 - val_loss: 0.4302 - val_mse: 0.4302 - val_mae: 0.4591\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1169 - mse: 0.1169 - mae: 0.2553 - val_loss: 0.4287 - val_mse: 0.4287 - val_mae: 0.4669\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1211 - mse: 0.1211 - mae: 0.2625 - val_loss: 0.4054 - val_mse: 0.4054 - val_mae: 0.4444\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1257 - mse: 0.1257 - mae: 0.2664 - val_loss: 0.4015 - val_mse: 0.4015 - val_mae: 0.4502\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1146 - mse: 0.1146 - mae: 0.2529 - val_loss: 0.4447 - val_mse: 0.4447 - val_mae: 0.4535\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1095 - mse: 0.1095 - mae: 0.2489 - val_loss: 0.4069 - val_mse: 0.4069 - val_mae: 0.4406\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1031 - mse: 0.1031 - mae: 0.2432 - val_loss: 0.4279 - val_mse: 0.4279 - val_mae: 0.4611\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1146 - mse: 0.1146 - mae: 0.2548 - val_loss: 0.4167 - val_mse: 0.4167 - val_mae: 0.4559\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1036 - mse: 0.1036 - mae: 0.2441 - val_loss: 0.5004 - val_mse: 0.5004 - val_mae: 0.4620\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1078 - mse: 0.1078 - mae: 0.2477 - val_loss: 0.4191 - val_mse: 0.4191 - val_mae: 0.4595\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1052 - mse: 0.1052 - mae: 0.2420 - val_loss: 0.4036 - val_mse: 0.4036 - val_mae: 0.4425\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0979 - mse: 0.0979 - mae: 0.2342 - val_loss: 0.4063 - val_mse: 0.4063 - val_mae: 0.4451\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1002 - mse: 0.1002 - mae: 0.2401 - val_loss: 0.3908 - val_mse: 0.3908 - val_mae: 0.4364\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0919 - mse: 0.0919 - mae: 0.2273 - val_loss: 0.4053 - val_mse: 0.4053 - val_mae: 0.4432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.0856 - mse: 0.0856 - mae: 0.2194 - val_loss: 0.4128 - val_mse: 0.4128 - val_mae: 0.4414\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0869 - mse: 0.0869 - mae: 0.2226 - val_loss: 0.4095 - val_mse: 0.4095 - val_mae: 0.4516\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0908 - mse: 0.0908 - mae: 0.2272 - val_loss: 0.4243 - val_mse: 0.4243 - val_mae: 0.4458\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.0875 - mse: 0.0875 - mae: 0.2195 - val_loss: 0.3996 - val_mse: 0.3996 - val_mae: 0.4387\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0866 - mse: 0.0866 - mae: 0.2231 - val_loss: 0.4223 - val_mse: 0.4223 - val_mae: 0.4469\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0841 - mse: 0.0841 - mae: 0.2203 - val_loss: 0.4277 - val_mse: 0.4277 - val_mae: 0.4649\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.0821 - mse: 0.0821 - mae: 0.2141 - val_loss: 0.4034 - val_mse: 0.4034 - val_mae: 0.4466\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.0886 - mse: 0.0886 - mae: 0.2224 - val_loss: 0.4163 - val_mse: 0.4163 - val_mae: 0.4498\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0853 - mse: 0.0853 - mae: 0.2179 - val_loss: 0.3865 - val_mse: 0.3865 - val_mae: 0.4403\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.0817 - mse: 0.0817 - mae: 0.2142 - val_loss: 0.4039 - val_mse: 0.4039 - val_mae: 0.4430\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0861 - mse: 0.0861 - mae: 0.2204 - val_loss: 0.4012 - val_mse: 0.4012 - val_mae: 0.4467\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0893 - mse: 0.0893 - mae: 0.2258 - val_loss: 0.4057 - val_mse: 0.4057 - val_mae: 0.4474\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.0827 - mse: 0.0827 - mae: 0.2156 - val_loss: 0.4074 - val_mse: 0.4074 - val_mae: 0.4497\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.0780 - mse: 0.0780 - mae: 0.2090 - val_loss: 0.4038 - val_mse: 0.4038 - val_mae: 0.4394\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0724 - mse: 0.0724 - mae: 0.2028 - val_loss: 0.4097 - val_mse: 0.4097 - val_mae: 0.4420\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.0676 - mse: 0.0676 - mae: 0.1960 - val_loss: 0.3920 - val_mse: 0.3920 - val_mae: 0.4353\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.0687 - mse: 0.0687 - mae: 0.1963 - val_loss: 0.4048 - val_mse: 0.4048 - val_mae: 0.4520\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.0746 - mse: 0.0746 - mae: 0.2046 - val_loss: 0.3947 - val_mse: 0.3947 - val_mae: 0.4405\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0740 - mse: 0.0740 - mae: 0.2035 - val_loss: 0.3867 - val_mse: 0.3867 - val_mae: 0.4323\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 143us/sample - loss: 2.9403 - mse: 2.9403 - mae: 1.0768 - val_loss: 1.4003 - val_mse: 1.4003 - val_mae: 0.8941\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.5236 - mse: 0.5236 - mae: 0.5424 - val_loss: 0.9236 - val_mse: 0.9236 - val_mae: 0.7714\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.4353 - mse: 0.4353 - mae: 0.4952 - val_loss: 0.8511 - val_mse: 0.8511 - val_mae: 0.7464\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3906 - mse: 0.3906 - mae: 0.4681 - val_loss: 0.7486 - val_mse: 0.7486 - val_mae: 0.6833\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3771 - mse: 0.3771 - mae: 0.4592 - val_loss: 0.5990 - val_mse: 0.5990 - val_mae: 0.6018\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3297 - mse: 0.3297 - mae: 0.4300 - val_loss: 0.5403 - val_mse: 0.5403 - val_mae: 0.5672\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2969 - mse: 0.2969 - mae: 0.4096 - val_loss: 0.4778 - val_mse: 0.4778 - val_mae: 0.5284\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2868 - mse: 0.2868 - mae: 0.3995 - val_loss: 0.4930 - val_mse: 0.4930 - val_mae: 0.5304\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2888 - mse: 0.2888 - mae: 0.4032 - val_loss: 0.4825 - val_mse: 0.4825 - val_mae: 0.5266\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2636 - mse: 0.2636 - mae: 0.3834 - val_loss: 0.4947 - val_mse: 0.4947 - val_mae: 0.4824\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2535 - mse: 0.2535 - mae: 0.3810 - val_loss: 0.4098 - val_mse: 0.4098 - val_mae: 0.4638\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2408 - mse: 0.2408 - mae: 0.3681 - val_loss: 0.4346 - val_mse: 0.4346 - val_mae: 0.4805\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2283 - mse: 0.2283 - mae: 0.3599 - val_loss: 0.4456 - val_mse: 0.4456 - val_mae: 0.4832\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2172 - mse: 0.2172 - mae: 0.3501 - val_loss: 0.4243 - val_mse: 0.4243 - val_mae: 0.4779\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2157 - mse: 0.2157 - mae: 0.3486 - val_loss: 0.5333 - val_mse: 0.5333 - val_mae: 0.5281\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2209 - mse: 0.2209 - mae: 0.3548 - val_loss: 0.4184 - val_mse: 0.4184 - val_mae: 0.4621\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.2004 - mse: 0.2004 - mae: 0.3362 - val_loss: 0.4014 - val_mse: 0.4014 - val_mae: 0.4545\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1879 - mse: 0.1879 - mae: 0.3253 - val_loss: 0.4077 - val_mse: 0.4077 - val_mae: 0.4542\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1754 - mse: 0.1754 - mae: 0.3152 - val_loss: 0.4473 - val_mse: 0.4473 - val_mae: 0.4673\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1744 - mse: 0.1744 - mae: 0.3143 - val_loss: 0.4187 - val_mse: 0.4187 - val_mae: 0.4601\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1732 - mse: 0.1732 - mae: 0.3163 - val_loss: 0.4133 - val_mse: 0.4133 - val_mae: 0.4538\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1505 - mse: 0.1505 - mae: 0.2933 - val_loss: 0.4290 - val_mse: 0.4290 - val_mae: 0.4681\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1533 - mse: 0.1533 - mae: 0.2995 - val_loss: 0.4256 - val_mse: 0.4256 - val_mae: 0.4638\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1485 - mse: 0.1485 - mae: 0.2921 - val_loss: 0.4105 - val_mse: 0.4105 - val_mae: 0.4610\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1467 - mse: 0.1467 - mae: 0.2885 - val_loss: 0.4415 - val_mse: 0.4415 - val_mae: 0.4912\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1479 - mse: 0.1479 - mae: 0.2903 - val_loss: 0.4140 - val_mse: 0.4140 - val_mae: 0.4611\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1452 - mse: 0.1452 - mae: 0.2870 - val_loss: 0.4100 - val_mse: 0.4100 - val_mae: 0.4535\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 2s 144us/sample - loss: 3.0220 - mse: 3.0220 - mae: 1.0795 - val_loss: 2.7712 - val_mse: 2.7712 - val_mae: 1.4248\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.5343 - mse: 0.5343 - mae: 0.5440 - val_loss: 1.1615 - val_mse: 1.1615 - val_mae: 0.9114\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.4379 - mse: 0.4379 - mae: 0.4961 - val_loss: 0.9256 - val_mse: 0.9256 - val_mae: 0.7986\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3956 - mse: 0.3956 - mae: 0.4705 - val_loss: 0.8469 - val_mse: 0.8469 - val_mae: 0.7672\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3612 - mse: 0.3612 - mae: 0.4489 - val_loss: 0.6688 - val_mse: 0.6688 - val_mae: 0.6438\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.3393 - mse: 0.3393 - mae: 0.4389 - val_loss: 0.5865 - val_mse: 0.5865 - val_mae: 0.6035\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.3357 - mse: 0.3357 - mae: 0.4330 - val_loss: 0.5196 - val_mse: 0.5196 - val_mae: 0.5601\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.2997 - mse: 0.2997 - mae: 0.4116 - val_loss: 0.5131 - val_mse: 0.5131 - val_mae: 0.5587\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2841 - mse: 0.2841 - mae: 0.3980 - val_loss: 0.4550 - val_mse: 0.4550 - val_mae: 0.5093\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2865 - mse: 0.2865 - mae: 0.4020 - val_loss: 0.5027 - val_mse: 0.5027 - val_mae: 0.5451\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2575 - mse: 0.2575 - mae: 0.3796 - val_loss: 0.4355 - val_mse: 0.4355 - val_mae: 0.4797\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2397 - mse: 0.2397 - mae: 0.3678 - val_loss: 0.4383 - val_mse: 0.4383 - val_mae: 0.4878\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2307 - mse: 0.2307 - mae: 0.3620 - val_loss: 0.4627 - val_mse: 0.4627 - val_mae: 0.4874\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.2247 - mse: 0.2247 - mae: 0.3548 - val_loss: 0.4365 - val_mse: 0.4365 - val_mae: 0.4778\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.2003 - mse: 0.2003 - mae: 0.3353 - val_loss: 0.4251 - val_mse: 0.4251 - val_mae: 0.4776\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1950 - mse: 0.1950 - mae: 0.3279 - val_loss: 0.4034 - val_mse: 0.4034 - val_mae: 0.4594\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1908 - mse: 0.1908 - mae: 0.3239 - val_loss: 0.4316 - val_mse: 0.4316 - val_mae: 0.4713\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1873 - mse: 0.1873 - mae: 0.3266 - val_loss: 0.4394 - val_mse: 0.4394 - val_mae: 0.4721\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.1888 - mse: 0.1888 - mae: 0.3251 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.4700\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1868 - mse: 0.1868 - mae: 0.3236 - val_loss: 0.4302 - val_mse: 0.4302 - val_mae: 0.4674\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1644 - mse: 0.1644 - mae: 0.3033 - val_loss: 0.4225 - val_mse: 0.4225 - val_mae: 0.4677\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1578 - mse: 0.1578 - mae: 0.3002 - val_loss: 0.4127 - val_mse: 0.4127 - val_mae: 0.4525\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1518 - mse: 0.1518 - mae: 0.2951 - val_loss: 0.4024 - val_mse: 0.4024 - val_mae: 0.4567\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1494 - mse: 0.1494 - mae: 0.2908 - val_loss: 0.4597 - val_mse: 0.4597 - val_mae: 0.4825\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1476 - mse: 0.1476 - mae: 0.2898 - val_loss: 0.3980 - val_mse: 0.3980 - val_mae: 0.4441\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1340 - mse: 0.1340 - mae: 0.2750 - val_loss: 0.4125 - val_mse: 0.4125 - val_mae: 0.4607\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1384 - mse: 0.1384 - mae: 0.2820 - val_loss: 0.4042 - val_mse: 0.4042 - val_mae: 0.4597\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1366 - mse: 0.1366 - mae: 0.2767 - val_loss: 0.4434 - val_mse: 0.4434 - val_mae: 0.4690\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1378 - mse: 0.1378 - mae: 0.2816 - val_loss: 0.3902 - val_mse: 0.3902 - val_mae: 0.4409\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1240 - mse: 0.1240 - mae: 0.2674 - val_loss: 0.3827 - val_mse: 0.3827 - val_mae: 0.4377\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.1155 - mse: 0.1155 - mae: 0.2554 - val_loss: 0.3804 - val_mse: 0.3804 - val_mae: 0.4364\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.1209 - mse: 0.1209 - mae: 0.2619 - val_loss: 0.4045 - val_mse: 0.4045 - val_mae: 0.4492\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1175 - mse: 0.1175 - mae: 0.2601 - val_loss: 0.3995 - val_mse: 0.3995 - val_mae: 0.4366\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1081 - mse: 0.1081 - mae: 0.2487 - val_loss: 0.4068 - val_mse: 0.4068 - val_mae: 0.4514\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1097 - mse: 0.1097 - mae: 0.2477 - val_loss: 0.4269 - val_mse: 0.4269 - val_mae: 0.4578\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.1161 - mse: 0.1161 - mae: 0.2553 - val_loss: 0.3750 - val_mse: 0.3750 - val_mae: 0.4392\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1043 - mse: 0.1043 - mae: 0.2416 - val_loss: 0.3669 - val_mse: 0.3669 - val_mae: 0.4305\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 62us/sample - loss: 0.1048 - mse: 0.1048 - mae: 0.2418 - val_loss: 0.3818 - val_mse: 0.3818 - val_mae: 0.4379\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0910 - mse: 0.0910 - mae: 0.2288 - val_loss: 0.3803 - val_mse: 0.3803 - val_mae: 0.4321\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0897 - mse: 0.0897 - mae: 0.2239 - val_loss: 0.3691 - val_mse: 0.3691 - val_mae: 0.4274\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.0951 - mse: 0.0951 - mae: 0.2313 - val_loss: 0.4039 - val_mse: 0.4039 - val_mae: 0.4615\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.0915 - mse: 0.0915 - mae: 0.2281 - val_loss: 0.3647 - val_mse: 0.3647 - val_mae: 0.4298\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.0970 - mse: 0.0970 - mae: 0.2361 - val_loss: 0.3824 - val_mse: 0.3824 - val_mae: 0.4359\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0906 - mse: 0.0906 - mae: 0.2262 - val_loss: 0.3799 - val_mse: 0.3799 - val_mae: 0.4345\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 58us/sample - loss: 0.0875 - mse: 0.0875 - mae: 0.2207 - val_loss: 0.3836 - val_mse: 0.3836 - val_mae: 0.4471\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.0908 - mse: 0.0908 - mae: 0.2270 - val_loss: 0.3828 - val_mse: 0.3828 - val_mae: 0.4380\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0847 - mse: 0.0847 - mae: 0.2182 - val_loss: 0.3754 - val_mse: 0.3754 - val_mae: 0.4298\n",
      "Epoch 48/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 60us/sample - loss: 0.0819 - mse: 0.0819 - mae: 0.2127 - val_loss: 0.3681 - val_mse: 0.3681 - val_mae: 0.4261\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.0868 - mse: 0.0868 - mae: 0.2226 - val_loss: 0.4078 - val_mse: 0.4078 - val_mae: 0.4492\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 59us/sample - loss: 0.0894 - mse: 0.0894 - mae: 0.2259 - val_loss: 0.3799 - val_mse: 0.3799 - val_mae: 0.4401\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 63us/sample - loss: 0.0920 - mse: 0.0920 - mae: 0.2253 - val_loss: 0.3991 - val_mse: 0.3991 - val_mae: 0.4599\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 61us/sample - loss: 0.0926 - mse: 0.0926 - mae: 0.2279 - val_loss: 0.3659 - val_mse: 0.3659 - val_mae: 0.4232\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 141us/sample - loss: 2.9603 - mse: 2.9603 - mae: 1.0666 - val_loss: 1.4460 - val_mse: 1.4460 - val_mae: 1.0088\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.5336 - mse: 0.5336 - mae: 0.5448 - val_loss: 1.0246 - val_mse: 1.0246 - val_mae: 0.8189\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.4203 - mse: 0.4203 - mae: 0.4874 - val_loss: 1.0298 - val_mse: 1.0298 - val_mae: 0.8171\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3897 - mse: 0.3897 - mae: 0.4667 - val_loss: 0.8999 - val_mse: 0.8999 - val_mae: 0.7728\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3414 - mse: 0.3414 - mae: 0.4398 - val_loss: 0.6532 - val_mse: 0.6532 - val_mae: 0.6252\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.3176 - mse: 0.3176 - mae: 0.4242 - val_loss: 0.5760 - val_mse: 0.5760 - val_mae: 0.5769\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.3180 - mse: 0.3180 - mae: 0.4225 - val_loss: 0.5653 - val_mse: 0.5653 - val_mae: 0.5841\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 60us/sample - loss: 0.2895 - mse: 0.2895 - mae: 0.4037 - val_loss: 0.4671 - val_mse: 0.4671 - val_mae: 0.5184\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.2649 - mse: 0.2649 - mae: 0.3846 - val_loss: 0.4362 - val_mse: 0.4362 - val_mae: 0.4866\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.2669 - mse: 0.2669 - mae: 0.3908 - val_loss: 0.5101 - val_mse: 0.5101 - val_mae: 0.5286\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.2504 - mse: 0.2504 - mae: 0.3750 - val_loss: 0.4670 - val_mse: 0.4670 - val_mae: 0.4955\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.2236 - mse: 0.2236 - mae: 0.3562 - val_loss: 0.4294 - val_mse: 0.4294 - val_mae: 0.4817\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.2211 - mse: 0.2211 - mae: 0.3538 - val_loss: 0.4326 - val_mse: 0.4326 - val_mae: 0.4737\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 1s 60us/sample - loss: 0.2191 - mse: 0.2191 - mae: 0.3522 - val_loss: 0.4567 - val_mse: 0.4567 - val_mae: 0.4880\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 1s 61us/sample - loss: 0.2133 - mse: 0.2133 - mae: 0.3473 - val_loss: 0.4259 - val_mse: 0.4259 - val_mae: 0.4527\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.1906 - mse: 0.1906 - mae: 0.3295 - val_loss: 0.4228 - val_mse: 0.4228 - val_mae: 0.4586\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.1813 - mse: 0.1813 - mae: 0.3230 - val_loss: 0.4572 - val_mse: 0.4572 - val_mae: 0.4662\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.1780 - mse: 0.1780 - mae: 0.3175 - val_loss: 0.4536 - val_mse: 0.4536 - val_mae: 0.4855\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.1691 - mse: 0.1691 - mae: 0.3116 - val_loss: 0.4076 - val_mse: 0.4076 - val_mae: 0.4470\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 1s 60us/sample - loss: 0.1668 - mse: 0.1668 - mae: 0.3084 - val_loss: 0.4254 - val_mse: 0.4254 - val_mae: 0.4640\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 1s 60us/sample - loss: 0.1745 - mse: 0.1745 - mae: 0.3130 - val_loss: 0.4268 - val_mse: 0.4268 - val_mae: 0.4564\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.1738 - mse: 0.1738 - mae: 0.3108 - val_loss: 0.4083 - val_mse: 0.4083 - val_mae: 0.4621\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 1s 60us/sample - loss: 0.1710 - mse: 0.1710 - mae: 0.3112 - val_loss: 0.4877 - val_mse: 0.4877 - val_mae: 0.4784\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 1s 61us/sample - loss: 0.1559 - mse: 0.1559 - mae: 0.2941 - val_loss: 0.3883 - val_mse: 0.3883 - val_mae: 0.4377\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.1492 - mse: 0.1492 - mae: 0.2906 - val_loss: 0.4211 - val_mse: 0.4211 - val_mae: 0.4640\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.1409 - mse: 0.1409 - mae: 0.2820 - val_loss: 0.3921 - val_mse: 0.3921 - val_mae: 0.4373\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.1369 - mse: 0.1369 - mae: 0.2797 - val_loss: 0.4030 - val_mse: 0.4030 - val_mae: 0.4427\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.1237 - mse: 0.1237 - mae: 0.2669 - val_loss: 0.3855 - val_mse: 0.3855 - val_mae: 0.4448\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.1263 - mse: 0.1263 - mae: 0.2696 - val_loss: 0.3811 - val_mse: 0.3811 - val_mae: 0.4325\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.1276 - mse: 0.1276 - mae: 0.2697 - val_loss: 0.4027 - val_mse: 0.4027 - val_mae: 0.4458\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.1192 - mse: 0.1192 - mae: 0.2606 - val_loss: 0.4126 - val_mse: 0.4126 - val_mae: 0.4461\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.1198 - mse: 0.1198 - mae: 0.2622 - val_loss: 0.3939 - val_mse: 0.3939 - val_mae: 0.4415\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 1s 57us/sample - loss: 0.1314 - mse: 0.1314 - mae: 0.2734 - val_loss: 0.3933 - val_mse: 0.3933 - val_mae: 0.4443\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.1137 - mse: 0.1137 - mae: 0.2556 - val_loss: 0.3939 - val_mse: 0.3939 - val_mae: 0.4480\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.1119 - mse: 0.1119 - mae: 0.2497 - val_loss: 0.3756 - val_mse: 0.3756 - val_mae: 0.4288\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.1029 - mse: 0.1029 - mae: 0.2428 - val_loss: 0.3821 - val_mse: 0.3821 - val_mae: 0.4336\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.1035 - mse: 0.1035 - mae: 0.2431 - val_loss: 0.3724 - val_mse: 0.3724 - val_mae: 0.4263\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.1019 - mse: 0.1019 - mae: 0.2425 - val_loss: 0.3805 - val_mse: 0.3805 - val_mae: 0.4303\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.1053 - mse: 0.1053 - mae: 0.2462 - val_loss: 0.3902 - val_mse: 0.3902 - val_mae: 0.4376\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.0959 - mse: 0.0959 - mae: 0.2350 - val_loss: 0.4041 - val_mse: 0.4041 - val_mae: 0.4415\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 1s 60us/sample - loss: 0.0994 - mse: 0.0994 - mae: 0.2370 - val_loss: 0.4141 - val_mse: 0.4141 - val_mae: 0.4567\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 1s 61us/sample - loss: 0.0969 - mse: 0.0969 - mae: 0.2353 - val_loss: 0.3722 - val_mse: 0.3722 - val_mae: 0.4255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.0925 - mse: 0.0925 - mae: 0.2313 - val_loss: 0.3796 - val_mse: 0.3796 - val_mae: 0.4359\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.1006 - mse: 0.1006 - mae: 0.2382 - val_loss: 0.3837 - val_mse: 0.3837 - val_mae: 0.4256\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.0928 - mse: 0.0928 - mae: 0.2283 - val_loss: 0.4082 - val_mse: 0.4082 - val_mae: 0.4566\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.0978 - mse: 0.0978 - mae: 0.2372 - val_loss: 0.3760 - val_mse: 0.3760 - val_mae: 0.4357\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.0948 - mse: 0.0948 - mae: 0.2338 - val_loss: 0.3636 - val_mse: 0.3636 - val_mae: 0.4200\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 1s 60us/sample - loss: 0.0855 - mse: 0.0855 - mae: 0.2214 - val_loss: 0.3772 - val_mse: 0.3772 - val_mae: 0.4328\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.0825 - mse: 0.0825 - mae: 0.2183 - val_loss: 0.3862 - val_mse: 0.3862 - val_mae: 0.4323\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.0853 - mse: 0.0853 - mae: 0.2218 - val_loss: 0.3701 - val_mse: 0.3701 - val_mae: 0.4242\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.0846 - mse: 0.0846 - mae: 0.2204 - val_loss: 0.3642 - val_mse: 0.3642 - val_mae: 0.4233\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 1s 59us/sample - loss: 0.0810 - mse: 0.0810 - mae: 0.2149 - val_loss: 0.3809 - val_mse: 0.3809 - val_mae: 0.4259\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.0757 - mse: 0.0757 - mae: 0.2085 - val_loss: 0.3730 - val_mse: 0.3730 - val_mae: 0.4244\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.0830 - mse: 0.0830 - mae: 0.2188 - val_loss: 0.3709 - val_mse: 0.3709 - val_mae: 0.4315\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.0773 - mse: 0.0773 - mae: 0.2129 - val_loss: 0.3735 - val_mse: 0.3735 - val_mae: 0.4218\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 1s 58us/sample - loss: 0.0718 - mse: 0.0718 - mae: 0.2021 - val_loss: 0.3866 - val_mse: 0.3866 - val_mae: 0.4358\n",
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 1s 60us/sample - loss: 0.0781 - mse: 0.0781 - mae: 0.2119 - val_loss: 0.3804 - val_mse: 0.3804 - val_mae: 0.4307\n",
      "Avg. MAE: 0.384187\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 240us/sample - loss: 0.9289 - mse: 0.9289 - mae: 0.7158 - val_loss: 1.1872 - val_mse: 1.1872 - val_mae: 0.8307\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.5504 - mse: 0.5504 - mae: 0.5549 - val_loss: 0.8923 - val_mse: 0.8923 - val_mae: 0.7393\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.4611 - mse: 0.4611 - mae: 0.5059 - val_loss: 0.7846 - val_mse: 0.7846 - val_mae: 0.6993\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.4322 - mse: 0.4322 - mae: 0.4899 - val_loss: 0.6718 - val_mse: 0.6718 - val_mae: 0.6411\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.3933 - mse: 0.3933 - mae: 0.4666 - val_loss: 0.5579 - val_mse: 0.5579 - val_mae: 0.5765\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.3623 - mse: 0.3623 - mae: 0.4496 - val_loss: 0.4969 - val_mse: 0.4969 - val_mae: 0.5282\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.3429 - mse: 0.3429 - mae: 0.4378 - val_loss: 0.4825 - val_mse: 0.4825 - val_mae: 0.5164\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.3265 - mse: 0.3265 - mae: 0.4266 - val_loss: 0.4539 - val_mse: 0.4539 - val_mae: 0.4940\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.3057 - mse: 0.3057 - mae: 0.4126 - val_loss: 0.4531 - val_mse: 0.4531 - val_mae: 0.4952\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2908 - mse: 0.2908 - mae: 0.4028 - val_loss: 0.4425 - val_mse: 0.4425 - val_mae: 0.4829\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.2745 - mse: 0.2745 - mae: 0.3915 - val_loss: 0.4449 - val_mse: 0.4449 - val_mae: 0.4890\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.2821 - mse: 0.2821 - mae: 0.3957 - val_loss: 0.4212 - val_mse: 0.4212 - val_mae: 0.4737\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.2569 - mse: 0.2569 - mae: 0.3805 - val_loss: 0.4442 - val_mse: 0.4442 - val_mae: 0.4815\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2468 - mse: 0.2468 - mae: 0.3707 - val_loss: 0.4337 - val_mse: 0.4337 - val_mae: 0.4757\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2412 - mse: 0.2412 - mae: 0.3675 - val_loss: 0.4447 - val_mse: 0.4447 - val_mae: 0.4823\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.2430 - mse: 0.2430 - mae: 0.3680 - val_loss: 0.4420 - val_mse: 0.4420 - val_mae: 0.4845\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.2285 - mse: 0.2285 - mae: 0.3596 - val_loss: 0.4501 - val_mse: 0.4501 - val_mae: 0.4806\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2230 - mse: 0.2230 - mae: 0.3530 - val_loss: 0.4294 - val_mse: 0.4294 - val_mae: 0.4687\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.2221 - mse: 0.2221 - mae: 0.3523 - val_loss: 0.4165 - val_mse: 0.4165 - val_mae: 0.4676\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.1986 - mse: 0.1986 - mae: 0.3372 - val_loss: 0.4299 - val_mse: 0.4299 - val_mae: 0.4742\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.2008 - mse: 0.2008 - mae: 0.3384 - val_loss: 0.4323 - val_mse: 0.4323 - val_mae: 0.4748\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.1969 - mse: 0.1969 - mae: 0.3321 - val_loss: 0.4351 - val_mse: 0.4351 - val_mae: 0.4727\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2025 - mse: 0.2025 - mae: 0.3371 - val_loss: 0.4032 - val_mse: 0.4032 - val_mae: 0.4599\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.1892 - mse: 0.1892 - mae: 0.3274 - val_loss: 0.4300 - val_mse: 0.4300 - val_mae: 0.4757\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1887 - mse: 0.1887 - mae: 0.3269 - val_loss: 0.4214 - val_mse: 0.4214 - val_mae: 0.4676\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1796 - mse: 0.1796 - mae: 0.3211 - val_loss: 0.4567 - val_mse: 0.4567 - val_mae: 0.4794\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.1734 - mse: 0.1734 - mae: 0.3119 - val_loss: 0.4258 - val_mse: 0.4258 - val_mae: 0.4657\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1680 - mse: 0.1680 - mae: 0.3093 - val_loss: 0.4167 - val_mse: 0.4167 - val_mae: 0.4602\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1660 - mse: 0.1660 - mae: 0.3061 - val_loss: 0.4058 - val_mse: 0.4058 - val_mae: 0.4595\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.1721 - mse: 0.1721 - mae: 0.3116 - val_loss: 0.4350 - val_mse: 0.4350 - val_mae: 0.4676\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.1716 - mse: 0.1716 - mae: 0.3110 - val_loss: 0.4535 - val_mse: 0.4535 - val_mae: 0.4817\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1670 - mse: 0.1670 - mae: 0.3061 - val_loss: 0.4130 - val_mse: 0.4130 - val_mae: 0.4647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1592 - mse: 0.1592 - mae: 0.2968 - val_loss: 0.4338 - val_mse: 0.4338 - val_mae: 0.4723\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 165us/sample - loss: 0.9201 - mse: 0.9201 - mae: 0.7105 - val_loss: 1.0078 - val_mse: 1.0078 - val_mae: 0.7569\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - ETA: 0s - loss: 0.5625 - mse: 0.5625 - mae: 0.561 - 0s 24us/sample - loss: 0.5607 - mse: 0.5607 - mae: 0.5605 - val_loss: 0.9217 - val_mse: 0.9217 - val_mae: 0.7249\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.4695 - mse: 0.4695 - mae: 0.5117 - val_loss: 0.9738 - val_mse: 0.9738 - val_mae: 0.7592\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.4235 - mse: 0.4235 - mae: 0.4858 - val_loss: 0.7417 - val_mse: 0.7417 - val_mae: 0.6782\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3975 - mse: 0.3975 - mae: 0.4720 - val_loss: 0.7263 - val_mse: 0.7263 - val_mae: 0.6276\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.3626 - mse: 0.3626 - mae: 0.4521 - val_loss: 0.5983 - val_mse: 0.5983 - val_mae: 0.5474\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.3403 - mse: 0.3403 - mae: 0.4340 - val_loss: 0.5431 - val_mse: 0.5431 - val_mae: 0.5389\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.3311 - mse: 0.3311 - mae: 0.4332 - val_loss: 0.5468 - val_mse: 0.5468 - val_mae: 0.5152\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.3089 - mse: 0.3089 - mae: 0.4169 - val_loss: 0.5734 - val_mse: 0.5734 - val_mae: 0.5248\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3083 - mse: 0.3083 - mae: 0.4151 - val_loss: 0.4751 - val_mse: 0.4751 - val_mae: 0.4904\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2756 - mse: 0.2756 - mae: 0.3941 - val_loss: 0.4833 - val_mse: 0.4833 - val_mae: 0.4952\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2647 - mse: 0.2647 - mae: 0.3859 - val_loss: 0.4975 - val_mse: 0.4975 - val_mae: 0.4939\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2561 - mse: 0.2561 - mae: 0.3809 - val_loss: 0.5426 - val_mse: 0.5426 - val_mae: 0.4914\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2463 - mse: 0.2463 - mae: 0.3723 - val_loss: 0.5114 - val_mse: 0.5114 - val_mae: 0.4887\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.2383 - mse: 0.2383 - mae: 0.3681 - val_loss: 0.4843 - val_mse: 0.4843 - val_mae: 0.4793\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2366 - mse: 0.2366 - mae: 0.3652 - val_loss: 0.5111 - val_mse: 0.5111 - val_mae: 0.4895\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2332 - mse: 0.2332 - mae: 0.3608 - val_loss: 0.5422 - val_mse: 0.5422 - val_mae: 0.4978\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2283 - mse: 0.2283 - mae: 0.3610 - val_loss: 0.4905 - val_mse: 0.4905 - val_mae: 0.4827\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2223 - mse: 0.2223 - mae: 0.3528 - val_loss: 0.4791 - val_mse: 0.4791 - val_mae: 0.4789\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2066 - mse: 0.2066 - mae: 0.3458 - val_loss: 0.4617 - val_mse: 0.4617 - val_mae: 0.4743\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2033 - mse: 0.2033 - mae: 0.3396 - val_loss: 0.4695 - val_mse: 0.4695 - val_mae: 0.4711\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2008 - mse: 0.2008 - mae: 0.3363 - val_loss: 0.5232 - val_mse: 0.5232 - val_mae: 0.4829\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1889 - mse: 0.1889 - mae: 0.3285 - val_loss: 0.4681 - val_mse: 0.4681 - val_mae: 0.4804\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - ETA: 0s - loss: 0.1823 - mse: 0.1823 - mae: 0.322 - 0s 23us/sample - loss: 0.1875 - mse: 0.1875 - mae: 0.3259 - val_loss: 0.4977 - val_mse: 0.4977 - val_mae: 0.4772\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1817 - mse: 0.1817 - mae: 0.3240 - val_loss: 0.5037 - val_mse: 0.5037 - val_mae: 0.4769\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1791 - mse: 0.1791 - mae: 0.3184 - val_loss: 0.5039 - val_mse: 0.5039 - val_mae: 0.4821\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1761 - mse: 0.1761 - mae: 0.3176 - val_loss: 0.4639 - val_mse: 0.4639 - val_mae: 0.4762\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1728 - mse: 0.1728 - mae: 0.3120 - val_loss: 0.4511 - val_mse: 0.4511 - val_mae: 0.4680\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1744 - mse: 0.1744 - mae: 0.3170 - val_loss: 0.4723 - val_mse: 0.4723 - val_mae: 0.4626\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1632 - mse: 0.1632 - mae: 0.3041 - val_loss: 0.4350 - val_mse: 0.4350 - val_mae: 0.4606\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1556 - mse: 0.1556 - mae: 0.2977 - val_loss: 0.4934 - val_mse: 0.4934 - val_mae: 0.4731\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1518 - mse: 0.1518 - mae: 0.2943 - val_loss: 0.4540 - val_mse: 0.4540 - val_mae: 0.4662\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1606 - mse: 0.1606 - mae: 0.3015 - val_loss: 0.4532 - val_mse: 0.4532 - val_mae: 0.4707\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.1623 - mse: 0.1623 - mae: 0.3031 - val_loss: 0.4761 - val_mse: 0.4761 - val_mae: 0.4685\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1558 - mse: 0.1558 - mae: 0.2986 - val_loss: 0.4868 - val_mse: 0.4868 - val_mae: 0.4747\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1533 - mse: 0.1533 - mae: 0.2951 - val_loss: 0.4980 - val_mse: 0.4980 - val_mae: 0.4826\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1478 - mse: 0.1478 - mae: 0.2906 - val_loss: 0.4865 - val_mse: 0.4865 - val_mae: 0.4739\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1513 - mse: 0.1513 - mae: 0.2946 - val_loss: 0.5221 - val_mse: 0.5221 - val_mae: 0.4796\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1450 - mse: 0.1450 - mae: 0.2895 - val_loss: 0.4664 - val_mse: 0.4664 - val_mae: 0.4658\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1419 - mse: 0.1419 - mae: 0.2860 - val_loss: 0.4725 - val_mse: 0.4725 - val_mae: 0.4703\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 167us/sample - loss: 0.9245 - mse: 0.9245 - mae: 0.7096 - val_loss: 1.1487 - val_mse: 1.1487 - val_mae: 0.8632\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.5637 - mse: 0.5637 - mae: 0.5642 - val_loss: 1.0195 - val_mse: 1.0195 - val_mae: 0.8038\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.4740 - mse: 0.4740 - mae: 0.5165 - val_loss: 0.9123 - val_mse: 0.9123 - val_mae: 0.7630\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.4268 - mse: 0.4268 - mae: 0.4900 - val_loss: 0.7085 - val_mse: 0.7085 - val_mae: 0.6557\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.4068 - mse: 0.4068 - mae: 0.4778 - val_loss: 0.6747 - val_mse: 0.6747 - val_mae: 0.6424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.3721 - mse: 0.3721 - mae: 0.4531 - val_loss: 0.5947 - val_mse: 0.5947 - val_mae: 0.5982\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3417 - mse: 0.3417 - mae: 0.4351 - val_loss: 0.5211 - val_mse: 0.5211 - val_mae: 0.5440\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.3272 - mse: 0.3272 - mae: 0.4286 - val_loss: 0.4777 - val_mse: 0.4777 - val_mae: 0.5125\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3171 - mse: 0.3171 - mae: 0.4228 - val_loss: 0.4876 - val_mse: 0.4876 - val_mae: 0.5145\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3157 - mse: 0.3157 - mae: 0.4194 - val_loss: 0.4989 - val_mse: 0.4989 - val_mae: 0.5152\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.2993 - mse: 0.2993 - mae: 0.4080 - val_loss: 0.4697 - val_mse: 0.4697 - val_mae: 0.5049\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2946 - mse: 0.2946 - mae: 0.4066 - val_loss: 0.4760 - val_mse: 0.4760 - val_mae: 0.4968\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2593 - mse: 0.2593 - mae: 0.3849 - val_loss: 0.4515 - val_mse: 0.4515 - val_mae: 0.4833\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2587 - mse: 0.2587 - mae: 0.3824 - val_loss: 0.4548 - val_mse: 0.4548 - val_mae: 0.4883\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2426 - mse: 0.2426 - mae: 0.3712 - val_loss: 0.4563 - val_mse: 0.4563 - val_mae: 0.4829\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2512 - mse: 0.2512 - mae: 0.3766 - val_loss: 0.4400 - val_mse: 0.4400 - val_mae: 0.4775\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2336 - mse: 0.2336 - mae: 0.3600 - val_loss: 0.4541 - val_mse: 0.4541 - val_mae: 0.4867\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2189 - mse: 0.2189 - mae: 0.3535 - val_loss: 0.4480 - val_mse: 0.4480 - val_mae: 0.4849\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2156 - mse: 0.2156 - mae: 0.3504 - val_loss: 0.4666 - val_mse: 0.4666 - val_mae: 0.4828\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2080 - mse: 0.2080 - mae: 0.3444 - val_loss: 0.4423 - val_mse: 0.4423 - val_mae: 0.4679\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2046 - mse: 0.2046 - mae: 0.3415 - val_loss: 0.4745 - val_mse: 0.4745 - val_mae: 0.4874\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1929 - mse: 0.1929 - mae: 0.3313 - val_loss: 0.4548 - val_mse: 0.4548 - val_mae: 0.4809\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1986 - mse: 0.1986 - mae: 0.3351 - val_loss: 0.4561 - val_mse: 0.4561 - val_mae: 0.4708\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1935 - mse: 0.1935 - mae: 0.3322 - val_loss: 0.4393 - val_mse: 0.4393 - val_mae: 0.4728\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1857 - mse: 0.1857 - mae: 0.3245 - val_loss: 0.4529 - val_mse: 0.4529 - val_mae: 0.4808\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1788 - mse: 0.1788 - mae: 0.3215 - val_loss: 0.4377 - val_mse: 0.4377 - val_mae: 0.4664\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1746 - mse: 0.1746 - mae: 0.3161 - val_loss: 0.4648 - val_mse: 0.4648 - val_mae: 0.4743\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1811 - mse: 0.1811 - mae: 0.3222 - val_loss: 0.4378 - val_mse: 0.4378 - val_mae: 0.4731\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1634 - mse: 0.1634 - mae: 0.3068 - val_loss: 0.4454 - val_mse: 0.4454 - val_mae: 0.4735\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1706 - mse: 0.1706 - mae: 0.3119 - val_loss: 0.5137 - val_mse: 0.5137 - val_mae: 0.5016\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1796 - mse: 0.1796 - mae: 0.3192 - val_loss: 0.4506 - val_mse: 0.4506 - val_mae: 0.4836\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1610 - mse: 0.1610 - mae: 0.3045 - val_loss: 0.4381 - val_mse: 0.4381 - val_mae: 0.4701\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1584 - mse: 0.1584 - mae: 0.3013 - val_loss: 0.4503 - val_mse: 0.4503 - val_mae: 0.4798\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1481 - mse: 0.1481 - mae: 0.2911 - val_loss: 0.4262 - val_mse: 0.4262 - val_mae: 0.4668\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1512 - mse: 0.1512 - mae: 0.2963 - val_loss: 0.4281 - val_mse: 0.4281 - val_mae: 0.4671\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1499 - mse: 0.1499 - mae: 0.2937 - val_loss: 0.4564 - val_mse: 0.4564 - val_mae: 0.4772\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1501 - mse: 0.1501 - mae: 0.2936 - val_loss: 0.4480 - val_mse: 0.4480 - val_mae: 0.4759\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1461 - mse: 0.1461 - mae: 0.2883 - val_loss: 0.4518 - val_mse: 0.4518 - val_mae: 0.4682\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1452 - mse: 0.1452 - mae: 0.2903 - val_loss: 0.4381 - val_mse: 0.4381 - val_mae: 0.4665\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1421 - mse: 0.1421 - mae: 0.2861 - val_loss: 0.4515 - val_mse: 0.4515 - val_mae: 0.4763\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1374 - mse: 0.1374 - mae: 0.2803 - val_loss: 0.4239 - val_mse: 0.4239 - val_mae: 0.4640\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1355 - mse: 0.1355 - mae: 0.2800 - val_loss: 0.4186 - val_mse: 0.4186 - val_mae: 0.4579\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1372 - mse: 0.1372 - mae: 0.2800 - val_loss: 0.4820 - val_mse: 0.4820 - val_mae: 0.4887\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1354 - mse: 0.1354 - mae: 0.2773 - val_loss: 0.4544 - val_mse: 0.4544 - val_mae: 0.4694\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1332 - mse: 0.1332 - mae: 0.2775 - val_loss: 0.4222 - val_mse: 0.4222 - val_mae: 0.4583\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1273 - mse: 0.1273 - mae: 0.2708 - val_loss: 0.4494 - val_mse: 0.4494 - val_mae: 0.4778\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1293 - mse: 0.1293 - mae: 0.2730 - val_loss: 0.4279 - val_mse: 0.4279 - val_mae: 0.4608\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1251 - mse: 0.1251 - mae: 0.2687 - val_loss: 0.4438 - val_mse: 0.4438 - val_mae: 0.4658\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1285 - mse: 0.1285 - mae: 0.2711 - val_loss: 0.4164 - val_mse: 0.4164 - val_mae: 0.4573\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1288 - mse: 0.1288 - mae: 0.2717 - val_loss: 0.4354 - val_mse: 0.4354 - val_mae: 0.4574\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1241 - mse: 0.1241 - mae: 0.2681 - val_loss: 0.4117 - val_mse: 0.4117 - val_mae: 0.4509\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.1185 - mse: 0.1185 - mae: 0.2655 - val_loss: 0.4218 - val_mse: 0.4218 - val_mae: 0.4536\n",
      "Epoch 53/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1178 - mse: 0.1178 - mae: 0.2621 - val_loss: 0.4302 - val_mse: 0.4302 - val_mae: 0.4618\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1238 - mse: 0.1238 - mae: 0.2662 - val_loss: 0.4365 - val_mse: 0.4365 - val_mae: 0.4669\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1231 - mse: 0.1231 - mae: 0.2669 - val_loss: 0.4315 - val_mse: 0.4315 - val_mae: 0.4582\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1181 - mse: 0.1181 - mae: 0.2603 - val_loss: 0.4314 - val_mse: 0.4314 - val_mae: 0.4599\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1175 - mse: 0.1175 - mae: 0.2591 - val_loss: 0.4474 - val_mse: 0.4474 - val_mae: 0.4676\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1160 - mse: 0.1160 - mae: 0.2595 - val_loss: 0.4139 - val_mse: 0.4139 - val_mae: 0.4489\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1169 - mse: 0.1169 - mae: 0.2595 - val_loss: 0.4275 - val_mse: 0.4275 - val_mae: 0.4597\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1137 - mse: 0.1137 - mae: 0.2562 - val_loss: 0.4393 - val_mse: 0.4393 - val_mae: 0.4653\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1082 - mse: 0.1082 - mae: 0.2499 - val_loss: 0.4304 - val_mse: 0.4304 - val_mae: 0.4615\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 165us/sample - loss: 0.9709 - mse: 0.9709 - mae: 0.7257 - val_loss: 1.2090 - val_mse: 1.2090 - val_mae: 0.9291\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.5564 - mse: 0.5564 - mae: 0.5521 - val_loss: 0.9356 - val_mse: 0.9356 - val_mae: 0.7874\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.4769 - mse: 0.4769 - mae: 0.5129 - val_loss: 0.7428 - val_mse: 0.7428 - val_mae: 0.6866\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.4297 - mse: 0.4297 - mae: 0.4895 - val_loss: 0.6989 - val_mse: 0.6989 - val_mae: 0.6654\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3986 - mse: 0.3986 - mae: 0.4703 - val_loss: 0.6065 - val_mse: 0.6065 - val_mae: 0.6082\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3644 - mse: 0.3644 - mae: 0.4514 - val_loss: 0.5387 - val_mse: 0.5387 - val_mae: 0.5557\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.3544 - mse: 0.3544 - mae: 0.4423 - val_loss: 0.5052 - val_mse: 0.5052 - val_mae: 0.5390\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.3206 - mse: 0.3206 - mae: 0.4255 - val_loss: 0.4521 - val_mse: 0.4521 - val_mae: 0.5071\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3110 - mse: 0.3110 - mae: 0.4173 - val_loss: 0.4517 - val_mse: 0.4517 - val_mae: 0.5053\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2914 - mse: 0.2914 - mae: 0.4060 - val_loss: 0.4555 - val_mse: 0.4555 - val_mae: 0.4959\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2736 - mse: 0.2736 - mae: 0.3931 - val_loss: 0.4350 - val_mse: 0.4350 - val_mae: 0.4857\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2734 - mse: 0.2734 - mae: 0.3908 - val_loss: 0.4388 - val_mse: 0.4388 - val_mae: 0.4834\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2657 - mse: 0.2657 - mae: 0.3860 - val_loss: 0.4297 - val_mse: 0.4297 - val_mae: 0.4808\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2588 - mse: 0.2588 - mae: 0.3799 - val_loss: 0.4236 - val_mse: 0.4236 - val_mae: 0.4760\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.2411 - mse: 0.2411 - mae: 0.3690 - val_loss: 0.4429 - val_mse: 0.4429 - val_mae: 0.4788\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2402 - mse: 0.2402 - mae: 0.3692 - val_loss: 0.4260 - val_mse: 0.4260 - val_mae: 0.4744\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2281 - mse: 0.2281 - mae: 0.3584 - val_loss: 0.4355 - val_mse: 0.4355 - val_mae: 0.4718\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2254 - mse: 0.2254 - mae: 0.3581 - val_loss: 0.4101 - val_mse: 0.4101 - val_mae: 0.4636\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - ETA: 0s - loss: 0.2145 - mse: 0.2145 - mae: 0.348 - 0s 23us/sample - loss: 0.2134 - mse: 0.2134 - mae: 0.3485 - val_loss: 0.4280 - val_mse: 0.4280 - val_mae: 0.4721\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2124 - mse: 0.2124 - mae: 0.3466 - val_loss: 0.4230 - val_mse: 0.4230 - val_mae: 0.4731\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2023 - mse: 0.2023 - mae: 0.3397 - val_loss: 0.4156 - val_mse: 0.4156 - val_mae: 0.4636\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1984 - mse: 0.1984 - mae: 0.3354 - val_loss: 0.4094 - val_mse: 0.4094 - val_mae: 0.4587\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1926 - mse: 0.1926 - mae: 0.3303 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4609\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1891 - mse: 0.1891 - mae: 0.3266 - val_loss: 0.4184 - val_mse: 0.4184 - val_mae: 0.4695\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1874 - mse: 0.1874 - mae: 0.3256 - val_loss: 0.4232 - val_mse: 0.4232 - val_mae: 0.4721\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1728 - mse: 0.1728 - mae: 0.3107 - val_loss: 0.4234 - val_mse: 0.4234 - val_mae: 0.4704\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.1743 - mse: 0.1743 - mae: 0.3163 - val_loss: 0.4152 - val_mse: 0.4152 - val_mae: 0.4631\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1759 - mse: 0.1759 - mae: 0.3168 - val_loss: 0.4131 - val_mse: 0.4131 - val_mae: 0.4621\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1731 - mse: 0.1731 - mae: 0.3109 - val_loss: 0.4141 - val_mse: 0.4141 - val_mae: 0.4643\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1618 - mse: 0.1618 - mae: 0.3015 - val_loss: 0.4473 - val_mse: 0.4473 - val_mae: 0.4803\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1649 - mse: 0.1649 - mae: 0.3063 - val_loss: 0.4007 - val_mse: 0.4007 - val_mae: 0.4535\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.1623 - mse: 0.1623 - mae: 0.3055 - val_loss: 0.4165 - val_mse: 0.4165 - val_mae: 0.4645\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1566 - mse: 0.1566 - mae: 0.2989 - val_loss: 0.4163 - val_mse: 0.4163 - val_mae: 0.4679\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1595 - mse: 0.1595 - mae: 0.3010 - val_loss: 0.4271 - val_mse: 0.4271 - val_mae: 0.4686\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1533 - mse: 0.1533 - mae: 0.2955 - val_loss: 0.4285 - val_mse: 0.4285 - val_mae: 0.4683\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1458 - mse: 0.1458 - mae: 0.2892 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.4673\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1490 - mse: 0.1490 - mae: 0.2914 - val_loss: 0.4077 - val_mse: 0.4077 - val_mae: 0.4657\n",
      "Epoch 38/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1530 - mse: 0.1530 - mae: 0.2921 - val_loss: 0.4170 - val_mse: 0.4170 - val_mae: 0.4645\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1464 - mse: 0.1464 - mae: 0.2906 - val_loss: 0.4168 - val_mse: 0.4168 - val_mae: 0.4633\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.1370 - mse: 0.1370 - mae: 0.2799 - val_loss: 0.4179 - val_mse: 0.4179 - val_mae: 0.4638\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.1398 - mse: 0.1398 - mae: 0.2812 - val_loss: 0.4056 - val_mse: 0.4056 - val_mae: 0.4577\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 3s 238us/sample - loss: 0.9367 - mse: 0.9367 - mae: 0.7192 - val_loss: 1.0612 - val_mse: 1.0612 - val_mae: 0.7791\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.5544 - mse: 0.5544 - mae: 0.5585 - val_loss: 0.9534 - val_mse: 0.9534 - val_mae: 0.7434\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.4719 - mse: 0.4719 - mae: 0.5138 - val_loss: 0.8007 - val_mse: 0.8007 - val_mae: 0.6842\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.4337 - mse: 0.4337 - mae: 0.4935 - val_loss: 0.7016 - val_mse: 0.7016 - val_mae: 0.6465\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.4005 - mse: 0.4005 - mae: 0.4749 - val_loss: 0.5925 - val_mse: 0.5925 - val_mae: 0.5871\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 24us/sample - loss: 0.3779 - mse: 0.3779 - mae: 0.4619 - val_loss: 0.5491 - val_mse: 0.5491 - val_mae: 0.5627\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.3544 - mse: 0.3544 - mae: 0.4466 - val_loss: 0.5143 - val_mse: 0.5143 - val_mae: 0.5191\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.3247 - mse: 0.3247 - mae: 0.4270 - val_loss: 0.4896 - val_mse: 0.4896 - val_mae: 0.5151\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.3231 - mse: 0.3231 - mae: 0.4249 - val_loss: 0.4414 - val_mse: 0.4414 - val_mae: 0.4891\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.3059 - mse: 0.3059 - mae: 0.4125 - val_loss: 0.4770 - val_mse: 0.4770 - val_mae: 0.5069\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 24us/sample - loss: 0.2850 - mse: 0.2850 - mae: 0.4010 - val_loss: 0.4583 - val_mse: 0.4583 - val_mae: 0.4910\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.2779 - mse: 0.2779 - mae: 0.3947 - val_loss: 0.4620 - val_mse: 0.4620 - val_mae: 0.5026\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.2606 - mse: 0.2606 - mae: 0.3819 - val_loss: 0.4390 - val_mse: 0.4390 - val_mae: 0.4713\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.2437 - mse: 0.2437 - mae: 0.3704 - val_loss: 0.4341 - val_mse: 0.4341 - val_mae: 0.4733\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.2494 - mse: 0.2494 - mae: 0.3755 - val_loss: 0.4389 - val_mse: 0.4389 - val_mae: 0.4720\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.2334 - mse: 0.2334 - mae: 0.3625 - val_loss: 0.4213 - val_mse: 0.4213 - val_mae: 0.4614\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 24us/sample - loss: 0.2243 - mse: 0.2243 - mae: 0.3576 - val_loss: 0.4393 - val_mse: 0.4393 - val_mae: 0.4657\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.2234 - mse: 0.2234 - mae: 0.3521 - val_loss: 0.4429 - val_mse: 0.4429 - val_mae: 0.4800\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 24us/sample - loss: 0.2241 - mse: 0.2241 - mae: 0.3574 - val_loss: 0.4615 - val_mse: 0.4615 - val_mae: 0.4782\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.2082 - mse: 0.2082 - mae: 0.3445 - val_loss: 0.3930 - val_mse: 0.3930 - val_mae: 0.4462\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.2058 - mse: 0.2058 - mae: 0.3414 - val_loss: 0.4267 - val_mse: 0.4267 - val_mae: 0.4654\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.1987 - mse: 0.1987 - mae: 0.3354 - val_loss: 0.4091 - val_mse: 0.4091 - val_mae: 0.4514\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 24us/sample - loss: 0.1923 - mse: 0.1923 - mae: 0.3307 - val_loss: 0.4615 - val_mse: 0.4615 - val_mae: 0.4858\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.1927 - mse: 0.1927 - mae: 0.3310 - val_loss: 0.4384 - val_mse: 0.4384 - val_mae: 0.4563\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 24us/sample - loss: 0.1851 - mse: 0.1851 - mae: 0.3240 - val_loss: 0.4149 - val_mse: 0.4149 - val_mae: 0.4589\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 24us/sample - loss: 0.1789 - mse: 0.1789 - mae: 0.3183 - val_loss: 0.4282 - val_mse: 0.4282 - val_mae: 0.4650\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 23us/sample - loss: 0.1788 - mse: 0.1788 - mae: 0.3185 - val_loss: 0.4109 - val_mse: 0.4109 - val_mae: 0.4527\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 24us/sample - loss: 0.1799 - mse: 0.1799 - mae: 0.3190 - val_loss: 0.4157 - val_mse: 0.4157 - val_mae: 0.4579\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 24us/sample - loss: 0.1751 - mse: 0.1751 - mae: 0.3165 - val_loss: 0.4225 - val_mse: 0.4225 - val_mae: 0.4613\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.1667 - mse: 0.1667 - mae: 0.3083 - val_loss: 0.4142 - val_mse: 0.4142 - val_mae: 0.4568\n",
      "Avg. MAE: 0.400380\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 306us/sample - loss: 13.0692 - mse: 13.0693 - mae: 1.7026 - val_loss: 267.7223 - val_mse: 267.7224 - val_mae: 13.2615\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.7333 - mse: 0.7333 - mae: 0.6395 - val_loss: 1.4718 - val_mse: 1.4718 - val_mae: 0.9205\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.6394 - mse: 0.6394 - mae: 0.5933 - val_loss: 1.0391 - val_mse: 1.0391 - val_mae: 0.7699\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.5973 - mse: 0.5973 - mae: 0.5735 - val_loss: 0.7280 - val_mse: 0.7280 - val_mae: 0.6495\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.5462 - mse: 0.5462 - mae: 0.5491 - val_loss: 0.6819 - val_mse: 0.6819 - val_mae: 0.6199\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.5060 - mse: 0.5060 - mae: 0.5323 - val_loss: 0.6148 - val_mse: 0.6148 - val_mae: 0.5880\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.4568 - mse: 0.4568 - mae: 0.5084 - val_loss: 0.5734 - val_mse: 0.5734 - val_mae: 0.5545\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.4169 - mse: 0.4169 - mae: 0.4851 - val_loss: 0.4903 - val_mse: 0.4903 - val_mae: 0.5277\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 2s 159us/sample - loss: 0.3974 - mse: 0.3974 - mae: 0.4740 - val_loss: 0.4737 - val_mse: 0.4737 - val_mae: 0.5121\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.3852 - mse: 0.3852 - mae: 0.4695 - val_loss: 0.5438 - val_mse: 0.5438 - val_mae: 0.5670\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.3449 - mse: 0.3449 - mae: 0.4420 - val_loss: 0.4787 - val_mse: 0.4787 - val_mae: 0.5071\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.3360 - mse: 0.3360 - mae: 0.4353 - val_loss: 0.4485 - val_mse: 0.4485 - val_mae: 0.4914\n",
      "Epoch 13/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.3276 - mse: 0.3276 - mae: 0.4328 - val_loss: 0.4489 - val_mse: 0.4489 - val_mae: 0.5080\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.2963 - mse: 0.2963 - mae: 0.4096 - val_loss: 0.4280 - val_mse: 0.4280 - val_mae: 0.4829\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.2835 - mse: 0.2835 - mae: 0.4003 - val_loss: 0.4210 - val_mse: 0.4210 - val_mae: 0.4762\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.2841 - mse: 0.2841 - mae: 0.4015 - val_loss: 0.4479 - val_mse: 0.4479 - val_mae: 0.4897\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.2593 - mse: 0.2593 - mae: 0.3834 - val_loss: 0.4245 - val_mse: 0.4245 - val_mae: 0.4798\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.2699 - mse: 0.2699 - mae: 0.3927 - val_loss: 0.4108 - val_mse: 0.4108 - val_mae: 0.4700\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.2603 - mse: 0.2603 - mae: 0.3876 - val_loss: 0.4106 - val_mse: 0.4106 - val_mae: 0.4658\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.2282 - mse: 0.2282 - mae: 0.3612 - val_loss: 0.4199 - val_mse: 0.4199 - val_mae: 0.4724\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.2230 - mse: 0.2230 - mae: 0.3572 - val_loss: 0.3992 - val_mse: 0.3992 - val_mae: 0.4625\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.2244 - mse: 0.2244 - mae: 0.3587 - val_loss: 0.4019 - val_mse: 0.4019 - val_mae: 0.4643\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.2154 - mse: 0.2154 - mae: 0.3524 - val_loss: 0.4285 - val_mse: 0.4285 - val_mae: 0.4752\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.1974 - mse: 0.1974 - mae: 0.3355 - val_loss: 0.4433 - val_mse: 0.4433 - val_mae: 0.4984\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.1977 - mse: 0.1977 - mae: 0.3352 - val_loss: 0.4573 - val_mse: 0.4573 - val_mae: 0.5066\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.1983 - mse: 0.1983 - mae: 0.3389 - val_loss: 0.4885 - val_mse: 0.4885 - val_mae: 0.5110\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1870 - mse: 0.1870 - mae: 0.3294 - val_loss: 0.4379 - val_mse: 0.4379 - val_mae: 0.4780\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1819 - mse: 0.1819 - mae: 0.3242 - val_loss: 0.4563 - val_mse: 0.4563 - val_mae: 0.4981\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.1848 - mse: 0.1848 - mae: 0.3269 - val_loss: 0.4180 - val_mse: 0.4180 - val_mae: 0.4691\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.1799 - mse: 0.1799 - mae: 0.3231 - val_loss: 0.4643 - val_mse: 0.4643 - val_mae: 0.4825\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1593 - mse: 0.1593 - mae: 0.3025 - val_loss: 0.4298 - val_mse: 0.4298 - val_mae: 0.4748\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 297us/sample - loss: 12.6747 - mse: 12.6747 - mae: 1.6596 - val_loss: 9.4099 - val_mse: 9.4099 - val_mae: 2.1447\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.7693 - mse: 0.7693 - mae: 0.6637 - val_loss: 1.9299 - val_mse: 1.9299 - val_mae: 0.9246\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 2s 161us/sample - loss: 0.6768 - mse: 0.6768 - mae: 0.6152 - val_loss: 0.8464 - val_mse: 0.8464 - val_mae: 0.6799\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.6384 - mse: 0.6384 - mae: 0.5942 - val_loss: 0.7719 - val_mse: 0.7719 - val_mae: 0.6393\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.5981 - mse: 0.5981 - mae: 0.5746 - val_loss: 0.7161 - val_mse: 0.7161 - val_mae: 0.6452\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.5467 - mse: 0.5467 - mae: 0.5514 - val_loss: 0.6627 - val_mse: 0.6627 - val_mae: 0.6315\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.5017 - mse: 0.5017 - mae: 0.5254 - val_loss: 0.6757 - val_mse: 0.6757 - val_mae: 0.5954\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.4609 - mse: 0.4609 - mae: 0.5070 - val_loss: 0.6415 - val_mse: 0.6415 - val_mae: 0.5876\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.4202 - mse: 0.4202 - mae: 0.4829 - val_loss: 0.6003 - val_mse: 0.6003 - val_mae: 0.5554\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.4107 - mse: 0.4107 - mae: 0.4755 - val_loss: 0.5717 - val_mse: 0.5717 - val_mae: 0.5598\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 2s 151us/sample - loss: 0.3868 - mse: 0.3868 - mae: 0.4614 - val_loss: 0.5221 - val_mse: 0.5221 - val_mae: 0.5014\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.3579 - mse: 0.3579 - mae: 0.4446 - val_loss: 0.4815 - val_mse: 0.4815 - val_mae: 0.5011\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.3383 - mse: 0.3383 - mae: 0.4334 - val_loss: 0.5083 - val_mse: 0.5083 - val_mae: 0.5051\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.3148 - mse: 0.3148 - mae: 0.4213 - val_loss: 0.5103 - val_mse: 0.5103 - val_mae: 0.4989\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.3098 - mse: 0.3098 - mae: 0.4115 - val_loss: 0.4942 - val_mse: 0.4942 - val_mae: 0.5038\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.3055 - mse: 0.3055 - mae: 0.4123 - val_loss: 0.4797 - val_mse: 0.4797 - val_mae: 0.4898\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.2857 - mse: 0.2857 - mae: 0.4007 - val_loss: 0.4658 - val_mse: 0.4658 - val_mae: 0.4900\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.2742 - mse: 0.2742 - mae: 0.3942 - val_loss: 0.4759 - val_mse: 0.4759 - val_mae: 0.4920\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.2651 - mse: 0.2651 - mae: 0.3807 - val_loss: 0.5708 - val_mse: 0.5708 - val_mae: 0.5020\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.2373 - mse: 0.2373 - mae: 0.3632 - val_loss: 0.4564 - val_mse: 0.4564 - val_mae: 0.4649\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.2323 - mse: 0.2323 - mae: 0.3608 - val_loss: 0.4367 - val_mse: 0.4367 - val_mae: 0.4770\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.2338 - mse: 0.2338 - mae: 0.3595 - val_loss: 0.5334 - val_mse: 0.5334 - val_mae: 0.4989\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.2289 - mse: 0.2289 - mae: 0.3596 - val_loss: 0.5105 - val_mse: 0.5105 - val_mae: 0.4853\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.2064 - mse: 0.2064 - mae: 0.3412 - val_loss: 0.4621 - val_mse: 0.4621 - val_mae: 0.4632\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.2103 - mse: 0.2103 - mae: 0.3442 - val_loss: 0.4477 - val_mse: 0.4477 - val_mae: 0.4750\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.2144 - mse: 0.2144 - mae: 0.3416 - val_loss: 0.4567 - val_mse: 0.4567 - val_mae: 0.4762\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.2098 - mse: 0.2098 - mae: 0.3408 - val_loss: 0.4281 - val_mse: 0.4281 - val_mae: 0.4631\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1810 - mse: 0.1810 - mae: 0.3185 - val_loss: 0.4469 - val_mse: 0.4469 - val_mae: 0.4621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1909 - mse: 0.1909 - mae: 0.3273 - val_loss: 0.4492 - val_mse: 0.4492 - val_mae: 0.4685\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1810 - mse: 0.1810 - mae: 0.3181 - val_loss: 0.4566 - val_mse: 0.4566 - val_mae: 0.4602\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1755 - mse: 0.1755 - mae: 0.3109 - val_loss: 0.4597 - val_mse: 0.4597 - val_mae: 0.4810\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1586 - mse: 0.1586 - mae: 0.3001 - val_loss: 0.4490 - val_mse: 0.4490 - val_mae: 0.4762\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.1548 - mse: 0.1548 - mae: 0.2963 - val_loss: 0.4197 - val_mse: 0.4197 - val_mae: 0.4481\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1550 - mse: 0.1550 - mae: 0.2950 - val_loss: 0.4484 - val_mse: 0.4484 - val_mae: 0.4616\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1455 - mse: 0.1455 - mae: 0.2889 - val_loss: 0.4231 - val_mse: 0.4231 - val_mae: 0.4508\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.1460 - mse: 0.1460 - mae: 0.2870 - val_loss: 0.4659 - val_mse: 0.4659 - val_mae: 0.4706\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1504 - mse: 0.1504 - mae: 0.2871 - val_loss: 0.5693 - val_mse: 0.5693 - val_mae: 0.4981\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.1571 - mse: 0.1571 - mae: 0.2939 - val_loss: 0.4529 - val_mse: 0.4529 - val_mae: 0.4721\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1307 - mse: 0.1307 - mae: 0.2720 - val_loss: 0.4663 - val_mse: 0.4663 - val_mae: 0.4766\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.1322 - mse: 0.1322 - mae: 0.2703 - val_loss: 0.4406 - val_mse: 0.4406 - val_mae: 0.4517\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1243 - mse: 0.1243 - mae: 0.2674 - val_loss: 0.4521 - val_mse: 0.4521 - val_mae: 0.4513\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1230 - mse: 0.1230 - mae: 0.2655 - val_loss: 0.4338 - val_mse: 0.4338 - val_mae: 0.4535\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.1232 - mse: 0.1232 - mae: 0.2626 - val_loss: 0.4447 - val_mse: 0.4447 - val_mae: 0.4559\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 298us/sample - loss: 14.8676 - mse: 14.8676 - mae: 1.7272 - val_loss: 11.8545 - val_mse: 11.8545 - val_mae: 2.6859\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.6884 - mse: 0.6884 - mae: 0.6206 - val_loss: 2.3041 - val_mse: 2.3041 - val_mae: 1.2430\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 2s 151us/sample - loss: 0.6077 - mse: 0.6077 - mae: 0.5814 - val_loss: 1.5256 - val_mse: 1.5256 - val_mae: 0.9163\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.5705 - mse: 0.5705 - mae: 0.5601 - val_loss: 0.9332 - val_mse: 0.9332 - val_mae: 0.7331\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.5262 - mse: 0.5262 - mae: 0.5396 - val_loss: 0.6630 - val_mse: 0.6630 - val_mae: 0.6119\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 2s 159us/sample - loss: 0.4814 - mse: 0.4814 - mae: 0.5159 - val_loss: 0.6210 - val_mse: 0.6210 - val_mae: 0.6054\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.4369 - mse: 0.4369 - mae: 0.4923 - val_loss: 0.5513 - val_mse: 0.5513 - val_mae: 0.5536\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.4083 - mse: 0.4083 - mae: 0.4762 - val_loss: 0.5144 - val_mse: 0.5144 - val_mae: 0.5268\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.4026 - mse: 0.4026 - mae: 0.4747 - val_loss: 0.5122 - val_mse: 0.5122 - val_mae: 0.5371\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.3609 - mse: 0.3609 - mae: 0.4478 - val_loss: 0.4870 - val_mse: 0.4870 - val_mae: 0.5123\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.3552 - mse: 0.3552 - mae: 0.4444 - val_loss: 0.4947 - val_mse: 0.4947 - val_mae: 0.5204\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.3435 - mse: 0.3435 - mae: 0.4433 - val_loss: 0.4629 - val_mse: 0.4629 - val_mae: 0.5002\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.3111 - mse: 0.3111 - mae: 0.4174 - val_loss: 0.4558 - val_mse: 0.4558 - val_mae: 0.4949\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.2888 - mse: 0.2888 - mae: 0.4032 - val_loss: 0.4548 - val_mse: 0.4548 - val_mae: 0.4820\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 2s 151us/sample - loss: 0.2663 - mse: 0.2663 - mae: 0.3884 - val_loss: 0.4704 - val_mse: 0.4704 - val_mae: 0.4962\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.2935 - mse: 0.2935 - mae: 0.4119 - val_loss: 0.5165 - val_mse: 0.5165 - val_mae: 0.5303\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.2819 - mse: 0.2819 - mae: 0.4025 - val_loss: 0.4833 - val_mse: 0.4833 - val_mae: 0.5127\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.2542 - mse: 0.2542 - mae: 0.3799 - val_loss: 0.4284 - val_mse: 0.4284 - val_mae: 0.4782\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 2s 151us/sample - loss: 0.2479 - mse: 0.2479 - mae: 0.3741 - val_loss: 0.4252 - val_mse: 0.4252 - val_mae: 0.4771\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.2312 - mse: 0.2312 - mae: 0.3625 - val_loss: 0.4183 - val_mse: 0.4183 - val_mae: 0.4693\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.2355 - mse: 0.2355 - mae: 0.3666 - val_loss: 0.4650 - val_mse: 0.4650 - val_mae: 0.4804\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.2186 - mse: 0.2186 - mae: 0.3561 - val_loss: 0.4351 - val_mse: 0.4351 - val_mae: 0.4782\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.2295 - mse: 0.2295 - mae: 0.3641 - val_loss: 0.4562 - val_mse: 0.4562 - val_mae: 0.4874\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1988 - mse: 0.1988 - mae: 0.3395 - val_loss: 0.4229 - val_mse: 0.4229 - val_mae: 0.4707\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1955 - mse: 0.1955 - mae: 0.3367 - val_loss: 0.4342 - val_mse: 0.4342 - val_mae: 0.4883\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.1893 - mse: 0.1893 - mae: 0.3308 - val_loss: 0.4752 - val_mse: 0.4752 - val_mae: 0.5078\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1770 - mse: 0.1770 - mae: 0.3209 - val_loss: 0.4164 - val_mse: 0.4164 - val_mae: 0.4504\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1809 - mse: 0.1809 - mae: 0.3220 - val_loss: 0.4190 - val_mse: 0.4190 - val_mae: 0.4617\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.1748 - mse: 0.1748 - mae: 0.3191 - val_loss: 0.4299 - val_mse: 0.4299 - val_mae: 0.4633\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1659 - mse: 0.1659 - mae: 0.3111 - val_loss: 0.4755 - val_mse: 0.4755 - val_mae: 0.4952\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1696 - mse: 0.1696 - mae: 0.3139 - val_loss: 0.4371 - val_mse: 0.4371 - val_mae: 0.4800\n",
      "Epoch 32/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.1584 - mse: 0.1584 - mae: 0.3030 - val_loss: 0.4154 - val_mse: 0.4154 - val_mae: 0.4609\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1481 - mse: 0.1481 - mae: 0.2931 - val_loss: 0.4161 - val_mse: 0.4161 - val_mae: 0.4495\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.1385 - mse: 0.1385 - mae: 0.2828 - val_loss: 0.4189 - val_mse: 0.4189 - val_mae: 0.4586\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.1447 - mse: 0.1447 - mae: 0.2885 - val_loss: 0.3877 - val_mse: 0.3877 - val_mae: 0.4434\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1447 - mse: 0.1447 - mae: 0.2885 - val_loss: 0.4158 - val_mse: 0.4158 - val_mae: 0.4533\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1541 - mse: 0.1541 - mae: 0.2992 - val_loss: 0.3963 - val_mse: 0.3963 - val_mae: 0.4526\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 2s 151us/sample - loss: 0.1346 - mse: 0.1346 - mae: 0.2806 - val_loss: 0.4467 - val_mse: 0.4467 - val_mae: 0.4621\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1379 - mse: 0.1379 - mae: 0.2848 - val_loss: 0.3893 - val_mse: 0.3893 - val_mae: 0.4309\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1277 - mse: 0.1277 - mae: 0.2706 - val_loss: 0.4027 - val_mse: 0.4027 - val_mae: 0.4378\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1287 - mse: 0.1287 - mae: 0.2719 - val_loss: 0.3866 - val_mse: 0.3866 - val_mae: 0.4401\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1378 - mse: 0.1378 - mae: 0.2802 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4578\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 2s 159us/sample - loss: 0.1241 - mse: 0.1241 - mae: 0.2684 - val_loss: 0.4496 - val_mse: 0.4496 - val_mae: 0.4895\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1235 - mse: 0.1235 - mae: 0.2697 - val_loss: 0.4161 - val_mse: 0.4161 - val_mae: 0.4447\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1244 - mse: 0.1244 - mae: 0.2696 - val_loss: 0.4085 - val_mse: 0.4085 - val_mae: 0.4458\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1303 - mse: 0.1303 - mae: 0.2766 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4439\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1034 - mse: 0.1034 - mae: 0.2472 - val_loss: 0.4360 - val_mse: 0.4360 - val_mae: 0.4764\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1168 - mse: 0.1168 - mae: 0.2602 - val_loss: 0.3889 - val_mse: 0.3889 - val_mae: 0.4381\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1003 - mse: 0.1003 - mae: 0.2391 - val_loss: 0.3879 - val_mse: 0.3879 - val_mae: 0.4378\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1115 - mse: 0.1115 - mae: 0.2547 - val_loss: 0.3811 - val_mse: 0.3811 - val_mae: 0.4400\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.1301 - mse: 0.1301 - mae: 0.2724 - val_loss: 0.3787 - val_mse: 0.3787 - val_mae: 0.4302\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.1028 - mse: 0.1028 - mae: 0.2454 - val_loss: 0.3860 - val_mse: 0.3860 - val_mae: 0.4324\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.0937 - mse: 0.0937 - mae: 0.2324 - val_loss: 0.3999 - val_mse: 0.3999 - val_mae: 0.4482\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.0996 - mse: 0.0996 - mae: 0.2385 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.4580\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1091 - mse: 0.1091 - mae: 0.2534 - val_loss: 0.4282 - val_mse: 0.4282 - val_mae: 0.4644\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.1050 - mse: 0.1050 - mae: 0.2471 - val_loss: 0.3625 - val_mse: 0.3625 - val_mae: 0.4206\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2285 - val_loss: 0.4441 - val_mse: 0.4441 - val_mae: 0.4544\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.0923 - mse: 0.0923 - mae: 0.2327 - val_loss: 0.3831 - val_mse: 0.3831 - val_mae: 0.4301\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.0961 - mse: 0.0961 - mae: 0.2356 - val_loss: 0.4260 - val_mse: 0.4260 - val_mae: 0.4605\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.0943 - mse: 0.0943 - mae: 0.2339 - val_loss: 0.3845 - val_mse: 0.3845 - val_mae: 0.4281\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.0924 - mse: 0.0924 - mae: 0.2319 - val_loss: 0.3803 - val_mse: 0.3803 - val_mae: 0.4257\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.0831 - mse: 0.0831 - mae: 0.2190 - val_loss: 0.3637 - val_mse: 0.3637 - val_mae: 0.4163\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 2s 154us/sample - loss: 0.0836 - mse: 0.0836 - mae: 0.2196 - val_loss: 0.3947 - val_mse: 0.3947 - val_mae: 0.4450\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.0751 - mse: 0.0751 - mae: 0.2080 - val_loss: 0.4188 - val_mse: 0.4188 - val_mae: 0.4567\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 2s 153us/sample - loss: 0.0965 - mse: 0.0965 - mae: 0.2339 - val_loss: 0.4076 - val_mse: 0.4076 - val_mae: 0.4394\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 2s 152us/sample - loss: 0.0864 - mse: 0.0864 - mae: 0.2215 - val_loss: 0.3935 - val_mse: 0.3935 - val_mae: 0.4369\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 4s 369us/sample - loss: 13.4856 - mse: 13.4856 - mae: 1.7991 - val_loss: 12.7631 - val_mse: 12.7631 - val_mae: 2.7098\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 2s 158us/sample - loss: 0.7400 - mse: 0.7400 - mae: 0.6473 - val_loss: 1.2230 - val_mse: 1.2230 - val_mae: 0.8466\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 2s 158us/sample - loss: 0.6589 - mse: 0.6589 - mae: 0.6052 - val_loss: 1.1696 - val_mse: 1.1696 - val_mae: 0.8605\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 2s 158us/sample - loss: 0.6023 - mse: 0.6023 - mae: 0.5795 - val_loss: 0.7909 - val_mse: 0.7909 - val_mae: 0.7066\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 2s 158us/sample - loss: 0.5531 - mse: 0.5531 - mae: 0.5513 - val_loss: 0.6800 - val_mse: 0.6800 - val_mae: 0.6458\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.5128 - mse: 0.5128 - mae: 0.5314 - val_loss: 0.5658 - val_mse: 0.5658 - val_mae: 0.5712\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.4735 - mse: 0.4735 - mae: 0.5125 - val_loss: 0.6180 - val_mse: 0.6180 - val_mae: 0.6132\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.4211 - mse: 0.4211 - mae: 0.4855 - val_loss: 0.5000 - val_mse: 0.5000 - val_mae: 0.5438\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.3920 - mse: 0.3920 - mae: 0.4695 - val_loss: 0.5408 - val_mse: 0.5408 - val_mae: 0.5481\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.3740 - mse: 0.3740 - mae: 0.4578 - val_loss: 0.5216 - val_mse: 0.5216 - val_mae: 0.5377\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.3406 - mse: 0.3406 - mae: 0.4357 - val_loss: 0.4519 - val_mse: 0.4519 - val_mae: 0.4983\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 2s 162us/sample - loss: 0.3336 - mse: 0.3336 - mae: 0.4320 - val_loss: 0.4576 - val_mse: 0.4576 - val_mae: 0.4981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.3108 - mse: 0.3108 - mae: 0.4179 - val_loss: 0.4535 - val_mse: 0.4535 - val_mae: 0.4969\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.3012 - mse: 0.3012 - mae: 0.4115 - val_loss: 0.4550 - val_mse: 0.4550 - val_mae: 0.5042\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.2824 - mse: 0.2824 - mae: 0.3999 - val_loss: 0.4514 - val_mse: 0.4514 - val_mae: 0.4947\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 2s 158us/sample - loss: 0.2807 - mse: 0.2807 - mae: 0.3981 - val_loss: 0.4199 - val_mse: 0.4199 - val_mae: 0.4716\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 2s 158us/sample - loss: 0.2710 - mse: 0.2710 - mae: 0.3901 - val_loss: 0.4540 - val_mse: 0.4540 - val_mae: 0.5019\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 2s 158us/sample - loss: 0.2488 - mse: 0.2488 - mae: 0.3789 - val_loss: 0.4300 - val_mse: 0.4300 - val_mae: 0.4739\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.2379 - mse: 0.2379 - mae: 0.3673 - val_loss: 0.4570 - val_mse: 0.4570 - val_mae: 0.4779\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.2411 - mse: 0.2411 - mae: 0.3724 - val_loss: 0.4293 - val_mse: 0.4293 - val_mae: 0.4710\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.2227 - mse: 0.2227 - mae: 0.3533 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.4707\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.2154 - mse: 0.2154 - mae: 0.3505 - val_loss: 0.4070 - val_mse: 0.4070 - val_mae: 0.4658\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.2085 - mse: 0.2085 - mae: 0.3462 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.5165\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.2133 - mse: 0.2133 - mae: 0.3490 - val_loss: 0.4331 - val_mse: 0.4331 - val_mae: 0.4759\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.1968 - mse: 0.1968 - mae: 0.3370 - val_loss: 0.4142 - val_mse: 0.4142 - val_mae: 0.4676\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 2s 159us/sample - loss: 0.1879 - mse: 0.1879 - mae: 0.3273 - val_loss: 0.4006 - val_mse: 0.4006 - val_mae: 0.4585\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.1927 - mse: 0.1927 - mae: 0.3359 - val_loss: 0.4035 - val_mse: 0.4035 - val_mae: 0.4585\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.1748 - mse: 0.1748 - mae: 0.3175 - val_loss: 0.4039 - val_mse: 0.4039 - val_mae: 0.4655\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.1895 - mse: 0.1895 - mae: 0.3307 - val_loss: 0.4307 - val_mse: 0.4307 - val_mae: 0.4760\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.1838 - mse: 0.1838 - mae: 0.3231 - val_loss: 0.4238 - val_mse: 0.4238 - val_mae: 0.4804\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.1714 - mse: 0.1714 - mae: 0.3127 - val_loss: 0.3788 - val_mse: 0.3788 - val_mae: 0.4417\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.1618 - mse: 0.1618 - mae: 0.3043 - val_loss: 0.3816 - val_mse: 0.3816 - val_mae: 0.4399\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 2s 158us/sample - loss: 0.1566 - mse: 0.1566 - mae: 0.2996 - val_loss: 0.3876 - val_mse: 0.3876 - val_mae: 0.4548\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.1632 - mse: 0.1632 - mae: 0.3073 - val_loss: 0.4493 - val_mse: 0.4493 - val_mae: 0.4863\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 2s 158us/sample - loss: 0.1488 - mse: 0.1488 - mae: 0.2952 - val_loss: 0.3852 - val_mse: 0.3852 - val_mae: 0.4503\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 2s 158us/sample - loss: 0.1376 - mse: 0.1376 - mae: 0.2806 - val_loss: 0.4328 - val_mse: 0.4328 - val_mae: 0.4804\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.1427 - mse: 0.1427 - mae: 0.2871 - val_loss: 0.4282 - val_mse: 0.4282 - val_mae: 0.4764\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 2s 161us/sample - loss: 0.1388 - mse: 0.1388 - mae: 0.2823 - val_loss: 0.4928 - val_mse: 0.4928 - val_mae: 0.5231\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 2s 159us/sample - loss: 0.1423 - mse: 0.1423 - mae: 0.2868 - val_loss: 0.3652 - val_mse: 0.3652 - val_mae: 0.4333\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.1332 - mse: 0.1332 - mae: 0.2741 - val_loss: 0.3882 - val_mse: 0.3882 - val_mae: 0.4483\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.1331 - mse: 0.1331 - mae: 0.2737 - val_loss: 0.4076 - val_mse: 0.4076 - val_mae: 0.4646\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.1315 - mse: 0.1315 - mae: 0.2738 - val_loss: 0.3806 - val_mse: 0.3806 - val_mae: 0.4444\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.1254 - mse: 0.1254 - mae: 0.2672 - val_loss: 0.3973 - val_mse: 0.3973 - val_mae: 0.4576\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.1283 - mse: 0.1283 - mae: 0.2739 - val_loss: 0.4106 - val_mse: 0.4106 - val_mae: 0.4749\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.1178 - mse: 0.1178 - mae: 0.2598 - val_loss: 0.4062 - val_mse: 0.4062 - val_mae: 0.4660\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.1163 - mse: 0.1163 - mae: 0.2583 - val_loss: 0.3727 - val_mse: 0.3727 - val_mae: 0.4423\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.1039 - mse: 0.1039 - mae: 0.2441 - val_loss: 0.3644 - val_mse: 0.3644 - val_mae: 0.4320\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 2s 163us/sample - loss: 0.1076 - mse: 0.1076 - mae: 0.2473 - val_loss: 0.3908 - val_mse: 0.3908 - val_mae: 0.4486\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.1200 - mse: 0.1200 - mae: 0.2661 - val_loss: 0.3868 - val_mse: 0.3868 - val_mae: 0.4476\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.1052 - mse: 0.1052 - mae: 0.2444 - val_loss: 0.3776 - val_mse: 0.3776 - val_mae: 0.4360\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.1101 - mse: 0.1101 - mae: 0.2505 - val_loss: 0.3957 - val_mse: 0.3957 - val_mae: 0.4554\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.1039 - mse: 0.1039 - mae: 0.2416 - val_loss: 0.4142 - val_mse: 0.4142 - val_mae: 0.4672\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.1021 - mse: 0.1021 - mae: 0.2427 - val_loss: 0.3971 - val_mse: 0.3971 - val_mae: 0.4502\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 2s 155us/sample - loss: 0.1062 - mse: 0.1062 - mae: 0.2449 - val_loss: 0.3904 - val_mse: 0.3904 - val_mae: 0.4512\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 2s 156us/sample - loss: 0.1056 - mse: 0.1056 - mae: 0.2454 - val_loss: 0.3874 - val_mse: 0.3874 - val_mae: 0.4547\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.1078 - mse: 0.1078 - mae: 0.2486 - val_loss: 0.3835 - val_mse: 0.3835 - val_mae: 0.4458\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 2s 157us/sample - loss: 0.0955 - mse: 0.0955 - mae: 0.2336 - val_loss: 0.4187 - val_mse: 0.4187 - val_mae: 0.4704\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 3s 301us/sample - loss: 13.3462 - mse: 13.3462 - mae: 1.7387 - val_loss: 319.4270 - val_mse: 319.4270 - val_mae: 13.5679\n",
      "Epoch 2/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.7545 - mse: 0.7545 - mae: 0.6573 - val_loss: 2.6693 - val_mse: 2.6693 - val_mae: 1.2637\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 2s 157us/sample - loss: 0.6558 - mse: 0.6558 - mae: 0.6121 - val_loss: 0.8076 - val_mse: 0.8076 - val_mae: 0.7030\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.6045 - mse: 0.6045 - mae: 0.5834 - val_loss: 0.6762 - val_mse: 0.6762 - val_mae: 0.6200\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 2s 157us/sample - loss: 0.5611 - mse: 0.5611 - mae: 0.5564 - val_loss: 0.6501 - val_mse: 0.6501 - val_mae: 0.6293\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.4940 - mse: 0.4940 - mae: 0.5277 - val_loss: 0.5473 - val_mse: 0.5473 - val_mae: 0.5460\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 2s 157us/sample - loss: 0.4532 - mse: 0.4532 - mae: 0.5023 - val_loss: 0.5597 - val_mse: 0.5597 - val_mae: 0.5556\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.4126 - mse: 0.4126 - mae: 0.4803 - val_loss: 0.5144 - val_mse: 0.5144 - val_mae: 0.5282\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.4186 - mse: 0.4186 - mae: 0.4832 - val_loss: 0.7710 - val_mse: 0.7710 - val_mae: 0.6100\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 2s 154us/sample - loss: 0.3881 - mse: 0.3881 - mae: 0.4686 - val_loss: 0.5919 - val_mse: 0.5919 - val_mae: 0.5710\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.3634 - mse: 0.3634 - mae: 0.4532 - val_loss: 0.4750 - val_mse: 0.4750 - val_mae: 0.4996\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.3416 - mse: 0.3416 - mae: 0.4393 - val_loss: 0.6363 - val_mse: 0.6363 - val_mae: 0.5565\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.3389 - mse: 0.3389 - mae: 0.4369 - val_loss: 0.4316 - val_mse: 0.4316 - val_mae: 0.4816\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 2s 154us/sample - loss: 0.2988 - mse: 0.2988 - mae: 0.4124 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.4878\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.3069 - mse: 0.3069 - mae: 0.4178 - val_loss: 0.4268 - val_mse: 0.4268 - val_mae: 0.4796\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 2s 158us/sample - loss: 0.2825 - mse: 0.2825 - mae: 0.3990 - val_loss: 0.4249 - val_mse: 0.4249 - val_mae: 0.4656\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.2775 - mse: 0.2775 - mae: 0.3983 - val_loss: 0.4408 - val_mse: 0.4408 - val_mae: 0.4742\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 2s 154us/sample - loss: 0.2769 - mse: 0.2769 - mae: 0.3962 - val_loss: 0.4357 - val_mse: 0.4357 - val_mae: 0.4831\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.2535 - mse: 0.2535 - mae: 0.3813 - val_loss: 0.4890 - val_mse: 0.4890 - val_mae: 0.5077\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 2s 154us/sample - loss: 0.2482 - mse: 0.2482 - mae: 0.3778 - val_loss: 0.4822 - val_mse: 0.4822 - val_mae: 0.4896\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.2322 - mse: 0.2322 - mae: 0.3643 - val_loss: 0.5185 - val_mse: 0.5185 - val_mae: 0.5155\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.2227 - mse: 0.2227 - mae: 0.3575 - val_loss: 0.4797 - val_mse: 0.4797 - val_mae: 0.5140\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 2s 159us/sample - loss: 0.2245 - mse: 0.2245 - mae: 0.3576 - val_loss: 0.4837 - val_mse: 0.4837 - val_mae: 0.5017\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 2s 161us/sample - loss: 0.2058 - mse: 0.2058 - mae: 0.3412 - val_loss: 0.4131 - val_mse: 0.4131 - val_mae: 0.4679\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.2265 - mse: 0.2265 - mae: 0.3590 - val_loss: 0.4152 - val_mse: 0.4152 - val_mae: 0.4614\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 2s 162us/sample - loss: 0.2018 - mse: 0.2018 - mae: 0.3393 - val_loss: 0.4484 - val_mse: 0.4484 - val_mae: 0.4750\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.2020 - mse: 0.2020 - mae: 0.3391 - val_loss: 0.4305 - val_mse: 0.4305 - val_mae: 0.4702\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 2s 157us/sample - loss: 0.2254 - mse: 0.2254 - mae: 0.3587 - val_loss: 0.4849 - val_mse: 0.4849 - val_mae: 0.5124\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.1853 - mse: 0.1853 - mae: 0.3265 - val_loss: 0.4476 - val_mse: 0.4476 - val_mae: 0.4797\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.2010 - mse: 0.2010 - mae: 0.3395 - val_loss: 0.3893 - val_mse: 0.3893 - val_mae: 0.4449\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 2s 154us/sample - loss: 0.1714 - mse: 0.1714 - mae: 0.3144 - val_loss: 0.4214 - val_mse: 0.4214 - val_mae: 0.4467\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.1739 - mse: 0.1739 - mae: 0.3146 - val_loss: 0.4343 - val_mse: 0.4343 - val_mae: 0.4677\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.1651 - mse: 0.1651 - mae: 0.3080 - val_loss: 0.4280 - val_mse: 0.4280 - val_mae: 0.4687\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.1661 - mse: 0.1661 - mae: 0.3078 - val_loss: 0.4620 - val_mse: 0.4620 - val_mae: 0.4914\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.1602 - mse: 0.1602 - mae: 0.3023 - val_loss: 0.4008 - val_mse: 0.4008 - val_mae: 0.4492\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.1511 - mse: 0.1511 - mae: 0.2957 - val_loss: 0.3878 - val_mse: 0.3878 - val_mae: 0.4368\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.1707 - mse: 0.1707 - mae: 0.3116 - val_loss: 0.4877 - val_mse: 0.4877 - val_mae: 0.4880\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.1417 - mse: 0.1417 - mae: 0.2863 - val_loss: 0.4866 - val_mse: 0.4866 - val_mae: 0.5052\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.1682 - mse: 0.1682 - mae: 0.3105 - val_loss: 0.4087 - val_mse: 0.4087 - val_mae: 0.4569\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 2s 157us/sample - loss: 0.1376 - mse: 0.1376 - mae: 0.2792 - val_loss: 0.3924 - val_mse: 0.3924 - val_mae: 0.4342\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 2s 154us/sample - loss: 0.1311 - mse: 0.1311 - mae: 0.2741 - val_loss: 0.4162 - val_mse: 0.4162 - val_mae: 0.4615\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.1296 - mse: 0.1296 - mae: 0.2721 - val_loss: 0.4118 - val_mse: 0.4118 - val_mae: 0.4539\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.1249 - mse: 0.1249 - mae: 0.2683 - val_loss: 0.4005 - val_mse: 0.4005 - val_mae: 0.4468\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 2s 155us/sample - loss: 0.1276 - mse: 0.1276 - mae: 0.2692 - val_loss: 0.3985 - val_mse: 0.3985 - val_mae: 0.4353\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.1218 - mse: 0.1218 - mae: 0.2626 - val_loss: 0.4009 - val_mse: 0.4009 - val_mae: 0.4430\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 2s 156us/sample - loss: 0.1268 - mse: 0.1268 - mae: 0.2700 - val_loss: 0.4005 - val_mse: 0.4005 - val_mae: 0.4352\n",
      "Avg. MAE: 0.387845\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 75us/sample - loss: 1.1308 - mse: 1.1308 - mae: 0.7977 - val_loss: 2.8421 - val_mse: 2.8421 - val_mae: 1.3463\n",
      "Epoch 2/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.6423 - mse: 0.6423 - mae: 0.6063 - val_loss: 1.4644 - val_mse: 1.4644 - val_mae: 0.9641\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.5548 - mse: 0.5548 - mae: 0.5596 - val_loss: 1.2073 - val_mse: 1.2073 - val_mae: 0.8806\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.5090 - mse: 0.5090 - mae: 0.5393 - val_loss: 1.0157 - val_mse: 1.0157 - val_mae: 0.8109\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.4773 - mse: 0.4773 - mae: 0.5182 - val_loss: 0.8071 - val_mse: 0.8071 - val_mae: 0.7099\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.4414 - mse: 0.4414 - mae: 0.4987 - val_loss: 0.7255 - val_mse: 0.7255 - val_mae: 0.6566\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.4268 - mse: 0.4268 - mae: 0.4909 - val_loss: 0.6268 - val_mse: 0.6268 - val_mae: 0.6125\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3972 - mse: 0.3972 - mae: 0.4731 - val_loss: 0.5631 - val_mse: 0.5631 - val_mae: 0.5711\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3868 - mse: 0.3868 - mae: 0.4687 - val_loss: 0.5509 - val_mse: 0.5509 - val_mae: 0.5639\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3776 - mse: 0.3776 - mae: 0.4640 - val_loss: 0.5533 - val_mse: 0.5533 - val_mae: 0.5601\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3656 - mse: 0.3656 - mae: 0.4549 - val_loss: 0.5239 - val_mse: 0.5239 - val_mae: 0.5414\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3558 - mse: 0.3558 - mae: 0.4481 - val_loss: 0.4982 - val_mse: 0.4982 - val_mae: 0.5217\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3471 - mse: 0.3471 - mae: 0.4424 - val_loss: 0.4791 - val_mse: 0.4791 - val_mae: 0.5150\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3333 - mse: 0.3333 - mae: 0.4355 - val_loss: 0.4707 - val_mse: 0.4707 - val_mae: 0.5093\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3226 - mse: 0.3226 - mae: 0.4277 - val_loss: 0.4589 - val_mse: 0.4589 - val_mae: 0.5081\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3195 - mse: 0.3195 - mae: 0.4251 - val_loss: 0.4592 - val_mse: 0.4592 - val_mae: 0.5041\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3147 - mse: 0.3147 - mae: 0.4240 - val_loss: 0.4762 - val_mse: 0.4762 - val_mae: 0.5104\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3092 - mse: 0.3092 - mae: 0.4182 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.5115\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3058 - mse: 0.3058 - mae: 0.4173 - val_loss: 0.4770 - val_mse: 0.4770 - val_mae: 0.5191\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3016 - mse: 0.3016 - mae: 0.4158 - val_loss: 0.4496 - val_mse: 0.4496 - val_mae: 0.5009\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2942 - mse: 0.2942 - mae: 0.4095 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.5030\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2840 - mse: 0.2840 - mae: 0.4025 - val_loss: 0.4462 - val_mse: 0.4462 - val_mae: 0.4952\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2788 - mse: 0.2788 - mae: 0.4006 - val_loss: 0.4571 - val_mse: 0.4571 - val_mae: 0.4917\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2758 - mse: 0.2758 - mae: 0.3959 - val_loss: 0.4547 - val_mse: 0.4547 - val_mae: 0.4999\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2793 - mse: 0.2793 - mae: 0.3985 - val_loss: 0.4627 - val_mse: 0.4627 - val_mae: 0.5000\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2735 - mse: 0.2735 - mae: 0.3957 - val_loss: 0.4656 - val_mse: 0.4656 - val_mae: 0.5011\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2689 - mse: 0.2689 - mae: 0.3927 - val_loss: 0.4543 - val_mse: 0.4543 - val_mae: 0.5032\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2617 - mse: 0.2617 - mae: 0.3873 - val_loss: 0.4478 - val_mse: 0.4478 - val_mae: 0.4965\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2641 - mse: 0.2641 - mae: 0.3894 - val_loss: 0.4432 - val_mse: 0.4432 - val_mae: 0.4929\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2630 - mse: 0.2630 - mae: 0.3868 - val_loss: 0.4744 - val_mse: 0.4744 - val_mae: 0.4989\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2575 - mse: 0.2575 - mae: 0.3861 - val_loss: 0.4572 - val_mse: 0.4572 - val_mae: 0.4958\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2568 - mse: 0.2568 - mae: 0.3838 - val_loss: 0.4563 - val_mse: 0.4563 - val_mae: 0.4962\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2469 - mse: 0.2469 - mae: 0.3759 - val_loss: 0.4646 - val_mse: 0.4646 - val_mae: 0.4945\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2426 - mse: 0.2426 - mae: 0.3728 - val_loss: 0.4489 - val_mse: 0.4489 - val_mae: 0.4857\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2465 - mse: 0.2465 - mae: 0.3771 - val_loss: 0.4534 - val_mse: 0.4534 - val_mae: 0.4940\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2369 - mse: 0.2369 - mae: 0.3678 - val_loss: 0.4526 - val_mse: 0.4526 - val_mae: 0.4877\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2340 - mse: 0.2340 - mae: 0.3648 - val_loss: 0.4396 - val_mse: 0.4396 - val_mae: 0.4838\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2395 - mse: 0.2395 - mae: 0.3719 - val_loss: 0.4469 - val_mse: 0.4469 - val_mae: 0.4909\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.2361 - mse: 0.2361 - mae: 0.3669 - val_loss: 0.4449 - val_mse: 0.4449 - val_mae: 0.4956\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2305 - mse: 0.2305 - mae: 0.3649 - val_loss: 0.4473 - val_mse: 0.4473 - val_mae: 0.4863\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2330 - mse: 0.2330 - mae: 0.3651 - val_loss: 0.4568 - val_mse: 0.4568 - val_mae: 0.4898\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2357 - mse: 0.2357 - mae: 0.3691 - val_loss: 0.4428 - val_mse: 0.4428 - val_mae: 0.4867\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2298 - mse: 0.2298 - mae: 0.3649 - val_loss: 0.4337 - val_mse: 0.4337 - val_mae: 0.4884\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2227 - mse: 0.2227 - mae: 0.3575 - val_loss: 0.4414 - val_mse: 0.4414 - val_mae: 0.4883\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2210 - mse: 0.2210 - mae: 0.3558 - val_loss: 0.4429 - val_mse: 0.4429 - val_mae: 0.4924\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2198 - mse: 0.2198 - mae: 0.3563 - val_loss: 0.4336 - val_mse: 0.4336 - val_mae: 0.4809\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2163 - mse: 0.2163 - mae: 0.3530 - val_loss: 0.4387 - val_mse: 0.4387 - val_mae: 0.4865\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2217 - mse: 0.2217 - mae: 0.3560 - val_loss: 0.4379 - val_mse: 0.4379 - val_mae: 0.4851\n",
      "Epoch 49/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2163 - mse: 0.2163 - mae: 0.3530 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.4847\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2137 - mse: 0.2137 - mae: 0.3520 - val_loss: 0.4482 - val_mse: 0.4482 - val_mae: 0.4873\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2121 - mse: 0.2121 - mae: 0.3494 - val_loss: 0.4467 - val_mse: 0.4467 - val_mae: 0.4907\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2208 - mse: 0.2208 - mae: 0.3567 - val_loss: 0.4572 - val_mse: 0.4572 - val_mae: 0.4934\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2197 - mse: 0.2197 - mae: 0.3566 - val_loss: 0.4319 - val_mse: 0.4319 - val_mae: 0.4804\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2093 - mse: 0.2093 - mae: 0.3482 - val_loss: 0.4370 - val_mse: 0.4370 - val_mae: 0.4804\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2009 - mse: 0.2009 - mae: 0.3411 - val_loss: 0.4313 - val_mse: 0.4313 - val_mae: 0.4799\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.2079 - mse: 0.2079 - mae: 0.3479 - val_loss: 0.4417 - val_mse: 0.4417 - val_mae: 0.4905\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2046 - mse: 0.2046 - mae: 0.3434 - val_loss: 0.4367 - val_mse: 0.4367 - val_mae: 0.4874\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2054 - mse: 0.2054 - mae: 0.3427 - val_loss: 0.4505 - val_mse: 0.4505 - val_mae: 0.4978\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2016 - mse: 0.2016 - mae: 0.3403 - val_loss: 0.4404 - val_mse: 0.4404 - val_mae: 0.4853\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2058 - mse: 0.2058 - mae: 0.3460 - val_loss: 0.4478 - val_mse: 0.4478 - val_mae: 0.4983\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2073 - mse: 0.2073 - mae: 0.3468 - val_loss: 0.4543 - val_mse: 0.4543 - val_mae: 0.5025\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.2046 - mse: 0.2046 - mae: 0.3447 - val_loss: 0.4490 - val_mse: 0.4490 - val_mae: 0.4866\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2007 - mse: 0.2007 - mae: 0.3404 - val_loss: 0.4400 - val_mse: 0.4400 - val_mae: 0.4896\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.1952 - mse: 0.1952 - mae: 0.3367 - val_loss: 0.4292 - val_mse: 0.4292 - val_mae: 0.4830\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.1959 - mse: 0.1959 - mae: 0.3353 - val_loss: 0.4438 - val_mse: 0.4438 - val_mae: 0.4856\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.1951 - mse: 0.1951 - mae: 0.3358 - val_loss: 0.4377 - val_mse: 0.4377 - val_mae: 0.4848\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.1930 - mse: 0.1930 - mae: 0.3325 - val_loss: 0.4562 - val_mse: 0.4562 - val_mae: 0.4858\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.1883 - mse: 0.1883 - mae: 0.3307 - val_loss: 0.4505 - val_mse: 0.4505 - val_mae: 0.4841\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.1961 - mse: 0.1961 - mae: 0.3377 - val_loss: 0.4581 - val_mse: 0.4581 - val_mae: 0.4939\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.1873 - mse: 0.1873 - mae: 0.3303 - val_loss: 0.4603 - val_mse: 0.4603 - val_mae: 0.4938\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.1912 - mse: 0.1912 - mae: 0.3342 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4877\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.1965 - mse: 0.1965 - mae: 0.3367 - val_loss: 0.4471 - val_mse: 0.4471 - val_mae: 0.4876\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.1939 - mse: 0.1939 - mae: 0.3363 - val_loss: 0.4341 - val_mse: 0.4341 - val_mae: 0.4806\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.1857 - mse: 0.1857 - mae: 0.3297 - val_loss: 0.4412 - val_mse: 0.4412 - val_mae: 0.4903\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 75us/sample - loss: 1.1401 - mse: 1.1401 - mae: 0.7966 - val_loss: 2.1589 - val_mse: 2.1589 - val_mae: 1.0635\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.6438 - mse: 0.6438 - mae: 0.6106 - val_loss: 1.4900 - val_mse: 1.4900 - val_mae: 0.9037\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.5516 - mse: 0.5516 - mae: 0.5583 - val_loss: 1.1809 - val_mse: 1.1809 - val_mae: 0.8424\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.5080 - mse: 0.5080 - mae: 0.5384 - val_loss: 0.9696 - val_mse: 0.9696 - val_mae: 0.7737\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.4740 - mse: 0.4740 - mae: 0.5189 - val_loss: 0.8943 - val_mse: 0.8943 - val_mae: 0.7303\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4477 - mse: 0.4477 - mae: 0.5057 - val_loss: 0.7482 - val_mse: 0.7482 - val_mae: 0.6270\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4240 - mse: 0.4240 - mae: 0.4906 - val_loss: 0.6418 - val_mse: 0.6418 - val_mae: 0.5808\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.4199 - mse: 0.4199 - mae: 0.4914 - val_loss: 0.6395 - val_mse: 0.6395 - val_mae: 0.5710\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3960 - mse: 0.3960 - mae: 0.4755 - val_loss: 0.6286 - val_mse: 0.6286 - val_mae: 0.5564\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3795 - mse: 0.3795 - mae: 0.4657 - val_loss: 0.5694 - val_mse: 0.5694 - val_mae: 0.5345\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.3627 - mse: 0.3627 - mae: 0.4580 - val_loss: 0.5868 - val_mse: 0.5868 - val_mae: 0.5316\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3519 - mse: 0.3519 - mae: 0.4470 - val_loss: 0.5654 - val_mse: 0.5654 - val_mae: 0.5359\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3456 - mse: 0.3456 - mae: 0.4454 - val_loss: 0.5173 - val_mse: 0.5173 - val_mae: 0.5136\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.3449 - mse: 0.3449 - mae: 0.4452 - val_loss: 0.5273 - val_mse: 0.5273 - val_mae: 0.5174\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3266 - mse: 0.3266 - mae: 0.4318 - val_loss: 0.4995 - val_mse: 0.4995 - val_mae: 0.5020\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3213 - mse: 0.3213 - mae: 0.4286 - val_loss: 0.4922 - val_mse: 0.4922 - val_mae: 0.5068\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3095 - mse: 0.3095 - mae: 0.4191 - val_loss: 0.5060 - val_mse: 0.5060 - val_mae: 0.5092\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.3170 - mse: 0.3170 - mae: 0.4283 - val_loss: 0.4800 - val_mse: 0.4800 - val_mae: 0.4967\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3044 - mse: 0.3044 - mae: 0.4157 - val_loss: 0.5216 - val_mse: 0.5216 - val_mae: 0.5133\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.2980 - mse: 0.2980 - mae: 0.4142 - val_loss: 0.5024 - val_mse: 0.5024 - val_mae: 0.4998\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.2875 - mse: 0.2875 - mae: 0.4071 - val_loss: 0.5222 - val_mse: 0.5222 - val_mae: 0.5090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2946 - mse: 0.2946 - mae: 0.4111 - val_loss: 0.4931 - val_mse: 0.4931 - val_mae: 0.5087\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2889 - mse: 0.2889 - mae: 0.4079 - val_loss: 0.5305 - val_mse: 0.5305 - val_mae: 0.5072\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.2835 - mse: 0.2835 - mae: 0.4025 - val_loss: 0.5133 - val_mse: 0.5133 - val_mae: 0.5010\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2791 - mse: 0.2791 - mae: 0.4015 - val_loss: 0.5043 - val_mse: 0.5043 - val_mae: 0.4990\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2678 - mse: 0.2678 - mae: 0.3929 - val_loss: 0.4935 - val_mse: 0.4935 - val_mae: 0.5033\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.2680 - mse: 0.2680 - mae: 0.3941 - val_loss: 0.5465 - val_mse: 0.5465 - val_mae: 0.5080\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2621 - mse: 0.2621 - mae: 0.3872 - val_loss: 0.5750 - val_mse: 0.5750 - val_mae: 0.4980\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 75us/sample - loss: 1.1625 - mse: 1.1625 - mae: 0.8035 - val_loss: 3.1033 - val_mse: 3.1033 - val_mae: 1.4099\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.6441 - mse: 0.6441 - mae: 0.6070 - val_loss: 1.6267 - val_mse: 1.6267 - val_mae: 1.0293\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.5561 - mse: 0.5561 - mae: 0.5601 - val_loss: 1.2727 - val_mse: 1.2727 - val_mae: 0.9081\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.5092 - mse: 0.5092 - mae: 0.5375 - val_loss: 1.0175 - val_mse: 1.0175 - val_mae: 0.8128\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.4771 - mse: 0.4771 - mae: 0.5212 - val_loss: 0.8592 - val_mse: 0.8592 - val_mae: 0.7334\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.4504 - mse: 0.4504 - mae: 0.5043 - val_loss: 0.7628 - val_mse: 0.7628 - val_mae: 0.6884\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.4372 - mse: 0.4372 - mae: 0.4995 - val_loss: 0.6262 - val_mse: 0.6262 - val_mae: 0.6096\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.4115 - mse: 0.4115 - mae: 0.4845 - val_loss: 0.6105 - val_mse: 0.6105 - val_mae: 0.5968\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3937 - mse: 0.3937 - mae: 0.4746 - val_loss: 0.5529 - val_mse: 0.5529 - val_mae: 0.5587\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3821 - mse: 0.3821 - mae: 0.4654 - val_loss: 0.5485 - val_mse: 0.5485 - val_mae: 0.5484\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3701 - mse: 0.3701 - mae: 0.4582 - val_loss: 0.5245 - val_mse: 0.5245 - val_mae: 0.5315\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3633 - mse: 0.3633 - mae: 0.4545 - val_loss: 0.5022 - val_mse: 0.5022 - val_mae: 0.5158\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3513 - mse: 0.3513 - mae: 0.4489 - val_loss: 0.5071 - val_mse: 0.5071 - val_mae: 0.5155\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3324 - mse: 0.3324 - mae: 0.4351 - val_loss: 0.4751 - val_mse: 0.4751 - val_mae: 0.5033\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3280 - mse: 0.3280 - mae: 0.4336 - val_loss: 0.4960 - val_mse: 0.4960 - val_mae: 0.5027\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3365 - mse: 0.3365 - mae: 0.4389 - val_loss: 0.4761 - val_mse: 0.4761 - val_mae: 0.4965\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3196 - mse: 0.3196 - mae: 0.4259 - val_loss: 0.4722 - val_mse: 0.4722 - val_mae: 0.4922\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3158 - mse: 0.3158 - mae: 0.4242 - val_loss: 0.4916 - val_mse: 0.4916 - val_mae: 0.4957\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3107 - mse: 0.3107 - mae: 0.4197 - val_loss: 0.4902 - val_mse: 0.4902 - val_mae: 0.5037\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3040 - mse: 0.3040 - mae: 0.4179 - val_loss: 0.4742 - val_mse: 0.4742 - val_mae: 0.4901\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3030 - mse: 0.3030 - mae: 0.4177 - val_loss: 0.4896 - val_mse: 0.4896 - val_mae: 0.4993\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2953 - mse: 0.2953 - mae: 0.4107 - val_loss: 0.5063 - val_mse: 0.5063 - val_mae: 0.5004\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2965 - mse: 0.2965 - mae: 0.4114 - val_loss: 0.4986 - val_mse: 0.4986 - val_mae: 0.4892\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2837 - mse: 0.2837 - mae: 0.4040 - val_loss: 0.4657 - val_mse: 0.4657 - val_mae: 0.4816\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2745 - mse: 0.2745 - mae: 0.3959 - val_loss: 0.4694 - val_mse: 0.4694 - val_mae: 0.4889\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2660 - mse: 0.2660 - mae: 0.3925 - val_loss: 0.4824 - val_mse: 0.4824 - val_mae: 0.4828\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2691 - mse: 0.2691 - mae: 0.3927 - val_loss: 0.4735 - val_mse: 0.4735 - val_mae: 0.4798\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2673 - mse: 0.2673 - mae: 0.3916 - val_loss: 0.4704 - val_mse: 0.4704 - val_mae: 0.4819\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2606 - mse: 0.2606 - mae: 0.3855 - val_loss: 0.4591 - val_mse: 0.4591 - val_mae: 0.4786\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2675 - mse: 0.2675 - mae: 0.3924 - val_loss: 0.4840 - val_mse: 0.4840 - val_mae: 0.4906\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2626 - mse: 0.2626 - mae: 0.3889 - val_loss: 0.4547 - val_mse: 0.4547 - val_mae: 0.4822\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2555 - mse: 0.2555 - mae: 0.3834 - val_loss: 0.4679 - val_mse: 0.4679 - val_mae: 0.4805\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2530 - mse: 0.2530 - mae: 0.3830 - val_loss: 0.4607 - val_mse: 0.4607 - val_mae: 0.4791\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2424 - mse: 0.2424 - mae: 0.3723 - val_loss: 0.4544 - val_mse: 0.4544 - val_mae: 0.4768\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2429 - mse: 0.2429 - mae: 0.3744 - val_loss: 0.4792 - val_mse: 0.4792 - val_mae: 0.4868\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2427 - mse: 0.2427 - mae: 0.3735 - val_loss: 0.4961 - val_mse: 0.4961 - val_mae: 0.4962\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2489 - mse: 0.2489 - mae: 0.3827 - val_loss: 0.4881 - val_mse: 0.4881 - val_mae: 0.4927\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2389 - mse: 0.2389 - mae: 0.3725 - val_loss: 0.4656 - val_mse: 0.4656 - val_mae: 0.4807\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2404 - mse: 0.2404 - mae: 0.3703 - val_loss: 0.4572 - val_mse: 0.4572 - val_mae: 0.4748\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2366 - mse: 0.2366 - mae: 0.3685 - val_loss: 0.4692 - val_mse: 0.4692 - val_mae: 0.4843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2360 - mse: 0.2360 - mae: 0.3684 - val_loss: 0.4797 - val_mse: 0.4797 - val_mae: 0.4885\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2311 - mse: 0.2311 - mae: 0.3641 - val_loss: 0.4584 - val_mse: 0.4584 - val_mae: 0.4760\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2239 - mse: 0.2239 - mae: 0.3593 - val_loss: 0.4595 - val_mse: 0.4595 - val_mae: 0.4807\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2282 - mse: 0.2282 - mae: 0.3633 - val_loss: 0.4604 - val_mse: 0.4604 - val_mae: 0.4721\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 76us/sample - loss: 1.1630 - mse: 1.1630 - mae: 0.8009 - val_loss: 2.5159 - val_mse: 2.5159 - val_mae: 1.2471\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.6415 - mse: 0.6415 - mae: 0.6035 - val_loss: 1.6090 - val_mse: 1.6090 - val_mae: 1.0089\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.5653 - mse: 0.5653 - mae: 0.5702 - val_loss: 1.3612 - val_mse: 1.3612 - val_mae: 0.9384\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.5074 - mse: 0.5074 - mae: 0.5361 - val_loss: 1.0696 - val_mse: 1.0696 - val_mae: 0.8269\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.4737 - mse: 0.4737 - mae: 0.5209 - val_loss: 0.8596 - val_mse: 0.8596 - val_mae: 0.7308\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.4500 - mse: 0.4500 - mae: 0.5041 - val_loss: 0.6884 - val_mse: 0.6884 - val_mae: 0.6361\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.4248 - mse: 0.4248 - mae: 0.4899 - val_loss: 0.6545 - val_mse: 0.6545 - val_mae: 0.6130\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.4108 - mse: 0.4108 - mae: 0.4813 - val_loss: 0.5790 - val_mse: 0.5790 - val_mae: 0.5749\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3919 - mse: 0.3919 - mae: 0.4700 - val_loss: 0.5594 - val_mse: 0.5594 - val_mae: 0.5641\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3803 - mse: 0.3803 - mae: 0.4651 - val_loss: 0.5621 - val_mse: 0.5621 - val_mae: 0.5559\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3730 - mse: 0.3730 - mae: 0.4613 - val_loss: 0.5444 - val_mse: 0.5444 - val_mae: 0.5385\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3665 - mse: 0.3665 - mae: 0.4569 - val_loss: 0.5073 - val_mse: 0.5073 - val_mae: 0.5209\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3496 - mse: 0.3496 - mae: 0.4464 - val_loss: 0.4936 - val_mse: 0.4936 - val_mae: 0.5108\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.3479 - mse: 0.3479 - mae: 0.4456 - val_loss: 0.5123 - val_mse: 0.5123 - val_mae: 0.5192\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3403 - mse: 0.3403 - mae: 0.4407 - val_loss: 0.4926 - val_mse: 0.4926 - val_mae: 0.5095\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.3299 - mse: 0.3299 - mae: 0.4335 - val_loss: 0.5332 - val_mse: 0.5332 - val_mae: 0.5153\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3329 - mse: 0.3329 - mae: 0.4326 - val_loss: 0.5039 - val_mse: 0.5039 - val_mae: 0.5091\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3241 - mse: 0.3241 - mae: 0.4296 - val_loss: 0.5172 - val_mse: 0.5172 - val_mae: 0.5158\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.3097 - mse: 0.3097 - mae: 0.4199 - val_loss: 0.5135 - val_mse: 0.5135 - val_mae: 0.5133\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.3008 - mse: 0.3008 - mae: 0.4122 - val_loss: 0.4764 - val_mse: 0.4764 - val_mae: 0.5018\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.2960 - mse: 0.2960 - mae: 0.4107 - val_loss: 0.4768 - val_mse: 0.4768 - val_mae: 0.4975\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2973 - mse: 0.2973 - mae: 0.4133 - val_loss: 0.4872 - val_mse: 0.4872 - val_mae: 0.4980\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2866 - mse: 0.2866 - mae: 0.4039 - val_loss: 0.4993 - val_mse: 0.4993 - val_mae: 0.5116\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2855 - mse: 0.2855 - mae: 0.4028 - val_loss: 0.4873 - val_mse: 0.4873 - val_mae: 0.5001\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2839 - mse: 0.2839 - mae: 0.4007 - val_loss: 0.4818 - val_mse: 0.4818 - val_mae: 0.5109\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2845 - mse: 0.2845 - mae: 0.4023 - val_loss: 0.4662 - val_mse: 0.4662 - val_mae: 0.4976\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.2726 - mse: 0.2726 - mae: 0.3955 - val_loss: 0.5083 - val_mse: 0.5083 - val_mae: 0.5079\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2710 - mse: 0.2710 - mae: 0.3940 - val_loss: 0.4902 - val_mse: 0.4902 - val_mae: 0.4994\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2645 - mse: 0.2645 - mae: 0.3893 - val_loss: 0.4779 - val_mse: 0.4779 - val_mae: 0.4995\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 11us/sample - loss: 0.2647 - mse: 0.2647 - mae: 0.3898 - val_loss: 0.4756 - val_mse: 0.4756 - val_mae: 0.5053\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2646 - mse: 0.2646 - mae: 0.3900 - val_loss: 0.4981 - val_mse: 0.4981 - val_mae: 0.5002\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2574 - mse: 0.2574 - mae: 0.3831 - val_loss: 0.4691 - val_mse: 0.4691 - val_mae: 0.4953\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2584 - mse: 0.2584 - mae: 0.3852 - val_loss: 0.4889 - val_mse: 0.4889 - val_mae: 0.5069\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2580 - mse: 0.2580 - mae: 0.3849 - val_loss: 0.4664 - val_mse: 0.4664 - val_mae: 0.4952\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2503 - mse: 0.2503 - mae: 0.3785 - val_loss: 0.4882 - val_mse: 0.4882 - val_mae: 0.4999\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2471 - mse: 0.2471 - mae: 0.3777 - val_loss: 0.4646 - val_mse: 0.4646 - val_mae: 0.4901\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2432 - mse: 0.2432 - mae: 0.3747 - val_loss: 0.4944 - val_mse: 0.4944 - val_mae: 0.4985\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2427 - mse: 0.2427 - mae: 0.3747 - val_loss: 0.4714 - val_mse: 0.4714 - val_mae: 0.4920\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2414 - mse: 0.2414 - mae: 0.3707 - val_loss: 0.5016 - val_mse: 0.5016 - val_mae: 0.4929\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2349 - mse: 0.2349 - mae: 0.3659 - val_loss: 0.5016 - val_mse: 0.5016 - val_mae: 0.4903\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2398 - mse: 0.2398 - mae: 0.3716 - val_loss: 0.4603 - val_mse: 0.4603 - val_mae: 0.4897\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2318 - mse: 0.2318 - mae: 0.3631 - val_loss: 0.4570 - val_mse: 0.4570 - val_mae: 0.4919\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2300 - mse: 0.2300 - mae: 0.3636 - val_loss: 0.4664 - val_mse: 0.4664 - val_mae: 0.4864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2268 - mse: 0.2268 - mae: 0.3623 - val_loss: 0.4747 - val_mse: 0.4747 - val_mae: 0.4936\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2275 - mse: 0.2275 - mae: 0.3609 - val_loss: 0.4808 - val_mse: 0.4808 - val_mae: 0.5024\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2244 - mse: 0.2244 - mae: 0.3609 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.4875\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2263 - mse: 0.2263 - mae: 0.3614 - val_loss: 0.4868 - val_mse: 0.4868 - val_mae: 0.4960\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2274 - mse: 0.2274 - mae: 0.3613 - val_loss: 0.4777 - val_mse: 0.4777 - val_mae: 0.4971\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2266 - mse: 0.2266 - mae: 0.3615 - val_loss: 0.4803 - val_mse: 0.4803 - val_mae: 0.4931\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2255 - mse: 0.2255 - mae: 0.3593 - val_loss: 0.4684 - val_mse: 0.4684 - val_mae: 0.4879\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 13us/sample - loss: 0.2139 - mse: 0.2139 - mae: 0.3514 - val_loss: 0.4821 - val_mse: 0.4821 - val_mae: 0.4938\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 12us/sample - loss: 0.2106 - mse: 0.2106 - mae: 0.3483 - val_loss: 0.4619 - val_mse: 0.4619 - val_mae: 0.4873\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 73us/sample - loss: 1.1395 - mse: 1.1395 - mae: 0.8021 - val_loss: 3.0245 - val_mse: 3.0245 - val_mae: 1.3823\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.6415 - mse: 0.6415 - mae: 0.6032 - val_loss: 1.5657 - val_mse: 1.5657 - val_mae: 0.9692\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.5558 - mse: 0.5558 - mae: 0.5629 - val_loss: 0.9769 - val_mse: 0.9769 - val_mae: 0.7693\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.5122 - mse: 0.5122 - mae: 0.5369 - val_loss: 0.7452 - val_mse: 0.7452 - val_mae: 0.6724\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 11us/sample - loss: 0.4760 - mse: 0.4760 - mae: 0.5204 - val_loss: 0.6327 - val_mse: 0.6327 - val_mae: 0.6166\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.4475 - mse: 0.4475 - mae: 0.5050 - val_loss: 0.6008 - val_mse: 0.6008 - val_mae: 0.6007\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 11us/sample - loss: 0.4337 - mse: 0.4337 - mae: 0.4950 - val_loss: 0.5929 - val_mse: 0.5929 - val_mae: 0.5951\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.4106 - mse: 0.4106 - mae: 0.4834 - val_loss: 0.5129 - val_mse: 0.5129 - val_mae: 0.5518\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.3994 - mse: 0.3994 - mae: 0.4758 - val_loss: 0.4877 - val_mse: 0.4877 - val_mae: 0.5243\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.3851 - mse: 0.3851 - mae: 0.4677 - val_loss: 0.4874 - val_mse: 0.4874 - val_mae: 0.5325\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.3744 - mse: 0.3744 - mae: 0.4611 - val_loss: 0.5194 - val_mse: 0.5194 - val_mae: 0.5353\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 11us/sample - loss: 0.3700 - mse: 0.3700 - mae: 0.4600 - val_loss: 0.4939 - val_mse: 0.4939 - val_mae: 0.5347\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.3606 - mse: 0.3606 - mae: 0.4516 - val_loss: 0.4633 - val_mse: 0.4633 - val_mae: 0.5034\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.3490 - mse: 0.3490 - mae: 0.4466 - val_loss: 0.4747 - val_mse: 0.4747 - val_mae: 0.5058\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.3430 - mse: 0.3430 - mae: 0.4406 - val_loss: 0.4570 - val_mse: 0.4570 - val_mae: 0.4957\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.3273 - mse: 0.3273 - mae: 0.4293 - val_loss: 0.4549 - val_mse: 0.4549 - val_mae: 0.4937\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.3275 - mse: 0.3275 - mae: 0.4324 - val_loss: 0.4795 - val_mse: 0.4795 - val_mae: 0.5020\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.3202 - mse: 0.3202 - mae: 0.4241 - val_loss: 0.4697 - val_mse: 0.4697 - val_mae: 0.5057\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.3241 - mse: 0.3241 - mae: 0.4306 - val_loss: 0.4506 - val_mse: 0.4506 - val_mae: 0.4805\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.3102 - mse: 0.3102 - mae: 0.4203 - val_loss: 0.4846 - val_mse: 0.4846 - val_mae: 0.4918\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.3012 - mse: 0.3012 - mae: 0.4126 - val_loss: 0.4588 - val_mse: 0.4588 - val_mae: 0.4955\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.3074 - mse: 0.3074 - mae: 0.4172 - val_loss: 0.4326 - val_mse: 0.4326 - val_mae: 0.4785\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.2960 - mse: 0.2960 - mae: 0.4094 - val_loss: 0.4732 - val_mse: 0.4732 - val_mae: 0.4975\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.3004 - mse: 0.3004 - mae: 0.4132 - val_loss: 0.4312 - val_mse: 0.4312 - val_mae: 0.4766\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.2867 - mse: 0.2867 - mae: 0.4055 - val_loss: 0.4537 - val_mse: 0.4537 - val_mae: 0.4770\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.2825 - mse: 0.2825 - mae: 0.4030 - val_loss: 0.4622 - val_mse: 0.4622 - val_mae: 0.4855\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.2784 - mse: 0.2784 - mae: 0.3995 - val_loss: 0.4569 - val_mse: 0.4569 - val_mae: 0.4888\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.2741 - mse: 0.2741 - mae: 0.3937 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.4817\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 11us/sample - loss: 0.2801 - mse: 0.2801 - mae: 0.3990 - val_loss: 0.4485 - val_mse: 0.4485 - val_mae: 0.4866\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 11us/sample - loss: 0.2694 - mse: 0.2694 - mae: 0.3932 - val_loss: 0.4322 - val_mse: 0.4322 - val_mae: 0.4748\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.2637 - mse: 0.2637 - mae: 0.3868 - val_loss: 0.4516 - val_mse: 0.4516 - val_mae: 0.4822\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.2646 - mse: 0.2646 - mae: 0.3895 - val_loss: 0.4449 - val_mse: 0.4449 - val_mae: 0.4773\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.2610 - mse: 0.2610 - mae: 0.3863 - val_loss: 0.4623 - val_mse: 0.4623 - val_mae: 0.4916\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 12us/sample - loss: 0.2567 - mse: 0.2567 - mae: 0.3843 - val_loss: 0.4513 - val_mse: 0.4513 - val_mae: 0.4791\n",
      "Avg. MAE: 0.427508\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 231us/sample - loss: 0.8825 - mse: 0.8825 - mae: 0.7012 - val_loss: 1.0610 - val_mse: 1.0610 - val_mae: 0.8433\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.5976 - mse: 0.5976 - mae: 0.5801 - val_loss: 0.8666 - val_mse: 0.8666 - val_mae: 0.7482\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 18us/sample - loss: 0.5374 - mse: 0.5374 - mae: 0.5499 - val_loss: 0.8203 - val_mse: 0.8203 - val_mae: 0.7194\n",
      "Epoch 4/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.4976 - mse: 0.4976 - mae: 0.5267 - val_loss: 0.7216 - val_mse: 0.7216 - val_mae: 0.6648\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.4622 - mse: 0.4622 - mae: 0.5063 - val_loss: 0.6933 - val_mse: 0.6933 - val_mae: 0.6520\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.4379 - mse: 0.4379 - mae: 0.4935 - val_loss: 0.5835 - val_mse: 0.5835 - val_mae: 0.5859\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.4204 - mse: 0.4204 - mae: 0.4845 - val_loss: 0.5550 - val_mse: 0.5550 - val_mae: 0.5680\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 18us/sample - loss: 0.3989 - mse: 0.3989 - mae: 0.4713 - val_loss: 0.5157 - val_mse: 0.5157 - val_mae: 0.5285\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 18us/sample - loss: 0.3837 - mse: 0.3837 - mae: 0.4602 - val_loss: 0.4850 - val_mse: 0.4850 - val_mae: 0.5185\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3725 - mse: 0.3725 - mae: 0.4537 - val_loss: 0.4782 - val_mse: 0.4782 - val_mae: 0.5061\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.3603 - mse: 0.3603 - mae: 0.4471 - val_loss: 0.4642 - val_mse: 0.4642 - val_mae: 0.5100\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 18us/sample - loss: 0.3615 - mse: 0.3615 - mae: 0.4487 - val_loss: 0.4752 - val_mse: 0.4752 - val_mae: 0.5043\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3399 - mse: 0.3399 - mae: 0.4345 - val_loss: 0.4837 - val_mse: 0.4837 - val_mae: 0.5035\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3291 - mse: 0.3291 - mae: 0.4276 - val_loss: 0.4587 - val_mse: 0.4587 - val_mae: 0.4981\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3149 - mse: 0.3149 - mae: 0.4230 - val_loss: 0.4476 - val_mse: 0.4476 - val_mae: 0.4918\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3222 - mse: 0.3222 - mae: 0.4243 - val_loss: 0.4838 - val_mse: 0.4838 - val_mae: 0.5064\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3069 - mse: 0.3069 - mae: 0.4186 - val_loss: 0.4467 - val_mse: 0.4467 - val_mae: 0.4941\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3060 - mse: 0.3060 - mae: 0.4156 - val_loss: 0.4630 - val_mse: 0.4630 - val_mae: 0.5058\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3019 - mse: 0.3019 - mae: 0.4113 - val_loss: 0.4501 - val_mse: 0.4501 - val_mae: 0.4924\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2862 - mse: 0.2862 - mae: 0.4025 - val_loss: 0.4526 - val_mse: 0.4526 - val_mae: 0.4923\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2888 - mse: 0.2888 - mae: 0.4035 - val_loss: 0.4838 - val_mse: 0.4838 - val_mae: 0.5036\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 18us/sample - loss: 0.2809 - mse: 0.2809 - mae: 0.3967 - val_loss: 0.4592 - val_mse: 0.4592 - val_mae: 0.4925\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2770 - mse: 0.2770 - mae: 0.3950 - val_loss: 0.4469 - val_mse: 0.4469 - val_mae: 0.4894\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2755 - mse: 0.2755 - mae: 0.3934 - val_loss: 0.4741 - val_mse: 0.4741 - val_mae: 0.5036\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2650 - mse: 0.2650 - mae: 0.3869 - val_loss: 0.4639 - val_mse: 0.4639 - val_mae: 0.4946\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2577 - mse: 0.2577 - mae: 0.3818 - val_loss: 0.4680 - val_mse: 0.4680 - val_mae: 0.4955\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2525 - mse: 0.2525 - mae: 0.3798 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4853\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2561 - mse: 0.2561 - mae: 0.3792 - val_loss: 0.4379 - val_mse: 0.4379 - val_mae: 0.4818\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 18us/sample - loss: 0.2597 - mse: 0.2597 - mae: 0.3820 - val_loss: 0.4421 - val_mse: 0.4421 - val_mae: 0.4877\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2479 - mse: 0.2479 - mae: 0.3723 - val_loss: 0.5020 - val_mse: 0.5020 - val_mae: 0.5103\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2513 - mse: 0.2513 - mae: 0.3763 - val_loss: 0.4795 - val_mse: 0.4795 - val_mae: 0.4977\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2465 - mse: 0.2465 - mae: 0.3730 - val_loss: 0.4510 - val_mse: 0.4510 - val_mae: 0.4871\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2370 - mse: 0.2370 - mae: 0.3659 - val_loss: 0.4507 - val_mse: 0.4507 - val_mae: 0.4866\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2300 - mse: 0.2300 - mae: 0.3620 - val_loss: 0.4509 - val_mse: 0.4509 - val_mae: 0.4892\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 35us/sample - loss: 0.2331 - mse: 0.2331 - mae: 0.3646 - val_loss: 0.4821 - val_mse: 0.4821 - val_mae: 0.4982\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 52us/sample - loss: 0.2232 - mse: 0.2232 - mae: 0.3587 - val_loss: 0.4711 - val_mse: 0.4711 - val_mae: 0.4933\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 71us/sample - loss: 0.2241 - mse: 0.2241 - mae: 0.3575 - val_loss: 0.4630 - val_mse: 0.4630 - val_mae: 0.4928\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.2238 - mse: 0.2238 - mae: 0.3578 - val_loss: 0.4398 - val_mse: 0.4398 - val_mae: 0.4772\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 162us/sample - loss: 0.9036 - mse: 0.9036 - mae: 0.7073 - val_loss: 1.2674 - val_mse: 1.2674 - val_mae: 0.9186\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.5966 - mse: 0.5966 - mae: 0.5772 - val_loss: 0.9629 - val_mse: 0.9629 - val_mae: 0.7577\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.5173 - mse: 0.5173 - mae: 0.5359 - val_loss: 0.8727 - val_mse: 0.8727 - val_mae: 0.7308\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 18us/sample - loss: 0.4815 - mse: 0.4815 - mae: 0.5186 - val_loss: 0.7656 - val_mse: 0.7656 - val_mae: 0.6832\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.4619 - mse: 0.4619 - mae: 0.5058 - val_loss: 0.6846 - val_mse: 0.6846 - val_mae: 0.6133\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.4326 - mse: 0.4326 - mae: 0.4936 - val_loss: 0.6641 - val_mse: 0.6641 - val_mae: 0.5823\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.4098 - mse: 0.4098 - mae: 0.4799 - val_loss: 0.6101 - val_mse: 0.6101 - val_mae: 0.5778\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3953 - mse: 0.3953 - mae: 0.4663 - val_loss: 0.5591 - val_mse: 0.5591 - val_mae: 0.5542\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.3752 - mse: 0.3752 - mae: 0.4578 - val_loss: 0.5297 - val_mse: 0.5297 - val_mae: 0.5337\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.3701 - mse: 0.3701 - mae: 0.4520 - val_loss: 0.5097 - val_mse: 0.5097 - val_mae: 0.5087\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3483 - mse: 0.3483 - mae: 0.4414 - val_loss: 0.5258 - val_mse: 0.5258 - val_mae: 0.5061\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3394 - mse: 0.3394 - mae: 0.4355 - val_loss: 0.5069 - val_mse: 0.5069 - val_mae: 0.5085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3253 - mse: 0.3253 - mae: 0.4262 - val_loss: 0.4713 - val_mse: 0.4713 - val_mae: 0.4874\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.3215 - mse: 0.3215 - mae: 0.4259 - val_loss: 0.4738 - val_mse: 0.4738 - val_mae: 0.4879\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3197 - mse: 0.3197 - mae: 0.4231 - val_loss: 0.4916 - val_mse: 0.4916 - val_mae: 0.4998\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.3118 - mse: 0.3118 - mae: 0.4183 - val_loss: 0.4754 - val_mse: 0.4754 - val_mae: 0.4876\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.3023 - mse: 0.3023 - mae: 0.4130 - val_loss: 0.5053 - val_mse: 0.5053 - val_mae: 0.4942\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.3018 - mse: 0.3018 - mae: 0.4126 - val_loss: 0.4883 - val_mse: 0.4883 - val_mae: 0.4951\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2953 - mse: 0.2953 - mae: 0.4068 - val_loss: 0.5221 - val_mse: 0.5221 - val_mae: 0.4993\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2808 - mse: 0.2808 - mae: 0.3978 - val_loss: 0.5039 - val_mse: 0.5039 - val_mae: 0.4980\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2807 - mse: 0.2807 - mae: 0.3986 - val_loss: 0.5531 - val_mse: 0.5531 - val_mae: 0.5046\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 21us/sample - loss: 0.2805 - mse: 0.2805 - mae: 0.3975 - val_loss: 0.5280 - val_mse: 0.5280 - val_mae: 0.4926\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.2810 - mse: 0.2810 - mae: 0.3984 - val_loss: 0.4881 - val_mse: 0.4881 - val_mae: 0.4994\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 177us/sample - loss: 0.9080 - mse: 0.9080 - mae: 0.7067 - val_loss: 1.5685 - val_mse: 1.5685 - val_mae: 1.0603\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.6048 - mse: 0.6048 - mae: 0.5809 - val_loss: 0.9131 - val_mse: 0.9131 - val_mae: 0.7635\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.5315 - mse: 0.5315 - mae: 0.5416 - val_loss: 0.8453 - val_mse: 0.8453 - val_mae: 0.7237\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4989 - mse: 0.4989 - mae: 0.5265 - val_loss: 0.7020 - val_mse: 0.7020 - val_mae: 0.6519\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.4681 - mse: 0.4681 - mae: 0.5080 - val_loss: 0.6380 - val_mse: 0.6380 - val_mae: 0.6200\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.4299 - mse: 0.4299 - mae: 0.4874 - val_loss: 0.5832 - val_mse: 0.5832 - val_mae: 0.5788\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.4096 - mse: 0.4096 - mae: 0.4765 - val_loss: 0.5269 - val_mse: 0.5269 - val_mae: 0.5358\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.4045 - mse: 0.4045 - mae: 0.4734 - val_loss: 0.5407 - val_mse: 0.5407 - val_mae: 0.5318\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.3862 - mse: 0.3862 - mae: 0.4636 - val_loss: 0.5221 - val_mse: 0.5221 - val_mae: 0.5314\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.3680 - mse: 0.3680 - mae: 0.4512 - val_loss: 0.4990 - val_mse: 0.4990 - val_mae: 0.5078\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.3573 - mse: 0.3573 - mae: 0.4464 - val_loss: 0.4838 - val_mse: 0.4838 - val_mae: 0.5036\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.3417 - mse: 0.3417 - mae: 0.4369 - val_loss: 0.5158 - val_mse: 0.5158 - val_mae: 0.4996\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3390 - mse: 0.3390 - mae: 0.4336 - val_loss: 0.5058 - val_mse: 0.5058 - val_mae: 0.5149\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3218 - mse: 0.3218 - mae: 0.4246 - val_loss: 0.4887 - val_mse: 0.4887 - val_mae: 0.5008\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.3203 - mse: 0.3203 - mae: 0.4257 - val_loss: 0.5104 - val_mse: 0.5104 - val_mae: 0.5106\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 25us/sample - loss: 0.3201 - mse: 0.3201 - mae: 0.4249 - val_loss: 0.4734 - val_mse: 0.4734 - val_mae: 0.4898\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 23us/sample - loss: 0.3014 - mse: 0.3014 - mae: 0.4099 - val_loss: 0.4974 - val_mse: 0.4974 - val_mae: 0.5005\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2945 - mse: 0.2945 - mae: 0.4056 - val_loss: 0.4669 - val_mse: 0.4669 - val_mae: 0.4835\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 24us/sample - loss: 0.2902 - mse: 0.2902 - mae: 0.4029 - val_loss: 0.4829 - val_mse: 0.4829 - val_mae: 0.4914\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 22us/sample - loss: 0.2782 - mse: 0.2782 - mae: 0.3961 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.4880\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 38us/sample - loss: 0.2759 - mse: 0.2759 - mae: 0.3958 - val_loss: 0.4878 - val_mse: 0.4878 - val_mae: 0.4899\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 18us/sample - loss: 0.2772 - mse: 0.2772 - mae: 0.3938 - val_loss: 0.4809 - val_mse: 0.4809 - val_mae: 0.5013\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2742 - mse: 0.2742 - mae: 0.3922 - val_loss: 0.4901 - val_mse: 0.4901 - val_mae: 0.4945\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2698 - mse: 0.2698 - mae: 0.3899 - val_loss: 0.4720 - val_mse: 0.4720 - val_mae: 0.4893\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2633 - mse: 0.2633 - mae: 0.3864 - val_loss: 0.4976 - val_mse: 0.4976 - val_mae: 0.4990\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2536 - mse: 0.2536 - mae: 0.3802 - val_loss: 0.4715 - val_mse: 0.4715 - val_mae: 0.4925\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2591 - mse: 0.2591 - mae: 0.3813 - val_loss: 0.4985 - val_mse: 0.4985 - val_mae: 0.4981\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2553 - mse: 0.2553 - mae: 0.3806 - val_loss: 0.4888 - val_mse: 0.4888 - val_mae: 0.4944\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 159us/sample - loss: 0.9204 - mse: 0.9204 - mae: 0.7181 - val_loss: 1.1474 - val_mse: 1.1474 - val_mae: 0.8950\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.5984 - mse: 0.5984 - mae: 0.5795 - val_loss: 0.8576 - val_mse: 0.8576 - val_mae: 0.7375\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.5353 - mse: 0.5353 - mae: 0.5472 - val_loss: 0.7554 - val_mse: 0.7554 - val_mae: 0.6746\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.4833 - mse: 0.4833 - mae: 0.5193 - val_loss: 0.6443 - val_mse: 0.6443 - val_mae: 0.6061\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 18us/sample - loss: 0.4529 - mse: 0.4529 - mae: 0.4985 - val_loss: 0.5925 - val_mse: 0.5925 - val_mae: 0.5720\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.4244 - mse: 0.4244 - mae: 0.4833 - val_loss: 0.5265 - val_mse: 0.5265 - val_mae: 0.5402\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.4046 - mse: 0.4046 - mae: 0.4720 - val_loss: 0.5131 - val_mse: 0.5131 - val_mae: 0.5298\n",
      "Epoch 8/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3808 - mse: 0.3808 - mae: 0.4599 - val_loss: 0.4851 - val_mse: 0.4851 - val_mae: 0.5158\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3765 - mse: 0.3765 - mae: 0.4566 - val_loss: 0.4852 - val_mse: 0.4852 - val_mae: 0.5256\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3632 - mse: 0.3632 - mae: 0.4477 - val_loss: 0.4953 - val_mse: 0.4953 - val_mae: 0.5172\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3427 - mse: 0.3427 - mae: 0.4385 - val_loss: 0.4733 - val_mse: 0.4733 - val_mae: 0.5045\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3402 - mse: 0.3402 - mae: 0.4363 - val_loss: 0.4830 - val_mse: 0.4830 - val_mae: 0.5062\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3351 - mse: 0.3351 - mae: 0.4295 - val_loss: 0.4854 - val_mse: 0.4854 - val_mae: 0.5086\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3291 - mse: 0.3291 - mae: 0.4284 - val_loss: 0.4613 - val_mse: 0.4613 - val_mae: 0.5009\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3128 - mse: 0.3128 - mae: 0.4171 - val_loss: 0.4521 - val_mse: 0.4521 - val_mae: 0.4892\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.3141 - mse: 0.3141 - mae: 0.4206 - val_loss: 0.4425 - val_mse: 0.4425 - val_mae: 0.4854\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3070 - mse: 0.3070 - mae: 0.4140 - val_loss: 0.4491 - val_mse: 0.4491 - val_mae: 0.4893\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.3071 - mse: 0.3071 - mae: 0.4151 - val_loss: 0.4323 - val_mse: 0.4323 - val_mae: 0.4817\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2896 - mse: 0.2896 - mae: 0.4043 - val_loss: 0.4451 - val_mse: 0.4451 - val_mae: 0.4904\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2858 - mse: 0.2858 - mae: 0.4013 - val_loss: 0.4460 - val_mse: 0.4460 - val_mae: 0.4904\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2791 - mse: 0.2791 - mae: 0.3973 - val_loss: 0.4198 - val_mse: 0.4198 - val_mae: 0.4780\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2730 - mse: 0.2730 - mae: 0.3927 - val_loss: 0.4611 - val_mse: 0.4611 - val_mae: 0.4897\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2681 - mse: 0.2681 - mae: 0.3896 - val_loss: 0.4566 - val_mse: 0.4566 - val_mae: 0.4886\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2650 - mse: 0.2650 - mae: 0.3877 - val_loss: 0.4311 - val_mse: 0.4311 - val_mae: 0.4794\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 18us/sample - loss: 0.2601 - mse: 0.2601 - mae: 0.3847 - val_loss: 0.4444 - val_mse: 0.4444 - val_mae: 0.4836\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2623 - mse: 0.2623 - mae: 0.3861 - val_loss: 0.4511 - val_mse: 0.4511 - val_mae: 0.4824\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2594 - mse: 0.2594 - mae: 0.3844 - val_loss: 0.4901 - val_mse: 0.4901 - val_mae: 0.4861\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 19us/sample - loss: 0.2538 - mse: 0.2538 - mae: 0.3810 - val_loss: 0.4715 - val_mse: 0.4715 - val_mae: 0.4819\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.2525 - mse: 0.2525 - mae: 0.3791 - val_loss: 0.4962 - val_mse: 0.4962 - val_mae: 0.4950\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.2433 - mse: 0.2433 - mae: 0.3730 - val_loss: 0.4588 - val_mse: 0.4588 - val_mae: 0.4861\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 20us/sample - loss: 0.2448 - mse: 0.2448 - mae: 0.3728 - val_loss: 0.4805 - val_mse: 0.4805 - val_mae: 0.4915\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 159us/sample - loss: 0.8932 - mse: 0.8932 - mae: 0.7084 - val_loss: 1.4124 - val_mse: 1.4124 - val_mae: 1.0122\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.6010 - mse: 0.6010 - mae: 0.5848 - val_loss: 0.9084 - val_mse: 0.9084 - val_mae: 0.7549\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - ETA: 0s - loss: 0.5335 - mse: 0.5335 - mae: 0.549 - 0s 18us/sample - loss: 0.5367 - mse: 0.5367 - mae: 0.5506 - val_loss: 0.8475 - val_mse: 0.8475 - val_mae: 0.7024\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 18us/sample - loss: 0.5022 - mse: 0.5022 - mae: 0.5288 - val_loss: 0.6776 - val_mse: 0.6776 - val_mae: 0.6349\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.4764 - mse: 0.4764 - mae: 0.5143 - val_loss: 0.6332 - val_mse: 0.6332 - val_mae: 0.6014\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 20us/sample - loss: 0.4453 - mse: 0.4453 - mae: 0.5014 - val_loss: 0.5379 - val_mse: 0.5379 - val_mae: 0.5589\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.4153 - mse: 0.4153 - mae: 0.4809 - val_loss: 0.5137 - val_mse: 0.5137 - val_mae: 0.5315\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.4004 - mse: 0.4004 - mae: 0.4714 - val_loss: 0.4851 - val_mse: 0.4851 - val_mae: 0.5161\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 18us/sample - loss: 0.3973 - mse: 0.3973 - mae: 0.4723 - val_loss: 0.4871 - val_mse: 0.4871 - val_mae: 0.5155\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 18us/sample - loss: 0.3766 - mse: 0.3766 - mae: 0.4569 - val_loss: 0.4738 - val_mse: 0.4738 - val_mae: 0.4966\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 20us/sample - loss: 0.3582 - mse: 0.3582 - mae: 0.4484 - val_loss: 0.4582 - val_mse: 0.4582 - val_mae: 0.4939\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.3510 - mse: 0.3510 - mae: 0.4433 - val_loss: 0.4661 - val_mse: 0.4661 - val_mae: 0.4984\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 20us/sample - loss: 0.3410 - mse: 0.3410 - mae: 0.4370 - val_loss: 0.4618 - val_mse: 0.4618 - val_mae: 0.4859\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 18us/sample - loss: 0.3224 - mse: 0.3224 - mae: 0.4248 - val_loss: 0.4854 - val_mse: 0.4854 - val_mae: 0.4996\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 18us/sample - loss: 0.3335 - mse: 0.3335 - mae: 0.4335 - val_loss: 0.4632 - val_mse: 0.4632 - val_mae: 0.4920\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.3144 - mse: 0.3144 - mae: 0.4211 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4816\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.3100 - mse: 0.3100 - mae: 0.4174 - val_loss: 0.4653 - val_mse: 0.4653 - val_mae: 0.4844\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.2988 - mse: 0.2988 - mae: 0.4098 - val_loss: 0.4466 - val_mse: 0.4466 - val_mae: 0.4777\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.2958 - mse: 0.2958 - mae: 0.4076 - val_loss: 0.4229 - val_mse: 0.4229 - val_mae: 0.4689\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.2809 - mse: 0.2809 - mae: 0.3992 - val_loss: 0.4455 - val_mse: 0.4455 - val_mae: 0.4833\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.2832 - mse: 0.2832 - mae: 0.3994 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.4831\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 18us/sample - loss: 0.2716 - mse: 0.2716 - mae: 0.3899 - val_loss: 0.4457 - val_mse: 0.4457 - val_mae: 0.4792\n",
      "Epoch 23/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.2804 - mse: 0.2804 - mae: 0.3992 - val_loss: 0.4983 - val_mse: 0.4983 - val_mae: 0.5130\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.2709 - mse: 0.2709 - mae: 0.3906 - val_loss: 0.4553 - val_mse: 0.4553 - val_mae: 0.4886\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.2649 - mse: 0.2649 - mae: 0.3873 - val_loss: 0.4538 - val_mse: 0.4538 - val_mae: 0.4927\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.2552 - mse: 0.2552 - mae: 0.3812 - val_loss: 0.4486 - val_mse: 0.4486 - val_mae: 0.4825\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 18us/sample - loss: 0.2544 - mse: 0.2544 - mae: 0.3778 - val_loss: 0.4598 - val_mse: 0.4598 - val_mae: 0.4852\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.2554 - mse: 0.2554 - mae: 0.3782 - val_loss: 0.4583 - val_mse: 0.4583 - val_mae: 0.4824\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 19us/sample - loss: 0.2513 - mse: 0.2513 - mae: 0.3792 - val_loss: 0.4548 - val_mse: 0.4548 - val_mae: 0.4789\n",
      "Avg. MAE: 0.423016\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 171us/sample - loss: 1.2707 - mse: 1.2707 - mae: 0.8340 - val_loss: 1.7047 - val_mse: 1.7047 - val_mae: 0.9579\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.5523 - mse: 0.5523 - mae: 0.5573 - val_loss: 1.3579 - val_mse: 1.3579 - val_mae: 0.8689\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.4422 - mse: 0.4422 - mae: 0.4967 - val_loss: 1.0896 - val_mse: 1.0896 - val_mae: 0.8008\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 18us/sample - loss: 0.3939 - mse: 0.3939 - mae: 0.4716 - val_loss: 0.9803 - val_mse: 0.9803 - val_mae: 0.7896\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.3557 - mse: 0.3557 - mae: 0.4448 - val_loss: 0.9923 - val_mse: 0.9923 - val_mae: 0.8021\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3245 - mse: 0.3245 - mae: 0.4273 - val_loss: 0.9834 - val_mse: 0.9834 - val_mae: 0.8148\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.3037 - mse: 0.3037 - mae: 0.4143 - val_loss: 0.8545 - val_mse: 0.8545 - val_mae: 0.7556\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2894 - mse: 0.2894 - mae: 0.4046 - val_loss: 0.7655 - val_mse: 0.7655 - val_mae: 0.7127\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2813 - mse: 0.2813 - mae: 0.3991 - val_loss: 0.6977 - val_mse: 0.6977 - val_mae: 0.6694\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.2611 - mse: 0.2611 - mae: 0.3819 - val_loss: 0.5797 - val_mse: 0.5797 - val_mae: 0.5989\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2410 - mse: 0.2410 - mae: 0.3699 - val_loss: 0.5823 - val_mse: 0.5823 - val_mae: 0.6048\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2337 - mse: 0.2337 - mae: 0.3631 - val_loss: 0.5224 - val_mse: 0.5224 - val_mae: 0.5564\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2254 - mse: 0.2254 - mae: 0.3572 - val_loss: 0.4995 - val_mse: 0.4995 - val_mae: 0.5365\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2152 - mse: 0.2152 - mae: 0.3495 - val_loss: 0.4785 - val_mse: 0.4785 - val_mae: 0.5181\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2078 - mse: 0.2078 - mae: 0.3446 - val_loss: 0.4725 - val_mse: 0.4725 - val_mae: 0.5154\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2056 - mse: 0.2056 - mae: 0.3411 - val_loss: 0.4681 - val_mse: 0.4681 - val_mae: 0.5033\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1984 - mse: 0.1984 - mae: 0.3345 - val_loss: 0.4929 - val_mse: 0.4929 - val_mae: 0.5135\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1968 - mse: 0.1968 - mae: 0.3340 - val_loss: 0.4593 - val_mse: 0.4593 - val_mae: 0.4968\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1903 - mse: 0.1903 - mae: 0.3280 - val_loss: 0.4564 - val_mse: 0.4564 - val_mae: 0.4916\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1741 - mse: 0.1741 - mae: 0.3131 - val_loss: 0.4347 - val_mse: 0.4347 - val_mae: 0.4894\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1720 - mse: 0.1720 - mae: 0.3094 - val_loss: 0.4285 - val_mse: 0.4285 - val_mae: 0.4857\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.1716 - mse: 0.1716 - mae: 0.3108 - val_loss: 0.4241 - val_mse: 0.4241 - val_mae: 0.4834\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1630 - mse: 0.1630 - mae: 0.3033 - val_loss: 0.4283 - val_mse: 0.4283 - val_mae: 0.4791\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1660 - mse: 0.1660 - mae: 0.3071 - val_loss: 0.4451 - val_mse: 0.4451 - val_mae: 0.4936\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.1629 - mse: 0.1629 - mae: 0.3036 - val_loss: 0.4267 - val_mse: 0.4267 - val_mae: 0.4724\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1519 - mse: 0.1519 - mae: 0.2946 - val_loss: 0.4422 - val_mse: 0.4422 - val_mae: 0.4816\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1451 - mse: 0.1451 - mae: 0.2865 - val_loss: 0.4168 - val_mse: 0.4168 - val_mae: 0.4705\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1311 - mse: 0.1311 - mae: 0.2729 - val_loss: 0.4183 - val_mse: 0.4183 - val_mae: 0.4632\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1399 - mse: 0.1399 - mae: 0.2832 - val_loss: 0.4065 - val_mse: 0.4065 - val_mae: 0.4653\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1346 - mse: 0.1346 - mae: 0.2780 - val_loss: 0.4542 - val_mse: 0.4542 - val_mae: 0.4836\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1407 - mse: 0.1407 - mae: 0.2846 - val_loss: 0.4324 - val_mse: 0.4324 - val_mae: 0.4760\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1317 - mse: 0.1317 - mae: 0.2744 - val_loss: 0.4321 - val_mse: 0.4321 - val_mae: 0.4679\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1301 - mse: 0.1301 - mae: 0.2695 - val_loss: 0.4411 - val_mse: 0.4411 - val_mae: 0.4761\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1294 - mse: 0.1294 - mae: 0.2714 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.4662\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1301 - mse: 0.1301 - mae: 0.2712 - val_loss: 0.4163 - val_mse: 0.4163 - val_mae: 0.4658\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1241 - mse: 0.1241 - mae: 0.2650 - val_loss: 0.4189 - val_mse: 0.4189 - val_mae: 0.4683\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1201 - mse: 0.1201 - mae: 0.2626 - val_loss: 0.4281 - val_mse: 0.4281 - val_mae: 0.4697\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1143 - mse: 0.1143 - mae: 0.2566 - val_loss: 0.4292 - val_mse: 0.4292 - val_mae: 0.4675\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1123 - mse: 0.1123 - mae: 0.2534 - val_loss: 0.4064 - val_mse: 0.4064 - val_mae: 0.4621\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1101 - mse: 0.1101 - mae: 0.2504 - val_loss: 0.4314 - val_mse: 0.4314 - val_mae: 0.4735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1162 - mse: 0.1162 - mae: 0.2578 - val_loss: 0.4246 - val_mse: 0.4246 - val_mae: 0.4699\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1069 - mse: 0.1069 - mae: 0.2468 - val_loss: 0.4243 - val_mse: 0.4243 - val_mae: 0.4682\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0998 - mse: 0.0998 - mae: 0.2402 - val_loss: 0.4207 - val_mse: 0.4207 - val_mae: 0.4715\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1050 - mse: 0.1050 - mae: 0.2454 - val_loss: 0.4081 - val_mse: 0.4081 - val_mae: 0.4611\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0987 - mse: 0.0987 - mae: 0.2374 - val_loss: 0.4223 - val_mse: 0.4223 - val_mae: 0.4653\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0956 - mse: 0.0956 - mae: 0.2345 - val_loss: 0.4306 - val_mse: 0.4306 - val_mae: 0.4703\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1020 - mse: 0.1020 - mae: 0.2433 - val_loss: 0.4088 - val_mse: 0.4088 - val_mae: 0.4554\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0953 - mse: 0.0953 - mae: 0.2345 - val_loss: 0.3913 - val_mse: 0.3913 - val_mae: 0.4578\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1007 - mse: 0.1007 - mae: 0.2428 - val_loss: 0.4344 - val_mse: 0.4344 - val_mae: 0.4729\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0963 - mse: 0.0963 - mae: 0.2369 - val_loss: 0.4310 - val_mse: 0.4310 - val_mae: 0.4704\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.0914 - mse: 0.0914 - mae: 0.2304 - val_loss: 0.4096 - val_mse: 0.4096 - val_mae: 0.4597\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0917 - mse: 0.0917 - mae: 0.2300 - val_loss: 0.4151 - val_mse: 0.4151 - val_mae: 0.4626\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0894 - mse: 0.0894 - mae: 0.2270 - val_loss: 0.4115 - val_mse: 0.4115 - val_mae: 0.4609\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.0924 - mse: 0.0924 - mae: 0.2310 - val_loss: 0.4297 - val_mse: 0.4297 - val_mae: 0.4681\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2255 - val_loss: 0.4042 - val_mse: 0.4042 - val_mae: 0.4585\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0890 - mse: 0.0890 - mae: 0.2265 - val_loss: 0.4121 - val_mse: 0.4121 - val_mae: 0.4637\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0859 - mse: 0.0859 - mae: 0.2229 - val_loss: 0.4014 - val_mse: 0.4014 - val_mae: 0.4582\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0870 - mse: 0.0870 - mae: 0.2231 - val_loss: 0.4348 - val_mse: 0.4348 - val_mae: 0.4757\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 1.2467 - mse: 1.2467 - mae: 0.8101 - val_loss: 2.3317 - val_mse: 2.3317 - val_mae: 1.1743\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.5495 - mse: 0.5495 - mae: 0.5565 - val_loss: 1.3091 - val_mse: 1.3091 - val_mae: 0.8322\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.4428 - mse: 0.4428 - mae: 0.4982 - val_loss: 1.0305 - val_mse: 1.0305 - val_mae: 0.7561\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.3956 - mse: 0.3956 - mae: 0.4728 - val_loss: 1.0002 - val_mse: 1.0002 - val_mae: 0.7729\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.3571 - mse: 0.3571 - mae: 0.4493 - val_loss: 1.0261 - val_mse: 1.0261 - val_mae: 0.8055\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3301 - mse: 0.3301 - mae: 0.4322 - val_loss: 0.9499 - val_mse: 0.9499 - val_mae: 0.7616\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3219 - mse: 0.3219 - mae: 0.4263 - val_loss: 0.9999 - val_mse: 0.9999 - val_mae: 0.7677\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3160 - mse: 0.3160 - mae: 0.4237 - val_loss: 0.9370 - val_mse: 0.9370 - val_mae: 0.7834\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2921 - mse: 0.2921 - mae: 0.4065 - val_loss: 0.7536 - val_mse: 0.7536 - val_mae: 0.6727\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2793 - mse: 0.2793 - mae: 0.3955 - val_loss: 0.6931 - val_mse: 0.6931 - val_mae: 0.6165\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2639 - mse: 0.2639 - mae: 0.3861 - val_loss: 0.6311 - val_mse: 0.6311 - val_mae: 0.6057\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2377 - mse: 0.2377 - mae: 0.3695 - val_loss: 0.5879 - val_mse: 0.5879 - val_mae: 0.5979\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2329 - mse: 0.2329 - mae: 0.3638 - val_loss: 0.5265 - val_mse: 0.5265 - val_mae: 0.5527\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2257 - mse: 0.2257 - mae: 0.3592 - val_loss: 0.5321 - val_mse: 0.5321 - val_mae: 0.5524\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2155 - mse: 0.2155 - mae: 0.3500 - val_loss: 0.5001 - val_mse: 0.5001 - val_mae: 0.5297\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2078 - mse: 0.2078 - mae: 0.3440 - val_loss: 0.4849 - val_mse: 0.4849 - val_mae: 0.5227\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2019 - mse: 0.2019 - mae: 0.3403 - val_loss: 0.4711 - val_mse: 0.4711 - val_mae: 0.5113\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1946 - mse: 0.1946 - mae: 0.3344 - val_loss: 0.4822 - val_mse: 0.4822 - val_mae: 0.5142\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1873 - mse: 0.1873 - mae: 0.3262 - val_loss: 0.4786 - val_mse: 0.4786 - val_mae: 0.5149\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1787 - mse: 0.1787 - mae: 0.3217 - val_loss: 0.4538 - val_mse: 0.4538 - val_mae: 0.4979\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1745 - mse: 0.1745 - mae: 0.3170 - val_loss: 0.4663 - val_mse: 0.4663 - val_mae: 0.4996\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1725 - mse: 0.1725 - mae: 0.3139 - val_loss: 0.4533 - val_mse: 0.4533 - val_mae: 0.4916\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1574 - mse: 0.1574 - mae: 0.2997 - val_loss: 0.4541 - val_mse: 0.4541 - val_mae: 0.4908\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1615 - mse: 0.1615 - mae: 0.3040 - val_loss: 0.4529 - val_mse: 0.4529 - val_mae: 0.4914\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1589 - mse: 0.1589 - mae: 0.3020 - val_loss: 0.4490 - val_mse: 0.4490 - val_mae: 0.4821\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1663 - mse: 0.1663 - mae: 0.3085 - val_loss: 0.4653 - val_mse: 0.4653 - val_mae: 0.4949\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1538 - mse: 0.1538 - mae: 0.2965 - val_loss: 0.4362 - val_mse: 0.4362 - val_mae: 0.4792\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1445 - mse: 0.1445 - mae: 0.2868 - val_loss: 0.4453 - val_mse: 0.4453 - val_mae: 0.4836\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1533 - mse: 0.1533 - mae: 0.2922 - val_loss: 0.4285 - val_mse: 0.4285 - val_mae: 0.4700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1483 - mse: 0.1483 - mae: 0.2905 - val_loss: 0.4481 - val_mse: 0.4481 - val_mae: 0.4796\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1335 - mse: 0.1335 - mae: 0.2755 - val_loss: 0.4374 - val_mse: 0.4374 - val_mae: 0.4771\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1367 - mse: 0.1367 - mae: 0.2796 - val_loss: 0.4490 - val_mse: 0.4490 - val_mae: 0.4677\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1276 - mse: 0.1276 - mae: 0.2700 - val_loss: 0.4496 - val_mse: 0.4496 - val_mae: 0.4749\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1311 - mse: 0.1311 - mae: 0.2743 - val_loss: 0.4394 - val_mse: 0.4394 - val_mae: 0.4804\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1291 - mse: 0.1291 - mae: 0.2714 - val_loss: 0.4206 - val_mse: 0.4206 - val_mae: 0.4624\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1211 - mse: 0.1211 - mae: 0.2636 - val_loss: 0.4831 - val_mse: 0.4831 - val_mae: 0.5063\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1296 - mse: 0.1296 - mae: 0.2717 - val_loss: 0.4366 - val_mse: 0.4366 - val_mae: 0.4810\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1207 - mse: 0.1207 - mae: 0.2610 - val_loss: 0.4465 - val_mse: 0.4465 - val_mae: 0.4716\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1165 - mse: 0.1165 - mae: 0.2566 - val_loss: 0.4302 - val_mse: 0.4302 - val_mae: 0.4686\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1146 - mse: 0.1146 - mae: 0.2557 - val_loss: 0.4491 - val_mse: 0.4491 - val_mae: 0.4726\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1104 - mse: 0.1104 - mae: 0.2519 - val_loss: 0.4501 - val_mse: 0.4501 - val_mae: 0.4853\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1119 - mse: 0.1119 - mae: 0.2523 - val_loss: 0.4390 - val_mse: 0.4390 - val_mae: 0.4747\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1038 - mse: 0.1038 - mae: 0.2414 - val_loss: 0.4366 - val_mse: 0.4366 - val_mae: 0.4731\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0992 - mse: 0.0992 - mae: 0.2393 - val_loss: 0.4346 - val_mse: 0.4346 - val_mae: 0.4703\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.0979 - mse: 0.0979 - mae: 0.2367 - val_loss: 0.4238 - val_mse: 0.4238 - val_mae: 0.4587\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 1.2131 - mse: 1.2131 - mae: 0.8163 - val_loss: 3.4568 - val_mse: 3.4568 - val_mae: 1.5216\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.5624 - mse: 0.5624 - mae: 0.5631 - val_loss: 1.5719 - val_mse: 1.5719 - val_mae: 0.9410\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4477 - mse: 0.4477 - mae: 0.5007 - val_loss: 1.0608 - val_mse: 1.0608 - val_mae: 0.7822\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3951 - mse: 0.3951 - mae: 0.4718 - val_loss: 0.9488 - val_mse: 0.9488 - val_mae: 0.7501\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3588 - mse: 0.3588 - mae: 0.4485 - val_loss: 0.8749 - val_mse: 0.8749 - val_mae: 0.7263\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3418 - mse: 0.3418 - mae: 0.4378 - val_loss: 0.8517 - val_mse: 0.8517 - val_mae: 0.7261\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3135 - mse: 0.3135 - mae: 0.4202 - val_loss: 0.7929 - val_mse: 0.7929 - val_mae: 0.7077\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3072 - mse: 0.3072 - mae: 0.4174 - val_loss: 0.7077 - val_mse: 0.7077 - val_mae: 0.6668\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2868 - mse: 0.2868 - mae: 0.4021 - val_loss: 0.6510 - val_mse: 0.6510 - val_mae: 0.6414\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2630 - mse: 0.2630 - mae: 0.3857 - val_loss: 0.5784 - val_mse: 0.5784 - val_mae: 0.5972\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2502 - mse: 0.2502 - mae: 0.3760 - val_loss: 0.5805 - val_mse: 0.5805 - val_mae: 0.5920\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2550 - mse: 0.2550 - mae: 0.3784 - val_loss: 0.4989 - val_mse: 0.4989 - val_mae: 0.5398\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2429 - mse: 0.2429 - mae: 0.3696 - val_loss: 0.5456 - val_mse: 0.5456 - val_mae: 0.5643\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2265 - mse: 0.2265 - mae: 0.3596 - val_loss: 0.5053 - val_mse: 0.5053 - val_mae: 0.5398\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.2164 - mse: 0.2164 - mae: 0.3536 - val_loss: 0.4509 - val_mse: 0.4509 - val_mae: 0.4997\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2124 - mse: 0.2124 - mae: 0.3486 - val_loss: 0.4936 - val_mse: 0.4936 - val_mae: 0.5279\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2048 - mse: 0.2048 - mae: 0.3415 - val_loss: 0.4196 - val_mse: 0.4196 - val_mae: 0.4731\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1879 - mse: 0.1879 - mae: 0.3271 - val_loss: 0.4538 - val_mse: 0.4538 - val_mae: 0.4876\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1886 - mse: 0.1886 - mae: 0.3263 - val_loss: 0.4287 - val_mse: 0.4287 - val_mae: 0.4751\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1830 - mse: 0.1830 - mae: 0.3224 - val_loss: 0.4432 - val_mse: 0.4432 - val_mae: 0.4804\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1728 - mse: 0.1728 - mae: 0.3137 - val_loss: 0.4308 - val_mse: 0.4308 - val_mae: 0.4676\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1685 - mse: 0.1685 - mae: 0.3099 - val_loss: 0.4109 - val_mse: 0.4109 - val_mae: 0.4665\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1642 - mse: 0.1642 - mae: 0.3069 - val_loss: 0.4574 - val_mse: 0.4574 - val_mae: 0.4814\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1614 - mse: 0.1614 - mae: 0.3057 - val_loss: 0.4313 - val_mse: 0.4313 - val_mae: 0.4687\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1537 - mse: 0.1537 - mae: 0.2954 - val_loss: 0.4095 - val_mse: 0.4095 - val_mae: 0.4543\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1497 - mse: 0.1497 - mae: 0.2947 - val_loss: 0.4264 - val_mse: 0.4264 - val_mae: 0.4642\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1524 - mse: 0.1524 - mae: 0.2951 - val_loss: 0.4206 - val_mse: 0.4206 - val_mae: 0.4575\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1422 - mse: 0.1422 - mae: 0.2879 - val_loss: 0.4277 - val_mse: 0.4277 - val_mae: 0.4575\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1381 - mse: 0.1381 - mae: 0.2816 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.4596\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1328 - mse: 0.1328 - mae: 0.2763 - val_loss: 0.4088 - val_mse: 0.4088 - val_mae: 0.4515\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1312 - mse: 0.1312 - mae: 0.2736 - val_loss: 0.4200 - val_mse: 0.4200 - val_mae: 0.4661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1313 - mse: 0.1313 - mae: 0.2741 - val_loss: 0.4336 - val_mse: 0.4336 - val_mae: 0.4634\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1299 - mse: 0.1299 - mae: 0.2727 - val_loss: 0.4426 - val_mse: 0.4426 - val_mae: 0.4592\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1287 - mse: 0.1287 - mae: 0.2732 - val_loss: 0.4260 - val_mse: 0.4260 - val_mae: 0.4544\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1271 - mse: 0.1271 - mae: 0.2709 - val_loss: 0.4108 - val_mse: 0.4108 - val_mae: 0.4561\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1245 - mse: 0.1245 - mae: 0.2682 - val_loss: 0.4518 - val_mse: 0.4518 - val_mae: 0.4722\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1251 - mse: 0.1251 - mae: 0.2723 - val_loss: 0.4167 - val_mse: 0.4167 - val_mae: 0.4577\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1120 - mse: 0.1120 - mae: 0.2553 - val_loss: 0.4255 - val_mse: 0.4255 - val_mae: 0.4533\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1109 - mse: 0.1109 - mae: 0.2513 - val_loss: 0.4132 - val_mse: 0.4132 - val_mae: 0.4512\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1040 - mse: 0.1040 - mae: 0.2452 - val_loss: 0.4247 - val_mse: 0.4247 - val_mae: 0.4554\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 1.2089 - mse: 1.2089 - mae: 0.8205 - val_loss: 1.8793 - val_mse: 1.8793 - val_mae: 1.0256\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.5533 - mse: 0.5533 - mae: 0.5538 - val_loss: 1.4821 - val_mse: 1.4821 - val_mae: 0.8993\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.4595 - mse: 0.4595 - mae: 0.5076 - val_loss: 1.2017 - val_mse: 1.2017 - val_mae: 0.8401\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3967 - mse: 0.3967 - mae: 0.4728 - val_loss: 1.1672 - val_mse: 1.1672 - val_mae: 0.8604\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3557 - mse: 0.3557 - mae: 0.4466 - val_loss: 1.1113 - val_mse: 1.1113 - val_mae: 0.8349\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3371 - mse: 0.3371 - mae: 0.4361 - val_loss: 1.0017 - val_mse: 1.0017 - val_mae: 0.7913\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.3093 - mse: 0.3093 - mae: 0.4171 - val_loss: 0.9525 - val_mse: 0.9525 - val_mae: 0.7965\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2899 - mse: 0.2899 - mae: 0.4047 - val_loss: 0.8431 - val_mse: 0.8431 - val_mae: 0.7492\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2769 - mse: 0.2769 - mae: 0.3950 - val_loss: 0.7952 - val_mse: 0.7952 - val_mae: 0.7309\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2720 - mse: 0.2720 - mae: 0.3901 - val_loss: 0.7115 - val_mse: 0.7115 - val_mae: 0.6803\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2660 - mse: 0.2660 - mae: 0.3827 - val_loss: 0.6256 - val_mse: 0.6256 - val_mae: 0.6260\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2605 - mse: 0.2605 - mae: 0.3797 - val_loss: 0.5514 - val_mse: 0.5514 - val_mae: 0.5807\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2368 - mse: 0.2368 - mae: 0.3650 - val_loss: 0.5006 - val_mse: 0.5006 - val_mae: 0.5423\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 16us/sample - loss: 0.2288 - mse: 0.2288 - mae: 0.3608 - val_loss: 0.4752 - val_mse: 0.4752 - val_mae: 0.5258\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.2078 - mse: 0.2078 - mae: 0.3434 - val_loss: 0.4774 - val_mse: 0.4774 - val_mae: 0.5255\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1959 - mse: 0.1959 - mae: 0.3339 - val_loss: 0.4512 - val_mse: 0.4512 - val_mae: 0.5039\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1982 - mse: 0.1982 - mae: 0.3350 - val_loss: 0.4441 - val_mse: 0.4441 - val_mae: 0.4937\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1911 - mse: 0.1911 - mae: 0.3283 - val_loss: 0.4423 - val_mse: 0.4423 - val_mae: 0.4941\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1870 - mse: 0.1870 - mae: 0.3225 - val_loss: 0.4399 - val_mse: 0.4399 - val_mae: 0.4888\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1763 - mse: 0.1763 - mae: 0.3143 - val_loss: 0.4212 - val_mse: 0.4212 - val_mae: 0.4782\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1765 - mse: 0.1765 - mae: 0.3145 - val_loss: 0.4129 - val_mse: 0.4129 - val_mae: 0.4699\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1729 - mse: 0.1729 - mae: 0.3143 - val_loss: 0.4299 - val_mse: 0.4299 - val_mae: 0.4862\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1620 - mse: 0.1620 - mae: 0.3065 - val_loss: 0.4284 - val_mse: 0.4284 - val_mae: 0.4828\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1564 - mse: 0.1564 - mae: 0.2967 - val_loss: 0.4191 - val_mse: 0.4191 - val_mae: 0.4725\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1458 - mse: 0.1458 - mae: 0.2852 - val_loss: 0.4129 - val_mse: 0.4129 - val_mae: 0.4699\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1499 - mse: 0.1499 - mae: 0.2899 - val_loss: 0.4164 - val_mse: 0.4164 - val_mae: 0.4620\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1557 - mse: 0.1557 - mae: 0.2996 - val_loss: 0.4240 - val_mse: 0.4240 - val_mae: 0.4758\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1472 - mse: 0.1472 - mae: 0.2891 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.4689\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1434 - mse: 0.1434 - mae: 0.2844 - val_loss: 0.4176 - val_mse: 0.4176 - val_mae: 0.4698\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1331 - mse: 0.1331 - mae: 0.2751 - val_loss: 0.4039 - val_mse: 0.4039 - val_mae: 0.4565\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1267 - mse: 0.1267 - mae: 0.2680 - val_loss: 0.4244 - val_mse: 0.4244 - val_mae: 0.4620\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1275 - mse: 0.1275 - mae: 0.2682 - val_loss: 0.4218 - val_mse: 0.4218 - val_mae: 0.4682\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1259 - mse: 0.1259 - mae: 0.2687 - val_loss: 0.4368 - val_mse: 0.4368 - val_mae: 0.4758\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1262 - mse: 0.1262 - mae: 0.2691 - val_loss: 0.4395 - val_mse: 0.4395 - val_mae: 0.4751\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1207 - mse: 0.1207 - mae: 0.2636 - val_loss: 0.4221 - val_mse: 0.4221 - val_mae: 0.4630\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 14us/sample - loss: 0.1158 - mse: 0.1158 - mae: 0.2574 - val_loss: 0.4367 - val_mse: 0.4367 - val_mae: 0.4793\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1208 - mse: 0.1208 - mae: 0.2626 - val_loss: 0.4465 - val_mse: 0.4465 - val_mae: 0.4831\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1215 - mse: 0.1215 - mae: 0.2631 - val_loss: 0.4249 - val_mse: 0.4249 - val_mae: 0.4669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1195 - mse: 0.1195 - mae: 0.2631 - val_loss: 0.4295 - val_mse: 0.4295 - val_mae: 0.4694\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 15us/sample - loss: 0.1176 - mse: 0.1176 - mae: 0.2605 - val_loss: 0.4396 - val_mse: 0.4396 - val_mae: 0.4764\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 97us/sample - loss: 1.0920 - mse: 1.0920 - mae: 0.7712 - val_loss: 1.8047 - val_mse: 1.8047 - val_mae: 1.0013\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 15us/sample - loss: 0.5462 - mse: 0.5462 - mae: 0.5555 - val_loss: 1.0721 - val_mse: 1.0721 - val_mae: 0.7771\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 15us/sample - loss: 0.4368 - mse: 0.4368 - mae: 0.4964 - val_loss: 0.9135 - val_mse: 0.9135 - val_mae: 0.7408\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.3899 - mse: 0.3899 - mae: 0.4679 - val_loss: 0.9282 - val_mse: 0.9282 - val_mae: 0.7542\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.3580 - mse: 0.3580 - mae: 0.4496 - val_loss: 0.9100 - val_mse: 0.9100 - val_mae: 0.7646\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.3292 - mse: 0.3292 - mae: 0.4312 - val_loss: 0.9755 - val_mse: 0.9755 - val_mae: 0.7993\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.3085 - mse: 0.3085 - mae: 0.4182 - val_loss: 1.0829 - val_mse: 1.0829 - val_mae: 0.8460\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.2836 - mse: 0.2836 - mae: 0.4007 - val_loss: 0.9086 - val_mse: 0.9086 - val_mae: 0.7732\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.2703 - mse: 0.2703 - mae: 0.3918 - val_loss: 0.7113 - val_mse: 0.7113 - val_mae: 0.6738\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.2573 - mse: 0.2573 - mae: 0.3813 - val_loss: 0.6943 - val_mse: 0.6943 - val_mae: 0.6605\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.2378 - mse: 0.2378 - mae: 0.3664 - val_loss: 0.6063 - val_mse: 0.6063 - val_mae: 0.6068\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.2304 - mse: 0.2304 - mae: 0.3607 - val_loss: 0.6021 - val_mse: 0.6021 - val_mae: 0.6001\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.2234 - mse: 0.2234 - mae: 0.3536 - val_loss: 0.5363 - val_mse: 0.5363 - val_mae: 0.5639\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 16us/sample - loss: 0.2125 - mse: 0.2125 - mae: 0.3463 - val_loss: 0.4900 - val_mse: 0.4900 - val_mae: 0.5173\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.2177 - mse: 0.2177 - mae: 0.3494 - val_loss: 0.5101 - val_mse: 0.5101 - val_mae: 0.5387\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.2105 - mse: 0.2105 - mae: 0.3447 - val_loss: 0.4588 - val_mse: 0.4588 - val_mae: 0.4944\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1991 - mse: 0.1991 - mae: 0.3350 - val_loss: 0.4994 - val_mse: 0.4994 - val_mae: 0.5095\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1847 - mse: 0.1847 - mae: 0.3235 - val_loss: 0.4688 - val_mse: 0.4688 - val_mae: 0.4868\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1860 - mse: 0.1860 - mae: 0.3241 - val_loss: 0.4318 - val_mse: 0.4318 - val_mae: 0.4825\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1678 - mse: 0.1678 - mae: 0.3101 - val_loss: 0.4275 - val_mse: 0.4275 - val_mae: 0.4748\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1513 - mse: 0.1513 - mae: 0.2928 - val_loss: 0.4405 - val_mse: 0.4405 - val_mae: 0.4822\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 15us/sample - loss: 0.1485 - mse: 0.1485 - mae: 0.2922 - val_loss: 0.4195 - val_mse: 0.4195 - val_mae: 0.4641\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1486 - mse: 0.1486 - mae: 0.2917 - val_loss: 0.4570 - val_mse: 0.4570 - val_mae: 0.4877\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1489 - mse: 0.1489 - mae: 0.2927 - val_loss: 0.4356 - val_mse: 0.4356 - val_mae: 0.4794\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1407 - mse: 0.1407 - mae: 0.2837 - val_loss: 0.4246 - val_mse: 0.4246 - val_mae: 0.4634\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1365 - mse: 0.1365 - mae: 0.2794 - val_loss: 0.4216 - val_mse: 0.4216 - val_mae: 0.4647\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1405 - mse: 0.1405 - mae: 0.2835 - val_loss: 0.4558 - val_mse: 0.4558 - val_mae: 0.4730\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1429 - mse: 0.1429 - mae: 0.2822 - val_loss: 0.4462 - val_mse: 0.4462 - val_mae: 0.4611\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1472 - mse: 0.1472 - mae: 0.2891 - val_loss: 0.4321 - val_mse: 0.4321 - val_mae: 0.4568\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1318 - mse: 0.1318 - mae: 0.2737 - val_loss: 0.4249 - val_mse: 0.4249 - val_mae: 0.4518\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 15us/sample - loss: 0.1251 - mse: 0.1251 - mae: 0.2677 - val_loss: 0.4114 - val_mse: 0.4114 - val_mae: 0.4507\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1211 - mse: 0.1211 - mae: 0.2633 - val_loss: 0.4161 - val_mse: 0.4161 - val_mae: 0.4482\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1196 - mse: 0.1196 - mae: 0.2622 - val_loss: 0.4330 - val_mse: 0.4330 - val_mae: 0.4660\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1135 - mse: 0.1135 - mae: 0.2535 - val_loss: 0.4221 - val_mse: 0.4221 - val_mae: 0.4574\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 0s 15us/sample - loss: 0.1111 - mse: 0.1111 - mae: 0.2510 - val_loss: 0.4184 - val_mse: 0.4184 - val_mae: 0.4572\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1087 - mse: 0.1087 - mae: 0.2496 - val_loss: 0.4222 - val_mse: 0.4222 - val_mae: 0.4546\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1086 - mse: 0.1086 - mae: 0.2502 - val_loss: 0.4306 - val_mse: 0.4306 - val_mae: 0.4565\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 15us/sample - loss: 0.1059 - mse: 0.1059 - mae: 0.2494 - val_loss: 0.4200 - val_mse: 0.4200 - val_mae: 0.4505\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 0s 13us/sample - loss: 0.1044 - mse: 0.1044 - mae: 0.2465 - val_loss: 0.4376 - val_mse: 0.4376 - val_mae: 0.4644\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 0s 15us/sample - loss: 0.1084 - mse: 0.1084 - mae: 0.2487 - val_loss: 0.4383 - val_mse: 0.4383 - val_mae: 0.4521\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 0s 14us/sample - loss: 0.1042 - mse: 0.1042 - mae: 0.2429 - val_loss: 0.4327 - val_mse: 0.4327 - val_mae: 0.4499\n",
      "Avg. MAE: 0.401752\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 199us/sample - loss: 13.4622 - mse: 13.4622 - mae: 1.6304 - val_loss: 5.7983 - val_mse: 5.7983 - val_mae: 1.7156\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.7018 - mse: 0.7018 - mae: 0.6277 - val_loss: 2.7512 - val_mse: 2.7512 - val_mae: 1.3315\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.6423 - mse: 0.6423 - mae: 0.5966 - val_loss: 1.0681 - val_mse: 1.0681 - val_mae: 0.8482\n",
      "Epoch 4/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.5988 - mse: 0.5988 - mae: 0.5761 - val_loss: 0.8069 - val_mse: 0.8069 - val_mae: 0.7346\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.5531 - mse: 0.5531 - mae: 0.5530 - val_loss: 0.6194 - val_mse: 0.6194 - val_mae: 0.6107\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.5117 - mse: 0.5117 - mae: 0.5354 - val_loss: 0.6145 - val_mse: 0.6145 - val_mae: 0.6166\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.4744 - mse: 0.4744 - mae: 0.5139 - val_loss: 0.5527 - val_mse: 0.5527 - val_mae: 0.5488\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.4416 - mse: 0.4416 - mae: 0.4945 - val_loss: 0.5537 - val_mse: 0.5537 - val_mae: 0.5514\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.4242 - mse: 0.4242 - mae: 0.4869 - val_loss: 0.4940 - val_mse: 0.4940 - val_mae: 0.5215\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.3943 - mse: 0.3943 - mae: 0.4703 - val_loss: 0.4892 - val_mse: 0.4892 - val_mae: 0.5187\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.3719 - mse: 0.3719 - mae: 0.4561 - val_loss: 0.5383 - val_mse: 0.5383 - val_mae: 0.5398\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.3652 - mse: 0.3652 - mae: 0.4507 - val_loss: 0.4579 - val_mse: 0.4579 - val_mae: 0.5001\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.3371 - mse: 0.3371 - mae: 0.4343 - val_loss: 0.4545 - val_mse: 0.4545 - val_mae: 0.4949\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.3178 - mse: 0.3178 - mae: 0.4197 - val_loss: 0.4481 - val_mse: 0.4481 - val_mae: 0.4947\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.3063 - mse: 0.3063 - mae: 0.4161 - val_loss: 0.4632 - val_mse: 0.4632 - val_mae: 0.5040\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.2954 - mse: 0.2954 - mae: 0.4063 - val_loss: 0.4373 - val_mse: 0.4373 - val_mae: 0.4828\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.2779 - mse: 0.2779 - mae: 0.3950 - val_loss: 0.4123 - val_mse: 0.4123 - val_mae: 0.4753\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.2859 - mse: 0.2859 - mae: 0.4023 - val_loss: 0.4452 - val_mse: 0.4452 - val_mae: 0.4925\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.2715 - mse: 0.2715 - mae: 0.3925 - val_loss: 0.4410 - val_mse: 0.4410 - val_mae: 0.4840\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.2378 - mse: 0.2378 - mae: 0.3664 - val_loss: 0.4063 - val_mse: 0.4063 - val_mae: 0.4616\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.2456 - mse: 0.2456 - mae: 0.3719 - val_loss: 0.4105 - val_mse: 0.4105 - val_mae: 0.4679\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.2713 - mse: 0.2713 - mae: 0.3914 - val_loss: 0.4228 - val_mse: 0.4228 - val_mae: 0.4707\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.2344 - mse: 0.2344 - mae: 0.3640 - val_loss: 0.4246 - val_mse: 0.4246 - val_mae: 0.4806\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.2477 - mse: 0.2477 - mae: 0.3715 - val_loss: 0.4121 - val_mse: 0.4121 - val_mae: 0.4728\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.2237 - mse: 0.2237 - mae: 0.3553 - val_loss: 0.4528 - val_mse: 0.4528 - val_mae: 0.4963\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.2197 - mse: 0.2197 - mae: 0.3507 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4815\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.2013 - mse: 0.2013 - mae: 0.3386 - val_loss: 0.3999 - val_mse: 0.3999 - val_mae: 0.4668\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1945 - mse: 0.1945 - mae: 0.3322 - val_loss: 0.5080 - val_mse: 0.5080 - val_mae: 0.5353\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.2012 - mse: 0.2012 - mae: 0.3410 - val_loss: 0.4060 - val_mse: 0.4060 - val_mae: 0.4571\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1908 - mse: 0.1908 - mae: 0.3309 - val_loss: 0.4248 - val_mse: 0.4248 - val_mae: 0.4715\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.1719 - mse: 0.1719 - mae: 0.3131 - val_loss: 0.4085 - val_mse: 0.4085 - val_mae: 0.4635\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1867 - mse: 0.1867 - mae: 0.3263 - val_loss: 0.4236 - val_mse: 0.4236 - val_mae: 0.4702\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1735 - mse: 0.1735 - mae: 0.3111 - val_loss: 0.4014 - val_mse: 0.4014 - val_mae: 0.4613\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1715 - mse: 0.1716 - mae: 0.3132 - val_loss: 0.4363 - val_mse: 0.4363 - val_mae: 0.4843\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1718 - mse: 0.1718 - mae: 0.3106 - val_loss: 0.3963 - val_mse: 0.3963 - val_mae: 0.4534\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1455 - mse: 0.1455 - mae: 0.2883 - val_loss: 0.3933 - val_mse: 0.3933 - val_mae: 0.4493\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1400 - mse: 0.1400 - mae: 0.2817 - val_loss: 0.3918 - val_mse: 0.3918 - val_mae: 0.4559\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1733 - mse: 0.1733 - mae: 0.3134 - val_loss: 0.3947 - val_mse: 0.3947 - val_mae: 0.4547\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.1802 - mse: 0.1802 - mae: 0.3192 - val_loss: 0.4007 - val_mse: 0.4007 - val_mae: 0.4610\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1666 - mse: 0.1666 - mae: 0.3052 - val_loss: 0.4636 - val_mse: 0.4636 - val_mae: 0.4939\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1506 - mse: 0.1506 - mae: 0.2946 - val_loss: 0.3821 - val_mse: 0.3821 - val_mae: 0.4504\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1533 - mse: 0.1533 - mae: 0.2912 - val_loss: 0.3843 - val_mse: 0.3843 - val_mae: 0.4465\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1351 - mse: 0.1351 - mae: 0.2767 - val_loss: 0.3951 - val_mse: 0.3951 - val_mae: 0.4522\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.1313 - mse: 0.1313 - mae: 0.2732 - val_loss: 0.4260 - val_mse: 0.4260 - val_mae: 0.4830\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.1349 - mse: 0.1349 - mae: 0.2767 - val_loss: 0.4215 - val_mse: 0.4215 - val_mae: 0.4701\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1200 - mse: 0.1200 - mae: 0.2619 - val_loss: 0.4013 - val_mse: 0.4013 - val_mae: 0.4565\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1166 - mse: 0.1166 - mae: 0.2571 - val_loss: 0.4042 - val_mse: 0.4042 - val_mae: 0.4561\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1197 - mse: 0.1197 - mae: 0.2596 - val_loss: 0.4082 - val_mse: 0.4082 - val_mae: 0.4670\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1419 - mse: 0.1419 - mae: 0.2821 - val_loss: 0.3942 - val_mse: 0.3942 - val_mae: 0.4442\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1252 - mse: 0.1252 - mae: 0.2671 - val_loss: 0.4070 - val_mse: 0.4070 - val_mae: 0.4557\n",
      "Epoch 51/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1201 - mse: 0.1201 - mae: 0.2609 - val_loss: 0.3762 - val_mse: 0.3762 - val_mae: 0.4398\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.1266 - mse: 0.1266 - mae: 0.2677 - val_loss: 0.4290 - val_mse: 0.4290 - val_mae: 0.4750\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1250 - mse: 0.1250 - mae: 0.2653 - val_loss: 0.3896 - val_mse: 0.3896 - val_mae: 0.4527\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1435 - mse: 0.1435 - mae: 0.2865 - val_loss: 0.3823 - val_mse: 0.3823 - val_mae: 0.4418\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1120 - mse: 0.1120 - mae: 0.2523 - val_loss: 0.4355 - val_mse: 0.4355 - val_mae: 0.4762\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.1166 - mse: 0.1166 - mae: 0.2584 - val_loss: 0.4075 - val_mse: 0.4075 - val_mae: 0.4564\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1252 - mse: 0.1252 - mae: 0.2628 - val_loss: 0.4113 - val_mse: 0.4113 - val_mae: 0.4638\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1260 - mse: 0.1260 - mae: 0.2629 - val_loss: 0.3905 - val_mse: 0.3905 - val_mae: 0.4509\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1195 - mse: 0.1195 - mae: 0.2591 - val_loss: 0.4113 - val_mse: 0.4113 - val_mae: 0.4703\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1142 - mse: 0.1142 - mae: 0.2533 - val_loss: 0.4071 - val_mse: 0.4071 - val_mae: 0.4578\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1052 - mse: 0.1052 - mae: 0.2432 - val_loss: 0.3793 - val_mse: 0.3793 - val_mae: 0.4406\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 190us/sample - loss: 10.7166 - mse: 10.7166 - mae: 1.4702 - val_loss: 41.5757 - val_mse: 41.5757 - val_mae: 4.7384\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.6991 - mse: 0.6991 - mae: 0.6245 - val_loss: 2.5706 - val_mse: 2.5706 - val_mae: 1.1608\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.6314 - mse: 0.6314 - mae: 0.5890 - val_loss: 1.3729 - val_mse: 1.3729 - val_mae: 0.8720\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.5869 - mse: 0.5869 - mae: 0.5686 - val_loss: 0.8381 - val_mse: 0.8381 - val_mae: 0.7226\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.5590 - mse: 0.5590 - mae: 0.5549 - val_loss: 0.7651 - val_mse: 0.7651 - val_mae: 0.6848\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.5225 - mse: 0.5225 - mae: 0.5379 - val_loss: 0.6325 - val_mse: 0.6325 - val_mae: 0.6059\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.4840 - mse: 0.4840 - mae: 0.5163 - val_loss: 0.6201 - val_mse: 0.6201 - val_mae: 0.5825\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.4467 - mse: 0.4467 - mae: 0.4981 - val_loss: 0.6514 - val_mse: 0.6514 - val_mae: 0.5720\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.4096 - mse: 0.4096 - mae: 0.4774 - val_loss: 0.7208 - val_mse: 0.7208 - val_mae: 0.5387\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.4134 - mse: 0.4134 - mae: 0.4797 - val_loss: 0.5045 - val_mse: 0.5045 - val_mae: 0.5224\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.3748 - mse: 0.3748 - mae: 0.4575 - val_loss: 0.5607 - val_mse: 0.5607 - val_mae: 0.5233\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.3473 - mse: 0.3473 - mae: 0.4417 - val_loss: 0.4915 - val_mse: 0.4915 - val_mae: 0.5035\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.3456 - mse: 0.3456 - mae: 0.4422 - val_loss: 0.5166 - val_mse: 0.5166 - val_mae: 0.5058\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.3389 - mse: 0.3389 - mae: 0.4364 - val_loss: 0.5174 - val_mse: 0.5174 - val_mae: 0.4945\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.3368 - mse: 0.3368 - mae: 0.4317 - val_loss: 0.5078 - val_mse: 0.5078 - val_mae: 0.4935\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 88us/sample - loss: 0.3306 - mse: 0.3306 - mae: 0.4281 - val_loss: 0.4935 - val_mse: 0.4935 - val_mae: 0.5011\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.3022 - mse: 0.3022 - mae: 0.4103 - val_loss: 0.5353 - val_mse: 0.5353 - val_mae: 0.4901\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.2896 - mse: 0.2896 - mae: 0.4046 - val_loss: 0.4551 - val_mse: 0.4551 - val_mae: 0.4775\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.2858 - mse: 0.2858 - mae: 0.3962 - val_loss: 0.4776 - val_mse: 0.4776 - val_mae: 0.4908\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.2838 - mse: 0.2838 - mae: 0.3969 - val_loss: 0.7480 - val_mse: 0.7480 - val_mae: 0.5244\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.2749 - mse: 0.2749 - mae: 0.3910 - val_loss: 0.4878 - val_mse: 0.4878 - val_mae: 0.4973\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.2535 - mse: 0.2535 - mae: 0.3762 - val_loss: 0.5557 - val_mse: 0.5557 - val_mae: 0.5446\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.2730 - mse: 0.2730 - mae: 0.3906 - val_loss: 0.5040 - val_mse: 0.5040 - val_mae: 0.5124\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.2298 - mse: 0.2298 - mae: 0.3617 - val_loss: 0.4527 - val_mse: 0.4527 - val_mae: 0.4862\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.2260 - mse: 0.2260 - mae: 0.3588 - val_loss: 0.4882 - val_mse: 0.4882 - val_mae: 0.4672\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.2160 - mse: 0.2160 - mae: 0.3480 - val_loss: 0.4978 - val_mse: 0.4978 - val_mae: 0.4874\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.2074 - mse: 0.2074 - mae: 0.3420 - val_loss: 0.4310 - val_mse: 0.4310 - val_mae: 0.4733\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.2150 - mse: 0.2150 - mae: 0.3443 - val_loss: 0.5654 - val_mse: 0.5654 - val_mae: 0.4897\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.2238 - mse: 0.2238 - mae: 0.3550 - val_loss: 0.6820 - val_mse: 0.6820 - val_mae: 0.5297\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.1983 - mse: 0.1983 - mae: 0.3340 - val_loss: 0.4337 - val_mse: 0.4337 - val_mae: 0.4689\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.1868 - mse: 0.1868 - mae: 0.3230 - val_loss: 0.4698 - val_mse: 0.4698 - val_mae: 0.4977\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 88us/sample - loss: 0.1854 - mse: 0.1854 - mae: 0.3220 - val_loss: 0.4121 - val_mse: 0.4121 - val_mae: 0.4571\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.1716 - mse: 0.1716 - mae: 0.3107 - val_loss: 0.4410 - val_mse: 0.4410 - val_mae: 0.4656\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.1812 - mse: 0.1812 - mae: 0.3201 - val_loss: 0.4272 - val_mse: 0.4272 - val_mae: 0.4567\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.1675 - mse: 0.1675 - mae: 0.3079 - val_loss: 0.4507 - val_mse: 0.4507 - val_mae: 0.4668\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.1725 - mse: 0.1725 - mae: 0.3084 - val_loss: 0.6393 - val_mse: 0.6393 - val_mae: 0.4992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.1686 - mse: 0.1686 - mae: 0.3069 - val_loss: 0.4474 - val_mse: 0.4474 - val_mae: 0.4816\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.1614 - mse: 0.1614 - mae: 0.3020 - val_loss: 0.4682 - val_mse: 0.4682 - val_mae: 0.4585\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.1576 - mse: 0.1576 - mae: 0.2999 - val_loss: 0.4670 - val_mse: 0.4670 - val_mae: 0.4623\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.1635 - mse: 0.1635 - mae: 0.2985 - val_loss: 0.4400 - val_mse: 0.4400 - val_mae: 0.4626\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.1565 - mse: 0.1565 - mae: 0.2966 - val_loss: 0.4516 - val_mse: 0.4516 - val_mae: 0.4658\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 0.2134 - mse: 0.2134 - mae: 0.3327 - val_loss: 0.4969 - val_mse: 0.4969 - val_mae: 0.4728\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 3s 272us/sample - loss: 8.5525 - mse: 8.5525 - mae: 1.3681 - val_loss: 14.0207 - val_mse: 14.0207 - val_mae: 3.0786\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.6935 - mse: 0.6935 - mae: 0.6237 - val_loss: 1.5408 - val_mse: 1.5408 - val_mae: 0.9746\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.6285 - mse: 0.6285 - mae: 0.5929 - val_loss: 0.9633 - val_mse: 0.9633 - val_mae: 0.7595\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 96us/sample - loss: 0.5858 - mse: 0.5858 - mae: 0.5693 - val_loss: 0.7717 - val_mse: 0.7717 - val_mae: 0.6829\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.5445 - mse: 0.5445 - mae: 0.5474 - val_loss: 0.6903 - val_mse: 0.6903 - val_mae: 0.6571\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.5051 - mse: 0.5051 - mae: 0.5273 - val_loss: 0.5866 - val_mse: 0.5866 - val_mae: 0.5839\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.4589 - mse: 0.4589 - mae: 0.5057 - val_loss: 0.5735 - val_mse: 0.5735 - val_mae: 0.5619\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.4292 - mse: 0.4292 - mae: 0.4885 - val_loss: 0.5207 - val_mse: 0.5207 - val_mae: 0.5376\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.3970 - mse: 0.3970 - mae: 0.4717 - val_loss: 0.5165 - val_mse: 0.5165 - val_mae: 0.5301\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.3748 - mse: 0.3748 - mae: 0.4559 - val_loss: 0.4518 - val_mse: 0.4518 - val_mae: 0.4944\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.3651 - mse: 0.3651 - mae: 0.4500 - val_loss: 0.4737 - val_mse: 0.4737 - val_mae: 0.4986\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.3429 - mse: 0.3429 - mae: 0.4391 - val_loss: 0.4383 - val_mse: 0.4383 - val_mae: 0.4812\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.3372 - mse: 0.3372 - mae: 0.4363 - val_loss: 0.4924 - val_mse: 0.4924 - val_mae: 0.5171\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.3172 - mse: 0.3172 - mae: 0.4237 - val_loss: 0.4358 - val_mse: 0.4358 - val_mae: 0.4762\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.2863 - mse: 0.2863 - mae: 0.4040 - val_loss: 0.4753 - val_mse: 0.4753 - val_mae: 0.4983\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 96us/sample - loss: 0.3130 - mse: 0.3130 - mae: 0.4237 - val_loss: 0.4694 - val_mse: 0.4694 - val_mae: 0.4963\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.2876 - mse: 0.2876 - mae: 0.3981 - val_loss: 0.4501 - val_mse: 0.4501 - val_mae: 0.4972\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.2786 - mse: 0.2786 - mae: 0.3921 - val_loss: 0.4603 - val_mse: 0.4603 - val_mae: 0.4923\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.2642 - mse: 0.2642 - mae: 0.3866 - val_loss: 0.4404 - val_mse: 0.4404 - val_mae: 0.5002\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.2438 - mse: 0.2438 - mae: 0.3749 - val_loss: 0.4592 - val_mse: 0.4592 - val_mae: 0.4968\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.2547 - mse: 0.2547 - mae: 0.3826 - val_loss: 0.4490 - val_mse: 0.4490 - val_mae: 0.4797\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.2444 - mse: 0.2444 - mae: 0.3705 - val_loss: 0.4339 - val_mse: 0.4339 - val_mae: 0.4812\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.2289 - mse: 0.2289 - mae: 0.3626 - val_loss: 0.4667 - val_mse: 0.4667 - val_mae: 0.4995\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.2335 - mse: 0.2335 - mae: 0.3642 - val_loss: 0.4213 - val_mse: 0.4213 - val_mae: 0.4593\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.2209 - mse: 0.2209 - mae: 0.3540 - val_loss: 0.4280 - val_mse: 0.4280 - val_mae: 0.4720\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.2117 - mse: 0.2117 - mae: 0.3456 - val_loss: 0.6161 - val_mse: 0.6161 - val_mae: 0.5644\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.2004 - mse: 0.2004 - mae: 0.3360 - val_loss: 0.4155 - val_mse: 0.4155 - val_mae: 0.4634\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.2067 - mse: 0.2067 - mae: 0.3436 - val_loss: 0.5778 - val_mse: 0.5778 - val_mae: 0.5288\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1969 - mse: 0.1969 - mae: 0.3323 - val_loss: 0.4022 - val_mse: 0.4022 - val_mae: 0.4577\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1840 - mse: 0.1840 - mae: 0.3246 - val_loss: 0.4080 - val_mse: 0.4080 - val_mae: 0.4472\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1918 - mse: 0.1918 - mae: 0.3309 - val_loss: 0.4525 - val_mse: 0.4525 - val_mae: 0.4839\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1739 - mse: 0.1739 - mae: 0.3159 - val_loss: 0.4084 - val_mse: 0.4084 - val_mae: 0.4529\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1991 - mse: 0.1991 - mae: 0.3347 - val_loss: 0.4378 - val_mse: 0.4378 - val_mae: 0.4867\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.2027 - mse: 0.2027 - mae: 0.3289 - val_loss: 0.4171 - val_mse: 0.4171 - val_mae: 0.4562\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1555 - mse: 0.1555 - mae: 0.2980 - val_loss: 0.4232 - val_mse: 0.4232 - val_mae: 0.4639\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 98us/sample - loss: 0.1620 - mse: 0.1620 - mae: 0.3060 - val_loss: 0.4613 - val_mse: 0.4613 - val_mae: 0.4693\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.1565 - mse: 0.1565 - mae: 0.2993 - val_loss: 0.3939 - val_mse: 0.3939 - val_mae: 0.4477\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1489 - mse: 0.1489 - mae: 0.2908 - val_loss: 0.4605 - val_mse: 0.4605 - val_mae: 0.4746\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1589 - mse: 0.1589 - mae: 0.3000 - val_loss: 0.3942 - val_mse: 0.3942 - val_mae: 0.4448\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.1559 - mse: 0.1559 - mae: 0.2918 - val_loss: 0.3937 - val_mse: 0.3937 - val_mae: 0.4452\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1438 - mse: 0.1438 - mae: 0.2845 - val_loss: 0.3956 - val_mse: 0.3956 - val_mae: 0.4484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.1365 - mse: 0.1365 - mae: 0.2783 - val_loss: 0.4026 - val_mse: 0.4026 - val_mae: 0.4585\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1370 - mse: 0.1370 - mae: 0.2778 - val_loss: 0.3869 - val_mse: 0.3869 - val_mae: 0.4384\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1239 - mse: 0.1239 - mae: 0.2650 - val_loss: 0.4230 - val_mse: 0.4230 - val_mae: 0.4735\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1361 - mse: 0.1361 - mae: 0.2793 - val_loss: 0.4093 - val_mse: 0.4093 - val_mae: 0.4666\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1491 - mse: 0.1491 - mae: 0.2861 - val_loss: 0.4459 - val_mse: 0.4459 - val_mae: 0.4787\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1265 - mse: 0.1265 - mae: 0.2704 - val_loss: 0.4704 - val_mse: 0.4704 - val_mae: 0.4876\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.1199 - mse: 0.1199 - mae: 0.2614 - val_loss: 0.4166 - val_mse: 0.4166 - val_mae: 0.4553\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1146 - mse: 0.1146 - mae: 0.2556 - val_loss: 0.4191 - val_mse: 0.4191 - val_mae: 0.4710\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1533 - mse: 0.1533 - mae: 0.2865 - val_loss: 0.4745 - val_mse: 0.4745 - val_mae: 0.4825\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1330 - mse: 0.1330 - mae: 0.2740 - val_loss: 0.4034 - val_mse: 0.4034 - val_mae: 0.4548\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1268 - mse: 0.1268 - mae: 0.2664 - val_loss: 0.4189 - val_mse: 0.4189 - val_mae: 0.4457\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1277 - mse: 0.1277 - mae: 0.2685 - val_loss: 0.4065 - val_mse: 0.4065 - val_mae: 0.4575\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 197us/sample - loss: 9.8224 - mse: 9.8224 - mae: 1.4277 - val_loss: 9.3245 - val_mse: 9.3245 - val_mae: 2.2959\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.6993 - mse: 0.6993 - mae: 0.6267 - val_loss: 1.2539 - val_mse: 1.2539 - val_mae: 0.8907\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.6267 - mse: 0.6267 - mae: 0.5902 - val_loss: 1.1563 - val_mse: 1.1563 - val_mae: 0.8974\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.5915 - mse: 0.5915 - mae: 0.5739 - val_loss: 0.7301 - val_mse: 0.7301 - val_mae: 0.6749\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.5412 - mse: 0.5412 - mae: 0.5471 - val_loss: 0.6545 - val_mse: 0.6545 - val_mae: 0.6263\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.4971 - mse: 0.4971 - mae: 0.5272 - val_loss: 0.6210 - val_mse: 0.6210 - val_mae: 0.5973\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.4642 - mse: 0.4642 - mae: 0.5109 - val_loss: 0.5681 - val_mse: 0.5681 - val_mae: 0.5760\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.4277 - mse: 0.4277 - mae: 0.4891 - val_loss: 0.5204 - val_mse: 0.5204 - val_mae: 0.5568\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.4198 - mse: 0.4198 - mae: 0.4839 - val_loss: 0.5548 - val_mse: 0.5548 - val_mae: 0.5399\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.4142 - mse: 0.4142 - mae: 0.4746 - val_loss: 0.5459 - val_mse: 0.5459 - val_mae: 0.5359\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.3902 - mse: 0.3902 - mae: 0.4657 - val_loss: 0.4795 - val_mse: 0.4795 - val_mae: 0.4999\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.3578 - mse: 0.3578 - mae: 0.4481 - val_loss: 0.5029 - val_mse: 0.5029 - val_mae: 0.5148\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.3377 - mse: 0.3377 - mae: 0.4334 - val_loss: 0.4781 - val_mse: 0.4781 - val_mae: 0.5024\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.3152 - mse: 0.3152 - mae: 0.4189 - val_loss: 0.4828 - val_mse: 0.4828 - val_mae: 0.5075\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.3055 - mse: 0.3055 - mae: 0.4138 - val_loss: 0.4581 - val_mse: 0.4581 - val_mae: 0.4926\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.3211 - mse: 0.3211 - mae: 0.4190 - val_loss: 0.4725 - val_mse: 0.4725 - val_mae: 0.5005\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.2822 - mse: 0.2822 - mae: 0.3989 - val_loss: 0.4365 - val_mse: 0.4365 - val_mae: 0.4695\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.2643 - mse: 0.2643 - mae: 0.3871 - val_loss: 0.4828 - val_mse: 0.4828 - val_mae: 0.4952\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.2567 - mse: 0.2567 - mae: 0.3806 - val_loss: 0.4602 - val_mse: 0.4602 - val_mae: 0.4831\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.2475 - mse: 0.2475 - mae: 0.3751 - val_loss: 0.4640 - val_mse: 0.4640 - val_mae: 0.4768\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.2435 - mse: 0.2435 - mae: 0.3689 - val_loss: 0.4927 - val_mse: 0.4927 - val_mae: 0.5004\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.2545 - mse: 0.2545 - mae: 0.3789 - val_loss: 0.4530 - val_mse: 0.4530 - val_mae: 0.4875\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.2427 - mse: 0.2427 - mae: 0.3705 - val_loss: 0.4563 - val_mse: 0.4563 - val_mae: 0.4861\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.2251 - mse: 0.2251 - mae: 0.3566 - val_loss: 0.4318 - val_mse: 0.4318 - val_mae: 0.4787\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.2351 - mse: 0.2351 - mae: 0.3586 - val_loss: 0.4492 - val_mse: 0.4492 - val_mae: 0.4771\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.2228 - mse: 0.2228 - mae: 0.3541 - val_loss: 0.4383 - val_mse: 0.4383 - val_mae: 0.4820\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.2181 - mse: 0.2181 - mae: 0.3492 - val_loss: 0.4199 - val_mse: 0.4199 - val_mae: 0.4652\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.2627 - mse: 0.2627 - mae: 0.3793 - val_loss: 0.4475 - val_mse: 0.4475 - val_mae: 0.4963\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.2086 - mse: 0.2086 - mae: 0.3445 - val_loss: 0.4312 - val_mse: 0.4312 - val_mae: 0.4868\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.2008 - mse: 0.2008 - mae: 0.3357 - val_loss: 0.4353 - val_mse: 0.4353 - val_mae: 0.4864\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1996 - mse: 0.1996 - mae: 0.3333 - val_loss: 0.4106 - val_mse: 0.4106 - val_mae: 0.4629\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1766 - mse: 0.1766 - mae: 0.3164 - val_loss: 0.4367 - val_mse: 0.4367 - val_mae: 0.4714\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 1s 95us/sample - loss: 0.1801 - mse: 0.1801 - mae: 0.3204 - val_loss: 0.4326 - val_mse: 0.4326 - val_mae: 0.4680\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1870 - mse: 0.1870 - mae: 0.3256 - val_loss: 0.4304 - val_mse: 0.4304 - val_mae: 0.4686\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1629 - mse: 0.1629 - mae: 0.3046 - val_loss: 0.4111 - val_mse: 0.4111 - val_mae: 0.4554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1451 - mse: 0.1451 - mae: 0.2871 - val_loss: 0.4038 - val_mse: 0.4038 - val_mae: 0.4586\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1817 - mse: 0.1817 - mae: 0.3164 - val_loss: 0.4361 - val_mse: 0.4361 - val_mae: 0.4769\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1517 - mse: 0.1517 - mae: 0.2921 - val_loss: 0.4133 - val_mse: 0.4133 - val_mae: 0.4715\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1451 - mse: 0.1451 - mae: 0.2877 - val_loss: 0.4529 - val_mse: 0.4529 - val_mae: 0.4712\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1412 - mse: 0.1412 - mae: 0.2827 - val_loss: 0.3880 - val_mse: 0.3880 - val_mae: 0.4444\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1405 - mse: 0.1405 - mae: 0.2819 - val_loss: 0.4584 - val_mse: 0.4584 - val_mae: 0.4992\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 1s 99us/sample - loss: 0.1480 - mse: 0.1480 - mae: 0.2875 - val_loss: 0.4194 - val_mse: 0.4194 - val_mae: 0.4768\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1726 - mse: 0.1726 - mae: 0.3080 - val_loss: 0.3958 - val_mse: 0.3958 - val_mae: 0.4572\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1452 - mse: 0.1452 - mae: 0.2847 - val_loss: 0.4290 - val_mse: 0.4290 - val_mae: 0.4652\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1303 - mse: 0.1303 - mae: 0.2696 - val_loss: 0.3955 - val_mse: 0.3955 - val_mae: 0.4458\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 0.1354 - mse: 0.1354 - mae: 0.2767 - val_loss: 0.4093 - val_mse: 0.4093 - val_mae: 0.4603\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1265 - mse: 0.1265 - mae: 0.2672 - val_loss: 0.4039 - val_mse: 0.4039 - val_mae: 0.4573\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1337 - mse: 0.1337 - mae: 0.2722 - val_loss: 0.3782 - val_mse: 0.3782 - val_mae: 0.4454\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1331 - mse: 0.1331 - mae: 0.2728 - val_loss: 0.4092 - val_mse: 0.4092 - val_mae: 0.4627\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1586 - mse: 0.1586 - mae: 0.2967 - val_loss: 0.4272 - val_mse: 0.4272 - val_mae: 0.4696\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1230 - mse: 0.1230 - mae: 0.2626 - val_loss: 0.3907 - val_mse: 0.3907 - val_mae: 0.4509\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1175 - mse: 0.1175 - mae: 0.2577 - val_loss: 0.3909 - val_mse: 0.3909 - val_mae: 0.4506\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1263 - mse: 0.1263 - mae: 0.2650 - val_loss: 0.4074 - val_mse: 0.4074 - val_mae: 0.4616\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1156 - mse: 0.1156 - mae: 0.2535 - val_loss: 0.4223 - val_mse: 0.4223 - val_mae: 0.4615\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1252 - mse: 0.1252 - mae: 0.2632 - val_loss: 0.4754 - val_mse: 0.4754 - val_mae: 0.4983\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1099 - mse: 0.1099 - mae: 0.2451 - val_loss: 0.3641 - val_mse: 0.3641 - val_mae: 0.4296\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1090 - mse: 0.1090 - mae: 0.2461 - val_loss: 0.3818 - val_mse: 0.3818 - val_mae: 0.4363\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1105 - mse: 0.1105 - mae: 0.2500 - val_loss: 0.3969 - val_mse: 0.3969 - val_mae: 0.4501\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.1095 - mse: 0.1095 - mae: 0.2469 - val_loss: 0.3798 - val_mse: 0.3798 - val_mae: 0.4393\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1060 - mse: 0.1060 - mae: 0.2435 - val_loss: 0.3819 - val_mse: 0.3819 - val_mae: 0.4392\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1045 - mse: 0.1045 - mae: 0.2416 - val_loss: 0.3887 - val_mse: 0.3887 - val_mae: 0.4360\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 0.1033 - mse: 0.1033 - mae: 0.2423 - val_loss: 0.3801 - val_mse: 0.3801 - val_mae: 0.4361\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 1s 91us/sample - loss: 0.0995 - mse: 0.0995 - mae: 0.2354 - val_loss: 0.4076 - val_mse: 0.4076 - val_mae: 0.4547\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 0.1074 - mse: 0.1074 - mae: 0.2439 - val_loss: 0.4169 - val_mse: 0.4169 - val_mae: 0.4539\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1318 - mse: 0.1318 - mae: 0.2689 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4732\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 1s 93us/sample - loss: 0.1093 - mse: 0.1093 - mae: 0.2432 - val_loss: 0.3911 - val_mse: 0.3911 - val_mae: 0.4420\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 196us/sample - loss: 11.9428 - mse: 11.9428 - mae: 1.5486 - val_loss: 15.5454 - val_mse: 15.5454 - val_mae: 3.1904\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.6916 - mse: 0.6916 - mae: 0.6230 - val_loss: 1.0343 - val_mse: 1.0343 - val_mae: 0.7772\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 1s 93us/sample - loss: 0.6202 - mse: 0.6202 - mae: 0.5887 - val_loss: 0.9187 - val_mse: 0.9187 - val_mae: 0.7362\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 1s 92us/sample - loss: 0.5728 - mse: 0.5728 - mae: 0.5655 - val_loss: 0.7293 - val_mse: 0.7293 - val_mae: 0.6680\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.5393 - mse: 0.5393 - mae: 0.5478 - val_loss: 0.6382 - val_mse: 0.6382 - val_mae: 0.6330\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 1s 92us/sample - loss: 0.4885 - mse: 0.4885 - mae: 0.5232 - val_loss: 0.5835 - val_mse: 0.5835 - val_mae: 0.5744\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.4450 - mse: 0.4450 - mae: 0.4999 - val_loss: 0.6025 - val_mse: 0.6025 - val_mae: 0.5730\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.4163 - mse: 0.4163 - mae: 0.4841 - val_loss: 0.5733 - val_mse: 0.5733 - val_mae: 0.5494\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.4107 - mse: 0.4107 - mae: 0.4809 - val_loss: 0.6896 - val_mse: 0.6896 - val_mae: 0.6216\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 1s 90us/sample - loss: 0.3869 - mse: 0.3869 - mae: 0.4683 - val_loss: 0.5391 - val_mse: 0.5391 - val_mae: 0.5261\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 1s 92us/sample - loss: 0.3562 - mse: 0.3562 - mae: 0.4485 - val_loss: 0.5404 - val_mse: 0.5404 - val_mae: 0.5383\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.3469 - mse: 0.3469 - mae: 0.4449 - val_loss: 0.6199 - val_mse: 0.6199 - val_mae: 0.5395\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.3261 - mse: 0.3261 - mae: 0.4273 - val_loss: 0.4513 - val_mse: 0.4513 - val_mae: 0.4849\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 1s 94us/sample - loss: 0.3109 - mse: 0.3109 - mae: 0.4219 - val_loss: 0.4704 - val_mse: 0.4704 - val_mae: 0.4870\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 1s 94us/sample - loss: 0.3085 - mse: 0.3085 - mae: 0.4162 - val_loss: 0.4266 - val_mse: 0.4266 - val_mae: 0.4715\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.2826 - mse: 0.2826 - mae: 0.3996 - val_loss: 0.4419 - val_mse: 0.4419 - val_mae: 0.4725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.2667 - mse: 0.2667 - mae: 0.3887 - val_loss: 0.4502 - val_mse: 0.4502 - val_mae: 0.4771\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 1s 92us/sample - loss: 0.2766 - mse: 0.2766 - mae: 0.3981 - val_loss: 0.4166 - val_mse: 0.4166 - val_mae: 0.4568\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 1s 92us/sample - loss: 0.2604 - mse: 0.2604 - mae: 0.3868 - val_loss: 0.4521 - val_mse: 0.4521 - val_mae: 0.4851\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 1s 90us/sample - loss: 0.2514 - mse: 0.2514 - mae: 0.3814 - val_loss: 0.4261 - val_mse: 0.4261 - val_mae: 0.4626\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.2276 - mse: 0.2276 - mae: 0.3581 - val_loss: 0.4368 - val_mse: 0.4368 - val_mae: 0.4637\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.2251 - mse: 0.2251 - mae: 0.3571 - val_loss: 0.4661 - val_mse: 0.4661 - val_mae: 0.4797\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.2367 - mse: 0.2367 - mae: 0.3679 - val_loss: 0.4421 - val_mse: 0.4421 - val_mae: 0.4725\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.2123 - mse: 0.2123 - mae: 0.3478 - val_loss: 0.4271 - val_mse: 0.4271 - val_mae: 0.4680\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.2198 - mse: 0.2198 - mae: 0.3532 - val_loss: 0.4291 - val_mse: 0.4291 - val_mae: 0.4560\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.2229 - mse: 0.2229 - mae: 0.3564 - val_loss: 0.4219 - val_mse: 0.4219 - val_mae: 0.4548\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 1s 91us/sample - loss: 0.1959 - mse: 0.1959 - mae: 0.3340 - val_loss: 0.4661 - val_mse: 0.4661 - val_mae: 0.4889\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 1s 92us/sample - loss: 0.2058 - mse: 0.2058 - mae: 0.3416 - val_loss: 0.4624 - val_mse: 0.4624 - val_mae: 0.4772\n",
      "Avg. MAE: 0.391657\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 92us/sample - loss: 1.6802 - mse: 1.6802 - mae: 0.9680 - val_loss: 1.2260 - val_mse: 1.2260 - val_mae: 0.8628\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.9251 - mse: 0.9251 - mae: 0.7285 - val_loss: 1.0773 - val_mse: 1.0773 - val_mae: 0.8272\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.7764 - mse: 0.7764 - mae: 0.6643 - val_loss: 1.0189 - val_mse: 1.0189 - val_mae: 0.8047\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.6857 - mse: 0.6857 - mae: 0.6259 - val_loss: 0.9378 - val_mse: 0.9378 - val_mae: 0.7791\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.6296 - mse: 0.6296 - mae: 0.6018 - val_loss: 0.8437 - val_mse: 0.8437 - val_mae: 0.7347\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.5815 - mse: 0.5815 - mae: 0.5792 - val_loss: 0.7802 - val_mse: 0.7802 - val_mae: 0.7034\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.5612 - mse: 0.5612 - mae: 0.5657 - val_loss: 0.7111 - val_mse: 0.7111 - val_mae: 0.6630\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.5220 - mse: 0.5220 - mae: 0.5467 - val_loss: 0.6510 - val_mse: 0.6510 - val_mae: 0.6355\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.5033 - mse: 0.5033 - mae: 0.5358 - val_loss: 0.6223 - val_mse: 0.6223 - val_mae: 0.6145\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4782 - mse: 0.4782 - mae: 0.5238 - val_loss: 0.6018 - val_mse: 0.6018 - val_mae: 0.6001\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.4629 - mse: 0.4629 - mae: 0.5133 - val_loss: 0.5803 - val_mse: 0.5803 - val_mae: 0.5842\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.4460 - mse: 0.4460 - mae: 0.5031 - val_loss: 0.5666 - val_mse: 0.5666 - val_mae: 0.5764\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4253 - mse: 0.4253 - mae: 0.4942 - val_loss: 0.5485 - val_mse: 0.5485 - val_mae: 0.5646\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.4136 - mse: 0.4136 - mae: 0.4849 - val_loss: 0.5439 - val_mse: 0.5439 - val_mae: 0.5620\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.3960 - mse: 0.3960 - mae: 0.4777 - val_loss: 0.5279 - val_mse: 0.5279 - val_mae: 0.5514\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3924 - mse: 0.3924 - mae: 0.4718 - val_loss: 0.5161 - val_mse: 0.5161 - val_mae: 0.5412\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3847 - mse: 0.3847 - mae: 0.4707 - val_loss: 0.5130 - val_mse: 0.5130 - val_mae: 0.5357\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 32us/sample - loss: 0.3728 - mse: 0.3728 - mae: 0.4586 - val_loss: 0.5130 - val_mse: 0.5130 - val_mae: 0.5338\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.3620 - mse: 0.3620 - mae: 0.4529 - val_loss: 0.5108 - val_mse: 0.5108 - val_mae: 0.5292\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3535 - mse: 0.3535 - mae: 0.4497 - val_loss: 0.4944 - val_mse: 0.4944 - val_mae: 0.5256\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.3436 - mse: 0.3436 - mae: 0.4434 - val_loss: 0.4936 - val_mse: 0.4936 - val_mae: 0.5254\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3370 - mse: 0.3370 - mae: 0.4387 - val_loss: 0.4904 - val_mse: 0.4904 - val_mae: 0.5196\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3362 - mse: 0.3362 - mae: 0.4367 - val_loss: 0.4877 - val_mse: 0.4877 - val_mae: 0.5207\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3244 - mse: 0.3244 - mae: 0.4302 - val_loss: 0.4870 - val_mse: 0.4870 - val_mae: 0.5202\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3185 - mse: 0.3185 - mae: 0.4254 - val_loss: 0.4759 - val_mse: 0.4759 - val_mae: 0.5171\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3152 - mse: 0.3152 - mae: 0.4230 - val_loss: 0.4738 - val_mse: 0.4738 - val_mae: 0.5100\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.3025 - mse: 0.3025 - mae: 0.4168 - val_loss: 0.4643 - val_mse: 0.4643 - val_mae: 0.5070\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.2943 - mse: 0.2943 - mae: 0.4093 - val_loss: 0.4676 - val_mse: 0.4676 - val_mae: 0.5086\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2979 - mse: 0.2979 - mae: 0.4125 - val_loss: 0.4615 - val_mse: 0.4615 - val_mae: 0.5034\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2940 - mse: 0.2940 - mae: 0.4099 - val_loss: 0.4616 - val_mse: 0.4616 - val_mae: 0.5024\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2852 - mse: 0.2852 - mae: 0.4049 - val_loss: 0.4609 - val_mse: 0.4609 - val_mae: 0.5031\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2821 - mse: 0.2821 - mae: 0.4015 - val_loss: 0.4488 - val_mse: 0.4488 - val_mae: 0.4993\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.2752 - mse: 0.2752 - mae: 0.3960 - val_loss: 0.4486 - val_mse: 0.4486 - val_mae: 0.4968\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2713 - mse: 0.2713 - mae: 0.3935 - val_loss: 0.4481 - val_mse: 0.4481 - val_mae: 0.4963\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.2668 - mse: 0.2668 - mae: 0.3931 - val_loss: 0.4447 - val_mse: 0.4447 - val_mae: 0.4952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2600 - mse: 0.2600 - mae: 0.3848 - val_loss: 0.4525 - val_mse: 0.4525 - val_mae: 0.4966\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.2597 - mse: 0.2597 - mae: 0.3857 - val_loss: 0.4544 - val_mse: 0.4544 - val_mae: 0.4938\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2600 - mse: 0.2600 - mae: 0.3864 - val_loss: 0.4453 - val_mse: 0.4453 - val_mae: 0.4937\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2515 - mse: 0.2515 - mae: 0.3782 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.4950\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2503 - mse: 0.2503 - mae: 0.3813 - val_loss: 0.4501 - val_mse: 0.4501 - val_mae: 0.4903\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2510 - mse: 0.2510 - mae: 0.3795 - val_loss: 0.4539 - val_mse: 0.4539 - val_mae: 0.4944\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2436 - mse: 0.2436 - mae: 0.3726 - val_loss: 0.4461 - val_mse: 0.4461 - val_mae: 0.4929\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2352 - mse: 0.2352 - mae: 0.3666 - val_loss: 0.4372 - val_mse: 0.4372 - val_mae: 0.4870\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2330 - mse: 0.2330 - mae: 0.3653 - val_loss: 0.4434 - val_mse: 0.4434 - val_mae: 0.4873\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2349 - mse: 0.2349 - mae: 0.3666 - val_loss: 0.4365 - val_mse: 0.4365 - val_mae: 0.4869\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2285 - mse: 0.2285 - mae: 0.3625 - val_loss: 0.4360 - val_mse: 0.4360 - val_mae: 0.4854\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2268 - mse: 0.2268 - mae: 0.3620 - val_loss: 0.4333 - val_mse: 0.4333 - val_mae: 0.4859\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2244 - mse: 0.2244 - mae: 0.3572 - val_loss: 0.4374 - val_mse: 0.4374 - val_mae: 0.4837\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2247 - mse: 0.2247 - mae: 0.3583 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.4856\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2204 - mse: 0.2204 - mae: 0.3548 - val_loss: 0.4411 - val_mse: 0.4411 - val_mae: 0.4845\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2163 - mse: 0.2163 - mae: 0.3528 - val_loss: 0.4280 - val_mse: 0.4280 - val_mae: 0.4823\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2167 - mse: 0.2167 - mae: 0.3512 - val_loss: 0.4245 - val_mse: 0.4245 - val_mae: 0.4813\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2102 - mse: 0.2102 - mae: 0.3450 - val_loss: 0.4285 - val_mse: 0.4285 - val_mae: 0.4821\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.2069 - mse: 0.2069 - mae: 0.3461 - val_loss: 0.4406 - val_mse: 0.4406 - val_mae: 0.4881\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2081 - mse: 0.2081 - mae: 0.3448 - val_loss: 0.4294 - val_mse: 0.4294 - val_mae: 0.4796\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2073 - mse: 0.2073 - mae: 0.3437 - val_loss: 0.4340 - val_mse: 0.4340 - val_mae: 0.4821\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2024 - mse: 0.2024 - mae: 0.3410 - val_loss: 0.4310 - val_mse: 0.4310 - val_mae: 0.4782\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2012 - mse: 0.2012 - mae: 0.3392 - val_loss: 0.4217 - val_mse: 0.4217 - val_mae: 0.4753\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1998 - mse: 0.1998 - mae: 0.3397 - val_loss: 0.4318 - val_mse: 0.4318 - val_mae: 0.4738\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.1976 - mse: 0.1976 - mae: 0.3364 - val_loss: 0.4266 - val_mse: 0.4266 - val_mae: 0.4774\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1941 - mse: 0.1941 - mae: 0.3335 - val_loss: 0.4177 - val_mse: 0.4177 - val_mae: 0.4740\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1932 - mse: 0.1932 - mae: 0.3321 - val_loss: 0.4273 - val_mse: 0.4273 - val_mae: 0.4747\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1925 - mse: 0.1925 - mae: 0.3335 - val_loss: 0.4194 - val_mse: 0.4194 - val_mae: 0.4721\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1873 - mse: 0.1873 - mae: 0.3290 - val_loss: 0.4233 - val_mse: 0.4233 - val_mae: 0.4711\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.1874 - mse: 0.1874 - mae: 0.3282 - val_loss: 0.4199 - val_mse: 0.4199 - val_mae: 0.4718\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1828 - mse: 0.1828 - mae: 0.3241 - val_loss: 0.4242 - val_mse: 0.4242 - val_mae: 0.4715\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1825 - mse: 0.1825 - mae: 0.3230 - val_loss: 0.4343 - val_mse: 0.4343 - val_mae: 0.4756\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1770 - mse: 0.1770 - mae: 0.3187 - val_loss: 0.4191 - val_mse: 0.4191 - val_mae: 0.4729\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1814 - mse: 0.1814 - mae: 0.3236 - val_loss: 0.4217 - val_mse: 0.4217 - val_mae: 0.4739\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1757 - mse: 0.1757 - mae: 0.3176 - val_loss: 0.4290 - val_mse: 0.4290 - val_mae: 0.4711\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1799 - mse: 0.1799 - mae: 0.3224 - val_loss: 0.4313 - val_mse: 0.4313 - val_mae: 0.4787\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 89us/sample - loss: 1.6924 - mse: 1.6924 - mae: 0.9825 - val_loss: 1.2377 - val_mse: 1.2377 - val_mae: 0.8565\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.9306 - mse: 0.9306 - mae: 0.7283 - val_loss: 1.2073 - val_mse: 1.2073 - val_mae: 0.8656\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.7714 - mse: 0.7714 - mae: 0.6667 - val_loss: 1.1222 - val_mse: 1.1222 - val_mae: 0.8377\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.7028 - mse: 0.7028 - mae: 0.6339 - val_loss: 1.0475 - val_mse: 1.0475 - val_mae: 0.8078\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.6422 - mse: 0.6422 - mae: 0.6099 - val_loss: 0.9898 - val_mse: 0.9898 - val_mae: 0.7819\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.5928 - mse: 0.5928 - mae: 0.5852 - val_loss: 0.9219 - val_mse: 0.9219 - val_mae: 0.7406\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.5636 - mse: 0.5636 - mae: 0.5690 - val_loss: 0.7997 - val_mse: 0.7997 - val_mae: 0.6886\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.5285 - mse: 0.5285 - mae: 0.5503 - val_loss: 0.7789 - val_mse: 0.7789 - val_mae: 0.6725\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.5080 - mse: 0.5080 - mae: 0.5418 - val_loss: 0.7618 - val_mse: 0.7618 - val_mae: 0.6484\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.4790 - mse: 0.4790 - mae: 0.5260 - val_loss: 0.6668 - val_mse: 0.6668 - val_mae: 0.6154\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.4644 - mse: 0.4644 - mae: 0.5159 - val_loss: 0.6575 - val_mse: 0.6575 - val_mae: 0.6099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4521 - mse: 0.4521 - mae: 0.5111 - val_loss: 0.6354 - val_mse: 0.6354 - val_mae: 0.5907\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.4293 - mse: 0.4293 - mae: 0.4976 - val_loss: 0.6158 - val_mse: 0.6158 - val_mae: 0.5726\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4170 - mse: 0.4170 - mae: 0.4913 - val_loss: 0.6162 - val_mse: 0.6162 - val_mae: 0.5687\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4071 - mse: 0.4071 - mae: 0.4839 - val_loss: 0.6067 - val_mse: 0.6067 - val_mae: 0.5671\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3992 - mse: 0.3992 - mae: 0.4787 - val_loss: 0.5730 - val_mse: 0.5730 - val_mae: 0.5508\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3787 - mse: 0.3787 - mae: 0.4666 - val_loss: 0.5756 - val_mse: 0.5756 - val_mae: 0.5488\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3751 - mse: 0.3751 - mae: 0.4640 - val_loss: 0.5660 - val_mse: 0.5660 - val_mae: 0.5511\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3614 - mse: 0.3614 - mae: 0.4543 - val_loss: 0.5645 - val_mse: 0.5645 - val_mae: 0.5451\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.3565 - mse: 0.3565 - mae: 0.4526 - val_loss: 0.5434 - val_mse: 0.5434 - val_mae: 0.5404\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3498 - mse: 0.3498 - mae: 0.4476 - val_loss: 0.5586 - val_mse: 0.5586 - val_mae: 0.5454\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3398 - mse: 0.3398 - mae: 0.4410 - val_loss: 0.5557 - val_mse: 0.5557 - val_mae: 0.5424\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3359 - mse: 0.3359 - mae: 0.4401 - val_loss: 0.5454 - val_mse: 0.5454 - val_mae: 0.5337\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3260 - mse: 0.3260 - mae: 0.4322 - val_loss: 0.5471 - val_mse: 0.5471 - val_mae: 0.5295\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3154 - mse: 0.3154 - mae: 0.4263 - val_loss: 0.5370 - val_mse: 0.5370 - val_mae: 0.5296\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3112 - mse: 0.3112 - mae: 0.4236 - val_loss: 0.5244 - val_mse: 0.5244 - val_mae: 0.5272\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3060 - mse: 0.3060 - mae: 0.4181 - val_loss: 0.5248 - val_mse: 0.5248 - val_mae: 0.5266\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2999 - mse: 0.2999 - mae: 0.4147 - val_loss: 0.5290 - val_mse: 0.5290 - val_mae: 0.5195\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2976 - mse: 0.2976 - mae: 0.4133 - val_loss: 0.5252 - val_mse: 0.5252 - val_mae: 0.5231\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2906 - mse: 0.2906 - mae: 0.4091 - val_loss: 0.5255 - val_mse: 0.5255 - val_mae: 0.5246\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2817 - mse: 0.2817 - mae: 0.4027 - val_loss: 0.5227 - val_mse: 0.5227 - val_mae: 0.5186\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2789 - mse: 0.2789 - mae: 0.4019 - val_loss: 0.5361 - val_mse: 0.5361 - val_mae: 0.5228\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2787 - mse: 0.2787 - mae: 0.4021 - val_loss: 0.5191 - val_mse: 0.5191 - val_mae: 0.5180\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2728 - mse: 0.2728 - mae: 0.3951 - val_loss: 0.5172 - val_mse: 0.5172 - val_mae: 0.5121\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2692 - mse: 0.2692 - mae: 0.3936 - val_loss: 0.5135 - val_mse: 0.5135 - val_mae: 0.5075\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2648 - mse: 0.2648 - mae: 0.3900 - val_loss: 0.5032 - val_mse: 0.5032 - val_mae: 0.5094\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2626 - mse: 0.2626 - mae: 0.3903 - val_loss: 0.5185 - val_mse: 0.5185 - val_mae: 0.5118\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2597 - mse: 0.2597 - mae: 0.3871 - val_loss: 0.4953 - val_mse: 0.4953 - val_mae: 0.5098\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2549 - mse: 0.2549 - mae: 0.3843 - val_loss: 0.5280 - val_mse: 0.5280 - val_mae: 0.5119\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2501 - mse: 0.2501 - mae: 0.3798 - val_loss: 0.4985 - val_mse: 0.4985 - val_mae: 0.5054\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2489 - mse: 0.2489 - mae: 0.3781 - val_loss: 0.4997 - val_mse: 0.4997 - val_mae: 0.5042\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.2460 - mse: 0.2460 - mae: 0.3766 - val_loss: 0.4876 - val_mse: 0.4876 - val_mae: 0.5006\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2390 - mse: 0.2390 - mae: 0.3688 - val_loss: 0.4797 - val_mse: 0.4797 - val_mae: 0.5006\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2381 - mse: 0.2381 - mae: 0.3685 - val_loss: 0.5229 - val_mse: 0.5228 - val_mae: 0.5105\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2333 - mse: 0.2333 - mae: 0.3668 - val_loss: 0.4864 - val_mse: 0.4864 - val_mae: 0.4983\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2323 - mse: 0.2323 - mae: 0.3640 - val_loss: 0.4902 - val_mse: 0.4902 - val_mae: 0.5055\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2241 - mse: 0.2241 - mae: 0.3586 - val_loss: 0.4727 - val_mse: 0.4727 - val_mae: 0.4956\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2231 - mse: 0.2231 - mae: 0.3583 - val_loss: 0.5259 - val_mse: 0.5259 - val_mae: 0.5009\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2207 - mse: 0.2207 - mae: 0.3568 - val_loss: 0.4807 - val_mse: 0.4807 - val_mae: 0.4924\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2206 - mse: 0.2206 - mae: 0.3560 - val_loss: 0.4792 - val_mse: 0.4792 - val_mae: 0.4929\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2182 - mse: 0.2182 - mae: 0.3538 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.4900\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2202 - mse: 0.2202 - mae: 0.3560 - val_loss: 0.4901 - val_mse: 0.4901 - val_mae: 0.4942\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2116 - mse: 0.2116 - mae: 0.3480 - val_loss: 0.4729 - val_mse: 0.4729 - val_mae: 0.4921\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2147 - mse: 0.2147 - mae: 0.3511 - val_loss: 0.4730 - val_mse: 0.4730 - val_mae: 0.4901\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2058 - mse: 0.2058 - mae: 0.3428 - val_loss: 0.4605 - val_mse: 0.4605 - val_mae: 0.4911\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2068 - mse: 0.2068 - mae: 0.3435 - val_loss: 0.4903 - val_mse: 0.4903 - val_mae: 0.4950\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2043 - mse: 0.2043 - mae: 0.3432 - val_loss: 0.4790 - val_mse: 0.4790 - val_mae: 0.4897\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2021 - mse: 0.2021 - mae: 0.3404 - val_loss: 0.4649 - val_mse: 0.4649 - val_mae: 0.4920\n",
      "Epoch 59/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1976 - mse: 0.1976 - mae: 0.3355 - val_loss: 0.4938 - val_mse: 0.4938 - val_mae: 0.4905\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1977 - mse: 0.1977 - mae: 0.3369 - val_loss: 0.5041 - val_mse: 0.5041 - val_mae: 0.4931\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1931 - mse: 0.1931 - mae: 0.3324 - val_loss: 0.4668 - val_mse: 0.4668 - val_mae: 0.4899\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1968 - mse: 0.1968 - mae: 0.3361 - val_loss: 0.4633 - val_mse: 0.4633 - val_mae: 0.4930\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.1891 - mse: 0.1891 - mae: 0.3295 - val_loss: 0.4649 - val_mse: 0.4649 - val_mae: 0.4851\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1925 - mse: 0.1925 - mae: 0.3316 - val_loss: 0.4664 - val_mse: 0.4664 - val_mae: 0.4875\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1845 - mse: 0.1845 - mae: 0.3269 - val_loss: 0.4509 - val_mse: 0.4509 - val_mae: 0.4813\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1853 - mse: 0.1853 - mae: 0.3261 - val_loss: 0.4619 - val_mse: 0.4619 - val_mae: 0.4898\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1845 - mse: 0.1845 - mae: 0.3257 - val_loss: 0.4762 - val_mse: 0.4762 - val_mae: 0.4844\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1837 - mse: 0.1837 - mae: 0.3242 - val_loss: 0.4684 - val_mse: 0.4684 - val_mae: 0.4888\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1785 - mse: 0.1785 - mae: 0.3191 - val_loss: 0.4635 - val_mse: 0.4635 - val_mae: 0.4820\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1792 - mse: 0.1792 - mae: 0.3209 - val_loss: 0.4517 - val_mse: 0.4517 - val_mae: 0.4778\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1782 - mse: 0.1782 - mae: 0.3184 - val_loss: 0.4796 - val_mse: 0.4796 - val_mae: 0.4819\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1790 - mse: 0.1790 - mae: 0.3203 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.4784\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1732 - mse: 0.1732 - mae: 0.3165 - val_loss: 0.4474 - val_mse: 0.4474 - val_mae: 0.4833\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1717 - mse: 0.1717 - mae: 0.3144 - val_loss: 0.4529 - val_mse: 0.4529 - val_mae: 0.4783\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1722 - mse: 0.1722 - mae: 0.3155 - val_loss: 0.4499 - val_mse: 0.4499 - val_mae: 0.4815\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1671 - mse: 0.1671 - mae: 0.3093 - val_loss: 0.4539 - val_mse: 0.4539 - val_mae: 0.4762\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1701 - mse: 0.1701 - mae: 0.3118 - val_loss: 0.4764 - val_mse: 0.4764 - val_mae: 0.4804\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1741 - mse: 0.1741 - mae: 0.3166 - val_loss: 0.4561 - val_mse: 0.4561 - val_mae: 0.4784\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1662 - mse: 0.1662 - mae: 0.3107 - val_loss: 0.4651 - val_mse: 0.4651 - val_mae: 0.4794\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1679 - mse: 0.1679 - mae: 0.3098 - val_loss: 0.4494 - val_mse: 0.4494 - val_mae: 0.4762\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1611 - mse: 0.1611 - mae: 0.3039 - val_loss: 0.4552 - val_mse: 0.4552 - val_mae: 0.4863\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 30us/sample - loss: 0.1699 - mse: 0.1699 - mae: 0.3127 - val_loss: 0.4519 - val_mse: 0.4519 - val_mae: 0.4749\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 90us/sample - loss: 1.7158 - mse: 1.7158 - mae: 0.9873 - val_loss: 1.2526 - val_mse: 1.2526 - val_mae: 0.8799\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.9523 - mse: 0.9523 - mae: 0.7401 - val_loss: 1.1507 - val_mse: 1.1507 - val_mae: 0.8509\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.7968 - mse: 0.7968 - mae: 0.6749 - val_loss: 1.1094 - val_mse: 1.1094 - val_mae: 0.8354\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.7046 - mse: 0.7046 - mae: 0.6371 - val_loss: 1.0375 - val_mse: 1.0375 - val_mae: 0.8075\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.6477 - mse: 0.6477 - mae: 0.6106 - val_loss: 0.9308 - val_mse: 0.9308 - val_mae: 0.7574\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.5983 - mse: 0.5983 - mae: 0.5847 - val_loss: 0.8558 - val_mse: 0.8558 - val_mae: 0.7243\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.5669 - mse: 0.5669 - mae: 0.5709 - val_loss: 0.7725 - val_mse: 0.7725 - val_mae: 0.6832\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.5399 - mse: 0.5399 - mae: 0.5574 - val_loss: 0.7042 - val_mse: 0.7042 - val_mae: 0.6438\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.5157 - mse: 0.5157 - mae: 0.5433 - val_loss: 0.6589 - val_mse: 0.6589 - val_mae: 0.6202\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.4931 - mse: 0.4931 - mae: 0.5336 - val_loss: 0.6161 - val_mse: 0.6161 - val_mae: 0.5940\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4717 - mse: 0.4717 - mae: 0.5193 - val_loss: 0.5959 - val_mse: 0.5959 - val_mae: 0.5808\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.4579 - mse: 0.4579 - mae: 0.5128 - val_loss: 0.5864 - val_mse: 0.5864 - val_mae: 0.5740\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4329 - mse: 0.4329 - mae: 0.4978 - val_loss: 0.5609 - val_mse: 0.5609 - val_mae: 0.5574\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.4222 - mse: 0.4222 - mae: 0.4911 - val_loss: 0.5547 - val_mse: 0.5547 - val_mae: 0.5522\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.4190 - mse: 0.4190 - mae: 0.4904 - val_loss: 0.5511 - val_mse: 0.5511 - val_mae: 0.5482\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4017 - mse: 0.4017 - mae: 0.4819 - val_loss: 0.5329 - val_mse: 0.5329 - val_mae: 0.5421\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.3919 - mse: 0.3919 - mae: 0.4734 - val_loss: 0.5190 - val_mse: 0.5190 - val_mae: 0.5293\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.3798 - mse: 0.3798 - mae: 0.4645 - val_loss: 0.5151 - val_mse: 0.5151 - val_mae: 0.5281\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3737 - mse: 0.3737 - mae: 0.4625 - val_loss: 0.5131 - val_mse: 0.5131 - val_mae: 0.5281\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3627 - mse: 0.3627 - mae: 0.4549 - val_loss: 0.5053 - val_mse: 0.5053 - val_mae: 0.5217\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3582 - mse: 0.3582 - mae: 0.4538 - val_loss: 0.5007 - val_mse: 0.5007 - val_mae: 0.5199\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3424 - mse: 0.3424 - mae: 0.4443 - val_loss: 0.5006 - val_mse: 0.5006 - val_mae: 0.5191\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3447 - mse: 0.3447 - mae: 0.4442 - val_loss: 0.4979 - val_mse: 0.4979 - val_mae: 0.5153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3310 - mse: 0.3310 - mae: 0.4358 - val_loss: 0.4836 - val_mse: 0.4836 - val_mae: 0.5078\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.3270 - mse: 0.3270 - mae: 0.4317 - val_loss: 0.4871 - val_mse: 0.4871 - val_mae: 0.5084\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3186 - mse: 0.3186 - mae: 0.4290 - val_loss: 0.4883 - val_mse: 0.4883 - val_mae: 0.5098\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.3149 - mse: 0.3149 - mae: 0.4254 - val_loss: 0.4758 - val_mse: 0.4758 - val_mae: 0.5014\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3107 - mse: 0.3107 - mae: 0.4225 - val_loss: 0.4800 - val_mse: 0.4800 - val_mae: 0.5053\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3011 - mse: 0.3011 - mae: 0.4150 - val_loss: 0.4870 - val_mse: 0.4870 - val_mae: 0.5059\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.3000 - mse: 0.3000 - mae: 0.4152 - val_loss: 0.4637 - val_mse: 0.4637 - val_mae: 0.4986\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2914 - mse: 0.2914 - mae: 0.4097 - val_loss: 0.4716 - val_mse: 0.4716 - val_mae: 0.4995\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2859 - mse: 0.2859 - mae: 0.4059 - val_loss: 0.4772 - val_mse: 0.4772 - val_mae: 0.4972\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.2843 - mse: 0.2843 - mae: 0.4038 - val_loss: 0.4611 - val_mse: 0.4611 - val_mae: 0.4925\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2764 - mse: 0.2764 - mae: 0.3958 - val_loss: 0.4771 - val_mse: 0.4771 - val_mae: 0.4998\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2742 - mse: 0.2742 - mae: 0.3957 - val_loss: 0.4670 - val_mse: 0.4670 - val_mae: 0.4959\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2755 - mse: 0.2755 - mae: 0.3977 - val_loss: 0.4735 - val_mse: 0.4735 - val_mae: 0.4993\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2673 - mse: 0.2673 - mae: 0.3905 - val_loss: 0.4590 - val_mse: 0.4590 - val_mae: 0.4865\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2655 - mse: 0.2655 - mae: 0.3903 - val_loss: 0.4508 - val_mse: 0.4508 - val_mae: 0.4842\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2601 - mse: 0.2601 - mae: 0.3856 - val_loss: 0.4501 - val_mse: 0.4501 - val_mae: 0.4846\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2555 - mse: 0.2555 - mae: 0.3826 - val_loss: 0.4530 - val_mse: 0.4530 - val_mae: 0.4828\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2543 - mse: 0.2543 - mae: 0.3807 - val_loss: 0.4498 - val_mse: 0.4498 - val_mae: 0.4822\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2478 - mse: 0.2478 - mae: 0.3763 - val_loss: 0.4508 - val_mse: 0.4508 - val_mae: 0.4855\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2424 - mse: 0.2424 - mae: 0.3714 - val_loss: 0.4443 - val_mse: 0.4443 - val_mae: 0.4805\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2354 - mse: 0.2354 - mae: 0.3668 - val_loss: 0.4460 - val_mse: 0.4460 - val_mae: 0.4797\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2360 - mse: 0.2360 - mae: 0.3673 - val_loss: 0.4463 - val_mse: 0.4463 - val_mae: 0.4786\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2347 - mse: 0.2347 - mae: 0.3654 - val_loss: 0.4428 - val_mse: 0.4428 - val_mae: 0.4775\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2325 - mse: 0.2325 - mae: 0.3659 - val_loss: 0.4358 - val_mse: 0.4358 - val_mae: 0.4757\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2324 - mse: 0.2324 - mae: 0.3652 - val_loss: 0.4431 - val_mse: 0.4431 - val_mae: 0.4809\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2267 - mse: 0.2267 - mae: 0.3611 - val_loss: 0.4388 - val_mse: 0.4388 - val_mae: 0.4780\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2299 - mse: 0.2299 - mae: 0.3639 - val_loss: 0.4478 - val_mse: 0.4478 - val_mae: 0.4818\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2198 - mse: 0.2198 - mae: 0.3557 - val_loss: 0.4456 - val_mse: 0.4456 - val_mae: 0.4745\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2191 - mse: 0.2191 - mae: 0.3536 - val_loss: 0.4412 - val_mse: 0.4412 - val_mae: 0.4744\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2156 - mse: 0.2156 - mae: 0.3514 - val_loss: 0.4370 - val_mse: 0.4370 - val_mae: 0.4729\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2165 - mse: 0.2165 - mae: 0.3548 - val_loss: 0.4446 - val_mse: 0.4446 - val_mae: 0.4769\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2117 - mse: 0.2117 - mae: 0.3484 - val_loss: 0.4372 - val_mse: 0.4372 - val_mae: 0.4752\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2127 - mse: 0.2127 - mae: 0.3489 - val_loss: 0.4470 - val_mse: 0.4470 - val_mae: 0.4770\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2097 - mse: 0.2097 - mae: 0.3465 - val_loss: 0.4432 - val_mse: 0.4432 - val_mae: 0.4754\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 1s 94us/sample - loss: 1.6787 - mse: 1.6787 - mae: 0.9683 - val_loss: 1.2507 - val_mse: 1.2507 - val_mae: 0.8835\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.9271 - mse: 0.9271 - mae: 0.7289 - val_loss: 1.1127 - val_mse: 1.1127 - val_mae: 0.8464\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.7730 - mse: 0.7730 - mae: 0.6665 - val_loss: 1.0822 - val_mse: 1.0822 - val_mae: 0.8517\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.6900 - mse: 0.6900 - mae: 0.6312 - val_loss: 0.9620 - val_mse: 0.9620 - val_mae: 0.7987\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.6296 - mse: 0.6296 - mae: 0.6028 - val_loss: 0.8708 - val_mse: 0.8708 - val_mae: 0.7553\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.5854 - mse: 0.5854 - mae: 0.5823 - val_loss: 0.7909 - val_mse: 0.7909 - val_mae: 0.7153\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.5491 - mse: 0.5491 - mae: 0.5631 - val_loss: 0.7133 - val_mse: 0.7133 - val_mae: 0.6690\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.5160 - mse: 0.5160 - mae: 0.5461 - val_loss: 0.6566 - val_mse: 0.6566 - val_mae: 0.6331\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.4934 - mse: 0.4934 - mae: 0.5337 - val_loss: 0.6221 - val_mse: 0.6221 - val_mae: 0.6082\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.4791 - mse: 0.4791 - mae: 0.5274 - val_loss: 0.5942 - val_mse: 0.5942 - val_mae: 0.5898\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.4566 - mse: 0.4566 - mae: 0.5129 - val_loss: 0.5745 - val_mse: 0.5745 - val_mae: 0.5769\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.4443 - mse: 0.4443 - mae: 0.5071 - val_loss: 0.5655 - val_mse: 0.5655 - val_mae: 0.5676\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.4257 - mse: 0.4257 - mae: 0.4970 - val_loss: 0.5567 - val_mse: 0.5567 - val_mae: 0.5614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.4113 - mse: 0.4113 - mae: 0.4865 - val_loss: 0.5599 - val_mse: 0.5599 - val_mae: 0.5586\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.4041 - mse: 0.4041 - mae: 0.4832 - val_loss: 0.5486 - val_mse: 0.5486 - val_mae: 0.5490\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.3927 - mse: 0.3927 - mae: 0.4741 - val_loss: 0.5432 - val_mse: 0.5432 - val_mae: 0.5427\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3781 - mse: 0.3781 - mae: 0.4662 - val_loss: 0.5457 - val_mse: 0.5457 - val_mae: 0.5386\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3686 - mse: 0.3686 - mae: 0.4608 - val_loss: 0.5462 - val_mse: 0.5462 - val_mae: 0.5357\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3605 - mse: 0.3605 - mae: 0.4554 - val_loss: 0.5508 - val_mse: 0.5508 - val_mae: 0.5351\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3524 - mse: 0.3524 - mae: 0.4503 - val_loss: 0.5319 - val_mse: 0.5319 - val_mae: 0.5234\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.3429 - mse: 0.3429 - mae: 0.4434 - val_loss: 0.5277 - val_mse: 0.5277 - val_mae: 0.5206\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3359 - mse: 0.3359 - mae: 0.4401 - val_loss: 0.5153 - val_mse: 0.5153 - val_mae: 0.5212\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3301 - mse: 0.3301 - mae: 0.4363 - val_loss: 0.5132 - val_mse: 0.5132 - val_mae: 0.5122\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3212 - mse: 0.3212 - mae: 0.4302 - val_loss: 0.5309 - val_mse: 0.5309 - val_mae: 0.5180\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3173 - mse: 0.3173 - mae: 0.4259 - val_loss: 0.5290 - val_mse: 0.5290 - val_mae: 0.5179\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3111 - mse: 0.3111 - mae: 0.4222 - val_loss: 0.5066 - val_mse: 0.5066 - val_mae: 0.5104\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.3082 - mse: 0.3082 - mae: 0.4196 - val_loss: 0.5150 - val_mse: 0.5150 - val_mae: 0.5135\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2984 - mse: 0.2984 - mae: 0.4138 - val_loss: 0.4989 - val_mse: 0.4989 - val_mae: 0.5127\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.3008 - mse: 0.3008 - mae: 0.4172 - val_loss: 0.5129 - val_mse: 0.5129 - val_mae: 0.5093\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2924 - mse: 0.2924 - mae: 0.4102 - val_loss: 0.5262 - val_mse: 0.5262 - val_mae: 0.5146\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2862 - mse: 0.2862 - mae: 0.4060 - val_loss: 0.4952 - val_mse: 0.4952 - val_mae: 0.5034\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2787 - mse: 0.2787 - mae: 0.3996 - val_loss: 0.5103 - val_mse: 0.5103 - val_mae: 0.5063\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2812 - mse: 0.2812 - mae: 0.4023 - val_loss: 0.5088 - val_mse: 0.5088 - val_mae: 0.5064\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2698 - mse: 0.2698 - mae: 0.3922 - val_loss: 0.5047 - val_mse: 0.5047 - val_mae: 0.5032\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2709 - mse: 0.2709 - mae: 0.3952 - val_loss: 0.4933 - val_mse: 0.4933 - val_mae: 0.5015\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2653 - mse: 0.2653 - mae: 0.3913 - val_loss: 0.4915 - val_mse: 0.4915 - val_mae: 0.4987\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2626 - mse: 0.2626 - mae: 0.3879 - val_loss: 0.4923 - val_mse: 0.4923 - val_mae: 0.5018\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2596 - mse: 0.2596 - mae: 0.3873 - val_loss: 0.4780 - val_mse: 0.4780 - val_mae: 0.4945\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2554 - mse: 0.2554 - mae: 0.3844 - val_loss: 0.4757 - val_mse: 0.4757 - val_mae: 0.4970\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2491 - mse: 0.2491 - mae: 0.3772 - val_loss: 0.4810 - val_mse: 0.4810 - val_mae: 0.4955\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2500 - mse: 0.2500 - mae: 0.3786 - val_loss: 0.4804 - val_mse: 0.4804 - val_mae: 0.4998\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2407 - mse: 0.2407 - mae: 0.3702 - val_loss: 0.4910 - val_mse: 0.4910 - val_mae: 0.4931\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2460 - mse: 0.2460 - mae: 0.3760 - val_loss: 0.4873 - val_mse: 0.4873 - val_mae: 0.4933\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2416 - mse: 0.2416 - mae: 0.3721 - val_loss: 0.4699 - val_mse: 0.4699 - val_mae: 0.4884\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2347 - mse: 0.2347 - mae: 0.3667 - val_loss: 0.4798 - val_mse: 0.4798 - val_mae: 0.4922\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2317 - mse: 0.2317 - mae: 0.3657 - val_loss: 0.4790 - val_mse: 0.4790 - val_mae: 0.4883\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2280 - mse: 0.2280 - mae: 0.3621 - val_loss: 0.4812 - val_mse: 0.4812 - val_mae: 0.4884\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2242 - mse: 0.2242 - mae: 0.3587 - val_loss: 0.4803 - val_mse: 0.4803 - val_mae: 0.4880\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2240 - mse: 0.2240 - mae: 0.3571 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.4923\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.2208 - mse: 0.2208 - mae: 0.3561 - val_loss: 0.4697 - val_mse: 0.4697 - val_mae: 0.4921\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2211 - mse: 0.2211 - mae: 0.3564 - val_loss: 0.4815 - val_mse: 0.4815 - val_mae: 0.4989\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2132 - mse: 0.2132 - mae: 0.3501 - val_loss: 0.4764 - val_mse: 0.4764 - val_mae: 0.4848\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2082 - mse: 0.2082 - mae: 0.3442 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.4840\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2119 - mse: 0.2119 - mae: 0.3492 - val_loss: 0.4726 - val_mse: 0.4726 - val_mae: 0.4801\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.2095 - mse: 0.2095 - mae: 0.3455 - val_loss: 0.4670 - val_mse: 0.4670 - val_mae: 0.4830\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.2048 - mse: 0.2048 - mae: 0.3409 - val_loss: 0.4783 - val_mse: 0.4783 - val_mae: 0.4837\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2046 - mse: 0.2046 - mae: 0.3433 - val_loss: 0.4913 - val_mse: 0.4913 - val_mae: 0.5024\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2046 - mse: 0.2046 - mae: 0.3426 - val_loss: 0.4472 - val_mse: 0.4472 - val_mae: 0.4811\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1978 - mse: 0.1978 - mae: 0.3366 - val_loss: 0.4715 - val_mse: 0.4715 - val_mae: 0.4893\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.2018 - mse: 0.2018 - mae: 0.3412 - val_loss: 0.4595 - val_mse: 0.4595 - val_mae: 0.4838\n",
      "Epoch 61/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1945 - mse: 0.1945 - mae: 0.3308 - val_loss: 0.4693 - val_mse: 0.4693 - val_mae: 0.4873\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1944 - mse: 0.1944 - mae: 0.3344 - val_loss: 0.4579 - val_mse: 0.4579 - val_mae: 0.4805\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1930 - mse: 0.1930 - mae: 0.3305 - val_loss: 0.4500 - val_mse: 0.4500 - val_mae: 0.4793\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1871 - mse: 0.1871 - mae: 0.3294 - val_loss: 0.4492 - val_mse: 0.4492 - val_mae: 0.4770\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1864 - mse: 0.1864 - mae: 0.3258 - val_loss: 0.5077 - val_mse: 0.5077 - val_mae: 0.4786\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1870 - mse: 0.1870 - mae: 0.3284 - val_loss: 0.4525 - val_mse: 0.4525 - val_mae: 0.4802\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1826 - mse: 0.1826 - mae: 0.3240 - val_loss: 0.4465 - val_mse: 0.4465 - val_mae: 0.4779\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 29us/sample - loss: 0.1807 - mse: 0.1807 - mae: 0.3211 - val_loss: 0.4628 - val_mse: 0.4628 - val_mae: 0.4814\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1827 - mse: 0.1827 - mae: 0.3230 - val_loss: 0.4685 - val_mse: 0.4685 - val_mae: 0.4746\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1795 - mse: 0.1795 - mae: 0.3220 - val_loss: 0.4453 - val_mse: 0.4453 - val_mae: 0.4755\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1779 - mse: 0.1779 - mae: 0.3197 - val_loss: 0.4329 - val_mse: 0.4329 - val_mae: 0.4756\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1774 - mse: 0.1774 - mae: 0.3194 - val_loss: 0.4609 - val_mse: 0.4609 - val_mae: 0.4844\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1802 - mse: 0.1802 - mae: 0.3208 - val_loss: 0.4666 - val_mse: 0.4666 - val_mae: 0.4778\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1740 - mse: 0.1740 - mae: 0.3156 - val_loss: 0.4412 - val_mse: 0.4412 - val_mae: 0.4787\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1732 - mse: 0.1732 - mae: 0.3159 - val_loss: 0.4478 - val_mse: 0.4478 - val_mae: 0.4726\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1716 - mse: 0.1716 - mae: 0.3137 - val_loss: 0.4474 - val_mse: 0.4474 - val_mae: 0.4770\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1682 - mse: 0.1682 - mae: 0.3114 - val_loss: 0.4451 - val_mse: 0.4451 - val_mae: 0.4748\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1712 - mse: 0.1712 - mae: 0.3130 - val_loss: 0.4421 - val_mse: 0.4421 - val_mae: 0.4741\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1660 - mse: 0.1660 - mae: 0.3076 - val_loss: 0.4359 - val_mse: 0.4359 - val_mae: 0.4729\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1654 - mse: 0.1654 - mae: 0.3082 - val_loss: 0.4386 - val_mse: 0.4386 - val_mae: 0.4732\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1623 - mse: 0.1623 - mae: 0.3046 - val_loss: 0.4291 - val_mse: 0.4291 - val_mae: 0.4707\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1619 - mse: 0.1619 - mae: 0.3057 - val_loss: 0.4332 - val_mse: 0.4332 - val_mae: 0.4708\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1625 - mse: 0.1625 - mae: 0.3053 - val_loss: 0.4330 - val_mse: 0.4330 - val_mae: 0.4721\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 26us/sample - loss: 0.1585 - mse: 0.1585 - mae: 0.3013 - val_loss: 0.4317 - val_mse: 0.4317 - val_mae: 0.4715\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1621 - mse: 0.1621 - mae: 0.3051 - val_loss: 0.4363 - val_mse: 0.4363 - val_mae: 0.4741\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1558 - mse: 0.1558 - mae: 0.2994 - val_loss: 0.4299 - val_mse: 0.4299 - val_mae: 0.4679\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1534 - mse: 0.1534 - mae: 0.2979 - val_loss: 0.4296 - val_mse: 0.4296 - val_mae: 0.4696\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1580 - mse: 0.1580 - mae: 0.3019 - val_loss: 0.4451 - val_mse: 0.4451 - val_mae: 0.4787\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1644 - mse: 0.1644 - mae: 0.3088 - val_loss: 0.4362 - val_mse: 0.4362 - val_mae: 0.4705\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 0s 27us/sample - loss: 0.1506 - mse: 0.1506 - mae: 0.2946 - val_loss: 0.4576 - val_mse: 0.4576 - val_mae: 0.4773\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 28us/sample - loss: 0.1546 - mse: 0.1546 - mae: 0.2976 - val_loss: 0.4371 - val_mse: 0.4371 - val_mae: 0.4687\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 1s 89us/sample - loss: 2.0667 - mse: 2.0667 - mae: 1.0787 - val_loss: 1.3196 - val_mse: 1.3196 - val_mae: 0.8736\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 1.0333 - mse: 1.0333 - mae: 0.7718 - val_loss: 1.3043 - val_mse: 1.3043 - val_mae: 0.9329\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.8479 - mse: 0.8479 - mae: 0.6962 - val_loss: 1.2551 - val_mse: 1.2551 - val_mae: 0.9215\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.7441 - mse: 0.7441 - mae: 0.6517 - val_loss: 1.1297 - val_mse: 1.1297 - val_mae: 0.8729\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.6779 - mse: 0.6779 - mae: 0.6233 - val_loss: 0.9649 - val_mse: 0.9649 - val_mae: 0.8019\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.6289 - mse: 0.6289 - mae: 0.6024 - val_loss: 0.8511 - val_mse: 0.8511 - val_mae: 0.7454\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.5947 - mse: 0.5947 - mae: 0.5848 - val_loss: 0.7593 - val_mse: 0.7593 - val_mae: 0.6910\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.5594 - mse: 0.5594 - mae: 0.5664 - val_loss: 0.6988 - val_mse: 0.6988 - val_mae: 0.6522\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.5348 - mse: 0.5348 - mae: 0.5533 - val_loss: 0.6301 - val_mse: 0.6301 - val_mae: 0.6096\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.5072 - mse: 0.5072 - mae: 0.5400 - val_loss: 0.6265 - val_mse: 0.6265 - val_mae: 0.6062\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.4923 - mse: 0.4923 - mae: 0.5305 - val_loss: 0.6081 - val_mse: 0.6081 - val_mae: 0.5927\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.4835 - mse: 0.4835 - mae: 0.5275 - val_loss: 0.5950 - val_mse: 0.5950 - val_mae: 0.5796\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.4617 - mse: 0.4617 - mae: 0.5138 - val_loss: 0.5770 - val_mse: 0.5770 - val_mae: 0.5638\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.4465 - mse: 0.4465 - mae: 0.5061 - val_loss: 0.5564 - val_mse: 0.5564 - val_mae: 0.5460\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.4216 - mse: 0.4216 - mae: 0.4904 - val_loss: 0.5510 - val_mse: 0.5510 - val_mae: 0.5449\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.4136 - mse: 0.4136 - mae: 0.4863 - val_loss: 0.5482 - val_mse: 0.5482 - val_mae: 0.5425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.4084 - mse: 0.4084 - mae: 0.4850 - val_loss: 0.5569 - val_mse: 0.5569 - val_mae: 0.5443\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.3979 - mse: 0.3979 - mae: 0.4769 - val_loss: 0.5406 - val_mse: 0.5406 - val_mae: 0.5317\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.3883 - mse: 0.3883 - mae: 0.4722 - val_loss: 0.5218 - val_mse: 0.5218 - val_mae: 0.5209\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.3734 - mse: 0.3734 - mae: 0.4612 - val_loss: 0.5362 - val_mse: 0.5362 - val_mae: 0.5238\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.3691 - mse: 0.3691 - mae: 0.4591 - val_loss: 0.5272 - val_mse: 0.5272 - val_mae: 0.5205\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.3549 - mse: 0.3549 - mae: 0.4492 - val_loss: 0.5168 - val_mse: 0.5168 - val_mae: 0.5131\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.3531 - mse: 0.3531 - mae: 0.4483 - val_loss: 0.5159 - val_mse: 0.5159 - val_mae: 0.5138\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.3457 - mse: 0.3457 - mae: 0.4441 - val_loss: 0.5124 - val_mse: 0.5124 - val_mae: 0.5136\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 28us/sample - loss: 0.3379 - mse: 0.3379 - mae: 0.4401 - val_loss: 0.5112 - val_mse: 0.5112 - val_mae: 0.5109\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.3311 - mse: 0.3311 - mae: 0.4361 - val_loss: 0.5008 - val_mse: 0.5008 - val_mae: 0.5044\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.3263 - mse: 0.3263 - mae: 0.4309 - val_loss: 0.5088 - val_mse: 0.5088 - val_mae: 0.5112\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.3218 - mse: 0.3218 - mae: 0.4283 - val_loss: 0.5075 - val_mse: 0.5075 - val_mae: 0.5042\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.3132 - mse: 0.3132 - mae: 0.4235 - val_loss: 0.5005 - val_mse: 0.5005 - val_mae: 0.5062\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.3039 - mse: 0.3039 - mae: 0.4176 - val_loss: 0.5079 - val_mse: 0.5079 - val_mae: 0.5133\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.3039 - mse: 0.3039 - mae: 0.4164 - val_loss: 0.5013 - val_mse: 0.5013 - val_mae: 0.5056\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2993 - mse: 0.2993 - mae: 0.4151 - val_loss: 0.4791 - val_mse: 0.4791 - val_mae: 0.4934\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.2955 - mse: 0.2955 - mae: 0.4116 - val_loss: 0.4925 - val_mse: 0.4925 - val_mae: 0.4980\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.2887 - mse: 0.2887 - mae: 0.4083 - val_loss: 0.4872 - val_mse: 0.4872 - val_mae: 0.5003\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.2829 - mse: 0.2829 - mae: 0.4017 - val_loss: 0.4866 - val_mse: 0.4866 - val_mae: 0.4909\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2833 - mse: 0.2833 - mae: 0.4031 - val_loss: 0.4904 - val_mse: 0.4904 - val_mae: 0.4945\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 25us/sample - loss: 0.2784 - mse: 0.2784 - mae: 0.3992 - val_loss: 0.4804 - val_mse: 0.4804 - val_mae: 0.4883\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2733 - mse: 0.2733 - mae: 0.3974 - val_loss: 0.4815 - val_mse: 0.4815 - val_mae: 0.4891\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2677 - mse: 0.2677 - mae: 0.3921 - val_loss: 0.4794 - val_mse: 0.4794 - val_mae: 0.4883\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 0s 26us/sample - loss: 0.2635 - mse: 0.2635 - mae: 0.3893 - val_loss: 0.4808 - val_mse: 0.4808 - val_mae: 0.4846\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 0s 27us/sample - loss: 0.2591 - mse: 0.2591 - mae: 0.3849 - val_loss: 0.4909 - val_mse: 0.4909 - val_mae: 0.4952\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 0s 28us/sample - loss: 0.2589 - mse: 0.2589 - mae: 0.3843 - val_loss: 0.4900 - val_mse: 0.4900 - val_mae: 0.4974\n",
      "Avg. MAE: 0.421731\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 133.6654 - mse: 133.6654 - mae: 5.4943 - val_loss: 45319.3194 - val_mse: 45319.3203 - val_mae: 188.4836\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 3.4215 - mse: 3.4215 - mae: 1.2501 - val_loss: 43.4044 - val_mse: 43.4044 - val_mae: 4.4916\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 1.0480 - mse: 1.0480 - mae: 0.7742 - val_loss: 18.8106 - val_mse: 18.8106 - val_mae: 2.7620\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.8101 - mse: 0.8101 - mae: 0.6861 - val_loss: 2.1006 - val_mse: 2.1006 - val_mae: 1.1021\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.7303 - mse: 0.7303 - mae: 0.6484 - val_loss: 1.2767 - val_mse: 1.2767 - val_mae: 0.8537\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6952 - mse: 0.6952 - mae: 0.6326 - val_loss: 0.9999 - val_mse: 0.9999 - val_mae: 0.7644\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6607 - mse: 0.6607 - mae: 0.6135 - val_loss: 0.9183 - val_mse: 0.9183 - val_mae: 0.7282\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6510 - mse: 0.6510 - mae: 0.6081 - val_loss: 0.7985 - val_mse: 0.7985 - val_mae: 0.6859\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6487 - mse: 0.6487 - mae: 0.6064 - val_loss: 0.7823 - val_mse: 0.7823 - val_mae: 0.6907\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6414 - mse: 0.6414 - mae: 0.6072 - val_loss: 0.7330 - val_mse: 0.7330 - val_mae: 0.6689\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6191 - mse: 0.6191 - mae: 0.5945 - val_loss: 0.6782 - val_mse: 0.6782 - val_mae: 0.6313\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6040 - mse: 0.6040 - mae: 0.5847 - val_loss: 0.6866 - val_mse: 0.6866 - val_mae: 0.6088\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6169 - mse: 0.6169 - mae: 0.5911 - val_loss: 0.7498 - val_mse: 0.7498 - val_mae: 0.6915\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5786 - mse: 0.5786 - mae: 0.5755 - val_loss: 0.6043 - val_mse: 0.6043 - val_mae: 0.5971\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5350 - mse: 0.5350 - mae: 0.5531 - val_loss: 0.5817 - val_mse: 0.5817 - val_mae: 0.5780\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4938 - mse: 0.4938 - mae: 0.5241 - val_loss: 0.5688 - val_mse: 0.5688 - val_mae: 0.5735\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4959 - mse: 0.4959 - mae: 0.5304 - val_loss: 0.5634 - val_mse: 0.5634 - val_mae: 0.5580\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4817 - mse: 0.4817 - mae: 0.5149 - val_loss: 0.5972 - val_mse: 0.5972 - val_mae: 0.6023\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4774 - mse: 0.4774 - mae: 0.5216 - val_loss: 0.5347 - val_mse: 0.5347 - val_mae: 0.5510\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4690 - mse: 0.4690 - mae: 0.5171 - val_loss: 0.6052 - val_mse: 0.6052 - val_mae: 0.5739\n",
      "Epoch 21/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4397 - mse: 0.4397 - mae: 0.4993 - val_loss: 0.5862 - val_mse: 0.5862 - val_mae: 0.5563\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4030 - mse: 0.4030 - mae: 0.4750 - val_loss: 0.5154 - val_mse: 0.5154 - val_mae: 0.5362\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3852 - mse: 0.3852 - mae: 0.4644 - val_loss: 0.5354 - val_mse: 0.5354 - val_mae: 0.5356\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3669 - mse: 0.3669 - mae: 0.4564 - val_loss: 0.4957 - val_mse: 0.4957 - val_mae: 0.5294\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3577 - mse: 0.3577 - mae: 0.4472 - val_loss: 0.4675 - val_mse: 0.4675 - val_mae: 0.5108\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3350 - mse: 0.3350 - mae: 0.4329 - val_loss: 0.5321 - val_mse: 0.5321 - val_mae: 0.5347\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3242 - mse: 0.3242 - mae: 0.4256 - val_loss: 0.4936 - val_mse: 0.4936 - val_mae: 0.5191\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3626 - mse: 0.3626 - mae: 0.4548 - val_loss: 0.5051 - val_mse: 0.5051 - val_mae: 0.5338\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3318 - mse: 0.3318 - mae: 0.4342 - val_loss: 0.4575 - val_mse: 0.4575 - val_mae: 0.5039\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2983 - mse: 0.2983 - mae: 0.4124 - val_loss: 0.5282 - val_mse: 0.5282 - val_mae: 0.5325\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2848 - mse: 0.2848 - mae: 0.3992 - val_loss: 0.5378 - val_mse: 0.5378 - val_mae: 0.5462\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2808 - mse: 0.2808 - mae: 0.3969 - val_loss: 0.4373 - val_mse: 0.4373 - val_mae: 0.4844\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2758 - mse: 0.2758 - mae: 0.3944 - val_loss: 0.4932 - val_mse: 0.4932 - val_mae: 0.5175\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2470 - mse: 0.2470 - mae: 0.3717 - val_loss: 0.4939 - val_mse: 0.4939 - val_mae: 0.5239\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 12s 1ms/sample - loss: 0.2550 - mse: 0.2550 - mae: 0.3813 - val_loss: 0.4806 - val_mse: 0.4806 - val_mae: 0.5205\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2383 - mse: 0.2383 - mae: 0.3681 - val_loss: 0.4104 - val_mse: 0.4104 - val_mae: 0.4699\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2403 - mse: 0.2403 - mae: 0.3643 - val_loss: 0.4267 - val_mse: 0.4267 - val_mae: 0.4760\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2454 - mse: 0.2454 - mae: 0.3700 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.4919\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2604 - mse: 0.2604 - mae: 0.3805 - val_loss: 0.4588 - val_mse: 0.4588 - val_mae: 0.5123\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2107 - mse: 0.2107 - mae: 0.3467 - val_loss: 0.4055 - val_mse: 0.4055 - val_mae: 0.4586\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2220 - mse: 0.2220 - mae: 0.3548 - val_loss: 0.4053 - val_mse: 0.4053 - val_mae: 0.4679\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2061 - mse: 0.2061 - mae: 0.3442 - val_loss: 0.4096 - val_mse: 0.4096 - val_mae: 0.4633\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1799 - mse: 0.1799 - mae: 0.3172 - val_loss: 0.4530 - val_mse: 0.4530 - val_mae: 0.4905\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1778 - mse: 0.1778 - mae: 0.3130 - val_loss: 0.4624 - val_mse: 0.4624 - val_mae: 0.5067\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.2342 - mse: 0.2342 - mae: 0.3562 - val_loss: 0.4814 - val_mse: 0.4814 - val_mae: 0.5150\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2094 - mse: 0.2094 - mae: 0.3444 - val_loss: 0.4794 - val_mse: 0.4794 - val_mae: 0.5129\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.1842 - mse: 0.1842 - mae: 0.3215 - val_loss: 0.4785 - val_mse: 0.4785 - val_mae: 0.5140\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.1909 - mse: 0.1909 - mae: 0.3261 - val_loss: 0.4275 - val_mse: 0.4275 - val_mae: 0.4766\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2040 - mse: 0.2040 - mae: 0.3413 - val_loss: 0.4040 - val_mse: 0.4040 - val_mae: 0.4662\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1959 - mse: 0.1959 - mae: 0.3249 - val_loss: 0.4399 - val_mse: 0.4399 - val_mae: 0.4806\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2502 - mse: 0.2502 - mae: 0.3453 - val_loss: 0.5773 - val_mse: 0.5773 - val_mae: 0.5734\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2661 - mse: 0.2661 - mae: 0.3720 - val_loss: 0.4618 - val_mse: 0.4618 - val_mae: 0.4938\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.1842 - mse: 0.1842 - mae: 0.3230 - val_loss: 0.4354 - val_mse: 0.4354 - val_mae: 0.4897\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1948 - mse: 0.1948 - mae: 0.3275 - val_loss: 0.5118 - val_mse: 0.5118 - val_mae: 0.5351\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1722 - mse: 0.1722 - mae: 0.3135 - val_loss: 0.4793 - val_mse: 0.4793 - val_mae: 0.5068\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1521 - mse: 0.1521 - mae: 0.2921 - val_loss: 0.5230 - val_mse: 0.5230 - val_mae: 0.5376\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1724 - mse: 0.1724 - mae: 0.3097 - val_loss: 0.4034 - val_mse: 0.4034 - val_mae: 0.4585\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1800 - mse: 0.1800 - mae: 0.3211 - val_loss: 0.4978 - val_mse: 0.4978 - val_mae: 0.5344\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1383 - mse: 0.1383 - mae: 0.2795 - val_loss: 0.4252 - val_mse: 0.4252 - val_mae: 0.4764\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1416 - mse: 0.1416 - mae: 0.2810 - val_loss: 0.4510 - val_mse: 0.4510 - val_mae: 0.4983\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.1460 - mse: 0.1460 - mae: 0.2842 - val_loss: 0.4044 - val_mse: 0.4044 - val_mae: 0.4511\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.1453 - mse: 0.1453 - mae: 0.2803 - val_loss: 0.4665 - val_mse: 0.4665 - val_mae: 0.5054\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.1560 - mse: 0.1560 - mae: 0.2889 - val_loss: 0.4369 - val_mse: 0.4369 - val_mae: 0.4941\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.1385 - mse: 0.1385 - mae: 0.2763 - val_loss: 0.4867 - val_mse: 0.4867 - val_mae: 0.5259\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1434 - mse: 0.1434 - mae: 0.2883 - val_loss: 0.5386 - val_mse: 0.5386 - val_mae: 0.5240\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1262 - mse: 0.1262 - mae: 0.2594 - val_loss: 0.4012 - val_mse: 0.4012 - val_mae: 0.4670\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 16s 1ms/sample - loss: 0.1498 - mse: 0.1498 - mae: 0.2823 - val_loss: 0.4393 - val_mse: 0.4393 - val_mae: 0.4814\n",
      "Epoch 68/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.1274 - mse: 0.1274 - mae: 0.2636 - val_loss: 0.4188 - val_mse: 0.4188 - val_mae: 0.4632\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1481 - mse: 0.1481 - mae: 0.2885 - val_loss: 0.4655 - val_mse: 0.4655 - val_mae: 0.5051\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1163 - mse: 0.1163 - mae: 0.2544 - val_loss: 0.4190 - val_mse: 0.4190 - val_mae: 0.4634\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.1642 - mse: 0.1642 - mae: 0.2995 - val_loss: 0.4861 - val_mse: 0.4861 - val_mae: 0.5214\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.1213 - mse: 0.1213 - mae: 0.2523 - val_loss: 0.4092 - val_mse: 0.4092 - val_mae: 0.4507\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.1311 - mse: 0.1311 - mae: 0.2756 - val_loss: 0.4222 - val_mse: 0.4222 - val_mae: 0.4642\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 18s 2ms/sample - loss: 0.1180 - mse: 0.1180 - mae: 0.2603 - val_loss: 0.4234 - val_mse: 0.4234 - val_mae: 0.4719\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.1117 - mse: 0.1117 - mae: 0.2505 - val_loss: 0.4630 - val_mse: 0.4630 - val_mae: 0.5047\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.1343 - mse: 0.1343 - mae: 0.2690 - val_loss: 0.3881 - val_mse: 0.3881 - val_mae: 0.4490\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 19s 2ms/sample - loss: 0.1763 - mse: 0.1763 - mae: 0.2927 - val_loss: 0.4821 - val_mse: 0.4821 - val_mae: 0.5061\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.1670 - mse: 0.1670 - mae: 0.2989 - val_loss: 0.4581 - val_mse: 0.4581 - val_mae: 0.5019\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 0.1295 - mse: 0.1295 - mae: 0.2639 - val_loss: 0.4343 - val_mse: 0.4343 - val_mae: 0.4819\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 16s 1ms/sample - loss: 0.1305 - mse: 0.1305 - mae: 0.2673 - val_loss: 0.4839 - val_mse: 0.4839 - val_mae: 0.4869\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.1347 - mse: 0.1347 - mae: 0.2668 - val_loss: 0.4074 - val_mse: 0.4074 - val_mae: 0.4561\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.1255 - mse: 0.1255 - mae: 0.2547 - val_loss: 0.4023 - val_mse: 0.4023 - val_mae: 0.4582\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.0983 - mse: 0.0983 - mae: 0.2324 - val_loss: 0.5053 - val_mse: 0.5053 - val_mae: 0.5358\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.1205 - mse: 0.1205 - mae: 0.2488 - val_loss: 0.5116 - val_mse: 0.5116 - val_mae: 0.5393\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 16s 1ms/sample - loss: 0.0974 - mse: 0.0974 - mae: 0.2296 - val_loss: 0.3979 - val_mse: 0.3979 - val_mae: 0.4452\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.1020 - mse: 0.1020 - mae: 0.2234 - val_loss: 0.4299 - val_mse: 0.4299 - val_mae: 0.4628\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 17s 2ms/sample - loss: 109.8257 - mse: 109.8257 - mae: 5.4206 - val_loss: 157363.7139 - val_mse: 157363.7031 - val_mae: 317.2125\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 2.5059 - mse: 2.5059 - mae: 1.2023 - val_loss: 642.2017 - val_mse: 642.2017 - val_mae: 18.7572\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 1.0235 - mse: 1.0235 - mae: 0.7643 - val_loss: 64.7561 - val_mse: 64.7561 - val_mae: 5.1799\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.8316 - mse: 0.8316 - mae: 0.6924 - val_loss: 2.2223 - val_mse: 2.2223 - val_mae: 1.0922\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.7722 - mse: 0.7722 - mae: 0.6645 - val_loss: 2.2912 - val_mse: 2.2912 - val_mae: 1.0714\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.7247 - mse: 0.7247 - mae: 0.6456 - val_loss: 1.9672 - val_mse: 1.9672 - val_mae: 0.9846\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.6964 - mse: 0.6964 - mae: 0.6311 - val_loss: 1.2129 - val_mse: 1.2129 - val_mae: 0.8100\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.7069 - mse: 0.7069 - mae: 0.6321 - val_loss: 1.0543 - val_mse: 1.0543 - val_mae: 0.7708\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 16s 1ms/sample - loss: 0.6942 - mse: 0.6942 - mae: 0.6302 - val_loss: 1.0438 - val_mse: 1.0438 - val_mae: 0.7394\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.6595 - mse: 0.6595 - mae: 0.6129 - val_loss: 0.8268 - val_mse: 0.8268 - val_mae: 0.7047\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.6392 - mse: 0.6392 - mae: 0.5982 - val_loss: 0.7811 - val_mse: 0.7811 - val_mae: 0.6683\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 18s 2ms/sample - loss: 0.6239 - mse: 0.6239 - mae: 0.5931 - val_loss: 0.7310 - val_mse: 0.7310 - val_mae: 0.6587\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 16s 2ms/sample - loss: 0.6007 - mse: 0.6007 - mae: 0.5842 - val_loss: 0.8491 - val_mse: 0.8491 - val_mae: 0.6279\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.6034 - mse: 0.6034 - mae: 0.5851 - val_loss: 0.7364 - val_mse: 0.7364 - val_mae: 0.6131\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.5687 - mse: 0.5687 - mae: 0.5630 - val_loss: 0.6431 - val_mse: 0.6431 - val_mae: 0.6038\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.5629 - mse: 0.5629 - mae: 0.5607 - val_loss: 0.6332 - val_mse: 0.6332 - val_mae: 0.5864\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.5431 - mse: 0.5431 - mae: 0.5507 - val_loss: 0.6951 - val_mse: 0.6951 - val_mae: 0.6116\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.5442 - mse: 0.5442 - mae: 0.5511 - val_loss: 0.6364 - val_mse: 0.6364 - val_mae: 0.6178\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.5327 - mse: 0.5327 - mae: 0.5448 - val_loss: 0.6573 - val_mse: 0.6573 - val_mae: 0.5929\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.5300 - mse: 0.5300 - mae: 0.5467 - val_loss: 0.5942 - val_mse: 0.5942 - val_mae: 0.5597\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.5352 - mse: 0.5352 - mae: 0.5468 - val_loss: 0.5917 - val_mse: 0.5917 - val_mae: 0.5810\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.5244 - mse: 0.5244 - mae: 0.5415 - val_loss: 0.6014 - val_mse: 0.6014 - val_mae: 0.5621\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.4873 - mse: 0.4873 - mae: 0.5236 - val_loss: 0.6070 - val_mse: 0.6070 - val_mae: 0.5682\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.4801 - mse: 0.4801 - mae: 0.5170 - val_loss: 0.5776 - val_mse: 0.5776 - val_mae: 0.5542\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.4484 - mse: 0.4484 - mae: 0.5000 - val_loss: 0.6054 - val_mse: 0.6054 - val_mae: 0.5567\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.4344 - mse: 0.4344 - mae: 0.4901 - val_loss: 0.5428 - val_mse: 0.5428 - val_mae: 0.5378\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.4274 - mse: 0.4274 - mae: 0.4894 - val_loss: 0.5985 - val_mse: 0.5985 - val_mae: 0.5493\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.3952 - mse: 0.3952 - mae: 0.4687 - val_loss: 0.5615 - val_mse: 0.5615 - val_mae: 0.5236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.3923 - mse: 0.3923 - mae: 0.4691 - val_loss: 0.6084 - val_mse: 0.6084 - val_mae: 0.5442\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3804 - mse: 0.3804 - mae: 0.4593 - val_loss: 0.5772 - val_mse: 0.5772 - val_mae: 0.5444\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.3721 - mse: 0.3721 - mae: 0.4584 - val_loss: 0.5245 - val_mse: 0.5245 - val_mae: 0.5193\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3462 - mse: 0.3462 - mae: 0.4433 - val_loss: 0.5486 - val_mse: 0.5486 - val_mae: 0.5308\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3416 - mse: 0.3416 - mae: 0.4364 - val_loss: 0.6853 - val_mse: 0.6853 - val_mae: 0.5972\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.4067 - mse: 0.4067 - mae: 0.4778 - val_loss: 0.6047 - val_mse: 0.6047 - val_mae: 0.5903\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.3732 - mse: 0.3732 - mae: 0.4474 - val_loss: 0.6827 - val_mse: 0.6827 - val_mae: 0.5405\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.3517 - mse: 0.3517 - mae: 0.4395 - val_loss: 0.7318 - val_mse: 0.7318 - val_mae: 0.5666\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3536 - mse: 0.3536 - mae: 0.4461 - val_loss: 0.4682 - val_mse: 0.4682 - val_mae: 0.5039\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3151 - mse: 0.3151 - mae: 0.4231 - val_loss: 0.5054 - val_mse: 0.5054 - val_mae: 0.4962\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3056 - mse: 0.3056 - mae: 0.4143 - val_loss: 0.7271 - val_mse: 0.7271 - val_mae: 0.5812\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 15s 1ms/sample - loss: 0.3300 - mse: 0.3300 - mae: 0.4292 - val_loss: 0.5924 - val_mse: 0.5924 - val_mae: 0.5718\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3092 - mse: 0.3092 - mae: 0.4143 - val_loss: 0.5366 - val_mse: 0.5366 - val_mae: 0.5155\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2889 - mse: 0.2889 - mae: 0.4049 - val_loss: 0.5163 - val_mse: 0.5163 - val_mae: 0.5120\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2780 - mse: 0.2780 - mae: 0.3921 - val_loss: 0.4376 - val_mse: 0.4376 - val_mae: 0.4780\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2662 - mse: 0.2662 - mae: 0.3865 - val_loss: 0.5122 - val_mse: 0.5122 - val_mae: 0.4955\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2810 - mse: 0.2810 - mae: 0.3961 - val_loss: 0.5488 - val_mse: 0.5488 - val_mae: 0.5396\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2395 - mse: 0.2395 - mae: 0.3631 - val_loss: 0.4588 - val_mse: 0.4588 - val_mae: 0.4840\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2197 - mse: 0.2197 - mae: 0.3494 - val_loss: 0.4487 - val_mse: 0.4487 - val_mae: 0.4733\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3549 - mse: 0.3549 - mae: 0.4272 - val_loss: 0.6013 - val_mse: 0.6013 - val_mae: 0.5508\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2213 - mse: 0.2213 - mae: 0.3551 - val_loss: 0.4293 - val_mse: 0.4293 - val_mae: 0.4688\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.2183 - mse: 0.2183 - mae: 0.3548 - val_loss: 0.4917 - val_mse: 0.4917 - val_mae: 0.5026\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.2145 - mse: 0.2145 - mae: 0.3514 - val_loss: 0.4581 - val_mse: 0.4581 - val_mae: 0.4877\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 0.2250 - mse: 0.2250 - mae: 0.3533 - val_loss: 0.5659 - val_mse: 0.5659 - val_mae: 0.5350\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2458 - mse: 0.2458 - mae: 0.3618 - val_loss: 0.4369 - val_mse: 0.4369 - val_mae: 0.4742\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2303 - mse: 0.2303 - mae: 0.3538 - val_loss: 1.3893 - val_mse: 1.3893 - val_mae: 0.6798\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3238 - mse: 0.3238 - mae: 0.4039 - val_loss: 0.5029 - val_mse: 0.5029 - val_mae: 0.4835\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2106 - mse: 0.2106 - mae: 0.3383 - val_loss: 0.5295 - val_mse: 0.5295 - val_mae: 0.5220\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2068 - mse: 0.2068 - mae: 0.3394 - val_loss: 0.5337 - val_mse: 0.5337 - val_mae: 0.4978\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1972 - mse: 0.1972 - mae: 0.3326 - val_loss: 0.6129 - val_mse: 0.6129 - val_mae: 0.5083\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1810 - mse: 0.1810 - mae: 0.3171 - val_loss: 0.5360 - val_mse: 0.5360 - val_mae: 0.4911\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 103.3267 - mse: 103.3267 - mae: 5.4019 - val_loss: 315595.9141 - val_mse: 315595.9062 - val_mae: 496.1767\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 2.1751 - mse: 2.1751 - mae: 1.0504 - val_loss: 705.5208 - val_mse: 705.5208 - val_mae: 23.2395\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.9283 - mse: 0.9283 - mae: 0.7231 - val_loss: 10.2098 - val_mse: 10.2098 - val_mae: 2.3907\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.7926 - mse: 0.7926 - mae: 0.6678 - val_loss: 3.0942 - val_mse: 3.0942 - val_mae: 1.3325\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.7376 - mse: 0.7376 - mae: 0.6463 - val_loss: 1.4372 - val_mse: 1.4372 - val_mae: 0.9249\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.7213 - mse: 0.7213 - mae: 0.6398 - val_loss: 1.1188 - val_mse: 1.1188 - val_mae: 0.7864\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.7040 - mse: 0.7040 - mae: 0.6336 - val_loss: 0.8800 - val_mse: 0.8800 - val_mae: 0.7106\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6822 - mse: 0.6822 - mae: 0.6181 - val_loss: 0.7992 - val_mse: 0.7992 - val_mae: 0.7039\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6665 - mse: 0.6665 - mae: 0.6130 - val_loss: 0.8257 - val_mse: 0.8257 - val_mae: 0.6774\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6650 - mse: 0.6650 - mae: 0.6083 - val_loss: 0.7897 - val_mse: 0.7897 - val_mae: 0.6968\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6612 - mse: 0.6612 - mae: 0.6103 - val_loss: 0.6497 - val_mse: 0.6497 - val_mae: 0.6184\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6185 - mse: 0.6185 - mae: 0.5924 - val_loss: 0.6379 - val_mse: 0.6379 - val_mae: 0.6050\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6045 - mse: 0.6045 - mae: 0.5806 - val_loss: 0.6475 - val_mse: 0.6475 - val_mae: 0.6285\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5970 - mse: 0.5970 - mae: 0.5778 - val_loss: 0.6891 - val_mse: 0.6891 - val_mae: 0.6243\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5744 - mse: 0.5744 - mae: 0.5689 - val_loss: 0.6938 - val_mse: 0.6938 - val_mae: 0.6069\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6055 - mse: 0.6055 - mae: 0.5846 - val_loss: 0.6295 - val_mse: 0.6295 - val_mae: 0.5836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5666 - mse: 0.5666 - mae: 0.5613 - val_loss: 0.6596 - val_mse: 0.6596 - val_mae: 0.6074\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5505 - mse: 0.5505 - mae: 0.5505 - val_loss: 0.5560 - val_mse: 0.5560 - val_mae: 0.5586\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5280 - mse: 0.5280 - mae: 0.5425 - val_loss: 0.5857 - val_mse: 0.5857 - val_mae: 0.5732\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5017 - mse: 0.5017 - mae: 0.5293 - val_loss: 0.5511 - val_mse: 0.5511 - val_mae: 0.5421\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4831 - mse: 0.4831 - mae: 0.5190 - val_loss: 0.6248 - val_mse: 0.6248 - val_mae: 0.5751\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4511 - mse: 0.4511 - mae: 0.5023 - val_loss: 0.5630 - val_mse: 0.5630 - val_mae: 0.5546\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4512 - mse: 0.4512 - mae: 0.5026 - val_loss: 0.5388 - val_mse: 0.5388 - val_mae: 0.5401\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4270 - mse: 0.4270 - mae: 0.4875 - val_loss: 0.6345 - val_mse: 0.6345 - val_mae: 0.5810\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4225 - mse: 0.4225 - mae: 0.4854 - val_loss: 0.5669 - val_mse: 0.5669 - val_mae: 0.5448\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3960 - mse: 0.3960 - mae: 0.4673 - val_loss: 0.5735 - val_mse: 0.5735 - val_mae: 0.5530\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3989 - mse: 0.3989 - mae: 0.4761 - val_loss: 0.7260 - val_mse: 0.7260 - val_mae: 0.6308\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3971 - mse: 0.3971 - mae: 0.4741 - val_loss: 0.6826 - val_mse: 0.6826 - val_mae: 0.6112\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3427 - mse: 0.3427 - mae: 0.4385 - val_loss: 0.4795 - val_mse: 0.4795 - val_mae: 0.5073\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3488 - mse: 0.3488 - mae: 0.4398 - val_loss: 0.5753 - val_mse: 0.5753 - val_mae: 0.5547\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 12s 1ms/sample - loss: 0.3714 - mse: 0.3714 - mae: 0.4502 - val_loss: 0.7276 - val_mse: 0.7276 - val_mae: 0.6432\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3294 - mse: 0.3294 - mae: 0.4264 - val_loss: 0.6430 - val_mse: 0.6430 - val_mae: 0.5867\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 12s 1ms/sample - loss: 0.3278 - mse: 0.3278 - mae: 0.4298 - val_loss: 0.5051 - val_mse: 0.5051 - val_mae: 0.5174\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2956 - mse: 0.2956 - mae: 0.4091 - val_loss: 0.5326 - val_mse: 0.5326 - val_mae: 0.5192\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2864 - mse: 0.2864 - mae: 0.4013 - val_loss: 0.5154 - val_mse: 0.5154 - val_mae: 0.5210\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2851 - mse: 0.2851 - mae: 0.3985 - val_loss: 0.6299 - val_mse: 0.6299 - val_mae: 0.5668\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2839 - mse: 0.2839 - mae: 0.4015 - val_loss: 0.4901 - val_mse: 0.4901 - val_mae: 0.4988\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2726 - mse: 0.2726 - mae: 0.3909 - val_loss: 0.5480 - val_mse: 0.5480 - val_mae: 0.5414\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2763 - mse: 0.2763 - mae: 0.3989 - val_loss: 0.5547 - val_mse: 0.5547 - val_mae: 0.5442\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 14s 1ms/sample - loss: 123.5735 - mse: 123.5735 - mae: 5.3325 - val_loss: 9673.5384 - val_mse: 9673.5391 - val_mae: 47.4504\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 3.6821 - mse: 3.6821 - mae: 1.3111 - val_loss: 264.5563 - val_mse: 264.5564 - val_mae: 12.0538\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 1.2893 - mse: 1.2893 - mae: 0.8422 - val_loss: 26.8077 - val_mse: 26.8077 - val_mae: 4.4997\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.9204 - mse: 0.9204 - mae: 0.7223 - val_loss: 8.2182 - val_mse: 8.2182 - val_mae: 2.5704\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.8414 - mse: 0.8414 - mae: 0.6914 - val_loss: 6.7492 - val_mse: 6.7492 - val_mae: 2.1985\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.7706 - mse: 0.7706 - mae: 0.6631 - val_loss: 2.6819 - val_mse: 2.6819 - val_mae: 1.4508\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.7685 - mse: 0.7685 - mae: 0.6577 - val_loss: 2.4905 - val_mse: 2.4905 - val_mae: 1.3914\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.7376 - mse: 0.7376 - mae: 0.6426 - val_loss: 2.1813 - val_mse: 2.1813 - val_mae: 1.2691\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.7592 - mse: 0.7592 - mae: 0.6523 - val_loss: 1.0814 - val_mse: 1.0814 - val_mae: 0.8459\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.7126 - mse: 0.7126 - mae: 0.6311 - val_loss: 1.2918 - val_mse: 1.2918 - val_mae: 0.9535\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6870 - mse: 0.6870 - mae: 0.6196 - val_loss: 1.0585 - val_mse: 1.0585 - val_mae: 0.8535\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6821 - mse: 0.6821 - mae: 0.6193 - val_loss: 0.8262 - val_mse: 0.8262 - val_mae: 0.7424\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6702 - mse: 0.6702 - mae: 0.6080 - val_loss: 0.7836 - val_mse: 0.7836 - val_mae: 0.6999\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6353 - mse: 0.6353 - mae: 0.5959 - val_loss: 0.8257 - val_mse: 0.8257 - val_mae: 0.7431\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6001 - mse: 0.6001 - mae: 0.5780 - val_loss: 0.6648 - val_mse: 0.6648 - val_mae: 0.6310\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5992 - mse: 0.5992 - mae: 0.5751 - val_loss: 0.6653 - val_mse: 0.6653 - val_mae: 0.6183\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6028 - mse: 0.6028 - mae: 0.5768 - val_loss: 0.6668 - val_mse: 0.6668 - val_mae: 0.6310\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5947 - mse: 0.5947 - mae: 0.5723 - val_loss: 0.6534 - val_mse: 0.6534 - val_mae: 0.6116\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5659 - mse: 0.5659 - mae: 0.5567 - val_loss: 0.6316 - val_mse: 0.6316 - val_mae: 0.5849\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.6129 - mse: 0.6129 - mae: 0.5725 - val_loss: 0.7624 - val_mse: 0.7624 - val_mae: 0.6295\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5674 - mse: 0.5674 - mae: 0.5534 - val_loss: 0.5902 - val_mse: 0.5902 - val_mae: 0.5548\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5340 - mse: 0.5340 - mae: 0.5387 - val_loss: 0.6304 - val_mse: 0.6304 - val_mae: 0.5714\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5014 - mse: 0.5014 - mae: 0.5264 - val_loss: 0.6539 - val_mse: 0.6539 - val_mae: 0.5848\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.5049 - mse: 0.5049 - mae: 0.5290 - val_loss: 0.5533 - val_mse: 0.5533 - val_mae: 0.5401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4516 - mse: 0.4516 - mae: 0.4950 - val_loss: 0.6059 - val_mse: 0.6059 - val_mae: 0.5596\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4205 - mse: 0.4205 - mae: 0.4823 - val_loss: 0.5413 - val_mse: 0.5413 - val_mae: 0.5261\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4228 - mse: 0.4228 - mae: 0.4817 - val_loss: 0.5104 - val_mse: 0.5104 - val_mae: 0.5188\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4084 - mse: 0.4084 - mae: 0.4697 - val_loss: 0.4673 - val_mse: 0.4673 - val_mae: 0.5010\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4128 - mse: 0.4128 - mae: 0.4780 - val_loss: 0.5182 - val_mse: 0.5182 - val_mae: 0.5180\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3867 - mse: 0.3867 - mae: 0.4597 - val_loss: 0.4698 - val_mse: 0.4698 - val_mae: 0.4996\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4312 - mse: 0.4312 - mae: 0.4847 - val_loss: 0.5440 - val_mse: 0.5440 - val_mae: 0.5387\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4495 - mse: 0.4495 - mae: 0.4855 - val_loss: 0.5091 - val_mse: 0.5091 - val_mae: 0.5248\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.4529 - mse: 0.4529 - mae: 0.4973 - val_loss: 0.5703 - val_mse: 0.5703 - val_mae: 0.5634\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3915 - mse: 0.3915 - mae: 0.4706 - val_loss: 0.5350 - val_mse: 0.5350 - val_mae: 0.5429\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3783 - mse: 0.3783 - mae: 0.4604 - val_loss: 0.4522 - val_mse: 0.4522 - val_mae: 0.4858\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3299 - mse: 0.3299 - mae: 0.4275 - val_loss: 0.4405 - val_mse: 0.4405 - val_mae: 0.4770\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2866 - mse: 0.2866 - mae: 0.3965 - val_loss: 0.4294 - val_mse: 0.4294 - val_mae: 0.4850\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2985 - mse: 0.2985 - mae: 0.4092 - val_loss: 0.4237 - val_mse: 0.4237 - val_mae: 0.4746\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3096 - mse: 0.3096 - mae: 0.4164 - val_loss: 0.4095 - val_mse: 0.4095 - val_mae: 0.4689\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2842 - mse: 0.2842 - mae: 0.3955 - val_loss: 0.3948 - val_mse: 0.3948 - val_mae: 0.4580\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2521 - mse: 0.2521 - mae: 0.3746 - val_loss: 0.4886 - val_mse: 0.4886 - val_mae: 0.5147\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3255 - mse: 0.3255 - mae: 0.4150 - val_loss: 0.4767 - val_mse: 0.4767 - val_mae: 0.5073\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2625 - mse: 0.2625 - mae: 0.3768 - val_loss: 0.4636 - val_mse: 0.4636 - val_mae: 0.4967\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2414 - mse: 0.2414 - mae: 0.3685 - val_loss: 0.4595 - val_mse: 0.4595 - val_mae: 0.5017\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2915 - mse: 0.2915 - mae: 0.3957 - val_loss: 0.4345 - val_mse: 0.4345 - val_mae: 0.4774\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2512 - mse: 0.2512 - mae: 0.3694 - val_loss: 0.4575 - val_mse: 0.4575 - val_mae: 0.4976\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2535 - mse: 0.2535 - mae: 0.3778 - val_loss: 0.5291 - val_mse: 0.5291 - val_mae: 0.5422\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2793 - mse: 0.2793 - mae: 0.3884 - val_loss: 0.3900 - val_mse: 0.3900 - val_mae: 0.4538\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2464 - mse: 0.2464 - mae: 0.3690 - val_loss: 0.4797 - val_mse: 0.4797 - val_mae: 0.5070\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.3510 - mse: 0.3510 - mae: 0.4198 - val_loss: 0.4056 - val_mse: 0.4056 - val_mae: 0.4668\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2243 - mse: 0.2243 - mae: 0.3579 - val_loss: 0.4016 - val_mse: 0.4016 - val_mae: 0.4631\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2050 - mse: 0.2050 - mae: 0.3439 - val_loss: 0.3831 - val_mse: 0.3831 - val_mae: 0.4478\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2020 - mse: 0.2020 - mae: 0.3309 - val_loss: 0.4132 - val_mse: 0.4132 - val_mae: 0.4712\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2017 - mse: 0.2017 - mae: 0.3415 - val_loss: 0.4585 - val_mse: 0.4585 - val_mae: 0.4915\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2379 - mse: 0.2379 - mae: 0.3530 - val_loss: 0.4623 - val_mse: 0.4623 - val_mae: 0.5003\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2275 - mse: 0.2275 - mae: 0.3460 - val_loss: 0.3871 - val_mse: 0.3871 - val_mae: 0.4465\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1858 - mse: 0.1858 - mae: 0.3185 - val_loss: 0.4136 - val_mse: 0.4136 - val_mae: 0.4707\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2325 - mse: 0.2325 - mae: 0.3587 - val_loss: 0.4202 - val_mse: 0.4202 - val_mae: 0.4696\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.2346 - mse: 0.2346 - mae: 0.3459 - val_loss: 0.3809 - val_mse: 0.3809 - val_mae: 0.4462\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1869 - mse: 0.1869 - mae: 0.3213 - val_loss: 0.4742 - val_mse: 0.4742 - val_mae: 0.5051\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1742 - mse: 0.1742 - mae: 0.3118 - val_loss: 0.4188 - val_mse: 0.4188 - val_mae: 0.4761\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1848 - mse: 0.1848 - mae: 0.3202 - val_loss: 0.3959 - val_mse: 0.3959 - val_mae: 0.4514\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1905 - mse: 0.1905 - mae: 0.3220 - val_loss: 0.4253 - val_mse: 0.4253 - val_mae: 0.4732\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1895 - mse: 0.1895 - mae: 0.3104 - val_loss: 0.4772 - val_mse: 0.4772 - val_mae: 0.4975\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1773 - mse: 0.1773 - mae: 0.3034 - val_loss: 0.4006 - val_mse: 0.4006 - val_mae: 0.4540\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1761 - mse: 0.1761 - mae: 0.3012 - val_loss: 0.4527 - val_mse: 0.4527 - val_mae: 0.4870\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1997 - mse: 0.1997 - mae: 0.3205 - val_loss: 0.4840 - val_mse: 0.4840 - val_mae: 0.5058\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1591 - mse: 0.1591 - mae: 0.2888 - val_loss: 0.4903 - val_mse: 0.4903 - val_mae: 0.4993\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 13s 1ms/sample - loss: 0.1587 - mse: 0.1587 - mae: 0.2953 - val_loss: 0.6455 - val_mse: 0.6455 - val_mae: 0.5623\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 14s 1ms/sample - loss: 130.5525 - mse: 130.5525 - mae: 5.4197 - val_loss: 102762.3561 - val_mse: 102762.3594 - val_mae: 190.5577\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 4.6252 - mse: 4.6252 - mae: 1.3558 - val_loss: 1944.3555 - val_mse: 1944.3556 - val_mae: 30.2674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 1.7017 - mse: 1.7017 - mae: 0.9075 - val_loss: 253.5512 - val_mse: 253.5512 - val_mae: 6.4225\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 1.3519 - mse: 1.3519 - mae: 0.8252 - val_loss: 23.7652 - val_mse: 23.7652 - val_mae: 3.0275\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 1.0736 - mse: 1.0736 - mae: 0.7319 - val_loss: 11.8609 - val_mse: 11.8609 - val_mae: 1.9497\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.9005 - mse: 0.9005 - mae: 0.6922 - val_loss: 2.9546 - val_mse: 2.9546 - val_mae: 1.4199\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.8147 - mse: 0.8147 - mae: 0.6688 - val_loss: 2.6801 - val_mse: 2.6801 - val_mae: 0.9831\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.9460 - mse: 0.9460 - mae: 0.6939 - val_loss: 4.6280 - val_mse: 4.6280 - val_mae: 1.0114\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.9976 - mse: 0.9976 - mae: 0.7127 - val_loss: 1.7199 - val_mse: 1.7199 - val_mae: 0.8883\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.9314 - mse: 0.9314 - mae: 0.7082 - val_loss: 0.7644 - val_mse: 0.7644 - val_mae: 0.6502\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.7482 - mse: 0.7482 - mae: 0.6347 - val_loss: 0.9765 - val_mse: 0.9765 - val_mae: 0.6484\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.7723 - mse: 0.7723 - mae: 0.6329 - val_loss: 0.8001 - val_mse: 0.8001 - val_mae: 0.6472\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.8292 - mse: 0.8292 - mae: 0.6593 - val_loss: 0.7242 - val_mse: 0.7242 - val_mae: 0.6458\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.7063 - mse: 0.7063 - mae: 0.6215 - val_loss: 0.7044 - val_mse: 0.7044 - val_mae: 0.6066\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.6740 - mse: 0.6740 - mae: 0.6004 - val_loss: 0.7037 - val_mse: 0.7037 - val_mae: 0.6202\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.6701 - mse: 0.6701 - mae: 0.6003 - val_loss: 1.4021 - val_mse: 1.4021 - val_mae: 0.6376\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.6340 - mse: 0.6340 - mae: 0.5878 - val_loss: 0.5982 - val_mse: 0.5982 - val_mae: 0.5731\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.5767 - mse: 0.5767 - mae: 0.5664 - val_loss: 0.6812 - val_mse: 0.6812 - val_mae: 0.5744\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.5629 - mse: 0.5629 - mae: 0.5522 - val_loss: 0.7790 - val_mse: 0.7790 - val_mae: 0.5902\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.5602 - mse: 0.5602 - mae: 0.5547 - val_loss: 0.5764 - val_mse: 0.5764 - val_mae: 0.5577\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.5652 - mse: 0.5652 - mae: 0.5501 - val_loss: 0.8925 - val_mse: 0.8925 - val_mae: 0.5800\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.5433 - mse: 0.5433 - mae: 0.5479 - val_loss: 0.7233 - val_mse: 0.7233 - val_mae: 0.5937\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.4881 - mse: 0.4881 - mae: 0.5184 - val_loss: 0.5603 - val_mse: 0.5603 - val_mae: 0.5412\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.4681 - mse: 0.4681 - mae: 0.5010 - val_loss: 0.5912 - val_mse: 0.5912 - val_mae: 0.5378\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.4689 - mse: 0.4689 - mae: 0.4973 - val_loss: 0.5268 - val_mse: 0.5268 - val_mae: 0.5225\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.4334 - mse: 0.4334 - mae: 0.4864 - val_loss: 0.5664 - val_mse: 0.5664 - val_mae: 0.5464\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.4517 - mse: 0.4517 - mae: 0.4955 - val_loss: 0.8042 - val_mse: 0.8042 - val_mae: 0.5448\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.4195 - mse: 0.4195 - mae: 0.4837 - val_loss: 0.5602 - val_mse: 0.5602 - val_mae: 0.5398\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.4292 - mse: 0.4292 - mae: 0.4788 - val_loss: 0.5184 - val_mse: 0.5184 - val_mae: 0.5146\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.3697 - mse: 0.3697 - mae: 0.4576 - val_loss: 0.4616 - val_mse: 0.4616 - val_mae: 0.5030\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.3620 - mse: 0.3620 - mae: 0.4500 - val_loss: 0.4637 - val_mse: 0.4637 - val_mae: 0.4997\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.3264 - mse: 0.3264 - mae: 0.4274 - val_loss: 0.4560 - val_mse: 0.4560 - val_mae: 0.5059\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.3236 - mse: 0.3236 - mae: 0.4243 - val_loss: 0.4445 - val_mse: 0.4445 - val_mae: 0.4745\n",
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.3310 - mse: 0.3310 - mae: 0.4308 - val_loss: 0.5369 - val_mse: 0.5369 - val_mae: 0.5199\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.3349 - mse: 0.3349 - mae: 0.4278 - val_loss: 0.4625 - val_mse: 0.4625 - val_mae: 0.5032\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.2908 - mse: 0.2908 - mae: 0.4038 - val_loss: 0.5181 - val_mse: 0.5181 - val_mae: 0.5085\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.3236 - mse: 0.3236 - mae: 0.4219 - val_loss: 0.4178 - val_mse: 0.4178 - val_mae: 0.4573\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.2954 - mse: 0.2954 - mae: 0.4053 - val_loss: 0.4751 - val_mse: 0.4751 - val_mae: 0.4958\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.2858 - mse: 0.2858 - mae: 0.3942 - val_loss: 0.4660 - val_mse: 0.4660 - val_mae: 0.4944\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.2699 - mse: 0.2699 - mae: 0.3902 - val_loss: 0.4484 - val_mse: 0.4484 - val_mae: 0.5009\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.2910 - mse: 0.2910 - mae: 0.4006 - val_loss: 0.4284 - val_mse: 0.4284 - val_mae: 0.4687\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.2557 - mse: 0.2557 - mae: 0.3706 - val_loss: 0.4542 - val_mse: 0.4542 - val_mae: 0.4699\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.2678 - mse: 0.2678 - mae: 0.3798 - val_loss: 0.4810 - val_mse: 0.4810 - val_mae: 0.5057\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.2785 - mse: 0.2785 - mae: 0.3969 - val_loss: 0.4587 - val_mse: 0.4587 - val_mae: 0.4675\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.2615 - mse: 0.2615 - mae: 0.3726 - val_loss: 0.4439 - val_mse: 0.4439 - val_mae: 0.4893\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.2631 - mse: 0.2631 - mae: 0.3768 - val_loss: 0.5002 - val_mse: 0.5002 - val_mae: 0.5241\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 13s 1ms/sample - loss: 0.2221 - mse: 0.2221 - mae: 0.3482 - val_loss: 0.4249 - val_mse: 0.4249 - val_mae: 0.4633\n",
      "Avg. MAE: 0.410494\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 144us/sample - loss: 1.5355 - mse: 1.5355 - mae: 0.9278 - val_loss: 1.1696 - val_mse: 1.1696 - val_mae: 0.8483\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.8837 - mse: 0.8837 - mae: 0.7171 - val_loss: 1.0183 - val_mse: 1.0183 - val_mae: 0.7831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.7091 - mse: 0.7091 - mae: 0.6436 - val_loss: 0.9170 - val_mse: 0.9170 - val_mae: 0.7255\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.6156 - mse: 0.6156 - mae: 0.5996 - val_loss: 0.8125 - val_mse: 0.8125 - val_mae: 0.6893\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.5520 - mse: 0.5520 - mae: 0.5689 - val_loss: 0.7318 - val_mse: 0.7318 - val_mae: 0.6558\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.4932 - mse: 0.4932 - mae: 0.5382 - val_loss: 0.6952 - val_mse: 0.6952 - val_mae: 0.6383\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.4690 - mse: 0.4690 - mae: 0.5262 - val_loss: 0.6229 - val_mse: 0.6229 - val_mae: 0.6000\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.4275 - mse: 0.4275 - mae: 0.5003 - val_loss: 0.5900 - val_mse: 0.5900 - val_mae: 0.5818\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.4050 - mse: 0.4050 - mae: 0.4863 - val_loss: 0.5607 - val_mse: 0.5607 - val_mae: 0.5641\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.3802 - mse: 0.3802 - mae: 0.4738 - val_loss: 0.5391 - val_mse: 0.5391 - val_mae: 0.5503\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.3660 - mse: 0.3660 - mae: 0.4611 - val_loss: 0.5229 - val_mse: 0.5229 - val_mae: 0.5399\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.3494 - mse: 0.3494 - mae: 0.4505 - val_loss: 0.5211 - val_mse: 0.5211 - val_mae: 0.5359\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.3343 - mse: 0.3343 - mae: 0.4406 - val_loss: 0.5173 - val_mse: 0.5173 - val_mae: 0.5308\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.3133 - mse: 0.3133 - mae: 0.4291 - val_loss: 0.5084 - val_mse: 0.5084 - val_mae: 0.5275\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.3065 - mse: 0.3065 - mae: 0.4211 - val_loss: 0.4945 - val_mse: 0.4945 - val_mae: 0.5198\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.2975 - mse: 0.2975 - mae: 0.4144 - val_loss: 0.4901 - val_mse: 0.4901 - val_mae: 0.5146\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 43us/sample - loss: 0.2855 - mse: 0.2855 - mae: 0.4085 - val_loss: 0.4892 - val_mse: 0.4892 - val_mae: 0.5119\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2724 - mse: 0.2724 - mae: 0.3990 - val_loss: 0.4930 - val_mse: 0.4930 - val_mae: 0.5138\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.2612 - mse: 0.2612 - mae: 0.3909 - val_loss: 0.4782 - val_mse: 0.4782 - val_mae: 0.5071\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2532 - mse: 0.2532 - mae: 0.3857 - val_loss: 0.4773 - val_mse: 0.4773 - val_mae: 0.5051\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.2454 - mse: 0.2454 - mae: 0.3781 - val_loss: 0.4856 - val_mse: 0.4856 - val_mae: 0.5099\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2382 - mse: 0.2382 - mae: 0.3741 - val_loss: 0.4849 - val_mse: 0.4849 - val_mae: 0.5071\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2330 - mse: 0.2330 - mae: 0.3676 - val_loss: 0.4711 - val_mse: 0.4711 - val_mae: 0.5028\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.2248 - mse: 0.2248 - mae: 0.3608 - val_loss: 0.4659 - val_mse: 0.4659 - val_mae: 0.4988\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.2235 - mse: 0.2235 - mae: 0.3614 - val_loss: 0.4684 - val_mse: 0.4684 - val_mae: 0.4979\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2139 - mse: 0.2139 - mae: 0.3516 - val_loss: 0.4600 - val_mse: 0.4600 - val_mae: 0.4936\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2058 - mse: 0.2058 - mae: 0.3473 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.4978\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2011 - mse: 0.2011 - mae: 0.3430 - val_loss: 0.4646 - val_mse: 0.4646 - val_mae: 0.4941\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2024 - mse: 0.2024 - mae: 0.3435 - val_loss: 0.4616 - val_mse: 0.4616 - val_mae: 0.4924\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1969 - mse: 0.1969 - mae: 0.3396 - val_loss: 0.4691 - val_mse: 0.4691 - val_mae: 0.4971\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1895 - mse: 0.1895 - mae: 0.3330 - val_loss: 0.4590 - val_mse: 0.4590 - val_mae: 0.4894\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1868 - mse: 0.1868 - mae: 0.3296 - val_loss: 0.4576 - val_mse: 0.4576 - val_mae: 0.4889\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1827 - mse: 0.1827 - mae: 0.3276 - val_loss: 0.4636 - val_mse: 0.4636 - val_mae: 0.4906\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1788 - mse: 0.1788 - mae: 0.3260 - val_loss: 0.4503 - val_mse: 0.4503 - val_mae: 0.4867\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1774 - mse: 0.1774 - mae: 0.3195 - val_loss: 0.4503 - val_mse: 0.4503 - val_mae: 0.4836\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1690 - mse: 0.1690 - mae: 0.3129 - val_loss: 0.4544 - val_mse: 0.4544 - val_mae: 0.4861\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1686 - mse: 0.1686 - mae: 0.3148 - val_loss: 0.4520 - val_mse: 0.4520 - val_mae: 0.4841\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1680 - mse: 0.1680 - mae: 0.3141 - val_loss: 0.4549 - val_mse: 0.4549 - val_mae: 0.4873\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1631 - mse: 0.1631 - mae: 0.3079 - val_loss: 0.4468 - val_mse: 0.4468 - val_mae: 0.4830\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.1564 - mse: 0.1564 - mae: 0.3040 - val_loss: 0.4492 - val_mse: 0.4492 - val_mae: 0.4837\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1585 - mse: 0.1585 - mae: 0.3049 - val_loss: 0.4539 - val_mse: 0.4539 - val_mae: 0.4877\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1512 - mse: 0.1512 - mae: 0.2971 - val_loss: 0.4473 - val_mse: 0.4473 - val_mae: 0.4820\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1520 - mse: 0.1520 - mae: 0.2991 - val_loss: 0.4512 - val_mse: 0.4512 - val_mae: 0.4825\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1493 - mse: 0.1493 - mae: 0.2936 - val_loss: 0.4448 - val_mse: 0.4448 - val_mae: 0.4792\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1429 - mse: 0.1429 - mae: 0.2887 - val_loss: 0.4416 - val_mse: 0.4416 - val_mae: 0.4771\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1407 - mse: 0.1407 - mae: 0.2878 - val_loss: 0.4422 - val_mse: 0.4422 - val_mae: 0.4769\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1397 - mse: 0.1397 - mae: 0.2850 - val_loss: 0.4392 - val_mse: 0.4392 - val_mae: 0.4769\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1378 - mse: 0.1378 - mae: 0.2838 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.4798\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1378 - mse: 0.1378 - mae: 0.2839 - val_loss: 0.4413 - val_mse: 0.4413 - val_mae: 0.4787\n",
      "Epoch 50/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1349 - mse: 0.1349 - mae: 0.2826 - val_loss: 0.4360 - val_mse: 0.4360 - val_mae: 0.4748\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1311 - mse: 0.1311 - mae: 0.2794 - val_loss: 0.4361 - val_mse: 0.4361 - val_mae: 0.4741\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1311 - mse: 0.1311 - mae: 0.2771 - val_loss: 0.4388 - val_mse: 0.4388 - val_mae: 0.4754\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1295 - mse: 0.1295 - mae: 0.2756 - val_loss: 0.4331 - val_mse: 0.4331 - val_mae: 0.4736\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1256 - mse: 0.1256 - mae: 0.2706 - val_loss: 0.4362 - val_mse: 0.4362 - val_mae: 0.4737\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1256 - mse: 0.1256 - mae: 0.2712 - val_loss: 0.4309 - val_mse: 0.4309 - val_mae: 0.4708\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1246 - mse: 0.1246 - mae: 0.2687 - val_loss: 0.4473 - val_mse: 0.4473 - val_mae: 0.4793\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1242 - mse: 0.1242 - mae: 0.2693 - val_loss: 0.4366 - val_mse: 0.4366 - val_mae: 0.4737\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1232 - mse: 0.1232 - mae: 0.2679 - val_loss: 0.4411 - val_mse: 0.4411 - val_mae: 0.4756\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1208 - mse: 0.1208 - mae: 0.2661 - val_loss: 0.4391 - val_mse: 0.4391 - val_mae: 0.4711\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1197 - mse: 0.1197 - mae: 0.2620 - val_loss: 0.4354 - val_mse: 0.4354 - val_mae: 0.4713\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1169 - mse: 0.1169 - mae: 0.2608 - val_loss: 0.4451 - val_mse: 0.4451 - val_mae: 0.4757\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1133 - mse: 0.1133 - mae: 0.2550 - val_loss: 0.4348 - val_mse: 0.4348 - val_mae: 0.4711\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1130 - mse: 0.1130 - mae: 0.2575 - val_loss: 0.4354 - val_mse: 0.4354 - val_mae: 0.4736\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1095 - mse: 0.1095 - mae: 0.2556 - val_loss: 0.4367 - val_mse: 0.4367 - val_mae: 0.4714\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1117 - mse: 0.1117 - mae: 0.2555 - val_loss: 0.4258 - val_mse: 0.4258 - val_mae: 0.4673\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1071 - mse: 0.1071 - mae: 0.2491 - val_loss: 0.4295 - val_mse: 0.4295 - val_mae: 0.4689\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1046 - mse: 0.1046 - mae: 0.2469 - val_loss: 0.4315 - val_mse: 0.4315 - val_mae: 0.4711\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1039 - mse: 0.1039 - mae: 0.2476 - val_loss: 0.4290 - val_mse: 0.4290 - val_mae: 0.4701\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1034 - mse: 0.1034 - mae: 0.2458 - val_loss: 0.4245 - val_mse: 0.4245 - val_mae: 0.4678\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1025 - mse: 0.1025 - mae: 0.2456 - val_loss: 0.4363 - val_mse: 0.4363 - val_mae: 0.4700\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1057 - mse: 0.1057 - mae: 0.2495 - val_loss: 0.4378 - val_mse: 0.4378 - val_mae: 0.4726\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1037 - mse: 0.1037 - mae: 0.2463 - val_loss: 0.4257 - val_mse: 0.4257 - val_mae: 0.4682\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1012 - mse: 0.1012 - mae: 0.2423 - val_loss: 0.4275 - val_mse: 0.4275 - val_mae: 0.4696\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0997 - mse: 0.0997 - mae: 0.2415 - val_loss: 0.4348 - val_mse: 0.4348 - val_mae: 0.4725\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0986 - mse: 0.0986 - mae: 0.2407 - val_loss: 0.4243 - val_mse: 0.4243 - val_mae: 0.4651\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1017 - mse: 0.1017 - mae: 0.2437 - val_loss: 0.4313 - val_mse: 0.4313 - val_mae: 0.4689\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0982 - mse: 0.0982 - mae: 0.2394 - val_loss: 0.4265 - val_mse: 0.4265 - val_mae: 0.4673\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0956 - mse: 0.0956 - mae: 0.2368 - val_loss: 0.4162 - val_mse: 0.4162 - val_mae: 0.4629\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0924 - mse: 0.0924 - mae: 0.2336 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.4634\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0946 - mse: 0.0946 - mae: 0.2347 - val_loss: 0.4258 - val_mse: 0.4258 - val_mae: 0.4653\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0940 - mse: 0.0940 - mae: 0.2336 - val_loss: 0.4245 - val_mse: 0.4245 - val_mae: 0.4658\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.0936 - mse: 0.0936 - mae: 0.2338 - val_loss: 0.4228 - val_mse: 0.4228 - val_mae: 0.4657\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0938 - mse: 0.0938 - mae: 0.2346 - val_loss: 0.4181 - val_mse: 0.4181 - val_mae: 0.4615\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0898 - mse: 0.0898 - mae: 0.2290 - val_loss: 0.4121 - val_mse: 0.4121 - val_mae: 0.4600\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0902 - mse: 0.0902 - mae: 0.2286 - val_loss: 0.4315 - val_mse: 0.4315 - val_mae: 0.4721\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0881 - mse: 0.0881 - mae: 0.2272 - val_loss: 0.4205 - val_mse: 0.4205 - val_mae: 0.4616\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0895 - mse: 0.0895 - mae: 0.2267 - val_loss: 0.4193 - val_mse: 0.4193 - val_mae: 0.4622\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0892 - mse: 0.0892 - mae: 0.2274 - val_loss: 0.4208 - val_mse: 0.4208 - val_mae: 0.4636\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0880 - mse: 0.0880 - mae: 0.2263 - val_loss: 0.4148 - val_mse: 0.4148 - val_mae: 0.4607\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0847 - mse: 0.0847 - mae: 0.2231 - val_loss: 0.4142 - val_mse: 0.4142 - val_mae: 0.4607\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.0868 - mse: 0.0868 - mae: 0.2249 - val_loss: 0.4120 - val_mse: 0.4120 - val_mae: 0.4582\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0888 - mse: 0.0888 - mae: 0.2276 - val_loss: 0.4111 - val_mse: 0.4111 - val_mae: 0.4574\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.0828 - mse: 0.0828 - mae: 0.2193 - val_loss: 0.4248 - val_mse: 0.4248 - val_mae: 0.4649\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0832 - mse: 0.0832 - mae: 0.2222 - val_loss: 0.4231 - val_mse: 0.4231 - val_mae: 0.4611\n",
      "Epoch 95/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0804 - mse: 0.0804 - mae: 0.2159 - val_loss: 0.4191 - val_mse: 0.4191 - val_mae: 0.4628\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0836 - mse: 0.0836 - mae: 0.2193 - val_loss: 0.4122 - val_mse: 0.4122 - val_mae: 0.4606\n",
      "Epoch 97/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0837 - mse: 0.0837 - mae: 0.2200 - val_loss: 0.4081 - val_mse: 0.4081 - val_mae: 0.4572\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0835 - mse: 0.0835 - mae: 0.2212 - val_loss: 0.4190 - val_mse: 0.4190 - val_mae: 0.4619\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0803 - mse: 0.0803 - mae: 0.2167 - val_loss: 0.4098 - val_mse: 0.4098 - val_mae: 0.4595\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.0785 - mse: 0.0785 - mae: 0.2138 - val_loss: 0.4176 - val_mse: 0.4176 - val_mae: 0.4604\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0769 - mse: 0.0769 - mae: 0.2129 - val_loss: 0.4102 - val_mse: 0.4102 - val_mae: 0.4561\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.0810 - mse: 0.0810 - mae: 0.2173 - val_loss: 0.4068 - val_mse: 0.4068 - val_mae: 0.4552\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0802 - mse: 0.0802 - mae: 0.2160 - val_loss: 0.4107 - val_mse: 0.4107 - val_mae: 0.4583\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0809 - mse: 0.0809 - mae: 0.2166 - val_loss: 0.3995 - val_mse: 0.3995 - val_mae: 0.4524\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0787 - mse: 0.0787 - mae: 0.2160 - val_loss: 0.4064 - val_mse: 0.4064 - val_mae: 0.4557\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0776 - mse: 0.0776 - mae: 0.2136 - val_loss: 0.4080 - val_mse: 0.4080 - val_mae: 0.4533\n",
      "Epoch 107/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.0777 - mse: 0.0777 - mae: 0.2118 - val_loss: 0.4180 - val_mse: 0.4180 - val_mae: 0.4604\n",
      "Epoch 108/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0778 - mse: 0.0778 - mae: 0.2111 - val_loss: 0.4079 - val_mse: 0.4079 - val_mae: 0.4560\n",
      "Epoch 109/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0763 - mse: 0.0763 - mae: 0.2112 - val_loss: 0.4026 - val_mse: 0.4026 - val_mae: 0.4522\n",
      "Epoch 110/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0787 - mse: 0.0787 - mae: 0.2143 - val_loss: 0.3993 - val_mse: 0.3993 - val_mae: 0.4514\n",
      "Epoch 111/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0747 - mse: 0.0747 - mae: 0.2076 - val_loss: 0.3995 - val_mse: 0.3995 - val_mae: 0.4510\n",
      "Epoch 112/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0754 - mse: 0.0754 - mae: 0.2104 - val_loss: 0.4072 - val_mse: 0.4072 - val_mae: 0.4550\n",
      "Epoch 113/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0738 - mse: 0.0738 - mae: 0.2087 - val_loss: 0.4014 - val_mse: 0.4014 - val_mae: 0.4533\n",
      "Epoch 114/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.0740 - mse: 0.0740 - mae: 0.2053 - val_loss: 0.3970 - val_mse: 0.3970 - val_mae: 0.4512\n",
      "Epoch 115/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0740 - mse: 0.0740 - mae: 0.2049 - val_loss: 0.4034 - val_mse: 0.4034 - val_mae: 0.4528\n",
      "Epoch 116/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0724 - mse: 0.0724 - mae: 0.2049 - val_loss: 0.4082 - val_mse: 0.4082 - val_mae: 0.4535\n",
      "Epoch 117/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0710 - mse: 0.0710 - mae: 0.2031 - val_loss: 0.4004 - val_mse: 0.4004 - val_mae: 0.4503\n",
      "Epoch 118/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0678 - mse: 0.0678 - mae: 0.1977 - val_loss: 0.4021 - val_mse: 0.4021 - val_mae: 0.4532\n",
      "Epoch 119/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0723 - mse: 0.0723 - mae: 0.2053 - val_loss: 0.4143 - val_mse: 0.4143 - val_mae: 0.4595\n",
      "Epoch 120/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0710 - mse: 0.0710 - mae: 0.2041 - val_loss: 0.4022 - val_mse: 0.4022 - val_mae: 0.4499\n",
      "Epoch 121/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0711 - mse: 0.0711 - mae: 0.2026 - val_loss: 0.3980 - val_mse: 0.3980 - val_mae: 0.4492\n",
      "Epoch 122/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0717 - mse: 0.0717 - mae: 0.2030 - val_loss: 0.3965 - val_mse: 0.3965 - val_mae: 0.4502\n",
      "Epoch 123/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0704 - mse: 0.0704 - mae: 0.2022 - val_loss: 0.3941 - val_mse: 0.3941 - val_mae: 0.4490\n",
      "Epoch 124/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0709 - mse: 0.0709 - mae: 0.2022 - val_loss: 0.3982 - val_mse: 0.3982 - val_mae: 0.4518\n",
      "Epoch 125/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0720 - mse: 0.0720 - mae: 0.2051 - val_loss: 0.4012 - val_mse: 0.4012 - val_mae: 0.4532\n",
      "Epoch 126/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0698 - mse: 0.0698 - mae: 0.2016 - val_loss: 0.3915 - val_mse: 0.3915 - val_mae: 0.4461\n",
      "Epoch 127/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0661 - mse: 0.0661 - mae: 0.1958 - val_loss: 0.3956 - val_mse: 0.3956 - val_mae: 0.4500\n",
      "Epoch 128/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0657 - mse: 0.0657 - mae: 0.1959 - val_loss: 0.4004 - val_mse: 0.4004 - val_mae: 0.4532\n",
      "Epoch 129/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0671 - mse: 0.0671 - mae: 0.1976 - val_loss: 0.3954 - val_mse: 0.3954 - val_mae: 0.4498\n",
      "Epoch 130/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0707 - mse: 0.0707 - mae: 0.2029 - val_loss: 0.4050 - val_mse: 0.4050 - val_mae: 0.4539\n",
      "Epoch 131/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0664 - mse: 0.0664 - mae: 0.1959 - val_loss: 0.3981 - val_mse: 0.3981 - val_mae: 0.4518\n",
      "Epoch 132/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0669 - mse: 0.0669 - mae: 0.1983 - val_loss: 0.3983 - val_mse: 0.3983 - val_mae: 0.4486\n",
      "Epoch 133/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0667 - mse: 0.0667 - mae: 0.1968 - val_loss: 0.3911 - val_mse: 0.3911 - val_mae: 0.4458\n",
      "Epoch 134/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.0668 - mse: 0.0668 - mae: 0.1958 - val_loss: 0.3944 - val_mse: 0.3944 - val_mae: 0.4474\n",
      "Epoch 135/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0695 - mse: 0.0695 - mae: 0.2014 - val_loss: 0.3983 - val_mse: 0.3983 - val_mae: 0.4479\n",
      "Epoch 136/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0669 - mse: 0.0669 - mae: 0.1966 - val_loss: 0.3983 - val_mse: 0.3983 - val_mae: 0.4488\n",
      "Epoch 137/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0657 - mse: 0.0657 - mae: 0.1937 - val_loss: 0.3957 - val_mse: 0.3957 - val_mae: 0.4454\n",
      "Epoch 138/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0651 - mse: 0.0651 - mae: 0.1947 - val_loss: 0.3946 - val_mse: 0.3946 - val_mae: 0.4475\n",
      "Epoch 139/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0636 - mse: 0.0636 - mae: 0.1910 - val_loss: 0.3930 - val_mse: 0.3930 - val_mae: 0.4445\n",
      "Epoch 140/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0638 - mse: 0.0638 - mae: 0.1924 - val_loss: 0.3937 - val_mse: 0.3937 - val_mae: 0.4473\n",
      "Epoch 141/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0630 - mse: 0.0630 - mae: 0.1897 - val_loss: 0.3959 - val_mse: 0.3959 - val_mae: 0.4475\n",
      "Epoch 142/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0618 - mse: 0.0618 - mae: 0.1901 - val_loss: 0.3913 - val_mse: 0.3913 - val_mae: 0.4459\n",
      "Epoch 143/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0627 - mse: 0.0627 - mae: 0.1908 - val_loss: 0.3915 - val_mse: 0.3915 - val_mae: 0.4464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 232us/sample - loss: 1.5026 - mse: 1.5026 - mae: 0.9273 - val_loss: 1.2930 - val_mse: 1.2930 - val_mae: 0.9027\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.8736 - mse: 0.8736 - mae: 0.7140 - val_loss: 1.0706 - val_mse: 1.0706 - val_mae: 0.8034\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.6986 - mse: 0.6986 - mae: 0.6391 - val_loss: 0.9662 - val_mse: 0.9662 - val_mae: 0.7493\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.6159 - mse: 0.6159 - mae: 0.5989 - val_loss: 0.8632 - val_mse: 0.8632 - val_mae: 0.7049\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.5514 - mse: 0.5514 - mae: 0.5684 - val_loss: 0.7976 - val_mse: 0.7976 - val_mae: 0.6722\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.5079 - mse: 0.5079 - mae: 0.5483 - val_loss: 0.7188 - val_mse: 0.7188 - val_mae: 0.6441\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.5192 - val_loss: 0.6732 - val_mse: 0.6732 - val_mae: 0.6243\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.4349 - mse: 0.4349 - mae: 0.5044 - val_loss: 0.6304 - val_mse: 0.6304 - val_mae: 0.5984\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.4006 - mse: 0.4006 - mae: 0.4827 - val_loss: 0.6189 - val_mse: 0.6189 - val_mae: 0.5816\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.3838 - mse: 0.3838 - mae: 0.4718 - val_loss: 0.5567 - val_mse: 0.5567 - val_mae: 0.5607\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.3581 - mse: 0.3581 - mae: 0.4566 - val_loss: 0.5555 - val_mse: 0.5555 - val_mae: 0.5560\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.3459 - mse: 0.3459 - mae: 0.4500 - val_loss: 0.5356 - val_mse: 0.5356 - val_mae: 0.5410\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.3280 - mse: 0.3280 - mae: 0.4384 - val_loss: 0.5433 - val_mse: 0.5433 - val_mae: 0.5363\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.3161 - mse: 0.3161 - mae: 0.4296 - val_loss: 0.5258 - val_mse: 0.5258 - val_mae: 0.5299\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2987 - mse: 0.2987 - mae: 0.4181 - val_loss: 0.5298 - val_mse: 0.5298 - val_mae: 0.5282\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2925 - mse: 0.2925 - mae: 0.4112 - val_loss: 0.5125 - val_mse: 0.5125 - val_mae: 0.5222\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2800 - mse: 0.2800 - mae: 0.4032 - val_loss: 0.5123 - val_mse: 0.5123 - val_mae: 0.5189\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2746 - mse: 0.2746 - mae: 0.4004 - val_loss: 0.5031 - val_mse: 0.5031 - val_mae: 0.5175\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2640 - mse: 0.2640 - mae: 0.3924 - val_loss: 0.4930 - val_mse: 0.4930 - val_mae: 0.5130\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2549 - mse: 0.2549 - mae: 0.3852 - val_loss: 0.5082 - val_mse: 0.5082 - val_mae: 0.5131\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2490 - mse: 0.2490 - mae: 0.3824 - val_loss: 0.5036 - val_mse: 0.5036 - val_mae: 0.5112\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.2372 - mse: 0.2372 - mae: 0.3735 - val_loss: 0.5006 - val_mse: 0.5006 - val_mae: 0.5095\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.2340 - mse: 0.2340 - mae: 0.3693 - val_loss: 0.5002 - val_mse: 0.5002 - val_mae: 0.5033\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 44us/sample - loss: 0.2293 - mse: 0.2293 - mae: 0.3652 - val_loss: 0.4901 - val_mse: 0.4901 - val_mae: 0.5036\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 43us/sample - loss: 0.2210 - mse: 0.2210 - mae: 0.3606 - val_loss: 0.4895 - val_mse: 0.4895 - val_mae: 0.5005\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2155 - mse: 0.2155 - mae: 0.3545 - val_loss: 0.5043 - val_mse: 0.5043 - val_mae: 0.5003\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 43us/sample - loss: 0.2130 - mse: 0.2130 - mae: 0.3513 - val_loss: 0.4792 - val_mse: 0.4792 - val_mae: 0.4948\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2025 - mse: 0.2025 - mae: 0.3432 - val_loss: 0.4777 - val_mse: 0.4777 - val_mae: 0.4964\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1962 - mse: 0.1962 - mae: 0.3380 - val_loss: 0.4879 - val_mse: 0.4879 - val_mae: 0.4992\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 45us/sample - loss: 0.1967 - mse: 0.1967 - mae: 0.3403 - val_loss: 0.4834 - val_mse: 0.4834 - val_mae: 0.4976\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1835 - mse: 0.1835 - mae: 0.3285 - val_loss: 0.4856 - val_mse: 0.4856 - val_mae: 0.4958\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1817 - mse: 0.1817 - mae: 0.3260 - val_loss: 0.4811 - val_mse: 0.4811 - val_mae: 0.4969\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1831 - mse: 0.1831 - mae: 0.3264 - val_loss: 0.4840 - val_mse: 0.4840 - val_mae: 0.4973\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1739 - mse: 0.1739 - mae: 0.3203 - val_loss: 0.4828 - val_mse: 0.4828 - val_mae: 0.4878\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1764 - mse: 0.1764 - mae: 0.3222 - val_loss: 0.4689 - val_mse: 0.4689 - val_mae: 0.4904\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1711 - mse: 0.1711 - mae: 0.3161 - val_loss: 0.4964 - val_mse: 0.4964 - val_mae: 0.4896\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1737 - mse: 0.1737 - mae: 0.3180 - val_loss: 0.4814 - val_mse: 0.4814 - val_mae: 0.4890\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1668 - mse: 0.1668 - mae: 0.3128 - val_loss: 0.4781 - val_mse: 0.4781 - val_mae: 0.4854\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1615 - mse: 0.1615 - mae: 0.3087 - val_loss: 0.4795 - val_mse: 0.4795 - val_mae: 0.4845\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1562 - mse: 0.1562 - mae: 0.3026 - val_loss: 0.4722 - val_mse: 0.4722 - val_mae: 0.4863\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1602 - mse: 0.1602 - mae: 0.3055 - val_loss: 0.4917 - val_mse: 0.4917 - val_mae: 0.4869\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1580 - mse: 0.1580 - mae: 0.3029 - val_loss: 0.4724 - val_mse: 0.4724 - val_mae: 0.4857\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 43us/sample - loss: 0.1475 - mse: 0.1475 - mae: 0.2926 - val_loss: 0.4652 - val_mse: 0.4652 - val_mae: 0.4863\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1483 - mse: 0.1483 - mae: 0.2947 - val_loss: 0.4777 - val_mse: 0.4777 - val_mae: 0.4877\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1436 - mse: 0.1436 - mae: 0.2896 - val_loss: 0.4751 - val_mse: 0.4751 - val_mae: 0.4834\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1450 - mse: 0.1450 - mae: 0.2897 - val_loss: 0.4713 - val_mse: 0.4713 - val_mae: 0.4792\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1389 - mse: 0.1389 - mae: 0.2851 - val_loss: 0.4503 - val_mse: 0.4503 - val_mae: 0.4818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1388 - mse: 0.1388 - mae: 0.2854 - val_loss: 0.4641 - val_mse: 0.4641 - val_mae: 0.4769\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1361 - mse: 0.1361 - mae: 0.2821 - val_loss: 0.4655 - val_mse: 0.4655 - val_mae: 0.4764\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1316 - mse: 0.1316 - mae: 0.2765 - val_loss: 0.4603 - val_mse: 0.4603 - val_mae: 0.4781\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 43us/sample - loss: 0.1376 - mse: 0.1376 - mae: 0.2838 - val_loss: 0.4560 - val_mse: 0.4560 - val_mae: 0.4748\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1352 - mse: 0.1352 - mae: 0.2799 - val_loss: 0.4891 - val_mse: 0.4891 - val_mae: 0.4773\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1278 - mse: 0.1278 - mae: 0.2739 - val_loss: 0.4671 - val_mse: 0.4671 - val_mae: 0.4755\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1306 - mse: 0.1306 - mae: 0.2748 - val_loss: 0.4593 - val_mse: 0.4593 - val_mae: 0.4714\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1247 - mse: 0.1247 - mae: 0.2692 - val_loss: 0.4626 - val_mse: 0.4626 - val_mae: 0.4773\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1271 - mse: 0.1271 - mae: 0.2732 - val_loss: 0.4615 - val_mse: 0.4615 - val_mae: 0.4752\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1217 - mse: 0.1217 - mae: 0.2665 - val_loss: 0.4482 - val_mse: 0.4482 - val_mae: 0.4710\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1196 - mse: 0.1196 - mae: 0.2651 - val_loss: 0.4584 - val_mse: 0.4584 - val_mae: 0.4746\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1166 - mse: 0.1166 - mae: 0.2599 - val_loss: 0.4695 - val_mse: 0.4695 - val_mae: 0.4742\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1178 - mse: 0.1178 - mae: 0.2614 - val_loss: 0.4676 - val_mse: 0.4676 - val_mae: 0.4706\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1161 - mse: 0.1161 - mae: 0.2608 - val_loss: 0.4554 - val_mse: 0.4554 - val_mae: 0.4697\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1206 - mse: 0.1206 - mae: 0.2666 - val_loss: 0.4505 - val_mse: 0.4505 - val_mae: 0.4709\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1143 - mse: 0.1143 - mae: 0.2589 - val_loss: 0.4430 - val_mse: 0.4430 - val_mae: 0.4694\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1158 - mse: 0.1158 - mae: 0.2619 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.4660\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1114 - mse: 0.1114 - mae: 0.2551 - val_loss: 0.4414 - val_mse: 0.4414 - val_mae: 0.4673\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1088 - mse: 0.1088 - mae: 0.2531 - val_loss: 0.4612 - val_mse: 0.4612 - val_mae: 0.4697\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1086 - mse: 0.1086 - mae: 0.2529 - val_loss: 0.4633 - val_mse: 0.4633 - val_mae: 0.4709\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1075 - mse: 0.1075 - mae: 0.2511 - val_loss: 0.4659 - val_mse: 0.4659 - val_mae: 0.4689\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1063 - mse: 0.1063 - mae: 0.2508 - val_loss: 0.4434 - val_mse: 0.4434 - val_mae: 0.4706\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1041 - mse: 0.1041 - mae: 0.2466 - val_loss: 0.4381 - val_mse: 0.4381 - val_mae: 0.4660\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1059 - mse: 0.1059 - mae: 0.2490 - val_loss: 0.4463 - val_mse: 0.4463 - val_mae: 0.4678\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1050 - mse: 0.1050 - mae: 0.2484 - val_loss: 0.4408 - val_mse: 0.4408 - val_mae: 0.4655\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0992 - mse: 0.0992 - mae: 0.2398 - val_loss: 0.4361 - val_mse: 0.4361 - val_mae: 0.4609\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0983 - mse: 0.0983 - mae: 0.2391 - val_loss: 0.4469 - val_mse: 0.4469 - val_mae: 0.4634\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1003 - mse: 0.1003 - mae: 0.2429 - val_loss: 0.4535 - val_mse: 0.4535 - val_mae: 0.4691\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0996 - mse: 0.0996 - mae: 0.2414 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.4634\n",
      "Epoch 77/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0997 - mse: 0.0997 - mae: 0.2407 - val_loss: 0.4401 - val_mse: 0.4401 - val_mae: 0.4651\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0994 - mse: 0.0994 - mae: 0.2420 - val_loss: 0.4475 - val_mse: 0.4475 - val_mae: 0.4688\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0945 - mse: 0.0945 - mae: 0.2365 - val_loss: 0.4530 - val_mse: 0.4530 - val_mae: 0.4694\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0986 - mse: 0.0986 - mae: 0.2399 - val_loss: 0.4569 - val_mse: 0.4569 - val_mae: 0.4649\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 43us/sample - loss: 0.0928 - mse: 0.0928 - mae: 0.2338 - val_loss: 0.4425 - val_mse: 0.4425 - val_mae: 0.4662\n",
      "Epoch 82/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0948 - mse: 0.0948 - mae: 0.2358 - val_loss: 0.4394 - val_mse: 0.4394 - val_mae: 0.4629\n",
      "Epoch 83/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0939 - mse: 0.0939 - mae: 0.2333 - val_loss: 0.4353 - val_mse: 0.4353 - val_mae: 0.4634\n",
      "Epoch 84/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0938 - mse: 0.0938 - mae: 0.2332 - val_loss: 0.4492 - val_mse: 0.4492 - val_mae: 0.4661\n",
      "Epoch 85/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0925 - mse: 0.0925 - mae: 0.2313 - val_loss: 0.4402 - val_mse: 0.4402 - val_mae: 0.4633\n",
      "Epoch 86/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0917 - mse: 0.0917 - mae: 0.2307 - val_loss: 0.4381 - val_mse: 0.4381 - val_mae: 0.4637\n",
      "Epoch 87/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0911 - mse: 0.0911 - mae: 0.2297 - val_loss: 0.4335 - val_mse: 0.4335 - val_mae: 0.4607\n",
      "Epoch 88/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0908 - mse: 0.0908 - mae: 0.2285 - val_loss: 0.4452 - val_mse: 0.4452 - val_mae: 0.4629\n",
      "Epoch 89/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0901 - mse: 0.0901 - mae: 0.2303 - val_loss: 0.4447 - val_mse: 0.4447 - val_mae: 0.4641\n",
      "Epoch 90/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0867 - mse: 0.0867 - mae: 0.2259 - val_loss: 0.4424 - val_mse: 0.4424 - val_mae: 0.4630\n",
      "Epoch 91/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0880 - mse: 0.0880 - mae: 0.2259 - val_loss: 0.4387 - val_mse: 0.4387 - val_mae: 0.4591\n",
      "Epoch 92/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0894 - mse: 0.0894 - mae: 0.2279 - val_loss: 0.4384 - val_mse: 0.4384 - val_mae: 0.4619\n",
      "Epoch 93/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0885 - mse: 0.0885 - mae: 0.2267 - val_loss: 0.4406 - val_mse: 0.4406 - val_mae: 0.4608\n",
      "Epoch 94/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0843 - mse: 0.0843 - mae: 0.2211 - val_loss: 0.4395 - val_mse: 0.4395 - val_mae: 0.4620\n",
      "Epoch 95/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0844 - mse: 0.0844 - mae: 0.2211 - val_loss: 0.4328 - val_mse: 0.4328 - val_mae: 0.4590\n",
      "Epoch 96/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0830 - mse: 0.0830 - mae: 0.2192 - val_loss: 0.4426 - val_mse: 0.4426 - val_mae: 0.4649\n",
      "Epoch 97/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0865 - mse: 0.0865 - mae: 0.2240 - val_loss: 0.4298 - val_mse: 0.4298 - val_mae: 0.4566\n",
      "Epoch 98/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0812 - mse: 0.0812 - mae: 0.2171 - val_loss: 0.4458 - val_mse: 0.4458 - val_mae: 0.4641\n",
      "Epoch 99/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0855 - mse: 0.0855 - mae: 0.2231 - val_loss: 0.4437 - val_mse: 0.4437 - val_mae: 0.4600\n",
      "Epoch 100/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0811 - mse: 0.0811 - mae: 0.2165 - val_loss: 0.4293 - val_mse: 0.4293 - val_mae: 0.4576\n",
      "Epoch 101/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0820 - mse: 0.0820 - mae: 0.2186 - val_loss: 0.4352 - val_mse: 0.4352 - val_mae: 0.4584\n",
      "Epoch 102/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0798 - mse: 0.0798 - mae: 0.2144 - val_loss: 0.4263 - val_mse: 0.4263 - val_mae: 0.4539\n",
      "Epoch 103/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0819 - mse: 0.0819 - mae: 0.2183 - val_loss: 0.4329 - val_mse: 0.4329 - val_mae: 0.4565\n",
      "Epoch 104/3000\n",
      "10663/10663 [==============================] - 0s 43us/sample - loss: 0.0788 - mse: 0.0788 - mae: 0.2142 - val_loss: 0.4316 - val_mse: 0.4316 - val_mae: 0.4577\n",
      "Epoch 105/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0821 - mse: 0.0821 - mae: 0.2182 - val_loss: 0.4351 - val_mse: 0.4351 - val_mae: 0.4564\n",
      "Epoch 106/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0778 - mse: 0.0778 - mae: 0.2129 - val_loss: 0.4328 - val_mse: 0.4328 - val_mae: 0.4556\n",
      "Epoch 107/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0791 - mse: 0.0791 - mae: 0.2144 - val_loss: 0.4403 - val_mse: 0.4403 - val_mae: 0.4583\n",
      "Epoch 108/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0785 - mse: 0.0785 - mae: 0.2144 - val_loss: 0.4378 - val_mse: 0.4378 - val_mae: 0.4601\n",
      "Epoch 109/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0767 - mse: 0.0767 - mae: 0.2120 - val_loss: 0.4339 - val_mse: 0.4339 - val_mae: 0.4591\n",
      "Epoch 110/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0759 - mse: 0.0759 - mae: 0.2104 - val_loss: 0.4360 - val_mse: 0.4360 - val_mae: 0.4595\n",
      "Epoch 111/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0755 - mse: 0.0755 - mae: 0.2105 - val_loss: 0.4364 - val_mse: 0.4364 - val_mae: 0.4555\n",
      "Epoch 112/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0746 - mse: 0.0746 - mae: 0.2090 - val_loss: 0.4356 - val_mse: 0.4356 - val_mae: 0.4616\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 145us/sample - loss: 1.4821 - mse: 1.4821 - mae: 0.9199 - val_loss: 1.2244 - val_mse: 1.2244 - val_mae: 0.8770\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.8703 - mse: 0.8703 - mae: 0.7153 - val_loss: 1.0654 - val_mse: 1.0654 - val_mae: 0.8000\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.7142 - mse: 0.7142 - mae: 0.6462 - val_loss: 0.9305 - val_mse: 0.9305 - val_mae: 0.7519\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.6126 - mse: 0.6126 - mae: 0.6009 - val_loss: 0.8283 - val_mse: 0.8283 - val_mae: 0.7020\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.5452 - mse: 0.5452 - mae: 0.5657 - val_loss: 0.7659 - val_mse: 0.7659 - val_mae: 0.6688\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.4999 - mse: 0.4999 - mae: 0.5409 - val_loss: 0.6921 - val_mse: 0.6921 - val_mae: 0.6355\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.4569 - mse: 0.4569 - mae: 0.5168 - val_loss: 0.6552 - val_mse: 0.6552 - val_mae: 0.6141\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.4216 - mse: 0.4216 - mae: 0.4977 - val_loss: 0.6151 - val_mse: 0.6151 - val_mae: 0.5939\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.4023 - mse: 0.4023 - mae: 0.4873 - val_loss: 0.5945 - val_mse: 0.5945 - val_mae: 0.5773\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.3765 - mse: 0.3765 - mae: 0.4698 - val_loss: 0.5671 - val_mse: 0.5671 - val_mae: 0.5633\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.3567 - mse: 0.3567 - mae: 0.4572 - val_loss: 0.5493 - val_mse: 0.5493 - val_mae: 0.5521\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.3498 - mse: 0.3498 - mae: 0.4547 - val_loss: 0.5417 - val_mse: 0.5417 - val_mae: 0.5442\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.3285 - mse: 0.3285 - mae: 0.4379 - val_loss: 0.5304 - val_mse: 0.5304 - val_mae: 0.5367\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.3147 - mse: 0.3147 - mae: 0.4301 - val_loss: 0.5296 - val_mse: 0.5296 - val_mae: 0.5331\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2975 - mse: 0.2975 - mae: 0.4193 - val_loss: 0.5185 - val_mse: 0.5185 - val_mae: 0.5276\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2901 - mse: 0.2901 - mae: 0.4118 - val_loss: 0.5051 - val_mse: 0.5051 - val_mae: 0.5212\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2787 - mse: 0.2787 - mae: 0.4049 - val_loss: 0.5061 - val_mse: 0.5061 - val_mae: 0.5193\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2688 - mse: 0.2688 - mae: 0.3955 - val_loss: 0.5038 - val_mse: 0.5038 - val_mae: 0.5172\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.2600 - mse: 0.2600 - mae: 0.3895 - val_loss: 0.5115 - val_mse: 0.5115 - val_mae: 0.5169\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2488 - mse: 0.2488 - mae: 0.3804 - val_loss: 0.4933 - val_mse: 0.4933 - val_mae: 0.5092\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2483 - mse: 0.2483 - mae: 0.3807 - val_loss: 0.4983 - val_mse: 0.4983 - val_mae: 0.5113\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2343 - mse: 0.2343 - mae: 0.3720 - val_loss: 0.4979 - val_mse: 0.4979 - val_mae: 0.5093\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2332 - mse: 0.2332 - mae: 0.3715 - val_loss: 0.4899 - val_mse: 0.4899 - val_mae: 0.5065\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2269 - mse: 0.2269 - mae: 0.3654 - val_loss: 0.4863 - val_mse: 0.4863 - val_mae: 0.5043\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2144 - mse: 0.2144 - mae: 0.3551 - val_loss: 0.4749 - val_mse: 0.4749 - val_mae: 0.4991\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2112 - mse: 0.2112 - mae: 0.3526 - val_loss: 0.4766 - val_mse: 0.4766 - val_mae: 0.4996\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2060 - mse: 0.2060 - mae: 0.3490 - val_loss: 0.4795 - val_mse: 0.4795 - val_mae: 0.4973\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2021 - mse: 0.2021 - mae: 0.3435 - val_loss: 0.4729 - val_mse: 0.4729 - val_mae: 0.4951\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1894 - mse: 0.1894 - mae: 0.3339 - val_loss: 0.4708 - val_mse: 0.4708 - val_mae: 0.4918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1946 - mse: 0.1946 - mae: 0.3386 - val_loss: 0.4778 - val_mse: 0.4778 - val_mae: 0.4944\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1869 - mse: 0.1869 - mae: 0.3325 - val_loss: 0.4702 - val_mse: 0.4702 - val_mae: 0.4940\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1801 - mse: 0.1801 - mae: 0.3245 - val_loss: 0.4682 - val_mse: 0.4682 - val_mae: 0.4926\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1812 - mse: 0.1812 - mae: 0.3272 - val_loss: 0.4694 - val_mse: 0.4694 - val_mae: 0.4902\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1727 - mse: 0.1727 - mae: 0.3180 - val_loss: 0.4601 - val_mse: 0.4601 - val_mae: 0.4893\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1723 - mse: 0.1723 - mae: 0.3166 - val_loss: 0.4696 - val_mse: 0.4696 - val_mae: 0.4901\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1719 - mse: 0.1719 - mae: 0.3172 - val_loss: 0.4661 - val_mse: 0.4661 - val_mae: 0.4881\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1672 - mse: 0.1672 - mae: 0.3139 - val_loss: 0.4745 - val_mse: 0.4745 - val_mae: 0.4887\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1658 - mse: 0.1658 - mae: 0.3125 - val_loss: 0.4570 - val_mse: 0.4570 - val_mae: 0.4860\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1574 - mse: 0.1574 - mae: 0.3051 - val_loss: 0.4605 - val_mse: 0.4605 - val_mae: 0.4848\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1611 - mse: 0.1611 - mae: 0.3072 - val_loss: 0.4612 - val_mse: 0.4612 - val_mae: 0.4845\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1533 - mse: 0.1533 - mae: 0.2992 - val_loss: 0.4649 - val_mse: 0.4649 - val_mae: 0.4874\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1540 - mse: 0.1540 - mae: 0.3021 - val_loss: 0.4562 - val_mse: 0.4562 - val_mae: 0.4815\n",
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1484 - mse: 0.1484 - mae: 0.2952 - val_loss: 0.4656 - val_mse: 0.4656 - val_mae: 0.4869\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1419 - mse: 0.1419 - mae: 0.2883 - val_loss: 0.4681 - val_mse: 0.4681 - val_mae: 0.4846\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1402 - mse: 0.1402 - mae: 0.2868 - val_loss: 0.4616 - val_mse: 0.4616 - val_mae: 0.4837\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1423 - mse: 0.1423 - mae: 0.2891 - val_loss: 0.4725 - val_mse: 0.4725 - val_mae: 0.4861\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1401 - mse: 0.1401 - mae: 0.2879 - val_loss: 0.4624 - val_mse: 0.4624 - val_mae: 0.4833\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1374 - mse: 0.1374 - mae: 0.2841 - val_loss: 0.4559 - val_mse: 0.4559 - val_mae: 0.4807\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1332 - mse: 0.1332 - mae: 0.2799 - val_loss: 0.4538 - val_mse: 0.4538 - val_mae: 0.4825\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1365 - mse: 0.1365 - mae: 0.2837 - val_loss: 0.4525 - val_mse: 0.4525 - val_mae: 0.4796\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 46us/sample - loss: 0.1297 - mse: 0.1297 - mae: 0.2765 - val_loss: 0.4565 - val_mse: 0.4565 - val_mae: 0.4790\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1244 - mse: 0.1244 - mae: 0.2715 - val_loss: 0.4538 - val_mse: 0.4538 - val_mae: 0.4808\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1263 - mse: 0.1263 - mae: 0.2719 - val_loss: 0.4571 - val_mse: 0.4571 - val_mae: 0.4801\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1285 - mse: 0.1285 - mae: 0.2743 - val_loss: 0.4643 - val_mse: 0.4643 - val_mae: 0.4825\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1255 - mse: 0.1255 - mae: 0.2724 - val_loss: 0.4504 - val_mse: 0.4504 - val_mae: 0.4772\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1225 - mse: 0.1225 - mae: 0.2690 - val_loss: 0.4562 - val_mse: 0.4562 - val_mae: 0.4763\n",
      "Epoch 57/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1181 - mse: 0.1181 - mae: 0.2651 - val_loss: 0.4511 - val_mse: 0.4511 - val_mae: 0.4742\n",
      "Epoch 58/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1195 - mse: 0.1195 - mae: 0.2678 - val_loss: 0.4484 - val_mse: 0.4484 - val_mae: 0.4752\n",
      "Epoch 59/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1171 - mse: 0.1171 - mae: 0.2618 - val_loss: 0.4516 - val_mse: 0.4516 - val_mae: 0.4727\n",
      "Epoch 60/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1170 - mse: 0.1170 - mae: 0.2637 - val_loss: 0.4636 - val_mse: 0.4636 - val_mae: 0.4814\n",
      "Epoch 61/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1128 - mse: 0.1128 - mae: 0.2580 - val_loss: 0.4478 - val_mse: 0.4478 - val_mae: 0.4739\n",
      "Epoch 62/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1133 - mse: 0.1133 - mae: 0.2575 - val_loss: 0.4499 - val_mse: 0.4499 - val_mae: 0.4725\n",
      "Epoch 63/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1118 - mse: 0.1118 - mae: 0.2560 - val_loss: 0.4610 - val_mse: 0.4610 - val_mae: 0.4747\n",
      "Epoch 64/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1132 - mse: 0.1132 - mae: 0.2597 - val_loss: 0.4478 - val_mse: 0.4478 - val_mae: 0.4737\n",
      "Epoch 65/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1080 - mse: 0.1080 - mae: 0.2531 - val_loss: 0.4483 - val_mse: 0.4483 - val_mae: 0.4756\n",
      "Epoch 66/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1093 - mse: 0.1093 - mae: 0.2521 - val_loss: 0.4440 - val_mse: 0.4440 - val_mae: 0.4715\n",
      "Epoch 67/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1046 - mse: 0.1046 - mae: 0.2490 - val_loss: 0.4504 - val_mse: 0.4504 - val_mae: 0.4743\n",
      "Epoch 68/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1040 - mse: 0.1040 - mae: 0.2473 - val_loss: 0.4439 - val_mse: 0.4439 - val_mae: 0.4715\n",
      "Epoch 69/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1024 - mse: 0.1024 - mae: 0.2462 - val_loss: 0.4486 - val_mse: 0.4486 - val_mae: 0.4705\n",
      "Epoch 70/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1015 - mse: 0.1015 - mae: 0.2449 - val_loss: 0.4464 - val_mse: 0.4464 - val_mae: 0.4689\n",
      "Epoch 71/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1034 - mse: 0.1034 - mae: 0.2451 - val_loss: 0.4413 - val_mse: 0.4413 - val_mae: 0.4700\n",
      "Epoch 72/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1008 - mse: 0.1008 - mae: 0.2430 - val_loss: 0.4503 - val_mse: 0.4503 - val_mae: 0.4731\n",
      "Epoch 73/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1005 - mse: 0.1005 - mae: 0.2432 - val_loss: 0.4502 - val_mse: 0.4502 - val_mae: 0.4747\n",
      "Epoch 74/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1010 - mse: 0.1010 - mae: 0.2440 - val_loss: 0.4502 - val_mse: 0.4502 - val_mae: 0.4737\n",
      "Epoch 75/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0967 - mse: 0.0967 - mae: 0.2392 - val_loss: 0.4500 - val_mse: 0.4500 - val_mae: 0.4731\n",
      "Epoch 76/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.0927 - mse: 0.0927 - mae: 0.2328 - val_loss: 0.4461 - val_mse: 0.4461 - val_mae: 0.4725\n",
      "Epoch 77/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0968 - mse: 0.0968 - mae: 0.2374 - val_loss: 0.4474 - val_mse: 0.4474 - val_mae: 0.4723\n",
      "Epoch 78/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0924 - mse: 0.0924 - mae: 0.2331 - val_loss: 0.4500 - val_mse: 0.4500 - val_mae: 0.4730\n",
      "Epoch 79/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0956 - mse: 0.0956 - mae: 0.2393 - val_loss: 0.4557 - val_mse: 0.4557 - val_mae: 0.4740\n",
      "Epoch 80/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.0906 - mse: 0.0906 - mae: 0.2325 - val_loss: 0.4495 - val_mse: 0.4495 - val_mae: 0.4747\n",
      "Epoch 81/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.0920 - mse: 0.0920 - mae: 0.2319 - val_loss: 0.4481 - val_mse: 0.4481 - val_mae: 0.4723\n",
      "Train on 10663 samples, validate on 2666 samples\n",
      "Epoch 1/3000\n",
      "10663/10663 [==============================] - 2s 144us/sample - loss: 1.5522 - mse: 1.5522 - mae: 0.9350 - val_loss: 1.2950 - val_mse: 1.2950 - val_mae: 0.9184\n",
      "Epoch 2/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.8913 - mse: 0.8913 - mae: 0.7187 - val_loss: 1.0493 - val_mse: 1.0493 - val_mae: 0.8109\n",
      "Epoch 3/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.7082 - mse: 0.7082 - mae: 0.6432 - val_loss: 0.9178 - val_mse: 0.9178 - val_mae: 0.7443\n",
      "Epoch 4/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.6187 - mse: 0.6187 - mae: 0.5987 - val_loss: 0.8300 - val_mse: 0.8300 - val_mae: 0.7072\n",
      "Epoch 5/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.5474 - mse: 0.5474 - mae: 0.5664 - val_loss: 0.7574 - val_mse: 0.7574 - val_mae: 0.6757\n",
      "Epoch 6/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.5017 - mse: 0.5017 - mae: 0.5420 - val_loss: 0.6974 - val_mse: 0.6974 - val_mae: 0.6476\n",
      "Epoch 7/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.4646 - mse: 0.4646 - mae: 0.5177 - val_loss: 0.6500 - val_mse: 0.6500 - val_mae: 0.6219\n",
      "Epoch 8/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.4321 - mse: 0.4321 - mae: 0.5028 - val_loss: 0.6148 - val_mse: 0.6148 - val_mae: 0.6014\n",
      "Epoch 9/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.4078 - mse: 0.4078 - mae: 0.4880 - val_loss: 0.5726 - val_mse: 0.5726 - val_mae: 0.5735\n",
      "Epoch 10/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.3857 - mse: 0.3857 - mae: 0.4732 - val_loss: 0.5622 - val_mse: 0.5622 - val_mae: 0.5629\n",
      "Epoch 11/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.3602 - mse: 0.3602 - mae: 0.4574 - val_loss: 0.5387 - val_mse: 0.5387 - val_mae: 0.5526\n",
      "Epoch 12/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.3473 - mse: 0.3473 - mae: 0.4515 - val_loss: 0.5320 - val_mse: 0.5320 - val_mae: 0.5486\n",
      "Epoch 13/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.3251 - mse: 0.3251 - mae: 0.4356 - val_loss: 0.5217 - val_mse: 0.5217 - val_mae: 0.5413\n",
      "Epoch 14/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.3145 - mse: 0.3145 - mae: 0.4279 - val_loss: 0.5153 - val_mse: 0.5153 - val_mae: 0.5343\n",
      "Epoch 15/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.2998 - mse: 0.2998 - mae: 0.4156 - val_loss: 0.5039 - val_mse: 0.5039 - val_mae: 0.5272\n",
      "Epoch 16/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2959 - mse: 0.2959 - mae: 0.4149 - val_loss: 0.5013 - val_mse: 0.5013 - val_mae: 0.5255\n",
      "Epoch 17/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.2832 - mse: 0.2832 - mae: 0.4043 - val_loss: 0.4939 - val_mse: 0.4939 - val_mae: 0.5177\n",
      "Epoch 18/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.2731 - mse: 0.2731 - mae: 0.3970 - val_loss: 0.4934 - val_mse: 0.4934 - val_mae: 0.5176\n",
      "Epoch 19/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2586 - mse: 0.2586 - mae: 0.3882 - val_loss: 0.4931 - val_mse: 0.4931 - val_mae: 0.5137\n",
      "Epoch 20/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2555 - mse: 0.2555 - mae: 0.3840 - val_loss: 0.4882 - val_mse: 0.4882 - val_mae: 0.5096\n",
      "Epoch 21/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2421 - mse: 0.2421 - mae: 0.3766 - val_loss: 0.4847 - val_mse: 0.4847 - val_mae: 0.5077\n",
      "Epoch 22/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2391 - mse: 0.2391 - mae: 0.3759 - val_loss: 0.4865 - val_mse: 0.4865 - val_mae: 0.5102\n",
      "Epoch 23/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2313 - mse: 0.2313 - mae: 0.3677 - val_loss: 0.4987 - val_mse: 0.4987 - val_mae: 0.5085\n",
      "Epoch 24/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2222 - mse: 0.2222 - mae: 0.3588 - val_loss: 0.4831 - val_mse: 0.4831 - val_mae: 0.5056\n",
      "Epoch 25/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2239 - mse: 0.2239 - mae: 0.3616 - val_loss: 0.4815 - val_mse: 0.4815 - val_mae: 0.5060\n",
      "Epoch 26/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2126 - mse: 0.2126 - mae: 0.3512 - val_loss: 0.4721 - val_mse: 0.4721 - val_mae: 0.4993\n",
      "Epoch 27/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2086 - mse: 0.2086 - mae: 0.3493 - val_loss: 0.4746 - val_mse: 0.4746 - val_mae: 0.4997\n",
      "Epoch 28/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.2022 - mse: 0.2022 - mae: 0.3445 - val_loss: 0.4745 - val_mse: 0.4745 - val_mae: 0.4999\n",
      "Epoch 29/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.2015 - mse: 0.2015 - mae: 0.3435 - val_loss: 0.4701 - val_mse: 0.4701 - val_mae: 0.4960\n",
      "Epoch 30/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1920 - mse: 0.1920 - mae: 0.3355 - val_loss: 0.4681 - val_mse: 0.4681 - val_mae: 0.4913\n",
      "Epoch 31/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1930 - mse: 0.1930 - mae: 0.3358 - val_loss: 0.4678 - val_mse: 0.4678 - val_mae: 0.4942\n",
      "Epoch 32/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1831 - mse: 0.1831 - mae: 0.3251 - val_loss: 0.4657 - val_mse: 0.4657 - val_mae: 0.4964\n",
      "Epoch 33/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1800 - mse: 0.1800 - mae: 0.3261 - val_loss: 0.4583 - val_mse: 0.4583 - val_mae: 0.4881\n",
      "Epoch 34/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1818 - mse: 0.1818 - mae: 0.3239 - val_loss: 0.4599 - val_mse: 0.4599 - val_mae: 0.4894\n",
      "Epoch 35/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1749 - mse: 0.1749 - mae: 0.3215 - val_loss: 0.4585 - val_mse: 0.4585 - val_mae: 0.4883\n",
      "Epoch 36/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1666 - mse: 0.1666 - mae: 0.3097 - val_loss: 0.4551 - val_mse: 0.4551 - val_mae: 0.4854\n",
      "Epoch 37/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1716 - mse: 0.1716 - mae: 0.3168 - val_loss: 0.4649 - val_mse: 0.4649 - val_mae: 0.4926\n",
      "Epoch 38/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1665 - mse: 0.1665 - mae: 0.3112 - val_loss: 0.4573 - val_mse: 0.4573 - val_mae: 0.4888\n",
      "Epoch 39/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1640 - mse: 0.1640 - mae: 0.3104 - val_loss: 0.4564 - val_mse: 0.4564 - val_mae: 0.4862\n",
      "Epoch 40/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1557 - mse: 0.1557 - mae: 0.3008 - val_loss: 0.4539 - val_mse: 0.4539 - val_mae: 0.4875\n",
      "Epoch 41/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1567 - mse: 0.1567 - mae: 0.3032 - val_loss: 0.4587 - val_mse: 0.4587 - val_mae: 0.4900\n",
      "Epoch 42/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1505 - mse: 0.1505 - mae: 0.2957 - val_loss: 0.4564 - val_mse: 0.4564 - val_mae: 0.4851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1544 - mse: 0.1544 - mae: 0.3005 - val_loss: 0.4489 - val_mse: 0.4489 - val_mae: 0.4835\n",
      "Epoch 44/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1467 - mse: 0.1467 - mae: 0.2911 - val_loss: 0.4494 - val_mse: 0.4494 - val_mae: 0.4818\n",
      "Epoch 45/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1429 - mse: 0.1429 - mae: 0.2881 - val_loss: 0.4491 - val_mse: 0.4491 - val_mae: 0.4807\n",
      "Epoch 46/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1407 - mse: 0.1407 - mae: 0.2858 - val_loss: 0.4418 - val_mse: 0.4418 - val_mae: 0.4801\n",
      "Epoch 47/3000\n",
      "10663/10663 [==============================] - 0s 39us/sample - loss: 0.1348 - mse: 0.1348 - mae: 0.2820 - val_loss: 0.4545 - val_mse: 0.4545 - val_mae: 0.4852\n",
      "Epoch 48/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1379 - mse: 0.1379 - mae: 0.2836 - val_loss: 0.4524 - val_mse: 0.4524 - val_mae: 0.4861\n",
      "Epoch 49/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1423 - mse: 0.1423 - mae: 0.2890 - val_loss: 0.4527 - val_mse: 0.4527 - val_mae: 0.4855\n",
      "Epoch 50/3000\n",
      "10663/10663 [==============================] - 0s 42us/sample - loss: 0.1350 - mse: 0.1350 - mae: 0.2809 - val_loss: 0.4534 - val_mse: 0.4534 - val_mae: 0.4855\n",
      "Epoch 51/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1341 - mse: 0.1341 - mae: 0.2784 - val_loss: 0.4483 - val_mse: 0.4483 - val_mae: 0.4810\n",
      "Epoch 52/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1277 - mse: 0.1277 - mae: 0.2728 - val_loss: 0.4451 - val_mse: 0.4451 - val_mae: 0.4794\n",
      "Epoch 53/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1300 - mse: 0.1300 - mae: 0.2747 - val_loss: 0.4447 - val_mse: 0.4447 - val_mae: 0.4805\n",
      "Epoch 54/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1264 - mse: 0.1264 - mae: 0.2702 - val_loss: 0.4432 - val_mse: 0.4432 - val_mae: 0.4780\n",
      "Epoch 55/3000\n",
      "10663/10663 [==============================] - 0s 40us/sample - loss: 0.1243 - mse: 0.1243 - mae: 0.2700 - val_loss: 0.4496 - val_mse: 0.4496 - val_mae: 0.4794\n",
      "Epoch 56/3000\n",
      "10663/10663 [==============================] - 0s 41us/sample - loss: 0.1234 - mse: 0.1234 - mae: 0.2692 - val_loss: 0.4439 - val_mse: 0.4439 - val_mae: 0.4751\n",
      "Train on 10664 samples, validate on 2665 samples\n",
      "Epoch 1/3000\n",
      "10664/10664 [==============================] - 2s 145us/sample - loss: 1.6288 - mse: 1.6288 - mae: 0.9642 - val_loss: 1.4241 - val_mse: 1.4241 - val_mae: 0.9768\n",
      "Epoch 2/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.9376 - mse: 0.9376 - mae: 0.7403 - val_loss: 1.0800 - val_mse: 1.0800 - val_mae: 0.8409\n",
      "Epoch 3/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.7434 - mse: 0.7434 - mae: 0.6605 - val_loss: 0.9647 - val_mse: 0.9647 - val_mae: 0.7741\n",
      "Epoch 4/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.6366 - mse: 0.6366 - mae: 0.6092 - val_loss: 0.8691 - val_mse: 0.8691 - val_mae: 0.7259\n",
      "Epoch 5/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.5614 - mse: 0.5614 - mae: 0.5746 - val_loss: 0.7758 - val_mse: 0.7758 - val_mae: 0.6852\n",
      "Epoch 6/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.5182 - mse: 0.5182 - mae: 0.5485 - val_loss: 0.6875 - val_mse: 0.6875 - val_mae: 0.6401\n",
      "Epoch 7/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.4746 - mse: 0.4746 - mae: 0.5243 - val_loss: 0.6480 - val_mse: 0.6480 - val_mae: 0.6154\n",
      "Epoch 8/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.4421 - mse: 0.4421 - mae: 0.5086 - val_loss: 0.6270 - val_mse: 0.6270 - val_mae: 0.6007\n",
      "Epoch 9/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.4199 - mse: 0.4199 - mae: 0.4944 - val_loss: 0.6009 - val_mse: 0.6009 - val_mae: 0.5778\n",
      "Epoch 10/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.3974 - mse: 0.3974 - mae: 0.4826 - val_loss: 0.5646 - val_mse: 0.5646 - val_mae: 0.5556\n",
      "Epoch 11/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.3735 - mse: 0.3735 - mae: 0.4680 - val_loss: 0.5598 - val_mse: 0.5598 - val_mae: 0.5472\n",
      "Epoch 12/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.3562 - mse: 0.3562 - mae: 0.4557 - val_loss: 0.5591 - val_mse: 0.5591 - val_mae: 0.5493\n",
      "Epoch 13/3000\n",
      "10664/10664 [==============================] - 0s 41us/sample - loss: 0.3327 - mse: 0.3327 - mae: 0.4393 - val_loss: 0.5555 - val_mse: 0.5555 - val_mae: 0.5424\n",
      "Epoch 14/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.3287 - mse: 0.3287 - mae: 0.4388 - val_loss: 0.5386 - val_mse: 0.5386 - val_mae: 0.5336\n",
      "Epoch 15/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.3120 - mse: 0.3120 - mae: 0.4255 - val_loss: 0.5343 - val_mse: 0.5343 - val_mae: 0.5257\n",
      "Epoch 16/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.2981 - mse: 0.2981 - mae: 0.4167 - val_loss: 0.5350 - val_mse: 0.5350 - val_mae: 0.5246\n",
      "Epoch 17/3000\n",
      "10664/10664 [==============================] - 0s 38us/sample - loss: 0.2872 - mse: 0.2872 - mae: 0.4087 - val_loss: 0.5308 - val_mse: 0.5308 - val_mae: 0.5203\n",
      "Epoch 18/3000\n",
      "10664/10664 [==============================] - 0s 41us/sample - loss: 0.2785 - mse: 0.2785 - mae: 0.4040 - val_loss: 0.5211 - val_mse: 0.5211 - val_mae: 0.5160\n",
      "Epoch 19/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.2715 - mse: 0.2715 - mae: 0.3960 - val_loss: 0.5335 - val_mse: 0.5335 - val_mae: 0.5186\n",
      "Epoch 20/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.2562 - mse: 0.2562 - mae: 0.3867 - val_loss: 0.5203 - val_mse: 0.5203 - val_mae: 0.5108\n",
      "Epoch 21/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.2560 - mse: 0.2560 - mae: 0.3864 - val_loss: 0.5187 - val_mse: 0.5187 - val_mae: 0.5092\n",
      "Epoch 22/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.2419 - mse: 0.2419 - mae: 0.3759 - val_loss: 0.5256 - val_mse: 0.5256 - val_mae: 0.5075\n",
      "Epoch 23/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.2389 - mse: 0.2389 - mae: 0.3708 - val_loss: 0.5285 - val_mse: 0.5285 - val_mae: 0.5106\n",
      "Epoch 24/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.2376 - mse: 0.2376 - mae: 0.3719 - val_loss: 0.5062 - val_mse: 0.5062 - val_mae: 0.5012\n",
      "Epoch 25/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.2222 - mse: 0.2222 - mae: 0.3586 - val_loss: 0.5166 - val_mse: 0.5166 - val_mae: 0.5066\n",
      "Epoch 26/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.2250 - mse: 0.2250 - mae: 0.3611 - val_loss: 0.5074 - val_mse: 0.5074 - val_mae: 0.5020\n",
      "Epoch 27/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.2164 - mse: 0.2164 - mae: 0.3536 - val_loss: 0.5277 - val_mse: 0.5277 - val_mae: 0.5062\n",
      "Epoch 28/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.2084 - mse: 0.2084 - mae: 0.3485 - val_loss: 0.5116 - val_mse: 0.5116 - val_mae: 0.5005\n",
      "Epoch 29/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.2014 - mse: 0.2014 - mae: 0.3420 - val_loss: 0.5060 - val_mse: 0.5060 - val_mae: 0.4963\n",
      "Epoch 30/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1962 - mse: 0.1962 - mae: 0.3397 - val_loss: 0.5096 - val_mse: 0.5096 - val_mae: 0.4963\n",
      "Epoch 31/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1955 - mse: 0.1955 - mae: 0.3352 - val_loss: 0.5026 - val_mse: 0.5026 - val_mae: 0.4973\n",
      "Epoch 32/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1918 - mse: 0.1918 - mae: 0.3349 - val_loss: 0.4973 - val_mse: 0.4973 - val_mae: 0.4913\n",
      "Epoch 33/3000\n",
      "10664/10664 [==============================] - 0s 38us/sample - loss: 0.1868 - mse: 0.1868 - mae: 0.3321 - val_loss: 0.5096 - val_mse: 0.5096 - val_mae: 0.4941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1768 - mse: 0.1768 - mae: 0.3225 - val_loss: 0.4937 - val_mse: 0.4937 - val_mae: 0.4916\n",
      "Epoch 35/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1813 - mse: 0.1813 - mae: 0.3230 - val_loss: 0.4984 - val_mse: 0.4984 - val_mae: 0.4904\n",
      "Epoch 36/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1719 - mse: 0.1719 - mae: 0.3182 - val_loss: 0.4986 - val_mse: 0.4986 - val_mae: 0.4881\n",
      "Epoch 37/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1754 - mse: 0.1754 - mae: 0.3216 - val_loss: 0.5078 - val_mse: 0.5078 - val_mae: 0.4900\n",
      "Epoch 38/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1714 - mse: 0.1714 - mae: 0.3154 - val_loss: 0.5109 - val_mse: 0.5109 - val_mae: 0.4920\n",
      "Epoch 39/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1647 - mse: 0.1647 - mae: 0.3121 - val_loss: 0.5006 - val_mse: 0.5006 - val_mae: 0.4866\n",
      "Epoch 40/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1606 - mse: 0.1606 - mae: 0.3064 - val_loss: 0.5019 - val_mse: 0.5019 - val_mae: 0.4889\n",
      "Epoch 41/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1571 - mse: 0.1571 - mae: 0.3022 - val_loss: 0.4911 - val_mse: 0.4911 - val_mae: 0.4845\n",
      "Epoch 42/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1513 - mse: 0.1513 - mae: 0.2959 - val_loss: 0.4942 - val_mse: 0.4942 - val_mae: 0.4868\n",
      "Epoch 43/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1514 - mse: 0.1514 - mae: 0.2972 - val_loss: 0.4966 - val_mse: 0.4966 - val_mae: 0.4834\n",
      "Epoch 44/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1516 - mse: 0.1516 - mae: 0.2968 - val_loss: 0.4872 - val_mse: 0.4872 - val_mae: 0.4789\n",
      "Epoch 45/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1435 - mse: 0.1435 - mae: 0.2906 - val_loss: 0.4919 - val_mse: 0.4919 - val_mae: 0.4843\n",
      "Epoch 46/3000\n",
      "10664/10664 [==============================] - 0s 41us/sample - loss: 0.1447 - mse: 0.1447 - mae: 0.2917 - val_loss: 0.4841 - val_mse: 0.4841 - val_mae: 0.4787\n",
      "Epoch 47/3000\n",
      "10664/10664 [==============================] - 0s 42us/sample - loss: 0.1426 - mse: 0.1426 - mae: 0.2896 - val_loss: 0.4870 - val_mse: 0.4870 - val_mae: 0.4800\n",
      "Epoch 48/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1413 - mse: 0.1413 - mae: 0.2899 - val_loss: 0.4938 - val_mse: 0.4938 - val_mae: 0.4783\n",
      "Epoch 49/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1372 - mse: 0.1372 - mae: 0.2855 - val_loss: 0.5022 - val_mse: 0.5022 - val_mae: 0.4810\n",
      "Epoch 50/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1312 - mse: 0.1312 - mae: 0.2786 - val_loss: 0.4851 - val_mse: 0.4851 - val_mae: 0.4764\n",
      "Epoch 51/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1357 - mse: 0.1357 - mae: 0.2827 - val_loss: 0.4828 - val_mse: 0.4828 - val_mae: 0.4734\n",
      "Epoch 52/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1307 - mse: 0.1307 - mae: 0.2784 - val_loss: 0.4872 - val_mse: 0.4872 - val_mae: 0.4763\n",
      "Epoch 53/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1300 - mse: 0.1300 - mae: 0.2763 - val_loss: 0.4794 - val_mse: 0.4794 - val_mae: 0.4766\n",
      "Epoch 54/3000\n",
      "10664/10664 [==============================] - 0s 38us/sample - loss: 0.1338 - mse: 0.1338 - mae: 0.2793 - val_loss: 0.4836 - val_mse: 0.4836 - val_mae: 0.4750\n",
      "Epoch 55/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1290 - mse: 0.1290 - mae: 0.2770 - val_loss: 0.4810 - val_mse: 0.4810 - val_mae: 0.4756\n",
      "Epoch 56/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1255 - mse: 0.1255 - mae: 0.2709 - val_loss: 0.4844 - val_mse: 0.4844 - val_mae: 0.4760\n",
      "Epoch 57/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1235 - mse: 0.1235 - mae: 0.2699 - val_loss: 0.4803 - val_mse: 0.4803 - val_mae: 0.4739\n",
      "Epoch 58/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1192 - mse: 0.1192 - mae: 0.2639 - val_loss: 0.4865 - val_mse: 0.4865 - val_mae: 0.4758\n",
      "Epoch 59/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1181 - mse: 0.1181 - mae: 0.2632 - val_loss: 0.4728 - val_mse: 0.4728 - val_mae: 0.4701\n",
      "Epoch 60/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1170 - mse: 0.1170 - mae: 0.2607 - val_loss: 0.4907 - val_mse: 0.4907 - val_mae: 0.4753\n",
      "Epoch 61/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1122 - mse: 0.1122 - mae: 0.2564 - val_loss: 0.4720 - val_mse: 0.4720 - val_mae: 0.4702\n",
      "Epoch 62/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1147 - mse: 0.1147 - mae: 0.2579 - val_loss: 0.4851 - val_mse: 0.4851 - val_mae: 0.4745\n",
      "Epoch 63/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1140 - mse: 0.1140 - mae: 0.2604 - val_loss: 0.4689 - val_mse: 0.4689 - val_mae: 0.4669\n",
      "Epoch 64/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1109 - mse: 0.1109 - mae: 0.2562 - val_loss: 0.4869 - val_mse: 0.4869 - val_mae: 0.4713\n",
      "Epoch 65/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1140 - mse: 0.1140 - mae: 0.2579 - val_loss: 0.4676 - val_mse: 0.4676 - val_mae: 0.4672\n",
      "Epoch 66/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1085 - mse: 0.1085 - mae: 0.2526 - val_loss: 0.4844 - val_mse: 0.4844 - val_mae: 0.4726\n",
      "Epoch 67/3000\n",
      "10664/10664 [==============================] - 0s 41us/sample - loss: 0.1100 - mse: 0.1100 - mae: 0.2542 - val_loss: 0.4740 - val_mse: 0.4740 - val_mae: 0.4684\n",
      "Epoch 68/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1103 - mse: 0.1103 - mae: 0.2535 - val_loss: 0.4797 - val_mse: 0.4797 - val_mae: 0.4693\n",
      "Epoch 69/3000\n",
      "10664/10664 [==============================] - 0s 39us/sample - loss: 0.1103 - mse: 0.1103 - mae: 0.2538 - val_loss: 0.4813 - val_mse: 0.4813 - val_mae: 0.4693\n",
      "Epoch 70/3000\n",
      "10664/10664 [==============================] - 0s 42us/sample - loss: 0.1064 - mse: 0.1064 - mae: 0.2499 - val_loss: 0.4778 - val_mse: 0.4778 - val_mae: 0.4684\n",
      "Epoch 71/3000\n",
      "10664/10664 [==============================] - 0s 41us/sample - loss: 0.1006 - mse: 0.1006 - mae: 0.2430 - val_loss: 0.4762 - val_mse: 0.4762 - val_mae: 0.4673\n",
      "Epoch 72/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1045 - mse: 0.1045 - mae: 0.2476 - val_loss: 0.4853 - val_mse: 0.4853 - val_mae: 0.4684\n",
      "Epoch 73/3000\n",
      "10664/10664 [==============================] - 0s 41us/sample - loss: 0.1021 - mse: 0.1021 - mae: 0.2453 - val_loss: 0.4722 - val_mse: 0.4722 - val_mae: 0.4662\n",
      "Epoch 74/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.0964 - mse: 0.0964 - mae: 0.2374 - val_loss: 0.4759 - val_mse: 0.4759 - val_mae: 0.4654\n",
      "Epoch 75/3000\n",
      "10664/10664 [==============================] - 0s 40us/sample - loss: 0.1019 - mse: 0.1019 - mae: 0.2428 - val_loss: 0.4899 - val_mse: 0.4899 - val_mae: 0.4685\n",
      "Avg. MAE: 0.408468\n",
      "Finished Optimization!\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin processing!\")\n",
    "\n",
    "np.random.seed(9700)\n",
    "optimizer = GPyOpt.methods.BayesianOptimization(f=search, domain=bounds,\n",
    "                model_type='GP',\n",
    "                acquisition_type ='EI',\n",
    "                acquisition_jitter = 0.05,\n",
    "                exact_feval = True,\n",
    "                num_cores = 40, # Adjust \n",
    "                maximize = False,\n",
    "                verbosity = True)\n",
    "\n",
    "print(\"Starting Optimizer!\")\n",
    "optimizer.run_optimization(max_iter=40)\n",
    "\n",
    "print(\"Finished Optimization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer.plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('learning_rate', 0.0027605806620987993),\n",
       " ('n_layers', 4.0),\n",
       " ('layer_size', 512.0),\n",
       " ('batch_size', 256.0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(bounds[i]['name'], optimum) for i, optimum in enumerate(optimizer.x_opt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(best['history'].history['mse'], label='Train')\n",
    "plt.plot(best['history'].history['val_mse'], label='Validation')\n",
    "\n",
    "plt.title('Loss v. Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
